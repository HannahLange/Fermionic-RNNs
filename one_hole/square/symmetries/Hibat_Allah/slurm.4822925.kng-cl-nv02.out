/var/spool/slurmd/job4822925/slurm_script: line 14: ../../ML_Environment/bin/activate: No such file or directory
1.13.1+cu117
GPU is available
Namespace(Jp=1.0, Jz=1.0, Nx=4, Ny=4, U=1.0, antisym=0.0, bounds=1, boundsx=0, boundsy=0, density=0.9375, hd=70, load_model=0, sym=0.0, t=3.0)
4x4_qubits/periodic/Jp=1.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 10000/ t/epoch=2.74............. Loss: 1.84341155, mean(E): -11.13831073-0.00967641j, var(E): 8.85366910
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 10000/ t/epoch=0.85............. Loss: 1.48414211, mean(E): -10.96886337-0.01419918j, var(E): 10.12844624
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 10000/ t/epoch=0.85............. Loss: 1.41304173, mean(E): -11.27579730-0.02025611j, var(E): 9.95468373
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 10000/ t/epoch=0.85............. Loss: 2.02057290, mean(E): -11.10851725-0.02058103j, var(E): 10.88996958
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 10000/ t/epoch=0.85............. Loss: 1.72987121, mean(E): -11.29432921-0.01812879j, var(E): 9.90474579
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 10000/ t/epoch=0.85............. Loss: 1.18250574, mean(E): -10.95998871-0.00905779j, var(E): 7.54919170
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 10000/ t/epoch=0.85............. Loss: 1.38096513, mean(E): -11.15619733-0.01487262j, var(E): 10.28522051
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 10000/ t/epoch=0.85............. Loss: 1.49257152, mean(E): -10.90488876-0.00093554j, var(E): 7.45099524
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 10000/ t/epoch=0.85............. Loss: 1.23118992, mean(E): -11.06843180-0.04305594j, var(E): 7.35886887
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 10000/ t/epoch=0.85............. Loss: 0.67449484, mean(E): -11.78920369-0.18566386j, var(E): 12.02558966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 10000/ t/epoch=0.85............. Loss: 1.52728769, mean(E): -13.97883597+0.11938679j, var(E): 18.79748692
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 10000/ t/epoch=0.85............. Loss: 3.71371321, mean(E): -14.20747442-0.09827327j, var(E): 22.58528627
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 10000/ t/epoch=0.85............. Loss: 0.98547534, mean(E): -14.62202050-0.52419935j, var(E): 17.50816689
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 10000/ t/epoch=0.85............. Loss: 2.52785012, mean(E): -14.99084033-0.26503277j, var(E): 19.09936243
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 10000/ t/epoch=0.85............. Loss: 1.32166371, mean(E): -15.29855108-0.55394560j, var(E): 20.38462207
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 10000/ t/epoch=0.85............. Loss: 1.39840371, mean(E): -15.16040242-0.23737066j, var(E): 17.89567914
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 10000/ t/epoch=0.85............. Loss: 2.97509029, mean(E): -15.41659134-0.29912045j, var(E): 17.09125088
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 10000/ t/epoch=0.85............. Loss: 1.94475089, mean(E): -15.51765891-0.45773243j, var(E): 18.46547379
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 10000/ t/epoch=0.85............. Loss: 2.14011832, mean(E): -15.87094374-0.14004620j, var(E): 18.90944290
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 10000/ t/epoch=0.85............. Loss: 2.52309439, mean(E): -15.76761950-0.26462093j, var(E): 16.94533311
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 10000/ t/epoch=0.85............. Loss: 2.17174324, mean(E): -15.83199677-0.45301535j, var(E): 18.38820970
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 10000/ t/epoch=0.85............. Loss: 0.64943392, mean(E): -16.02879888-0.30080009j, var(E): 15.90390806
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 10000/ t/epoch=0.88............. Loss: 1.92305476, mean(E): -16.13723930-0.15204238j, var(E): 18.57937593
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 10000/ t/epoch=0.85............. Loss: 1.63220862, mean(E): -16.51246499+0.06124029j, var(E): 19.49082167
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 10000/ t/epoch=0.85............. Loss: 1.62095490, mean(E): -16.04827864-0.18863613j, var(E): 19.92353690
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 10000/ t/epoch=0.85............. Loss: 2.35713516, mean(E): -16.15677286-0.07108506j, var(E): 14.65538960
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 10000/ t/epoch=0.85............. Loss: 0.80052070, mean(E): -16.64498932-0.12629692j, var(E): 19.76113510
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 10000/ t/epoch=0.85............. Loss: 1.47907349, mean(E): -16.94514466-0.15325365j, var(E): 16.65227095
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 10000/ t/epoch=0.85............. Loss: 1.97419261, mean(E): -17.09488722+0.03348460j, var(E): 19.39781140
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 10000/ t/epoch=0.85............. Loss: 2.92421977, mean(E): -17.63357837-0.03176544j, var(E): 20.84713989
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 10000/ t/epoch=0.85............. Loss: 1.20214368, mean(E): -17.43525076-0.07951666j, var(E): 16.39719982
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 10000/ t/epoch=0.85............. Loss: 1.05362259, mean(E): -17.67914547+0.22509860j, var(E): 17.42284825
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 10000/ t/epoch=0.85............. Loss: 0.95072221, mean(E): -17.92734314+0.01450309j, var(E): 15.70369883
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 10000/ t/epoch=0.85............. Loss: 1.74150891, mean(E): -17.93611372+0.05460490j, var(E): 22.64358633
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 10000/ t/epoch=0.85............. Loss: 2.04793833, mean(E): -18.27605565+0.13035769j, var(E): 19.62352717
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 10000/ t/epoch=0.85............. Loss: 3.16611145, mean(E): -18.00792679-0.32558173j, var(E): 17.23826573
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 10000/ t/epoch=0.85............. Loss: 1.80558380, mean(E): -18.21704838-0.06805620j, var(E): 15.24452063
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 10000/ t/epoch=0.85............. Loss: 2.43074694, mean(E): -18.56588323+0.02519904j, var(E): 18.96611588
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 10000/ t/epoch=0.85............. Loss: 1.51154714, mean(E): -18.72101320-0.02076457j, var(E): 20.34588138
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 10000/ t/epoch=0.85............. Loss: 1.48539742, mean(E): -18.77550466-0.05670568j, var(E): 16.66403044
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 10000/ t/epoch=0.85............. Loss: 2.52186427, mean(E): -18.62250830+0.31951950j, var(E): 16.51295435
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 10000/ t/epoch=0.85............. Loss: -0.06747542, mean(E): -18.94247321+0.03508264j, var(E): 18.45834438
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 10000/ t/epoch=0.85............. Loss: 1.07753414, mean(E): -18.85779847+0.09121044j, var(E): 20.20181267
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 10000/ t/epoch=0.85............. Loss: 2.14879964, mean(E): -19.11100141-0.01379448j, var(E): 18.38439942
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 10000/ t/epoch=0.85............. Loss: 1.33610559, mean(E): -19.38836973-0.06756879j, var(E): 14.73650584
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 10000/ t/epoch=0.85............. Loss: 1.67330541, mean(E): -19.37072965-0.03789172j, var(E): 17.26356858
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 10000/ t/epoch=0.85............. Loss: 0.55606200, mean(E): -19.16517425+0.03803237j, var(E): 15.46522550
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 10000/ t/epoch=0.85............. Loss: 2.33879617, mean(E): -19.44696425+0.00464965j, var(E): 16.34000356
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 10000/ t/epoch=0.85............. Loss: 0.58124315, mean(E): -19.14734279-0.11035853j, var(E): 15.09508927
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 10000/ t/epoch=0.85............. Loss: 0.85299293, mean(E): -19.75080719+0.10351306j, var(E): 17.27859536
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 10000/ t/epoch=0.85............. Loss: 0.37759578, mean(E): -19.23451212+0.04827630j, var(E): 14.52267921
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 10000/ t/epoch=0.85............. Loss: -0.02192599, mean(E): -20.20959952+0.00674634j, var(E): 15.03109834
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 10000/ t/epoch=0.85............. Loss: 0.92417249, mean(E): -19.91865578-0.23054618j, var(E): 16.19914450
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 10000/ t/epoch=0.85............. Loss: 2.27656420, mean(E): -19.73658895+0.12118259j, var(E): 14.10906552
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 10000/ t/epoch=0.85............. Loss: -0.73163899, mean(E): -20.13659181+0.14182369j, var(E): 14.58380942
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 10000/ t/epoch=0.85............. Loss: 2.76572044, mean(E): -20.46369420+0.37463249j, var(E): 16.51042782
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 10000/ t/epoch=0.85............. Loss: 0.06576284, mean(E): -19.78056783-0.01672276j, var(E): 13.93017940
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 10000/ t/epoch=0.85............. Loss: 0.22112895, mean(E): -20.04977255-0.13623888j, var(E): 12.14912791
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 10000/ t/epoch=0.85............. Loss: -1.04600781, mean(E): -20.21158278+0.30776669j, var(E): 14.44659264
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 10000/ t/epoch=0.85............. Loss: -0.94744151, mean(E): -20.32256336+0.08154280j, var(E): 14.57616529
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 10000/ t/epoch=0.85............. Loss: -1.89926238, mean(E): -19.99032953+0.05772332j, var(E): 14.37192564
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 10000/ t/epoch=0.85............. Loss: 0.62216920, mean(E): -20.74238404+0.02318999j, var(E): 15.05671261
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 10000/ t/epoch=0.85............. Loss: -1.36233527, mean(E): -20.07155686+0.25935398j, var(E): 14.15274096
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 10000/ t/epoch=0.85............. Loss: 1.86074000, mean(E): -20.44056528+0.09443251j, var(E): 15.56545910
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 10000/ t/epoch=0.85............. Loss: -0.51077000, mean(E): -20.34760112+0.06852547j, var(E): 14.03584458
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 10000/ t/epoch=0.85............. Loss: 0.09656402, mean(E): -20.24264913-0.11310224j, var(E): 14.64144355
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 10000/ t/epoch=0.85............. Loss: -1.54273272, mean(E): -19.93327137+0.11321220j, var(E): 15.55318099
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 10000/ t/epoch=0.85............. Loss: -0.58921569, mean(E): -20.20430402+0.20061870j, var(E): 14.49497898
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 10000/ t/epoch=0.85............. Loss: 0.20472858, mean(E): -20.22209609+0.01562993j, var(E): 12.00552865
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 10000/ t/epoch=0.85............. Loss: -0.57624615, mean(E): -20.29379168+0.00565686j, var(E): 13.28674917
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 10000/ t/epoch=0.85............. Loss: -1.37049819, mean(E): -20.24601014+0.08016673j, var(E): 13.80516841
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 10000/ t/epoch=0.85............. Loss: -1.62695887, mean(E): -19.99571040-0.06825204j, var(E): 14.78160551
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 10000/ t/epoch=0.85............. Loss: -0.05808277, mean(E): -20.84136908+0.07776710j, var(E): 10.54316958
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 10000/ t/epoch=0.85............. Loss: -0.15580520, mean(E): -20.56023018-0.08850837j, var(E): 13.17579056
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 10000/ t/epoch=0.85............. Loss: -1.13756738, mean(E): -20.32214244-0.06382649j, var(E): 12.33454604
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 10000/ t/epoch=0.85............. Loss: 0.17610490, mean(E): -20.93470744+0.00067022j, var(E): 11.70424747
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 10000/ t/epoch=0.85............. Loss: 1.51006555, mean(E): -20.81963179-0.02097578j, var(E): 14.32597398
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 10000/ t/epoch=0.85............. Loss: -1.42763615, mean(E): -20.43208693+0.08631818j, var(E): 12.19056408
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 10000/ t/epoch=0.85............. Loss: -0.01894679, mean(E): -20.28462075-0.06943097j, var(E): 12.79072920
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 10000/ t/epoch=0.85............. Loss: 0.98744309, mean(E): -20.53370336-0.08083776j, var(E): 13.87524844
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 10000/ t/epoch=0.85............. Loss: -0.35575221, mean(E): -20.69466823-0.04755156j, var(E): 13.10159360
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 10000/ t/epoch=0.85............. Loss: 0.39309118, mean(E): -20.64535235-0.02111627j, var(E): 12.30036296
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 10000/ t/epoch=0.85............. Loss: 0.80209556, mean(E): -20.74445854+0.03042250j, var(E): 13.49159650
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 10000/ t/epoch=0.85............. Loss: -0.94392044, mean(E): -20.40023822+0.01379322j, var(E): 13.35591299
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 10000/ t/epoch=0.85............. Loss: -0.42038895, mean(E): -20.52683669-0.10376293j, var(E): 14.36839076
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 10000/ t/epoch=0.85............. Loss: 1.03564842, mean(E): -20.47130396+0.01051104j, var(E): 13.21184304
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 10000/ t/epoch=0.85............. Loss: 1.24302939, mean(E): -20.57060409+0.15482751j, var(E): 12.08390745
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 10000/ t/epoch=0.85............. Loss: 0.91831145, mean(E): -20.72014481-0.22095772j, var(E): 10.63415398
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 10000/ t/epoch=0.85............. Loss: 0.61994442, mean(E): -20.63831051-0.19079824j, var(E): 11.45687107
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 10000/ t/epoch=0.85............. Loss: -0.30258847, mean(E): -20.85687466-0.13979172j, var(E): 12.00102086
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 10000/ t/epoch=0.85............. Loss: -1.57578045, mean(E): -20.92623658-0.19022792j, var(E): 13.26125550
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 10000/ t/epoch=0.85............. Loss: -0.06686130, mean(E): -21.09496978-0.29056202j, var(E): 12.42932916
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 10000/ t/epoch=0.85............. Loss: 0.74586699, mean(E): -21.00822112+0.16459585j, var(E): 10.35999466
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 10000/ t/epoch=0.85............. Loss: 0.43923466, mean(E): -20.91752548-0.13304198j, var(E): 13.34070867
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 10000/ t/epoch=0.85............. Loss: -1.21413136, mean(E): -20.71263136-0.00075991j, var(E): 13.99519949
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 10000/ t/epoch=0.85............. Loss: -0.23822714, mean(E): -20.99892422+0.21440014j, var(E): 10.66108582
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 10000/ t/epoch=0.85............. Loss: 1.24784415, mean(E): -21.05682699+0.13679916j, var(E): 11.60420222
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 10000/ t/epoch=0.85............. Loss: -1.47225597, mean(E): -20.50828309-0.11267948j, var(E): 13.16185227
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 10000/ t/epoch=0.85............. Loss: -0.85762456, mean(E): -21.13815440-0.04341892j, var(E): 11.95883674
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 10000/ t/epoch=0.85............. Loss: 0.51204977, mean(E): -20.81721694+0.18763546j, var(E): 12.49987945
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 10000/ t/epoch=0.85............. Loss: -1.70159014, mean(E): -21.17440523-0.24501071j, var(E): 9.58664551
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 10000/ t/epoch=0.85............. Loss: -0.54120377, mean(E): -20.71769566+0.12410792j, var(E): 9.71490130
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 10000/ t/epoch=0.85............. Loss: 2.09087982, mean(E): -21.18376152+0.12549860j, var(E): 13.18315008
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 10000/ t/epoch=0.85............. Loss: -1.47813766, mean(E): -20.85111533+0.05995314j, var(E): 12.04397271
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 10000/ t/epoch=0.85............. Loss: -1.58130189, mean(E): -21.39790843+0.03187200j, var(E): 11.75982552
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 10000/ t/epoch=0.85............. Loss: -0.78131222, mean(E): -21.00793231-0.07524191j, var(E): 10.94606362
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 10000/ t/epoch=0.85............. Loss: -1.22156705, mean(E): -21.13076545+0.04371986j, var(E): 10.45123104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 10000/ t/epoch=0.85............. Loss: -2.11565443, mean(E): -21.32761100+0.05264526j, var(E): 11.79177997
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 10000/ t/epoch=0.85............. Loss: 0.54044533, mean(E): -21.19391147-0.04248544j, var(E): 10.67279443
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 10000/ t/epoch=0.85............. Loss: -0.72790778, mean(E): -21.12976335-0.03422502j, var(E): 15.24458338
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 10000/ t/epoch=0.85............. Loss: 0.77349553, mean(E): -21.44413390+0.25478817j, var(E): 10.77818864
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 10000/ t/epoch=0.85............. Loss: -0.45184136, mean(E): -21.61909028+0.08778385j, var(E): 11.71578644
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 10000/ t/epoch=0.85............. Loss: 0.47190623, mean(E): -21.67810738+0.30187926j, var(E): 12.83438569
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 10000/ t/epoch=0.85............. Loss: -0.09291755, mean(E): -21.23282439+0.03510530j, var(E): 10.09064504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 10000/ t/epoch=0.85............. Loss: -0.63906152, mean(E): -21.39572017-0.08656834j, var(E): 10.68738566
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 10000/ t/epoch=0.85............. Loss: -0.98563932, mean(E): -21.27916006-0.23462246j, var(E): 11.51807504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 10000/ t/epoch=0.85............. Loss: -1.07592406, mean(E): -21.23211928-0.11406093j, var(E): 11.24764505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 10000/ t/epoch=0.85............. Loss: -0.23969849, mean(E): -21.10516907-0.05222643j, var(E): 9.96212481
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 10000/ t/epoch=0.85............. Loss: -2.02500437, mean(E): -21.04270542-0.20164592j, var(E): 11.44126858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 10000/ t/epoch=0.85............. Loss: -0.66953356, mean(E): -21.56832694-0.10662389j, var(E): 10.84560320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 10000/ t/epoch=0.85............. Loss: -0.66919186, mean(E): -21.17608426-0.09845470j, var(E): 12.87285095
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 10000/ t/epoch=0.85............. Loss: -0.42560932, mean(E): -21.31880913-0.17456158j, var(E): 12.39389242
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 10000/ t/epoch=0.85............. Loss: 0.46441979, mean(E): -21.51627303+0.05850447j, var(E): 11.02712768
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 10000/ t/epoch=0.85............. Loss: -0.96604544, mean(E): -21.22162675+0.19549066j, var(E): 13.96625368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 10000/ t/epoch=0.85............. Loss: 0.31683144, mean(E): -21.32753596+0.10137692j, var(E): 10.73942066
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 10000/ t/epoch=0.85............. Loss: -0.62647541, mean(E): -21.40873350-0.08794533j, var(E): 10.24389141
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 10000/ t/epoch=0.85............. Loss: -2.42306048, mean(E): -21.40030148-0.13081552j, var(E): 12.57579559
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 10000/ t/epoch=0.85............. Loss: -0.45037418, mean(E): -21.22010333+0.07586768j, var(E): 10.40107826
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 10000/ t/epoch=0.85............. Loss: 0.50802275, mean(E): -21.29443496-0.21927551j, var(E): 12.70130061
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 10000/ t/epoch=0.85............. Loss: -1.14192505, mean(E): -21.32235811+0.01959704j, var(E): 10.03426702
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 10000/ t/epoch=0.85............. Loss: -1.98593448, mean(E): -21.54144473+0.02765463j, var(E): 10.95654930
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 10000/ t/epoch=0.88............. Loss: -1.69433360, mean(E): -21.75288004+0.10168896j, var(E): 10.50927942
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 10000/ t/epoch=0.85............. Loss: -2.28292134, mean(E): -21.42134713-0.16412628j, var(E): 13.11497439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 10000/ t/epoch=0.85............. Loss: -2.66405846, mean(E): -21.44951029+0.45809751j, var(E): 17.18033507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 10000/ t/epoch=0.85............. Loss: 0.61823867, mean(E): -21.58723072-0.08866305j, var(E): 10.61987534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 10000/ t/epoch=0.85............. Loss: -0.61372754, mean(E): -21.42770268-0.06812238j, var(E): 11.40512195
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 10000/ t/epoch=0.85............. Loss: -0.31224485, mean(E): -21.50111968-0.24398701j, var(E): 11.05531476
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 10000/ t/epoch=0.85............. Loss: 0.21262912, mean(E): -21.75292379+0.16254535j, var(E): 10.70702179
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 10000/ t/epoch=0.85............. Loss: -0.85677210, mean(E): -21.26168314+0.47913231j, var(E): 13.98165498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 10000/ t/epoch=0.85............. Loss: -0.94113444, mean(E): -21.16525834+0.08774341j, var(E): 11.59190958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 10000/ t/epoch=0.85............. Loss: 0.13736420, mean(E): -21.90765454+0.18462954j, var(E): 10.82950533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 10000/ t/epoch=0.85............. Loss: -1.93284531, mean(E): -21.31513455+0.10316520j, var(E): 13.90954969
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 10000/ t/epoch=0.85............. Loss: 0.85998773, mean(E): -21.96293267-0.06101671j, var(E): 12.90161156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 10000/ t/epoch=0.85............. Loss: -1.92660841, mean(E): -21.81352993+0.10781489j, var(E): 14.63347483
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 10000/ t/epoch=0.85............. Loss: -0.11139648, mean(E): -21.62194284+0.03234907j, var(E): 9.86386080
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 10000/ t/epoch=0.85............. Loss: -1.28944645, mean(E): -21.48378166+0.25207055j, var(E): 10.56871360
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 10000/ t/epoch=0.85............. Loss: -0.56242342, mean(E): -21.78778777+0.17099693j, var(E): 8.46764553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 10000/ t/epoch=0.85............. Loss: -0.01778388, mean(E): -21.42592025+0.00437390j, var(E): 8.79154517
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 10000/ t/epoch=0.85............. Loss: 0.94313835, mean(E): -21.63127050-0.06942468j, var(E): 13.46724872
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 10000/ t/epoch=0.85............. Loss: 1.97131390, mean(E): -21.71806857+0.06271366j, var(E): 12.37572572
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 10000/ t/epoch=0.85............. Loss: -1.15398715, mean(E): -21.73071987+0.05391519j, var(E): 12.17097384
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 10000/ t/epoch=0.85............. Loss: -3.36425971, mean(E): -21.78502418-0.07540596j, var(E): 11.61967959
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 10000/ t/epoch=0.88............. Loss: 0.85485859, mean(E): -21.48174829-0.13695404j, var(E): 9.55878073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 10000/ t/epoch=0.85............. Loss: -2.74194167, mean(E): -21.49307547-0.13783354j, var(E): 12.25445066
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 10000/ t/epoch=0.85............. Loss: -1.81763506, mean(E): -21.70401769-0.02599081j, var(E): 8.13005688
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 10000/ t/epoch=0.85............. Loss: 0.01091517, mean(E): -21.45377891-0.07698797j, var(E): 11.80545532
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 10000/ t/epoch=0.85............. Loss: 0.38800500, mean(E): -21.56249871+0.19355357j, var(E): 9.23624385
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 10000/ t/epoch=0.85............. Loss: -0.48214823, mean(E): -21.57091417-0.33607787j, var(E): 11.77908628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 10000/ t/epoch=0.85............. Loss: -0.57972070, mean(E): -21.92599905-0.06575975j, var(E): 10.51829006
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 10000/ t/epoch=0.85............. Loss: -0.02613046, mean(E): -22.02630646-0.10730404j, var(E): 9.06272738
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 10000/ t/epoch=0.85............. Loss: 0.31337875, mean(E): -21.75097752+0.08902988j, var(E): 8.84315245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 10000/ t/epoch=0.85............. Loss: 0.97079122, mean(E): -21.84305485-0.04143768j, var(E): 10.30582438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 10000/ t/epoch=0.85............. Loss: 0.19127501, mean(E): -22.12792605-0.07000005j, var(E): 11.32887628
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 10000/ t/epoch=0.85............. Loss: -1.01193084, mean(E): -21.92320806-0.35418748j, var(E): 12.04330642
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 10000/ t/epoch=0.85............. Loss: -1.62998555, mean(E): -21.67057547-0.02165101j, var(E): 9.86384560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 10000/ t/epoch=0.85............. Loss: 0.13623464, mean(E): -21.78222420+0.46882130j, var(E): 11.98969633
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 10000/ t/epoch=0.85............. Loss: 2.35072362, mean(E): -21.83325873-0.05777514j, var(E): 11.44143417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 10000/ t/epoch=0.85............. Loss: 2.06904097, mean(E): -21.75706833+0.10569979j, var(E): 10.75898976
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 10000/ t/epoch=0.85............. Loss: -1.41317356, mean(E): -21.98842179+0.07238333j, var(E): 11.76179878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 10000/ t/epoch=0.85............. Loss: -1.00886679, mean(E): -21.73859861+0.26169787j, var(E): 13.50206695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 10000/ t/epoch=0.85............. Loss: -1.41378723, mean(E): -21.55076780+0.12482095j, var(E): 9.52401890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 10000/ t/epoch=0.85............. Loss: 1.04590244, mean(E): -22.12017570+0.06965407j, var(E): 8.85563530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 10000/ t/epoch=0.85............. Loss: -0.00942657, mean(E): -21.79530262-0.18359150j, var(E): 11.36413871
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 10000/ t/epoch=0.85............. Loss: 0.82074132, mean(E): -22.26693496-0.16593822j, var(E): 9.15396360
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 10000/ t/epoch=0.85............. Loss: -0.29180026, mean(E): -21.57249973-0.14934773j, var(E): 8.78274550
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 10000/ t/epoch=0.85............. Loss: -0.94225715, mean(E): -21.92192362-0.04373706j, var(E): 8.86384592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 10000/ t/epoch=0.85............. Loss: 2.48647858, mean(E): -21.79727619-0.15888310j, var(E): 10.12963965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 10000/ t/epoch=0.85............. Loss: -1.07084753, mean(E): -21.51355792+0.14240392j, var(E): 9.34274890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 10000/ t/epoch=0.85............. Loss: -2.22578792, mean(E): -21.69665755-0.02147960j, var(E): 11.11244414
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 10000/ t/epoch=0.85............. Loss: -0.53575305, mean(E): -22.01211818+0.10029624j, var(E): 9.44126343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 10000/ t/epoch=0.85............. Loss: -0.94363539, mean(E): -21.64716247+0.07907495j, var(E): 9.65305020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 10000/ t/epoch=0.85............. Loss: 0.65459197, mean(E): -22.34686011+0.09877741j, var(E): 9.33137200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 10000/ t/epoch=0.85............. Loss: 1.29444914, mean(E): -21.73961050-0.01238806j, var(E): 8.38472610
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 10000/ t/epoch=0.85............. Loss: 0.73416777, mean(E): -22.12823201+0.29763732j, var(E): 10.97170714
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 10000/ t/epoch=0.85............. Loss: 1.64404226, mean(E): -21.76939479+0.10894739j, var(E): 7.63403458
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 10000/ t/epoch=0.85............. Loss: 1.73778482, mean(E): -21.66251494-0.16044974j, var(E): 12.49808324
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 10000/ t/epoch=0.85............. Loss: -0.04786658, mean(E): -21.97841780+0.17270279j, var(E): 7.29116098
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 10000/ t/epoch=0.85............. Loss: 0.56696163, mean(E): -21.72845502-0.02690553j, var(E): 12.05235746
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 10000/ t/epoch=0.85............. Loss: 0.55836184, mean(E): -21.99382463-0.05314695j, var(E): 9.69664866
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 10000/ t/epoch=0.85............. Loss: 0.92435157, mean(E): -21.99176878-0.35472106j, var(E): 8.61163786
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 10000/ t/epoch=0.85............. Loss: -1.13896684, mean(E): -21.68288173+0.06148671j, var(E): 8.10823010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 10000/ t/epoch=0.85............. Loss: -0.84012337, mean(E): -22.07622775-0.10233512j, var(E): 7.32495605
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 10000/ t/epoch=0.85............. Loss: -0.52818298, mean(E): -22.02385617-0.13300510j, var(E): 10.02303393
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 10000/ t/epoch=0.85............. Loss: -0.24436318, mean(E): -22.01471330+0.01948159j, var(E): 9.21786279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 10000/ t/epoch=0.85............. Loss: -2.39062871, mean(E): -21.79536552+0.18278715j, var(E): 8.21878629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 10000/ t/epoch=0.85............. Loss: 1.94258428, mean(E): -22.28102556-0.04942983j, var(E): 8.26882648
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 10000/ t/epoch=0.85............. Loss: -0.71010646, mean(E): -21.93992214+0.02189821j, var(E): 8.92110107
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 10000/ t/epoch=0.85............. Loss: -0.50558600, mean(E): -22.14215873-0.11042022j, var(E): 11.72697778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 10000/ t/epoch=0.85............. Loss: 0.68658507, mean(E): -21.87900590-0.09664898j, var(E): 10.44418860
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 10000/ t/epoch=0.85............. Loss: 0.57824296, mean(E): -21.88498180-0.17202905j, var(E): 9.67931700
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 10000/ t/epoch=0.85............. Loss: -0.38097275, mean(E): -22.08574118-0.19960196j, var(E): 11.51214563
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 10000/ t/epoch=0.85............. Loss: -0.82901356, mean(E): -22.02258336-0.01722868j, var(E): 7.64719320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 10000/ t/epoch=0.85............. Loss: 0.04002820, mean(E): -22.30946604-0.10186388j, var(E): 8.01551219
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 10000/ t/epoch=0.85............. Loss: -0.17832209, mean(E): -21.99110354+0.10906872j, var(E): 11.03013798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 10000/ t/epoch=0.85............. Loss: -2.22018110, mean(E): -21.95743250+0.00281799j, var(E): 13.94063284
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 10000/ t/epoch=0.85............. Loss: 1.51406438, mean(E): -22.00284167+0.01099118j, var(E): 11.92281639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 10000/ t/epoch=0.85............. Loss: 0.51302015, mean(E): -21.73130445-0.14687683j, var(E): 8.88539129
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 10000/ t/epoch=0.85............. Loss: 0.81896379, mean(E): -22.04605266+0.01901626j, var(E): 7.88825158
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 10000/ t/epoch=0.85............. Loss: 0.62598634, mean(E): -21.94912009-0.15182526j, var(E): 9.84007653
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 10000/ t/epoch=0.85............. Loss: -0.74967367, mean(E): -22.06496576+0.05475492j, var(E): 7.49233238
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 10000/ t/epoch=0.85............. Loss: -1.43931309, mean(E): -22.24828333-0.14343058j, var(E): 8.58597522
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 10000/ t/epoch=0.85............. Loss: -0.84302954, mean(E): -22.00817651+0.06666769j, var(E): 10.13615869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 10000/ t/epoch=0.85............. Loss: 0.14075868, mean(E): -21.97946842-0.03881790j, var(E): 8.76638147
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 10000/ t/epoch=0.85............. Loss: 0.25221982, mean(E): -22.00157320-0.08174586j, var(E): 7.51074366
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 10000/ t/epoch=0.85............. Loss: 1.17341978, mean(E): -22.03096072-0.01509357j, var(E): 9.75750156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 10000/ t/epoch=0.85............. Loss: -2.04671646, mean(E): -21.99121581+0.00163409j, var(E): 9.18273074
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 10000/ t/epoch=0.85............. Loss: -3.03656916, mean(E): -22.03144335+0.27572181j, var(E): 8.26072744
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 10000/ t/epoch=0.85............. Loss: 2.06322055, mean(E): -22.13099403+0.11152429j, var(E): 9.01783685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 10000/ t/epoch=0.85............. Loss: -0.49836637, mean(E): -21.97367286-0.02682034j, var(E): 9.18097321
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 10000/ t/epoch=0.85............. Loss: -2.39520347, mean(E): -21.80573730-0.07287786j, var(E): 9.89234040
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 10000/ t/epoch=0.85............. Loss: -4.27304468, mean(E): -21.99135993+0.00159064j, var(E): 15.08386625
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 10000/ t/epoch=0.85............. Loss: 0.86380318, mean(E): -22.04367587-0.03085642j, var(E): 9.81907342
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 10000/ t/epoch=0.85............. Loss: -0.61905967, mean(E): -21.99101367+0.36473413j, var(E): 11.15478368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 10000/ t/epoch=0.85............. Loss: 0.07703962, mean(E): -22.10398585-0.00552682j, var(E): 6.98132203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 10000/ t/epoch=0.85............. Loss: -2.96651591, mean(E): -22.31848275-0.38471564j, var(E): 8.81904903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 10000/ t/epoch=0.85............. Loss: -0.06976212, mean(E): -22.40339800+0.27046250j, var(E): 10.63030101
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 10000/ t/epoch=0.85............. Loss: -1.77480800, mean(E): -21.77076646+0.00942446j, var(E): 8.01002789
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 10000/ t/epoch=0.85............. Loss: -0.34956562, mean(E): -22.27788620-0.13903383j, var(E): 9.74933819
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 10000/ t/epoch=0.85............. Loss: 2.23360794, mean(E): -22.16788081-0.00038741j, var(E): 8.18399894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 10000/ t/epoch=0.85............. Loss: -1.86934484, mean(E): -22.02391834-0.10504699j, var(E): 7.86618665
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 10000/ t/epoch=0.85............. Loss: 0.32571596, mean(E): -22.01100070+0.10928445j, var(E): 8.07248839
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 10000/ t/epoch=0.85............. Loss: 0.09254683, mean(E): -21.85889767+0.01026555j, var(E): 11.79833699
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 10000/ t/epoch=0.85............. Loss: -0.28351240, mean(E): -21.69131137-0.05726546j, var(E): 8.72083260
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 10000/ t/epoch=0.85............. Loss: -0.23414685, mean(E): -21.89019509-0.02131375j, var(E): 11.58085412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 10000/ t/epoch=0.85............. Loss: 0.54121386, mean(E): -22.12995693+0.13085228j, var(E): 6.99300112
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 10000/ t/epoch=0.85............. Loss: 0.00359610, mean(E): -21.95882527-0.12735450j, var(E): 8.60181570
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 10000/ t/epoch=0.85............. Loss: 0.29380707, mean(E): -22.17704406+0.09369323j, var(E): 13.17537112
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 10000/ t/epoch=0.85............. Loss: 0.46882593, mean(E): -21.83385693-0.07805243j, var(E): 8.87177677
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 10000/ t/epoch=0.85............. Loss: -2.18495015, mean(E): -21.95657920-0.22532011j, var(E): 13.44393229
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 10000/ t/epoch=0.85............. Loss: 0.53314252, mean(E): -22.22518362-0.04237416j, var(E): 7.71395516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 10000/ t/epoch=0.85............. Loss: -0.73638069, mean(E): -21.84281817+0.05520446j, var(E): 8.54584325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 10000/ t/epoch=0.85............. Loss: 0.19163039, mean(E): -22.03867789-0.20155363j, var(E): 9.04056897
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 10000/ t/epoch=0.85............. Loss: -0.06213369, mean(E): -21.99597347-0.08362129j, var(E): 6.50067403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 10000/ t/epoch=0.85............. Loss: -0.79808989, mean(E): -22.16842055-0.02548571j, var(E): 7.45472071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 10000/ t/epoch=0.85............. Loss: 0.47179649, mean(E): -22.07035654-0.05696207j, var(E): 8.40433043
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 10000/ t/epoch=0.85............. Loss: 1.87701688, mean(E): -22.09183027-0.12193976j, var(E): 5.25026756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 10000/ t/epoch=0.85............. Loss: -0.95858848, mean(E): -22.43020892+0.24521951j, var(E): 7.57113960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 10000/ t/epoch=0.85............. Loss: -0.94431318, mean(E): -22.15980832+0.09319190j, var(E): 7.66938516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 10000/ t/epoch=0.85............. Loss: -1.90507158, mean(E): -21.93242303+0.10693535j, var(E): 6.54072528
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 10000/ t/epoch=0.85............. Loss: -3.52887946, mean(E): -22.22136790-0.18204851j, var(E): 10.91006625
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 10000/ t/epoch=0.85............. Loss: -0.31385145, mean(E): -22.27632362-0.06978144j, var(E): 10.03533440
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 10000/ t/epoch=0.85............. Loss: -1.33069377, mean(E): -22.10031057-0.07678608j, var(E): 10.97939065
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 10000/ t/epoch=0.85............. Loss: -0.76341667, mean(E): -22.08708209+0.15009664j, var(E): 7.78902503
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 10000/ t/epoch=0.85............. Loss: 0.06954400, mean(E): -22.15629745-0.15644642j, var(E): 6.83764131
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 10000/ t/epoch=0.85............. Loss: -2.36309625, mean(E): -22.21278334-0.06092898j, var(E): 8.21083603
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 10000/ t/epoch=0.85............. Loss: 1.22812808, mean(E): -22.21876262+0.15456667j, var(E): 9.57207745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 10000/ t/epoch=0.85............. Loss: 1.21903115, mean(E): -22.20581740+0.06731019j, var(E): 6.34294488
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 10000/ t/epoch=0.85............. Loss: 0.36986905, mean(E): -22.23561994+0.10937093j, var(E): 6.20805620
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 10000/ t/epoch=0.85............. Loss: -2.16786051, mean(E): -21.78722693-0.16642453j, var(E): 12.48090986
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 10000/ t/epoch=0.85............. Loss: -1.59158928, mean(E): -22.04971543+0.10351688j, var(E): 7.63777572
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 10000/ t/epoch=0.85............. Loss: -1.79312349, mean(E): -21.90355157-0.09052751j, var(E): 6.87397763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 10000/ t/epoch=0.85............. Loss: 0.44666225, mean(E): -22.18333949+0.02077641j, var(E): 8.77354403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 10000/ t/epoch=0.85............. Loss: -1.66734574, mean(E): -21.90131684+0.09392312j, var(E): 9.50578504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 10000/ t/epoch=0.85............. Loss: -4.39797206, mean(E): -21.83957294-0.10460002j, var(E): 11.22477120
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 10000/ t/epoch=0.85............. Loss: 0.74739476, mean(E): -22.21163959-0.37600041j, var(E): 7.60393765
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 10000/ t/epoch=0.85............. Loss: -0.25869111, mean(E): -22.18192108-0.36214825j, var(E): 6.86338198
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 10000/ t/epoch=0.85............. Loss: -1.00069852, mean(E): -22.19251664-0.00954232j, var(E): 6.69427183
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 10000/ t/epoch=0.85............. Loss: 1.74593859, mean(E): -22.28099269-0.08736210j, var(E): 7.50764689
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 10000/ t/epoch=0.85............. Loss: -1.52765227, mean(E): -21.90666768-0.10425786j, var(E): 5.86302739
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 10000/ t/epoch=0.85............. Loss: -1.87597528, mean(E): -22.17683941-0.28840530j, var(E): 6.45430514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 10000/ t/epoch=0.85............. Loss: 0.88439975, mean(E): -22.02288485+0.17695788j, var(E): 8.91213748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 10000/ t/epoch=0.85............. Loss: -0.50637020, mean(E): -22.13867954+0.26588259j, var(E): 7.00393902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 10000/ t/epoch=0.85............. Loss: 0.45292472, mean(E): -22.38974321-0.34660165j, var(E): 6.50458517
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 10000/ t/epoch=0.85............. Loss: -0.23380986, mean(E): -22.26226749-0.32749800j, var(E): 5.86792753
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 10000/ t/epoch=0.85............. Loss: -1.45937375, mean(E): -22.16661685-0.10742363j, var(E): 7.33644187
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 10000/ t/epoch=0.85............. Loss: 1.93120318, mean(E): -22.03749133-0.21068063j, var(E): 9.16843479
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 10000/ t/epoch=0.85............. Loss: 0.18658711, mean(E): -22.25807914+0.04292990j, var(E): 5.74526421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 10000/ t/epoch=0.85............. Loss: -0.82857196, mean(E): -22.17912670+0.09005780j, var(E): 8.67364999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 10000/ t/epoch=0.85............. Loss: -1.51764356, mean(E): -22.08633770+0.06400304j, var(E): 10.22548094
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 10000/ t/epoch=0.85............. Loss: 1.05005368, mean(E): -22.54249825-0.11746404j, var(E): 6.43540986
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 10000/ t/epoch=0.85............. Loss: 0.98549468, mean(E): -22.23283169-0.01773575j, var(E): 7.91583797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 10000/ t/epoch=0.85............. Loss: -0.76531611, mean(E): -22.20673774-0.04815269j, var(E): 6.71912436
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 10000/ t/epoch=0.85............. Loss: -0.16524113, mean(E): -22.14916390-0.15419714j, var(E): 8.28865078
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 10000/ t/epoch=0.85............. Loss: -1.21508963, mean(E): -22.19548652-0.12992633j, var(E): 9.11136136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 10000/ t/epoch=0.85............. Loss: 1.52602625, mean(E): -22.29489412-0.17224205j, var(E): 6.30489010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 10000/ t/epoch=0.85............. Loss: -0.40155182, mean(E): -22.21306790-0.00305827j, var(E): 6.18120568
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 10000/ t/epoch=0.85............. Loss: 0.19576234, mean(E): -22.08527688+0.30607942j, var(E): 8.23913626
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 10000/ t/epoch=0.85............. Loss: -1.16043414, mean(E): -22.40240477+0.04180731j, var(E): 7.85064815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 10000/ t/epoch=0.85............. Loss: 0.88326644, mean(E): -22.27643655+0.22232800j, var(E): 9.34583142
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 10000/ t/epoch=0.85............. Loss: -0.31254176, mean(E): -22.21165053+0.11726774j, var(E): 5.01481843
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 10000/ t/epoch=0.85............. Loss: 0.57710195, mean(E): -22.18459811-0.18236078j, var(E): 5.82063875
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 10000/ t/epoch=0.85............. Loss: -2.21002660, mean(E): -22.18501901+0.15358413j, var(E): 5.29201685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 10000/ t/epoch=0.85............. Loss: 1.20377826, mean(E): -22.03103717-0.17797685j, var(E): 6.44702829
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 10000/ t/epoch=0.85............. Loss: -0.97654379, mean(E): -22.36243376+0.12395112j, var(E): 5.25164649
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 10000/ t/epoch=0.85............. Loss: 1.00696951, mean(E): -22.46774927+0.16837222j, var(E): 8.31346830
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 10000/ t/epoch=0.85............. Loss: 0.82258790, mean(E): -22.24407942-0.02552167j, var(E): 7.44514533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 10000/ t/epoch=0.85............. Loss: -1.97596369, mean(E): -22.14186519+0.01396358j, var(E): 5.57687737
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 10000/ t/epoch=0.85............. Loss: 1.63282373, mean(E): -22.36150492+0.01549608j, var(E): 8.35015228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 10000/ t/epoch=0.88............. Loss: 0.37067040, mean(E): -22.35426437-0.16290020j, var(E): 6.81626250
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 10000/ t/epoch=0.85............. Loss: -1.97835417, mean(E): -22.47843582-0.14688196j, var(E): 9.28302881
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 10000/ t/epoch=0.85............. Loss: -0.53284663, mean(E): -22.07589968+0.02320305j, var(E): 8.96646686
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 10000/ t/epoch=0.85............. Loss: 0.45452977, mean(E): -22.15381097-0.01826279j, var(E): 6.30898217
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 10000/ t/epoch=0.85............. Loss: -0.65641238, mean(E): -22.39441421-0.22416996j, var(E): 6.59799452
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 10000/ t/epoch=0.85............. Loss: -1.52111951, mean(E): -22.04253380-0.13094911j, var(E): 9.92690519
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 10000/ t/epoch=0.85............. Loss: -2.09414371, mean(E): -22.07997178-0.10596045j, var(E): 8.09869811
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 10000/ t/epoch=0.85............. Loss: 1.39924199, mean(E): -22.40243719+0.16334419j, var(E): 5.89493108
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 10000/ t/epoch=0.85............. Loss: 0.21326115, mean(E): -22.08842336+0.09349669j, var(E): 9.13511229
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 10000/ t/epoch=0.85............. Loss: -1.40647563, mean(E): -22.12696586-0.13730654j, var(E): 6.22907938
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 10000/ t/epoch=0.85............. Loss: -1.23436256, mean(E): -22.24619901+0.00850756j, var(E): 6.53681083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 10000/ t/epoch=0.85............. Loss: 0.90774674, mean(E): -22.22122391-0.11560872j, var(E): 4.63248207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 10000/ t/epoch=0.85............. Loss: -0.49173818, mean(E): -22.17802163-0.10874314j, var(E): 4.50875805
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 10000/ t/epoch=0.85............. Loss: -1.89181669, mean(E): -22.22421753-0.09423156j, var(E): 7.71180156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 10000/ t/epoch=0.85............. Loss: 2.64087711, mean(E): -22.29115685-0.05234798j, var(E): 7.15802522
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 10000/ t/epoch=0.85............. Loss: 0.77941427, mean(E): -22.18938225+0.18725337j, var(E): 9.66369818
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 10000/ t/epoch=0.85............. Loss: -0.48588392, mean(E): -22.39837255+0.29702743j, var(E): 5.74071482
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 10000/ t/epoch=0.85............. Loss: 0.89608614, mean(E): -22.38581903+0.07052024j, var(E): 6.78017649
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 10000/ t/epoch=0.85............. Loss: -0.33497685, mean(E): -21.95595534-0.00868058j, var(E): 7.48428724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 10000/ t/epoch=0.85............. Loss: 0.70441801, mean(E): -22.35484828+0.07146310j, var(E): 6.99424292
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 10000/ t/epoch=0.85............. Loss: 0.09803269, mean(E): -22.15164431+0.17784462j, var(E): 6.80153176
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 10000/ t/epoch=0.85............. Loss: -0.43756646, mean(E): -22.37677095-0.09855080j, var(E): 5.81289956
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 10000/ t/epoch=0.85............. Loss: 0.67316766, mean(E): -22.36860603+0.21447867j, var(E): 8.25944295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 10000/ t/epoch=0.85............. Loss: -0.31079731, mean(E): -22.18747895-0.22498536j, var(E): 6.36739687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 10000/ t/epoch=0.85............. Loss: -0.15031371, mean(E): -22.38345099+0.11039592j, var(E): 6.51256523
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 10000/ t/epoch=0.85............. Loss: -1.93665137, mean(E): -22.22348816-0.18556039j, var(E): 7.22898686
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 10000/ t/epoch=0.85............. Loss: 0.32937492, mean(E): -22.39875434-0.39691945j, var(E): 11.10516646
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 10000/ t/epoch=0.85............. Loss: -0.04748807, mean(E): -22.22640693+0.01802638j, var(E): 6.25450071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 10000/ t/epoch=0.85............. Loss: 0.85252810, mean(E): -22.17388782+0.12398703j, var(E): 6.07530677
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 10000/ t/epoch=0.85............. Loss: -2.41207273, mean(E): -22.47314577+0.13672703j, var(E): 7.36459839
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 10000/ t/epoch=0.85............. Loss: -1.93486594, mean(E): -22.16588002-0.24014863j, var(E): 5.19426368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 10000/ t/epoch=0.85............. Loss: 0.02194341, mean(E): -22.51621249-0.23292047j, var(E): 6.17631133
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 10000/ t/epoch=0.85............. Loss: 0.59282892, mean(E): -22.16299138+0.24492510j, var(E): 8.34301131
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 10000/ t/epoch=0.85............. Loss: 1.30258601, mean(E): -22.22709177+0.05619771j, var(E): 6.56363536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 10000/ t/epoch=0.85............. Loss: -1.01129584, mean(E): -22.16565519+0.01655665j, var(E): 8.44001787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 10000/ t/epoch=0.85............. Loss: -0.22636821, mean(E): -22.37155261+0.06494108j, var(E): 6.51456097
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 10000/ t/epoch=0.85............. Loss: -0.81508656, mean(E): -22.18373268+0.14242773j, var(E): 6.38155745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 10000/ t/epoch=0.85............. Loss: -2.46896932, mean(E): -22.47933396+0.03668417j, var(E): 11.40191698
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 10000/ t/epoch=0.85............. Loss: -0.69613071, mean(E): -22.36312122+0.12529558j, var(E): 8.37446660
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 10000/ t/epoch=0.85............. Loss: 0.11719774, mean(E): -22.37870926-0.21301428j, var(E): 6.75983867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 10000/ t/epoch=0.85............. Loss: 0.17137106, mean(E): -22.25334253+0.09374600j, var(E): 6.83369224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 10000/ t/epoch=0.85............. Loss: -1.87672330, mean(E): -22.15279374+0.00171552j, var(E): 5.98261523
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 10000/ t/epoch=0.85............. Loss: 0.15285639, mean(E): -22.37977293+0.07100157j, var(E): 7.52273599
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 10000/ t/epoch=0.85............. Loss: 1.11557958, mean(E): -22.22722198-0.05375534j, var(E): 7.69314724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 10000/ t/epoch=0.85............. Loss: -1.76082068, mean(E): -22.05910943+0.28316685j, var(E): 9.09023324
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 10000/ t/epoch=0.85............. Loss: -0.55822218, mean(E): -22.49001484+0.22840799j, var(E): 6.63192146
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 10000/ t/epoch=0.85............. Loss: 0.82517796, mean(E): -22.27740163+0.09648287j, var(E): 6.86819716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 10000/ t/epoch=0.85............. Loss: -0.93152588, mean(E): -22.29453991+0.37832071j, var(E): 12.04864230
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 10000/ t/epoch=0.85............. Loss: -3.25106809, mean(E): -22.03851237-0.16871487j, var(E): 20.89202521
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 10000/ t/epoch=0.85............. Loss: 2.54107474, mean(E): -22.52100753+0.01345570j, var(E): 6.53864719
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 10000/ t/epoch=0.85............. Loss: 0.11002753, mean(E): -22.29368989+0.06039120j, var(E): 5.12142818
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 10000/ t/epoch=0.85............. Loss: 0.25734330, mean(E): -22.42124445-0.00063396j, var(E): 7.37210644
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 10000/ t/epoch=0.85............. Loss: 1.55365294, mean(E): -22.29365611+0.09599341j, var(E): 7.20044331
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 10000/ t/epoch=0.85............. Loss: -1.00090218, mean(E): -22.24403110-0.00088486j, var(E): 8.96372607
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 10000/ t/epoch=0.85............. Loss: 1.33759828, mean(E): -22.49254520-0.11067528j, var(E): 6.13676009
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 10000/ t/epoch=0.85............. Loss: -2.30292823, mean(E): -22.36215466-0.11280527j, var(E): 5.72032724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 10000/ t/epoch=0.85............. Loss: -3.49225131, mean(E): -22.52191856+0.15216799j, var(E): 9.26255185
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 10000/ t/epoch=0.85............. Loss: -0.97609192, mean(E): -22.23319586-0.15550002j, var(E): 11.02023755
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 10000/ t/epoch=0.85............. Loss: -0.72600405, mean(E): -22.46898712+0.10993012j, var(E): 4.30843552
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 10000/ t/epoch=0.85............. Loss: -1.05530954, mean(E): -22.34190884+0.04753549j, var(E): 5.12931363
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 10000/ t/epoch=0.85............. Loss: -2.19972798, mean(E): -22.47802537-0.23532249j, var(E): 8.57844699
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 10000/ t/epoch=0.85............. Loss: 0.56597500, mean(E): -22.40544281-0.21975076j, var(E): 6.73148176
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 10000/ t/epoch=0.85............. Loss: -1.62825788, mean(E): -22.40188938+0.04380725j, var(E): 6.78183979
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 10000/ t/epoch=0.85............. Loss: -1.61313442, mean(E): -22.09155390+0.18554716j, var(E): 5.76949155
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 10000/ t/epoch=0.85............. Loss: -1.23113030, mean(E): -22.39454483+0.15094660j, var(E): 6.65518453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 10000/ t/epoch=0.85............. Loss: 2.82781648, mean(E): -22.41739129+0.09875215j, var(E): 8.59132747
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 10000/ t/epoch=0.85............. Loss: 1.15398669, mean(E): -22.42849712+0.08628014j, var(E): 7.16733128
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 10000/ t/epoch=0.85............. Loss: -1.13886214, mean(E): -22.15504195-0.07147801j, var(E): 5.95395516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 10000/ t/epoch=0.85............. Loss: -0.99482520, mean(E): -22.39667981+0.08827246j, var(E): 6.24983996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 10000/ t/epoch=0.85............. Loss: -1.45994039, mean(E): -22.37548282+0.03614135j, var(E): 5.83546286
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 10000/ t/epoch=0.85............. Loss: 0.41287220, mean(E): -22.55158988+0.01029240j, var(E): 5.40662019
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 10000/ t/epoch=0.85............. Loss: 2.45885994, mean(E): -22.46258088-0.10215681j, var(E): 4.88217845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 10000/ t/epoch=0.85............. Loss: -2.42464371, mean(E): -22.32540690-0.21588207j, var(E): 6.71513263
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 10000/ t/epoch=0.85............. Loss: -1.96557929, mean(E): -22.31186992-0.28578428j, var(E): 8.71347665
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 10000/ t/epoch=0.85............. Loss: 1.50673430, mean(E): -22.34846887+0.03656774j, var(E): 4.99552024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 10000/ t/epoch=0.85............. Loss: -1.42541075, mean(E): -22.25311807+0.12959411j, var(E): 6.68076855
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 10000/ t/epoch=0.85............. Loss: 0.04284755, mean(E): -22.26678621+0.06269046j, var(E): 6.32461348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 10000/ t/epoch=0.85............. Loss: -0.89649067, mean(E): -22.16887417+0.06805937j, var(E): 6.37290120
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 10000/ t/epoch=0.85............. Loss: -2.22543367, mean(E): -22.53093328+0.06832333j, var(E): 6.18239365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 10000/ t/epoch=0.85............. Loss: 2.50454905, mean(E): -22.47795297-0.13081111j, var(E): 6.32358474
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 10000/ t/epoch=0.85............. Loss: -1.89829846, mean(E): -22.27389672-0.02255134j, var(E): 5.65675017
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 10000/ t/epoch=0.85............. Loss: 0.79408965, mean(E): -22.52030022-0.28606142j, var(E): 5.64390992
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 10000/ t/epoch=0.85............. Loss: -0.54119915, mean(E): -22.51701865+0.17642045j, var(E): 6.48908221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 10000/ t/epoch=0.85............. Loss: -0.78062769, mean(E): -22.27646668-0.04729057j, var(E): 7.61609107
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 10000/ t/epoch=0.85............. Loss: -1.03643398, mean(E): -22.25606681+0.10224354j, var(E): 10.04081672
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 10000/ t/epoch=0.85............. Loss: -1.45658183, mean(E): -22.46361013+0.17936496j, var(E): 10.57378496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 10000/ t/epoch=0.85............. Loss: 1.70517099, mean(E): -22.34375111-0.16605583j, var(E): 7.47476523
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 10000/ t/epoch=0.85............. Loss: -1.45534479, mean(E): -22.28060088-0.19553877j, var(E): 7.10672370
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 10000/ t/epoch=0.85............. Loss: 1.56111114, mean(E): -22.51368862-0.27732118j, var(E): 9.18089005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 10000/ t/epoch=0.85............. Loss: 1.30790678, mean(E): -22.24258406+0.07647270j, var(E): 5.67720716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 10000/ t/epoch=0.85............. Loss: -2.38108594, mean(E): -22.10011545+0.03819889j, var(E): 7.79628858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 10000/ t/epoch=0.85............. Loss: 1.23001727, mean(E): -22.44007992-0.11784449j, var(E): 6.37270021
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 10000/ t/epoch=0.85............. Loss: -1.13712320, mean(E): -22.47477591-0.00352054j, var(E): 7.07092114
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 10000/ t/epoch=0.85............. Loss: 1.20991166, mean(E): -22.29759686-0.19628296j, var(E): 7.36557274
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 10000/ t/epoch=0.85............. Loss: -1.91975087, mean(E): -22.15145206-0.20765280j, var(E): 7.98565262
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 10000/ t/epoch=0.85............. Loss: 2.30613689, mean(E): -22.49424440-0.02869302j, var(E): 5.53992494
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 10000/ t/epoch=0.85............. Loss: -0.26970178, mean(E): -22.48720108-0.14610068j, var(E): 5.44843270
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 10000/ t/epoch=0.85............. Loss: -0.83916749, mean(E): -22.53199474+0.00274055j, var(E): 10.63740255
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 10000/ t/epoch=0.85............. Loss: 2.28606057, mean(E): -22.27167973+0.02507859j, var(E): 7.58101799
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 10000/ t/epoch=0.85............. Loss: 2.00201124, mean(E): -22.57158230+0.15473020j, var(E): 7.30020048
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 10000/ t/epoch=0.85............. Loss: 0.02001385, mean(E): -22.13921309-0.03355286j, var(E): 7.90761365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 10000/ t/epoch=0.85............. Loss: -0.53009956, mean(E): -22.50447418+0.05852600j, var(E): 8.01696485
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 10000/ t/epoch=0.85............. Loss: 0.12883776, mean(E): -22.36350497-0.13442491j, var(E): 5.02553391
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 10000/ t/epoch=0.85............. Loss: -1.63315388, mean(E): -22.58744177-0.05762174j, var(E): 5.99941065
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 10000/ t/epoch=0.85............. Loss: 2.35608723, mean(E): -22.58612705-0.01377469j, var(E): 5.88706596
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 10000/ t/epoch=0.85............. Loss: 0.03449979, mean(E): -22.41066503+0.01422530j, var(E): 6.49966400
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 10000/ t/epoch=0.85............. Loss: -1.88376121, mean(E): -22.35687710+0.03435968j, var(E): 6.92572976
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 10000/ t/epoch=0.85............. Loss: 1.76490608, mean(E): -22.33764413-0.44768440j, var(E): 7.41513044
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 10000/ t/epoch=0.85............. Loss: -1.13922434, mean(E): -22.59019113-0.11566523j, var(E): 7.77614196
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 10000/ t/epoch=0.85............. Loss: -1.72412897, mean(E): -22.61088124+0.14389058j, var(E): 7.05326306
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 10000/ t/epoch=0.85............. Loss: -0.22469725, mean(E): -22.43557371-0.27660975j, var(E): 7.02982896
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 10000/ t/epoch=0.85............. Loss: 1.92086712, mean(E): -22.63855470+0.00333800j, var(E): 5.17416270
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 10000/ t/epoch=0.85............. Loss: -1.90231192, mean(E): -22.32315028+0.02434938j, var(E): 5.40500226
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 10000/ t/epoch=0.85............. Loss: 1.55506594, mean(E): -22.57783317-0.09843574j, var(E): 7.97471557
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 10000/ t/epoch=0.85............. Loss: -0.90680324, mean(E): -22.54119584-0.16342803j, var(E): 9.49770918
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 10000/ t/epoch=0.85............. Loss: 1.15073650, mean(E): -22.45098978+0.03610265j, var(E): 5.69451958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 10000/ t/epoch=0.85............. Loss: 1.30955970, mean(E): -22.22906513+0.05639288j, var(E): 6.05553205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 10000/ t/epoch=0.85............. Loss: 0.77607575, mean(E): -22.63290126-0.02019062j, var(E): 9.36552519
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 10000/ t/epoch=0.85............. Loss: -0.25014413, mean(E): -22.67675492-0.14114824j, var(E): 7.82021478
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 10000/ t/epoch=0.85............. Loss: -0.41238887, mean(E): -22.45528965-0.29385469j, var(E): 6.31881330
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 10000/ t/epoch=0.85............. Loss: -2.12270590, mean(E): -22.34633383-0.08351841j, var(E): 6.77905578
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 10000/ t/epoch=0.85............. Loss: 0.32182551, mean(E): -22.47474437+0.08602553j, var(E): 5.09267692
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 10000/ t/epoch=0.85............. Loss: -1.98430458, mean(E): -22.37306603-0.01320290j, var(E): 6.89141693
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 10000/ t/epoch=0.85............. Loss: -1.83733795, mean(E): -22.27806748-0.06407406j, var(E): 8.86906269
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 10000/ t/epoch=0.85............. Loss: 0.29568563, mean(E): -22.49076708+0.01124274j, var(E): 5.07002357
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 10000/ t/epoch=0.85............. Loss: -2.15940404, mean(E): -22.34510806-0.36962128j, var(E): 9.00875956
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 10000/ t/epoch=0.85............. Loss: -0.31206540, mean(E): -22.55466903-0.02448804j, var(E): 7.93687893
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 10000/ t/epoch=0.85............. Loss: 0.28577680, mean(E): -22.49481325+0.08612604j, var(E): 9.87992902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 10000/ t/epoch=0.85............. Loss: -0.66882445, mean(E): -22.56154801+0.07976561j, var(E): 7.15917589
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 10000/ t/epoch=0.85............. Loss: -0.96557775, mean(E): -22.43870623-0.01671179j, var(E): 7.31726430
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 10000/ t/epoch=0.85............. Loss: -1.10758011, mean(E): -22.38030085-0.02844568j, var(E): 9.39098886
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 10000/ t/epoch=0.85............. Loss: 0.38169066, mean(E): -22.45882679+0.19956185j, var(E): 6.55867001
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 10000/ t/epoch=0.85............. Loss: 0.54418426, mean(E): -22.64567164+0.01020204j, var(E): 6.64940495
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 10000/ t/epoch=0.85............. Loss: 1.32195431, mean(E): -22.43842862-0.20643414j, var(E): 8.32844041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 10000/ t/epoch=0.85............. Loss: -1.49335316, mean(E): -22.75900157-0.06486106j, var(E): 6.68068673
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 10000/ t/epoch=0.85............. Loss: -0.82194363, mean(E): -22.43413070-0.01901746j, var(E): 6.71670561
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 10000/ t/epoch=0.85............. Loss: -1.22512022, mean(E): -22.44132273-0.15889989j, var(E): 7.72788509
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 10000/ t/epoch=0.85............. Loss: -0.00891245, mean(E): -22.35213815-0.17074750j, var(E): 6.18144180
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 10000/ t/epoch=0.85............. Loss: -0.63312100, mean(E): -22.46543009+0.00408709j, var(E): 5.42976816
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 10000/ t/epoch=0.85............. Loss: 0.17007244, mean(E): -22.39526202+0.16613819j, var(E): 8.04844072
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 10000/ t/epoch=0.85............. Loss: -0.91677306, mean(E): -22.58302294+0.00222542j, var(E): 7.97730869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 10000/ t/epoch=0.85............. Loss: -0.38280943, mean(E): -22.47865314+0.11233290j, var(E): 7.44660832
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 10000/ t/epoch=0.85............. Loss: 0.16237943, mean(E): -22.34280538+0.03853829j, var(E): 6.75678545
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 10000/ t/epoch=0.85............. Loss: 0.96250064, mean(E): -22.34623179+0.11766648j, var(E): 6.29037007
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 10000/ t/epoch=0.85............. Loss: -1.51278764, mean(E): -22.50761786-0.09109074j, var(E): 7.18650454
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 10000/ t/epoch=0.85............. Loss: -1.72983932, mean(E): -22.57833385+0.05508411j, var(E): 7.69664135
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 10000/ t/epoch=0.85............. Loss: -1.16032835, mean(E): -22.51868943-0.01884306j, var(E): 5.25085514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 10000/ t/epoch=0.85............. Loss: -3.49789050, mean(E): -22.55976513+0.20089723j, var(E): 7.87846554
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 10000/ t/epoch=0.85............. Loss: -0.27513408, mean(E): -22.53833872+0.10652126j, var(E): 5.57174484
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 10000/ t/epoch=0.85............. Loss: 1.13207451, mean(E): -22.55642456-0.02066858j, var(E): 5.89605461
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 10000/ t/epoch=0.85............. Loss: -1.99823077, mean(E): -22.45037248+0.02764874j, var(E): 7.42182778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 10000/ t/epoch=0.85............. Loss: 1.00178277, mean(E): -22.45087074-0.11582515j, var(E): 6.36572754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 10000/ t/epoch=0.85............. Loss: -0.17715656, mean(E): -22.33867674-0.16839289j, var(E): 5.17197236
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 10000/ t/epoch=0.85............. Loss: 0.23392656, mean(E): -22.40185929-0.02808566j, var(E): 6.39523249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 10000/ t/epoch=0.85............. Loss: 0.57770795, mean(E): -22.74109613-0.01570735j, var(E): 5.53772546
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 10000/ t/epoch=0.85............. Loss: 1.90985478, mean(E): -22.45452900-0.30318775j, var(E): 5.20062186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 10000/ t/epoch=0.85............. Loss: -0.85160894, mean(E): -22.59334588+0.04669561j, var(E): 5.19785767
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 10000/ t/epoch=0.85............. Loss: -1.99114987, mean(E): -22.58208189-0.12463466j, var(E): 6.87027691
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 10000/ t/epoch=0.85............. Loss: 0.72073379, mean(E): -22.44530807-0.02145627j, var(E): 9.64413885
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 10000/ t/epoch=0.85............. Loss: -1.72272809, mean(E): -22.32988842-0.10237917j, var(E): 8.24541712
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 10000/ t/epoch=0.85............. Loss: -0.26408502, mean(E): -22.62667355-0.19415909j, var(E): 7.13560925
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 10000/ t/epoch=0.85............. Loss: 1.48895139, mean(E): -22.36935797-0.11373139j, var(E): 6.70046067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 10000/ t/epoch=0.85............. Loss: -1.32031963, mean(E): -22.41508712+0.38072801j, var(E): 7.99164548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 10000/ t/epoch=0.85............. Loss: 1.08494472, mean(E): -22.48532355+0.22118961j, var(E): 4.99829919
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 10000/ t/epoch=0.85............. Loss: -0.50953944, mean(E): -22.56393289-0.12287415j, var(E): 4.51955396
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 10000/ t/epoch=0.85............. Loss: 0.48037441, mean(E): -22.35233714-0.12815265j, var(E): 8.02693952
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 10000/ t/epoch=0.85............. Loss: -1.16374637, mean(E): -22.44308378+0.14170292j, var(E): 11.96421228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 10000/ t/epoch=0.85............. Loss: -1.65525980, mean(E): -22.37906351-0.00255226j, var(E): 7.02594005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 10000/ t/epoch=0.85............. Loss: 2.33276152, mean(E): -22.85786712-0.21599571j, var(E): 7.15900611
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 10000/ t/epoch=0.85............. Loss: 0.58874110, mean(E): -22.53422286-0.28801084j, var(E): 5.91622984
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 10000/ t/epoch=0.85............. Loss: 1.01517067, mean(E): -22.49424341-0.27287692j, var(E): 5.79874453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 10000/ t/epoch=0.85............. Loss: -0.00097726, mean(E): -22.38729488+0.01653099j, var(E): 7.14869477
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 10000/ t/epoch=0.85............. Loss: -1.53593896, mean(E): -22.23625039-0.07185394j, var(E): 6.93453090
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 10000/ t/epoch=0.85............. Loss: 1.21469067, mean(E): -22.42918495-0.27525177j, var(E): 6.58705302
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 10000/ t/epoch=0.85............. Loss: 0.75134534, mean(E): -22.73676743+0.24482800j, var(E): 8.47890246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 10000/ t/epoch=0.85............. Loss: 2.10112176, mean(E): -22.35742311+0.04537369j, var(E): 5.48187152
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 10000/ t/epoch=0.85............. Loss: -0.01749460, mean(E): -22.56450614-0.13228087j, var(E): 8.71965401
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 10000/ t/epoch=0.85............. Loss: -1.94460686, mean(E): -22.19422430-0.02159117j, var(E): 6.98270770
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 10000/ t/epoch=0.85............. Loss: 0.39173919, mean(E): -22.20991433-0.05368095j, var(E): 4.98499731
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 10000/ t/epoch=0.85............. Loss: -0.79333477, mean(E): -22.57100508-0.06241359j, var(E): 5.67790175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 10000/ t/epoch=0.85............. Loss: 0.21355667, mean(E): -22.66895849+0.11676303j, var(E): 8.44615895
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 10000/ t/epoch=0.85............. Loss: -0.88483422, mean(E): -22.42255934+0.06548560j, var(E): 8.32601816
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 10000/ t/epoch=0.85............. Loss: 2.45171348, mean(E): -22.34344431-0.08747388j, var(E): 6.41824908
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 10000/ t/epoch=0.85............. Loss: -1.59514581, mean(E): -22.54107053+0.06283821j, var(E): 8.35325351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 10000/ t/epoch=0.85............. Loss: -0.00500356, mean(E): -22.53068271+0.03674760j, var(E): 6.81330960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 10000/ t/epoch=0.85............. Loss: -0.59284296, mean(E): -22.60960733-0.12600840j, var(E): 6.40536635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 10000/ t/epoch=0.85............. Loss: 0.79378049, mean(E): -22.47946276+0.00477525j, var(E): 5.33437377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 10000/ t/epoch=0.85............. Loss: -0.88547524, mean(E): -22.60328786+0.01044808j, var(E): 5.77394969
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 10000/ t/epoch=0.85............. Loss: 0.38127752, mean(E): -22.31967365-0.09023048j, var(E): 5.70556627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 10000/ t/epoch=0.85............. Loss: -1.57795846, mean(E): -22.53198545+0.02933719j, var(E): 7.77095311
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 10000/ t/epoch=0.85............. Loss: -0.50642565, mean(E): -22.45335259-0.02602813j, var(E): 4.78146963
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 10000/ t/epoch=0.85............. Loss: 1.04186587, mean(E): -22.44968798-0.15161413j, var(E): 6.20875123
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 10000/ t/epoch=0.85............. Loss: -1.55796613, mean(E): -22.24657514-0.27184894j, var(E): 7.80212189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 10000/ t/epoch=0.85............. Loss: 0.95224799, mean(E): -22.41028042-0.22426686j, var(E): 7.30027626
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 10000/ t/epoch=0.85............. Loss: -1.33207274, mean(E): -22.56914480+0.10045796j, var(E): 6.60528893
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 10000/ t/epoch=0.85............. Loss: 0.19173542, mean(E): -22.53954758+0.00066961j, var(E): 7.48411748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 10000/ t/epoch=0.85............. Loss: -0.74735758, mean(E): -22.31034944-0.02978313j, var(E): 5.64961317
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 10000/ t/epoch=0.85............. Loss: -0.59800426, mean(E): -22.39260324-0.09795810j, var(E): 6.28592742
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 10000/ t/epoch=0.85............. Loss: 1.12882643, mean(E): -22.54953227+0.03211293j, var(E): 8.95387411
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 10000/ t/epoch=0.85............. Loss: -0.48560438, mean(E): -22.47950747+0.26829323j, var(E): 5.94052579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 10000/ t/epoch=0.85............. Loss: -0.43616406, mean(E): -22.61611348+0.03069787j, var(E): 5.82380696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 10000/ t/epoch=0.85............. Loss: 2.22463506, mean(E): -22.46970685-0.10527548j, var(E): 6.94546615
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 10000/ t/epoch=0.85............. Loss: -0.35135985, mean(E): -22.44103337-0.05230479j, var(E): 6.31091076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 10000/ t/epoch=0.85............. Loss: 0.40107123, mean(E): -22.57314326+0.00431231j, var(E): 5.68693499
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 10000/ t/epoch=0.85............. Loss: -0.52679490, mean(E): -22.60342130+0.10120891j, var(E): 5.64565546
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 10000/ t/epoch=0.85............. Loss: -1.75280813, mean(E): -22.68668154-0.00467776j, var(E): 5.83253451
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 10000/ t/epoch=0.85............. Loss: 0.99846474, mean(E): -22.58266314+0.14706995j, var(E): 5.61962268
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 10000/ t/epoch=0.88............. Loss: 1.38021193, mean(E): -22.42769453-0.01508447j, var(E): 4.29942940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 10000/ t/epoch=0.85............. Loss: -1.60907922, mean(E): -22.45832816+0.18273257j, var(E): 5.73841121
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 10000/ t/epoch=0.85............. Loss: -1.44948190, mean(E): -22.58954012+0.14594491j, var(E): 6.90778878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 10000/ t/epoch=0.85............. Loss: -0.60774118, mean(E): -22.71777368-0.18677861j, var(E): 7.05480081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 10000/ t/epoch=0.85............. Loss: 1.20621272, mean(E): -22.55630887+0.10959865j, var(E): 7.16717580
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 10000/ t/epoch=0.85............. Loss: -0.56181851, mean(E): -22.45513758+0.03989060j, var(E): 4.44838954
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 10000/ t/epoch=0.85............. Loss: -0.73569785, mean(E): -22.36509339+0.16577866j, var(E): 8.00503796
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 10000/ t/epoch=0.85............. Loss: -0.51605216, mean(E): -22.66496988+0.07328476j, var(E): 4.89882590
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 10000/ t/epoch=0.85............. Loss: 0.15815855, mean(E): -22.66943644-0.27956423j, var(E): 8.84564659
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 10000/ t/epoch=0.85............. Loss: -1.39021123, mean(E): -22.61624613-0.02453861j, var(E): 5.55315837
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 10000/ t/epoch=0.85............. Loss: 0.14352269, mean(E): -22.45249749+0.00734980j, var(E): 5.85705325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 10000/ t/epoch=0.85............. Loss: 0.26345275, mean(E): -22.57889914-0.04467546j, var(E): 5.65991174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 10000/ t/epoch=0.85............. Loss: -0.30768309, mean(E): -22.54407950-0.09434367j, var(E): 5.11429375
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 10000/ t/epoch=0.85............. Loss: -1.18688625, mean(E): -22.59812949-0.12114185j, var(E): 5.30233397
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 10000/ t/epoch=0.85............. Loss: -1.08827349, mean(E): -22.42424187-0.00693701j, var(E): 7.09522619
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 10000/ t/epoch=0.85............. Loss: -0.42618964, mean(E): -22.56718877-0.01165401j, var(E): 6.40039328
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 10000/ t/epoch=0.85............. Loss: -0.18565536, mean(E): -22.40664725-0.19130569j, var(E): 9.08993026
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 10000/ t/epoch=0.85............. Loss: -1.86163714, mean(E): -22.50988485-0.03954603j, var(E): 6.81459024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 10000/ t/epoch=0.85............. Loss: -0.63045088, mean(E): -22.71816677+0.02889664j, var(E): 7.64285272
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 10000/ t/epoch=0.85............. Loss: -0.17013824, mean(E): -22.59123534+0.11598754j, var(E): 7.22217116
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 10000/ t/epoch=0.85............. Loss: -2.33289715, mean(E): -22.59949612+0.04584345j, var(E): 7.56151609
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 10000/ t/epoch=0.85............. Loss: -0.22960183, mean(E): -22.71076210-0.02727230j, var(E): 5.51266641
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 10000/ t/epoch=0.85............. Loss: -0.84583521, mean(E): -22.45385809-0.26460668j, var(E): 5.43322930
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 10000/ t/epoch=0.85............. Loss: -1.57771996, mean(E): -22.55404371-0.16026186j, var(E): 6.46196407
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 10000/ t/epoch=0.85............. Loss: -0.35896183, mean(E): -22.42038178+0.16101649j, var(E): 6.36944320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 10000/ t/epoch=0.85............. Loss: 0.90095471, mean(E): -22.60503771+0.03038441j, var(E): 6.46148899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 10000/ t/epoch=0.85............. Loss: -1.04582619, mean(E): -22.59027829-0.00419039j, var(E): 5.06247710
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 10000/ t/epoch=0.85............. Loss: 0.97516000, mean(E): -22.59875098-0.16966407j, var(E): 4.86073845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 10000/ t/epoch=0.85............. Loss: -2.25936395, mean(E): -22.67471263+0.02733784j, var(E): 7.64159055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 10000/ t/epoch=0.85............. Loss: 1.98230793, mean(E): -22.72033158-0.38475668j, var(E): 6.10119052
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 10000/ t/epoch=0.85............. Loss: -0.65897245, mean(E): -22.55430348+0.06195508j, var(E): 5.74915103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 10000/ t/epoch=0.85............. Loss: -0.93142936, mean(E): -22.54204819-0.27300152j, var(E): 5.87524751
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 10000/ t/epoch=0.85............. Loss: 1.40821095, mean(E): -22.41512607-0.01316909j, var(E): 12.06189205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 10000/ t/epoch=0.85............. Loss: 1.52535587, mean(E): -22.40584605-0.17733674j, var(E): 8.45876685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 10000/ t/epoch=0.85............. Loss: 1.10220417, mean(E): -22.53855512+0.13828526j, var(E): 6.84431327
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 10000/ t/epoch=0.85............. Loss: 0.08611026, mean(E): -22.51007147-0.12404186j, var(E): 5.73971277
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 10000/ t/epoch=0.85............. Loss: -1.55331982, mean(E): -22.46394866-0.02232879j, var(E): 4.14010497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 10000/ t/epoch=0.85............. Loss: 1.79227075, mean(E): -22.68470426+0.10605833j, var(E): 7.98658724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 10000/ t/epoch=0.85............. Loss: 2.76435992, mean(E): -22.74920571+0.04576455j, var(E): 5.00713898
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 10000/ t/epoch=0.85............. Loss: 0.81550846, mean(E): -22.53350223+0.25319498j, var(E): 7.74606285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 10000/ t/epoch=0.85............. Loss: -0.70149562, mean(E): -22.50473207+0.22517771j, var(E): 7.38036581
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 10000/ t/epoch=0.85............. Loss: -1.03461927, mean(E): -22.36663340-0.00885183j, var(E): 7.25078551
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 10000/ t/epoch=0.85............. Loss: -0.01776412, mean(E): -22.58244870+0.00743546j, var(E): 7.39523476
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 10000/ t/epoch=0.85............. Loss: 0.84244654, mean(E): -22.60146331-0.04912915j, var(E): 6.97823225
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 10000/ t/epoch=0.85............. Loss: 0.63386059, mean(E): -22.56311963+0.03372558j, var(E): 6.95440878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 10000/ t/epoch=0.85............. Loss: -0.09993977, mean(E): -22.53970188+0.01823412j, var(E): 5.85435428
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 10000/ t/epoch=0.85............. Loss: -0.86818839, mean(E): -22.51376242+0.27350444j, var(E): 8.18514267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 10000/ t/epoch=0.85............. Loss: 0.18440402, mean(E): -22.58254269+0.14153227j, var(E): 7.64339996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 10000/ t/epoch=0.85............. Loss: -2.23504303, mean(E): -22.58068138+0.15910790j, var(E): 10.19264416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 10000/ t/epoch=0.85............. Loss: -0.88389092, mean(E): -22.59266162-0.01480320j, var(E): 8.64707295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 10000/ t/epoch=0.85............. Loss: -2.23686663, mean(E): -22.63235662+0.00782981j, var(E): 5.03869711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 10000/ t/epoch=0.85............. Loss: -0.24324687, mean(E): -22.67005278+0.12136356j, var(E): 3.76054940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 10000/ t/epoch=0.85............. Loss: -0.38519710, mean(E): -22.75765205+0.05755128j, var(E): 8.40046746
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 10000/ t/epoch=0.85............. Loss: -0.12018904, mean(E): -22.47976862+0.07687319j, var(E): 8.11775880
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 10000/ t/epoch=0.85............. Loss: -0.69494153, mean(E): -22.39339709-0.27470590j, var(E): 6.31831916
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 10000/ t/epoch=0.85............. Loss: -0.79710472, mean(E): -22.61804288-0.10514115j, var(E): 11.11560650
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 10000/ t/epoch=0.85............. Loss: 0.96645039, mean(E): -22.30038068-0.15138898j, var(E): 4.90742939
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 10000/ t/epoch=0.85............. Loss: 0.27192489, mean(E): -22.83404994-0.11828556j, var(E): 5.59471766
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 10000/ t/epoch=0.85............. Loss: 1.22572923, mean(E): -22.58832412-0.09937703j, var(E): 4.87001496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 10000/ t/epoch=0.85............. Loss: 1.05683691, mean(E): -22.59481855-0.06464898j, var(E): 5.89600659
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 10000/ t/epoch=0.85............. Loss: 0.48980581, mean(E): -22.79224144-0.08082376j, var(E): 6.85003429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 10000/ t/epoch=0.85............. Loss: 0.11410140, mean(E): -22.66963722+0.04210649j, var(E): 6.29727576
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 10000/ t/epoch=0.85............. Loss: -0.13009425, mean(E): -22.76439914+0.06883797j, var(E): 5.12360852
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 10000/ t/epoch=0.85............. Loss: -0.25435633, mean(E): -22.69277410+0.24237683j, var(E): 4.20208584
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 10000/ t/epoch=0.85............. Loss: 1.38023423, mean(E): -22.59876220-0.12970316j, var(E): 4.44721005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 10000/ t/epoch=0.85............. Loss: -0.25278247, mean(E): -22.63443243+0.06238470j, var(E): 5.11394128
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 10000/ t/epoch=0.85............. Loss: -0.54903912, mean(E): -22.45544285-0.03262239j, var(E): 5.34870560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 10000/ t/epoch=0.85............. Loss: 0.39398047, mean(E): -22.71872565-0.14512809j, var(E): 5.51312829
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 10000/ t/epoch=0.85............. Loss: -1.93519987, mean(E): -22.59936714-0.10848866j, var(E): 5.53498727
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 10000/ t/epoch=0.85............. Loss: 1.06801430, mean(E): -22.45706028-0.07513189j, var(E): 4.84599136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 10000/ t/epoch=0.85............. Loss: -1.62652969, mean(E): -22.46092925+0.07213544j, var(E): 10.11325538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 10000/ t/epoch=0.88............. Loss: 1.51343376, mean(E): -22.39805807+0.04751928j, var(E): 8.09642109
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 10000/ t/epoch=0.85............. Loss: -0.76858071, mean(E): -22.48062118-0.05830515j, var(E): 6.12392436
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 10000/ t/epoch=0.85............. Loss: -1.79024332, mean(E): -22.46714322-0.20027656j, var(E): 7.24509721
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 10000/ t/epoch=0.85............. Loss: -0.62998145, mean(E): -22.33928143+0.04757824j, var(E): 6.71424784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 10000/ t/epoch=0.85............. Loss: -0.49417822, mean(E): -22.52973364-0.15756106j, var(E): 6.44702579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 10000/ t/epoch=0.85............. Loss: 0.04115305, mean(E): -22.57082220-0.08661341j, var(E): 6.13335543
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 10000/ t/epoch=0.85............. Loss: -1.48898423, mean(E): -22.59382111-0.30042269j, var(E): 5.99622420
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 10000/ t/epoch=0.85............. Loss: 0.58143547, mean(E): -22.49441431-0.20889025j, var(E): 5.94911888
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 10000/ t/epoch=0.85............. Loss: 0.47307164, mean(E): -22.58266078-0.24587654j, var(E): 6.12168102
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 10000/ t/epoch=0.85............. Loss: -0.34718161, mean(E): -22.45087453-0.10363089j, var(E): 5.96608469
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 10000/ t/epoch=0.85............. Loss: 1.27752732, mean(E): -22.43542245+0.03502934j, var(E): 6.35180706
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 10000/ t/epoch=0.85............. Loss: -0.85009796, mean(E): -22.44523446-0.08052161j, var(E): 5.81318430
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 10000/ t/epoch=0.85............. Loss: -0.96575757, mean(E): -22.61834528-0.02994082j, var(E): 6.03347642
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 10000/ t/epoch=0.85............. Loss: 0.49521738, mean(E): -22.50866278-0.07277709j, var(E): 4.80798432
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 10000/ t/epoch=0.85............. Loss: -1.39192426, mean(E): -22.73729314-0.11222162j, var(E): 4.68965289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 10000/ t/epoch=0.85............. Loss: 0.89695101, mean(E): -22.82545238-0.00568229j, var(E): 8.18785967
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 10000/ t/epoch=0.85............. Loss: -1.39860502, mean(E): -22.45455728-0.15646756j, var(E): 5.33183476
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 10000/ t/epoch=0.85............. Loss: -1.72377007, mean(E): -22.58098936+0.04734274j, var(E): 8.80749951
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 10000/ t/epoch=0.85............. Loss: 0.06849391, mean(E): -22.44153100+0.03256667j, var(E): 7.42806107
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 10000/ t/epoch=0.85............. Loss: -0.44669203, mean(E): -22.34556214+0.04495259j, var(E): 6.07279303
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 10000/ t/epoch=0.85............. Loss: -0.86240651, mean(E): -22.58683187+0.04004149j, var(E): 4.88531241
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 10000/ t/epoch=0.85............. Loss: -1.24751289, mean(E): -22.83465113-0.12032500j, var(E): 5.78282164
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 10000/ t/epoch=0.85............. Loss: 2.10919885, mean(E): -22.66572847-0.03386118j, var(E): 5.11858444
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 10000/ t/epoch=0.85............. Loss: -2.03660784, mean(E): -22.51359925-0.04778124j, var(E): 9.43049602
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 10000/ t/epoch=0.85............. Loss: -1.03550913, mean(E): -22.61213786-0.02011075j, var(E): 7.76518279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 10000/ t/epoch=0.85............. Loss: 0.97527016, mean(E): -22.65095678+0.09262488j, var(E): 6.70202467
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 10000/ t/epoch=0.85............. Loss: -0.61404585, mean(E): -22.59615408-0.14468232j, var(E): 6.10606420
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 10000/ t/epoch=0.85............. Loss: -0.79186880, mean(E): -22.48630963-0.22010656j, var(E): 5.68195751
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 10000/ t/epoch=0.85............. Loss: -1.59415529, mean(E): -22.46604874-0.08229799j, var(E): 6.71196194
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 10000/ t/epoch=0.85............. Loss: -2.11716775, mean(E): -22.51778501-0.22689196j, var(E): 9.34671351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 10000/ t/epoch=0.85............. Loss: 1.00147874, mean(E): -22.60959917+0.04602216j, var(E): 6.09207373
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 10000/ t/epoch=0.85............. Loss: -1.48767106, mean(E): -22.50594657-0.06700139j, var(E): 5.52119341
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 10000/ t/epoch=0.85............. Loss: 0.32616079, mean(E): -22.79859163+0.02560006j, var(E): 8.16384417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 10000/ t/epoch=0.85............. Loss: -0.95226779, mean(E): -22.43084135+0.26050808j, var(E): 10.71777002
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 10000/ t/epoch=0.85............. Loss: -0.73270063, mean(E): -22.57582007-0.07396944j, var(E): 5.55337465
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 10000/ t/epoch=0.85............. Loss: 1.10661318, mean(E): -22.55417988+0.05176619j, var(E): 5.91574412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 10000/ t/epoch=0.85............. Loss: -0.20594100, mean(E): -22.55216316-0.14326447j, var(E): 6.35302268
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 10000/ t/epoch=0.85............. Loss: 0.87031831, mean(E): -22.69941401+0.14189132j, var(E): 5.93353152
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 10000/ t/epoch=0.85............. Loss: 0.06353009, mean(E): -22.60835711+0.26433857j, var(E): 7.16332201
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 10000/ t/epoch=0.85............. Loss: 1.25237704, mean(E): -22.53437206+0.11781096j, var(E): 4.20723592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 10000/ t/epoch=0.85............. Loss: 1.26883546, mean(E): -22.31652345+0.05058096j, var(E): 5.24853826
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 10000/ t/epoch=0.85............. Loss: -1.43413230, mean(E): -22.71584185+0.17911224j, var(E): 6.36265035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 10000/ t/epoch=0.85............. Loss: -0.24879525, mean(E): -22.56591162+0.28484909j, var(E): 7.00291521
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 10000/ t/epoch=0.85............. Loss: -0.13269414, mean(E): -22.62161122+0.02409361j, var(E): 5.39723696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 10000/ t/epoch=0.85............. Loss: -2.72665675, mean(E): -22.57951234-0.00067055j, var(E): 7.66610706
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 10000/ t/epoch=0.85............. Loss: 0.43177184, mean(E): -22.75259975-0.03288544j, var(E): 5.81963701
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 10000/ t/epoch=0.85............. Loss: -1.89507637, mean(E): -22.78063490+0.01104415j, var(E): 8.90106002
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 10000/ t/epoch=0.85............. Loss: -0.21555520, mean(E): -22.54296274+0.07793357j, var(E): 9.37878133
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 10000/ t/epoch=0.85............. Loss: -0.73620527, mean(E): -22.69018859+0.16261294j, var(E): 6.74009439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 10000/ t/epoch=0.85............. Loss: -2.39780576, mean(E): -22.57539459-0.08554619j, var(E): 5.48195802
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 10000/ t/epoch=0.85............. Loss: 2.19989890, mean(E): -22.73680472+0.10069133j, var(E): 9.47127954
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 10000/ t/epoch=0.85............. Loss: -0.36476361, mean(E): -22.54350118+0.03181083j, var(E): 6.58199310
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 10000/ t/epoch=0.85............. Loss: 0.34109079, mean(E): -22.84511740-0.01963458j, var(E): 5.21874655
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 10000/ t/epoch=0.85............. Loss: 0.64845933, mean(E): -22.65050932-0.01114768j, var(E): 5.94334151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 10000/ t/epoch=0.85............. Loss: 0.15091223, mean(E): -22.56059761-0.20916658j, var(E): 9.14362618
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 10000/ t/epoch=0.85............. Loss: -1.72876933, mean(E): -22.54227232-0.18556146j, var(E): 5.54677410
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 10000/ t/epoch=0.85............. Loss: -1.57239293, mean(E): -22.81373625-0.12699704j, var(E): 9.36151395
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 10000/ t/epoch=0.85............. Loss: 0.06026943, mean(E): -22.66523109-0.21609410j, var(E): 5.37330652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 10000/ t/epoch=0.85............. Loss: -0.96774890, mean(E): -22.68403427+0.02387848j, var(E): 8.69629384
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 10000/ t/epoch=0.85............. Loss: 0.41721849, mean(E): -22.69196492+0.00910398j, var(E): 9.65005859
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 10000/ t/epoch=0.85............. Loss: -0.38880439, mean(E): -22.53945745-0.11440980j, var(E): 6.88513406
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 10000/ t/epoch=0.85............. Loss: 0.92461359, mean(E): -22.61614429-0.24939750j, var(E): 5.98382491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 10000/ t/epoch=0.85............. Loss: -0.64583568, mean(E): -22.77102156-0.01595092j, var(E): 6.40059163
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 10000/ t/epoch=0.85............. Loss: -0.50545034, mean(E): -22.60122312-0.01181772j, var(E): 5.07473973
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 10000/ t/epoch=0.85............. Loss: -0.99815516, mean(E): -22.56085662+0.02810826j, var(E): 4.74364104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 10000/ t/epoch=0.85............. Loss: 1.68128497, mean(E): -22.67063807+0.14665311j, var(E): 6.09261359
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 10000/ t/epoch=0.85............. Loss: -0.40949306, mean(E): -22.47363484-0.09578346j, var(E): 8.39637164
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 10000/ t/epoch=0.85............. Loss: -2.88012689, mean(E): -22.35018290+0.18461159j, var(E): 8.21415488
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 10000/ t/epoch=0.85............. Loss: 0.48023715, mean(E): -22.56679370+0.05912233j, var(E): 8.71079224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 10000/ t/epoch=0.85............. Loss: -1.05768250, mean(E): -22.63486710-0.28791330j, var(E): 4.05495502
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 10000/ t/epoch=0.85............. Loss: -0.37829684, mean(E): -22.68215342-0.01654479j, var(E): 5.89646621
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 10000/ t/epoch=0.85............. Loss: -2.99625925, mean(E): -22.50803964-0.19098857j, var(E): 12.39915038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 10000/ t/epoch=0.85............. Loss: 1.26296700, mean(E): -22.66492537+0.29932550j, var(E): 6.10721618
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 10000/ t/epoch=0.85............. Loss: -0.02739392, mean(E): -22.72121340+0.21201307j, var(E): 5.44475042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 10000/ t/epoch=0.85............. Loss: 1.32324620, mean(E): -22.77694383+0.08727090j, var(E): 6.00674011
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 10000/ t/epoch=0.85............. Loss: 0.08620944, mean(E): -22.75549848-0.06907769j, var(E): 6.17227724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 10000/ t/epoch=0.85............. Loss: 0.14403477, mean(E): -22.63531435+0.19204545j, var(E): 5.69002905
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 10000/ t/epoch=0.85............. Loss: -0.39602016, mean(E): -22.70294838-0.10422715j, var(E): 7.96250293
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 10000/ t/epoch=0.85............. Loss: 0.62883084, mean(E): -22.79884514+0.04023064j, var(E): 5.76708505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 10000/ t/epoch=0.85............. Loss: -0.64113859, mean(E): -22.57166269+0.32378430j, var(E): 10.52116909
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 10000/ t/epoch=0.85............. Loss: -0.03021709, mean(E): -22.63605041+0.02032407j, var(E): 6.26871180
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 10000/ t/epoch=0.85............. Loss: 0.73548524, mean(E): -22.68937892-0.05479223j, var(E): 6.26559076
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 10000/ t/epoch=0.85............. Loss: 0.63851494, mean(E): -22.80181237-0.17005160j, var(E): 5.25053840
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 10000/ t/epoch=0.85............. Loss: -0.23640804, mean(E): -22.73512468-0.17381575j, var(E): 4.72843476
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 10000/ t/epoch=0.85............. Loss: -0.77587104, mean(E): -22.56362084-0.08638478j, var(E): 6.19075966
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 10000/ t/epoch=0.85............. Loss: 0.10690518, mean(E): -22.68879741-0.02491284j, var(E): 6.69003872
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 10000/ t/epoch=0.85............. Loss: -0.88088142, mean(E): -22.71029790-0.13379813j, var(E): 7.04432094
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 10000/ t/epoch=0.85............. Loss: 0.93402262, mean(E): -22.59923494-0.17951163j, var(E): 5.59105756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 10000/ t/epoch=0.85............. Loss: 0.48650051, mean(E): -22.57036996+0.05362565j, var(E): 6.27056176
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 10000/ t/epoch=0.85............. Loss: -2.20855622, mean(E): -22.69341771+0.10685073j, var(E): 5.91770626
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 10000/ t/epoch=0.85............. Loss: -0.84681307, mean(E): -22.59121956-0.10335016j, var(E): 6.28321951
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 10000/ t/epoch=0.85............. Loss: -2.65683000, mean(E): -22.88816905+0.15362922j, var(E): 6.39980701
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 10000/ t/epoch=0.85............. Loss: 0.97787442, mean(E): -22.59979288-0.09107918j, var(E): 5.80845192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 10000/ t/epoch=0.85............. Loss: -1.95234108, mean(E): -22.82613535+0.19957209j, var(E): 4.62126936
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 10000/ t/epoch=0.85............. Loss: 0.66474138, mean(E): -22.55443477+0.15346064j, var(E): 4.94301055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 10000/ t/epoch=0.88............. Loss: -0.34225869, mean(E): -22.62060385+0.02975067j, var(E): 6.22176481
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 10000/ t/epoch=0.85............. Loss: 0.18599882, mean(E): -22.57420500-0.04876566j, var(E): 8.59937293
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 10000/ t/epoch=0.85............. Loss: -0.77965477, mean(E): -22.64051297+0.19070533j, var(E): 4.56438022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 10000/ t/epoch=0.85............. Loss: -1.31743564, mean(E): -22.47679016-0.05631815j, var(E): 7.69562638
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 10000/ t/epoch=0.85............. Loss: 0.43611954, mean(E): -22.59183557-0.15095597j, var(E): 7.09714195
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 10000/ t/epoch=0.85............. Loss: 0.36022565, mean(E): -22.63747553-0.06409287j, var(E): 7.29769103
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 10000/ t/epoch=0.85............. Loss: -0.45956518, mean(E): -22.44561995-0.01030324j, var(E): 4.72381499
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 10000/ t/epoch=0.85............. Loss: -0.65480738, mean(E): -22.65405690+0.15114825j, var(E): 4.88613984
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 10000/ t/epoch=0.85............. Loss: -0.86252702, mean(E): -22.65459675+0.05603231j, var(E): 5.57111946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 10000/ t/epoch=0.85............. Loss: -0.00425379, mean(E): -22.57207512+0.15072431j, var(E): 6.56094452
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 10000/ t/epoch=0.85............. Loss: -0.34571162, mean(E): -22.55524482+0.06846747j, var(E): 5.19889309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 10000/ t/epoch=0.85............. Loss: 0.89770072, mean(E): -22.73830580-0.10836281j, var(E): 5.26112425
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 10000/ t/epoch=0.85............. Loss: 1.34844597, mean(E): -22.67068579+0.07558910j, var(E): 5.68306128
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 10000/ t/epoch=0.85............. Loss: -0.01972721, mean(E): -22.77163208-0.02444532j, var(E): 6.22112631
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 10000/ t/epoch=0.85............. Loss: -2.23060689, mean(E): -22.31436986+0.06049225j, var(E): 6.25199439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 10000/ t/epoch=0.85............. Loss: 1.34920994, mean(E): -22.72272883-0.12364130j, var(E): 5.30601215
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 10000/ t/epoch=0.85............. Loss: -0.90831018, mean(E): -22.91570495+0.12369704j, var(E): 5.98465012
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 10000/ t/epoch=0.85............. Loss: 1.00794951, mean(E): -22.53820372+0.00511994j, var(E): 5.40182252
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 10000/ t/epoch=0.85............. Loss: -2.30454284, mean(E): -22.63531775-0.17755276j, var(E): 7.27789465
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 10000/ t/epoch=0.85............. Loss: -0.23716677, mean(E): -22.74190527+0.02818859j, var(E): 5.16151102
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 10000/ t/epoch=0.85............. Loss: 1.30923175, mean(E): -22.75994554+0.17128497j, var(E): 7.33028752
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 10000/ t/epoch=0.85............. Loss: -0.73230627, mean(E): -22.87599019-0.22609955j, var(E): 6.58496801
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 10000/ t/epoch=0.85............. Loss: 0.42085427, mean(E): -22.57897197+0.03987726j, var(E): 6.03228693
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 10000/ t/epoch=0.85............. Loss: -3.06293410, mean(E): -22.53529010+0.03679151j, var(E): 8.49022579
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 10000/ t/epoch=0.85............. Loss: 1.15552487, mean(E): -22.63994370+0.02511171j, var(E): 5.21161412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 10000/ t/epoch=0.85............. Loss: -1.32304172, mean(E): -22.73652149-0.02906841j, var(E): 4.95964658
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 10000/ t/epoch=0.85............. Loss: 0.36918294, mean(E): -22.78228709+0.08369859j, var(E): 6.31169547
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 10000/ t/epoch=0.85............. Loss: -0.38492607, mean(E): -22.73040487+0.15262198j, var(E): 6.22261712
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 10000/ t/epoch=0.85............. Loss: 0.30722155, mean(E): -22.54699427-0.02371882j, var(E): 4.12768289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 10000/ t/epoch=0.85............. Loss: 0.28799336, mean(E): -22.81941168-0.13420858j, var(E): 4.11623846
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 10000/ t/epoch=0.85............. Loss: 0.92854482, mean(E): -22.82941957-0.01389937j, var(E): 5.58808736
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 10000/ t/epoch=0.85............. Loss: -0.66638949, mean(E): -22.59359156+0.08480924j, var(E): 6.68663212
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 10000/ t/epoch=0.85............. Loss: -0.80236902, mean(E): -22.75871834-0.25387298j, var(E): 4.85796459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 10000/ t/epoch=0.85............. Loss: -1.63642023, mean(E): -22.73350364-0.22802409j, var(E): 4.85924168
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 10000/ t/epoch=0.85............. Loss: -1.12249177, mean(E): -22.88494371-0.03776426j, var(E): 6.01425516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 10000/ t/epoch=0.85............. Loss: 0.95774148, mean(E): -22.89385799-0.02948591j, var(E): 5.12551418
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 10000/ t/epoch=0.85............. Loss: 0.28108914, mean(E): -22.52990130+0.06683122j, var(E): 5.93349540
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 10000/ t/epoch=0.85............. Loss: 0.06892754, mean(E): -22.74410173+0.00641562j, var(E): 6.83574961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 10000/ t/epoch=0.85............. Loss: 0.72589567, mean(E): -22.68664400+0.00646448j, var(E): 4.97878670
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 10000/ t/epoch=0.85............. Loss: 0.00057771, mean(E): -22.77011222+0.01173011j, var(E): 4.27935505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 10000/ t/epoch=0.85............. Loss: -0.44761829, mean(E): -22.94316174-0.19314533j, var(E): 7.63568857
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 10000/ t/epoch=0.85............. Loss: -0.44012175, mean(E): -22.82247665-0.06289862j, var(E): 5.88865382
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 10000/ t/epoch=0.85............. Loss: 0.65885469, mean(E): -22.48669327+0.33387648j, var(E): 8.13025214
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 10000/ t/epoch=0.85............. Loss: 1.88974014, mean(E): -22.61470322+0.05511105j, var(E): 7.29066200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 10000/ t/epoch=0.85............. Loss: -0.73537945, mean(E): -22.62718165+0.11865267j, var(E): 4.25460958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 10000/ t/epoch=0.85............. Loss: -0.23902764, mean(E): -22.63211830+0.01027282j, var(E): 7.21849107
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 10000/ t/epoch=0.85............. Loss: -0.78089953, mean(E): -22.48034380+0.08681657j, var(E): 9.64482903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 10000/ t/epoch=0.85............. Loss: -0.28034558, mean(E): -22.76337994+0.00448450j, var(E): 9.83067905
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 10000/ t/epoch=0.85............. Loss: -1.32354056, mean(E): -22.50777670-0.12356795j, var(E): 4.98337024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 10000/ t/epoch=0.85............. Loss: -2.96631985, mean(E): -22.66926699-0.12040095j, var(E): 6.34029032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 10000/ t/epoch=0.88............. Loss: -0.73178564, mean(E): -22.83928444+0.06896105j, var(E): 5.17977591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 10000/ t/epoch=0.85............. Loss: -0.23571425, mean(E): -22.75575077-0.06154083j, var(E): 5.62477542
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 10000/ t/epoch=0.85............. Loss: -0.89218474, mean(E): -22.71069503-0.18000861j, var(E): 6.45714396
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 10000/ t/epoch=0.85............. Loss: 0.50594624, mean(E): -22.74215702+0.09287501j, var(E): 6.36449868
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 10000/ t/epoch=0.85............. Loss: -0.45449936, mean(E): -22.61806605+0.15738687j, var(E): 5.06425779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 10000/ t/epoch=0.85............. Loss: 0.56429522, mean(E): -22.62203890+0.09862275j, var(E): 6.42428684
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 10000/ t/epoch=0.85............. Loss: -1.02531667, mean(E): -22.66684286+0.15614821j, var(E): 7.30268124
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 10000/ t/epoch=0.85............. Loss: -1.06114036, mean(E): -22.61169093-0.02977321j, var(E): 8.40703606
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 10000/ t/epoch=0.85............. Loss: -0.09660779, mean(E): -22.73855346+0.03573736j, var(E): 4.11359651
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 10000/ t/epoch=0.85............. Loss: -0.42255824, mean(E): -22.59365755-0.00432487j, var(E): 6.65139498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 10000/ t/epoch=0.85............. Loss: -0.48608568, mean(E): -22.56672484+0.04913389j, var(E): 5.80351355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 10000/ t/epoch=0.85............. Loss: -0.52506115, mean(E): -22.89226971+0.06851676j, var(E): 6.10842167
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 10000/ t/epoch=0.85............. Loss: 0.44889368, mean(E): -22.60711834-0.04226344j, var(E): 7.63203474
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 10000/ t/epoch=0.85............. Loss: -0.80453508, mean(E): -22.57252863-0.08215127j, var(E): 6.37126105
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 10000/ t/epoch=0.85............. Loss: -0.29589356, mean(E): -22.60587039+0.11225646j, var(E): 6.29167111
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 10000/ t/epoch=0.85............. Loss: 0.05943870, mean(E): -22.82082284-0.08092473j, var(E): 4.18445224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 10000/ t/epoch=0.85............. Loss: 0.43501825, mean(E): -22.77039681-0.05620378j, var(E): 5.15315765
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 10000/ t/epoch=0.85............. Loss: -0.41639926, mean(E): -22.94266434+0.12013193j, var(E): 6.37689751
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 10000/ t/epoch=0.85............. Loss: -0.59670736, mean(E): -22.63693439+0.02092160j, var(E): 5.13877941
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 10000/ t/epoch=0.85............. Loss: -1.47273193, mean(E): -22.67342073-0.06924559j, var(E): 5.43299576
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 10000/ t/epoch=0.85............. Loss: 0.18569743, mean(E): -22.80045811-0.14197006j, var(E): 6.52247589
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 10000/ t/epoch=0.85............. Loss: -0.54974268, mean(E): -22.84122662+0.03175527j, var(E): 5.20619726
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 10000/ t/epoch=0.85............. Loss: -0.31518233, mean(E): -22.60035906-0.18709072j, var(E): 7.86132616
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 10000/ t/epoch=0.85............. Loss: -1.46872568, mean(E): -22.59850039-0.06432374j, var(E): 6.15974823
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 10000/ t/epoch=0.85............. Loss: 0.81212781, mean(E): -22.77442927+0.02265900j, var(E): 9.00037127
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 10000/ t/epoch=0.85............. Loss: 1.60595320, mean(E): -22.73089186+0.08420620j, var(E): 4.35176093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 10000/ t/epoch=0.85............. Loss: -0.63262325, mean(E): -22.88509728+0.28390270j, var(E): 5.05869403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 10000/ t/epoch=0.85............. Loss: -1.83147069, mean(E): -22.85752583+0.02744511j, var(E): 6.90344173
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 10000/ t/epoch=0.85............. Loss: 0.76876481, mean(E): -22.67641650-0.26544060j, var(E): 8.69902983
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 10000/ t/epoch=0.85............. Loss: -0.53291555, mean(E): -22.69205915+0.18257154j, var(E): 6.02739010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 10000/ t/epoch=0.85............. Loss: 0.59651041, mean(E): -22.71877625+0.00924678j, var(E): 4.99963437
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 10000/ t/epoch=0.85............. Loss: -0.91871316, mean(E): -22.42757466-0.08494250j, var(E): 6.38909167
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 10000/ t/epoch=0.85............. Loss: -0.15062030, mean(E): -22.63873262+0.03476006j, var(E): 6.30600799
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 10000/ t/epoch=0.85............. Loss: 0.03483696, mean(E): -22.86172619-0.13491731j, var(E): 8.26484085
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 10000/ t/epoch=0.85............. Loss: 0.22215085, mean(E): -22.78621959-0.05615697j, var(E): 4.87818497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 10000/ t/epoch=0.85............. Loss: 0.48349643, mean(E): -22.76157066+0.05432728j, var(E): 3.67597236
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 10000/ t/epoch=0.85............. Loss: -0.19104129, mean(E): -22.79483410+0.05250527j, var(E): 4.18745057
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 10000/ t/epoch=0.85............. Loss: 1.19209014, mean(E): -23.01781334-0.19477161j, var(E): 5.44272278
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 10000/ t/epoch=0.85............. Loss: -0.10107730, mean(E): -22.68583109+0.03859097j, var(E): 4.77251426
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 10000/ t/epoch=0.85............. Loss: 0.39140400, mean(E): -22.63981122+0.00732403j, var(E): 4.93990696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 10000/ t/epoch=0.85............. Loss: 0.31484043, mean(E): -22.66628563+0.17006415j, var(E): 5.58610291
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 10000/ t/epoch=0.85............. Loss: 0.07654264, mean(E): -22.71315765-0.09602744j, var(E): 7.06007958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 10000/ t/epoch=0.85............. Loss: -0.08849685, mean(E): -22.83853509-0.08615097j, var(E): 6.01597438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 10000/ t/epoch=0.85............. Loss: -0.28883160, mean(E): -22.81058496-0.12347724j, var(E): 5.71240054
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 10000/ t/epoch=0.85............. Loss: -1.87311810, mean(E): -22.62117260+0.05627292j, var(E): 6.61262282
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 10000/ t/epoch=0.85............. Loss: 0.52365875, mean(E): -22.90823714-0.19380876j, var(E): 6.75366013
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 10000/ t/epoch=0.85............. Loss: 0.31558990, mean(E): -22.74949786+0.09483264j, var(E): 6.19224450
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 10000/ t/epoch=0.85............. Loss: -1.21160303, mean(E): -22.63537711-0.07357237j, var(E): 4.19381997
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 10000/ t/epoch=0.85............. Loss: 0.39370694, mean(E): -22.87733658-0.15399853j, var(E): 5.87114095
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 10000/ t/epoch=0.85............. Loss: 0.07150853, mean(E): -22.68448179+0.03676115j, var(E): 4.45161203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 10000/ t/epoch=0.85............. Loss: 0.59749591, mean(E): -22.84721862+0.02858617j, var(E): 6.86582763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 10000/ t/epoch=0.85............. Loss: -1.58695151, mean(E): -22.73602665+0.28460028j, var(E): 7.33706262
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 10000/ t/epoch=0.85............. Loss: 1.69391074, mean(E): -22.68878740+0.15141073j, var(E): 9.30225657
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 10000/ t/epoch=0.85............. Loss: -0.02709576, mean(E): -22.76724210+0.18645423j, var(E): 3.95429207
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 10000/ t/epoch=0.85............. Loss: -1.19672083, mean(E): -22.54641294-0.06594959j, var(E): 6.91718757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 10000/ t/epoch=0.85............. Loss: 0.90492552, mean(E): -22.99730934-0.03630577j, var(E): 5.47175709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 10000/ t/epoch=0.85............. Loss: -1.01401833, mean(E): -22.50540636+0.00347684j, var(E): 7.10587825
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 10000/ t/epoch=0.85............. Loss: -0.12527863, mean(E): -22.94381240+0.00097924j, var(E): 4.50423784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 10000/ t/epoch=0.85............. Loss: -1.50207433, mean(E): -22.76818466+0.12410686j, var(E): 5.48311143
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 10000/ t/epoch=0.85............. Loss: 0.49701263, mean(E): -22.69573350+0.11919303j, var(E): 5.13280538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 10000/ t/epoch=0.85............. Loss: -0.92604055, mean(E): -22.66167391+0.27291134j, var(E): 3.90526555
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 10000/ t/epoch=0.85............. Loss: -0.67711966, mean(E): -22.55522504+0.18297025j, var(E): 5.82744988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 10000/ t/epoch=0.85............. Loss: -1.35551798, mean(E): -22.56964021+0.04044483j, var(E): 5.35114861
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 10000/ t/epoch=0.85............. Loss: -0.28116612, mean(E): -22.82965528+0.21796967j, var(E): 6.74687612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 10000/ t/epoch=0.85............. Loss: 0.83544855, mean(E): -22.80514451-0.13917494j, var(E): 7.52717508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 10000/ t/epoch=0.85............. Loss: 1.35189823, mean(E): -22.95726688+0.11749960j, var(E): 4.14106726
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 10000/ t/epoch=0.85............. Loss: -0.88634805, mean(E): -22.74663970+0.14813788j, var(E): 4.18726859
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 10000/ t/epoch=0.85............. Loss: 0.19549484, mean(E): -22.83918723+0.09409153j, var(E): 5.57701923
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 10000/ t/epoch=0.85............. Loss: 1.39982555, mean(E): -22.90147530+0.14315977j, var(E): 5.08448022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 10000/ t/epoch=0.85............. Loss: 0.09468805, mean(E): -22.86707836+0.08016083j, var(E): 5.73070791
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 10000/ t/epoch=0.85............. Loss: -2.08358856, mean(E): -22.65201554+0.25073064j, var(E): 11.52634274
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 10000/ t/epoch=0.85............. Loss: -1.09244821, mean(E): -22.64008424+0.13701665j, var(E): 6.24436037
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 10000/ t/epoch=0.85............. Loss: 2.58227820, mean(E): -22.72000016+0.04815653j, var(E): 4.70669154
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 10000/ t/epoch=0.85............. Loss: -0.26742185, mean(E): -22.58043071+0.00752387j, var(E): 4.13038588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 10000/ t/epoch=0.85............. Loss: -2.00509336, mean(E): -22.62379145+0.14678506j, var(E): 7.03539742
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 10000/ t/epoch=0.85............. Loss: -1.27005252, mean(E): -22.67536713-0.12904622j, var(E): 6.30074218
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 10000/ t/epoch=0.85............. Loss: -0.52837385, mean(E): -22.71489409+0.03523462j, var(E): 5.25588471
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 10000/ t/epoch=0.85............. Loss: -0.84310849, mean(E): -22.74690369-0.00323093j, var(E): 5.42506035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 10000/ t/epoch=0.85............. Loss: 0.01372116, mean(E): -22.77345588+0.03670101j, var(E): 4.53587379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 10000/ t/epoch=0.85............. Loss: -0.19846493, mean(E): -22.71877527+0.05592067j, var(E): 5.57317310
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 10000/ t/epoch=0.85............. Loss: 0.53575509, mean(E): -22.68249675+0.15836117j, var(E): 5.30853129
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 10000/ t/epoch=0.85............. Loss: -2.58414141, mean(E): -22.74839990-0.06842622j, var(E): 5.95278591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 10000/ t/epoch=0.85............. Loss: 1.15004198, mean(E): -22.66808455+0.04957372j, var(E): 4.04403445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 10000/ t/epoch=0.85............. Loss: -2.01547577, mean(E): -22.77425481-0.13570173j, var(E): 7.14247122
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 10000/ t/epoch=0.85............. Loss: -0.30134954, mean(E): -22.63335336+0.07106727j, var(E): 5.99016348
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 10000/ t/epoch=0.85............. Loss: 0.80706192, mean(E): -22.51254575+0.07369050j, var(E): 7.17548211
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 10000/ t/epoch=0.85............. Loss: -0.16850376, mean(E): -22.58139568+0.11246116j, var(E): 4.00070141
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 10000/ t/epoch=0.85............. Loss: -0.73626236, mean(E): -22.49374325+0.21392945j, var(E): 6.17564915
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 10000/ t/epoch=0.85............. Loss: 0.25103997, mean(E): -22.80700471+0.01013487j, var(E): 5.78778205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 10000/ t/epoch=0.85............. Loss: 1.38979772, mean(E): -22.81481783-0.06059506j, var(E): 4.43919514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 10000/ t/epoch=0.85............. Loss: 0.62943774, mean(E): -22.71127108+0.06035496j, var(E): 5.43044780
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 10000/ t/epoch=0.85............. Loss: -0.83372708, mean(E): -22.81240623+0.05421878j, var(E): 6.77314203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 10000/ t/epoch=0.85............. Loss: -0.10005343, mean(E): -22.94319048+0.00231573j, var(E): 6.73043765
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 10000/ t/epoch=0.85............. Loss: -2.72129922, mean(E): -22.63745486+0.15131616j, var(E): 6.02042586
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 10000/ t/epoch=0.85............. Loss: -0.34181883, mean(E): -22.88244494+0.08943367j, var(E): 6.32497999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 10000/ t/epoch=0.85............. Loss: -0.61806128, mean(E): -22.93990880+0.25780863j, var(E): 6.84618256
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 10000/ t/epoch=0.85............. Loss: -2.51093509, mean(E): -22.54319637+0.19799160j, var(E): 7.89154536
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 10000/ t/epoch=0.85............. Loss: -0.15394938, mean(E): -22.85675301+0.07776918j, var(E): 6.88059794
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 10000/ t/epoch=0.85............. Loss: -1.43596111, mean(E): -22.84535767+0.08516613j, var(E): 6.24297981
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 10000/ t/epoch=0.85............. Loss: -0.36488180, mean(E): -22.65138003+0.10009639j, var(E): 5.52357507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 10000/ t/epoch=0.85............. Loss: -0.31159849, mean(E): -22.69385116+0.07909137j, var(E): 5.03239493
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 10000/ t/epoch=0.85............. Loss: -0.36014634, mean(E): -22.74128191+0.16518120j, var(E): 6.85416526
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 10000/ t/epoch=0.85............. Loss: -1.19059501, mean(E): -22.57967661+0.08770108j, var(E): 5.74513524
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 10000/ t/epoch=0.85............. Loss: 2.63922368, mean(E): -22.68383067+0.06716198j, var(E): 7.03467529
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 10000/ t/epoch=0.85............. Loss: 0.79539975, mean(E): -22.74847732+0.04215793j, var(E): 5.64661551
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 10000/ t/epoch=0.85............. Loss: -0.25876366, mean(E): -22.65084375-0.23572852j, var(E): 8.09070712
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 10000/ t/epoch=0.85............. Loss: -0.14432918, mean(E): -22.58962254+0.00762964j, var(E): 5.77547866
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 10000/ t/epoch=0.85............. Loss: 0.49413070, mean(E): -22.63538408-0.05658756j, var(E): 6.76712037
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 10000/ t/epoch=0.85............. Loss: 0.83630410, mean(E): -22.96936115-0.33027987j, var(E): 7.79255045
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 10000/ t/epoch=0.85............. Loss: 0.61688439, mean(E): -22.77475932-0.03901864j, var(E): 4.29670674
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 10000/ t/epoch=0.85............. Loss: -0.49236993, mean(E): -22.72573548+0.01358460j, var(E): 4.89527574
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 10000/ t/epoch=0.85............. Loss: -0.62986136, mean(E): -22.86257459-0.05498892j, var(E): 5.41629106
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 10000/ t/epoch=0.85............. Loss: 0.25877094, mean(E): -23.02588515+0.06353920j, var(E): 8.05573491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 10000/ t/epoch=0.85............. Loss: -0.06314180, mean(E): -22.65105125+0.09164676j, var(E): 5.31547725
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 10000/ t/epoch=0.85............. Loss: 0.56280238, mean(E): -22.95033399+0.05835772j, var(E): 5.40344719
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 10000/ t/epoch=0.85............. Loss: -1.42666506, mean(E): -22.68312522-0.02663771j, var(E): 7.53541807
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 10000/ t/epoch=0.85............. Loss: -0.03461286, mean(E): -22.54825469-0.15890364j, var(E): 5.65247672
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 10000/ t/epoch=0.85............. Loss: -1.30200755, mean(E): -22.96324947+0.12877540j, var(E): 6.22362248
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 10000/ t/epoch=0.85............. Loss: -0.05678383, mean(E): -22.54423828+0.11770944j, var(E): 4.84452625
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 10000/ t/epoch=0.85............. Loss: -3.16039703, mean(E): -22.73299206-0.01485240j, var(E): 6.13057433
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 10000/ t/epoch=0.85............. Loss: 0.40213350, mean(E): -22.79256112-0.08229718j, var(E): 4.40619814
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 10000/ t/epoch=0.85............. Loss: -0.69238694, mean(E): -22.80097459-0.17645012j, var(E): 9.54919858
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 10000/ t/epoch=0.85............. Loss: -0.34792081, mean(E): -22.52810263-0.00408826j, var(E): 6.35290652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 10000/ t/epoch=0.85............. Loss: -1.44808380, mean(E): -22.73095920+0.16002151j, var(E): 6.84390276
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 10000/ t/epoch=0.85............. Loss: 0.50532770, mean(E): -22.68281367-0.00311643j, var(E): 5.38287454
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 10000/ t/epoch=0.85............. Loss: -0.86290153, mean(E): -22.58355060+0.17791771j, var(E): 3.65632773
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 10000/ t/epoch=0.85............. Loss: 0.61290144, mean(E): -22.57003327+0.17021801j, var(E): 6.58160525
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 10000/ t/epoch=0.85............. Loss: 0.65996850, mean(E): -22.70910981-0.14645448j, var(E): 5.11739292
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 10000/ t/epoch=0.85............. Loss: 0.59896288, mean(E): -22.61312911+0.15716842j, var(E): 6.64870176
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 10000/ t/epoch=0.85............. Loss: 1.05332308, mean(E): -22.85672010+0.00135200j, var(E): 5.83947621
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 10000/ t/epoch=0.85............. Loss: 0.34123929, mean(E): -22.55888223+0.05168892j, var(E): 5.19368118
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 10000/ t/epoch=0.85............. Loss: -1.16393796, mean(E): -22.87283908-0.25541685j, var(E): 7.96740156
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 10000/ t/epoch=0.85............. Loss: -0.65846124, mean(E): -22.76950095-0.20424136j, var(E): 6.19990158
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 10000/ t/epoch=0.85............. Loss: -1.19974824, mean(E): -22.60837884+0.09093598j, var(E): 5.25484789
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 10000/ t/epoch=0.85............. Loss: 0.09136846, mean(E): -22.69892728+0.03219996j, var(E): 5.41133312
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 10000/ t/epoch=0.85............. Loss: 2.63926467, mean(E): -22.91519891-0.06944514j, var(E): 5.42992897
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 10000/ t/epoch=0.85............. Loss: -0.37109070, mean(E): -22.72818767-0.28421339j, var(E): 4.91698529
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 10000/ t/epoch=0.85............. Loss: -0.36426045, mean(E): -22.98734329-0.05451429j, var(E): 6.37505835
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 10000/ t/epoch=0.85............. Loss: -1.20830899, mean(E): -22.65197093-0.33138097j, var(E): 7.68510424
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 10000/ t/epoch=0.85............. Loss: 0.39170671, mean(E): -22.67381642-0.02186319j, var(E): 4.65584075
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 10000/ t/epoch=0.85............. Loss: -1.75962129, mean(E): -22.59840573+0.01066100j, var(E): 8.67329887
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 10000/ t/epoch=0.85............. Loss: -1.56891721, mean(E): -22.61459724-0.09449521j, var(E): 4.64351699
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 10000/ t/epoch=0.85............. Loss: 0.76886159, mean(E): -22.76100666-0.02206242j, var(E): 8.08277679
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 10000/ t/epoch=0.85............. Loss: 0.63914513, mean(E): -22.86207946-0.01737454j, var(E): 4.93310931
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 10000/ t/epoch=0.85............. Loss: -0.37585448, mean(E): -22.70306707-0.07386481j, var(E): 4.16606445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 10000/ t/epoch=0.85............. Loss: -1.95014711, mean(E): -22.63453332+0.06150022j, var(E): 6.25084497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 10000/ t/epoch=0.85............. Loss: 2.06408199, mean(E): -22.69866368-0.13159347j, var(E): 5.16095869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 10000/ t/epoch=0.85............. Loss: -0.17184069, mean(E): -22.51253689+0.12796825j, var(E): 8.02841585
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 10000/ t/epoch=0.88............. Loss: -0.52813611, mean(E): -22.66902113-0.08013498j, var(E): 5.62201553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 10000/ t/epoch=0.85............. Loss: -1.45358309, mean(E): -22.52784471-0.02137277j, var(E): 6.50808031
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 10000/ t/epoch=0.85............. Loss: -0.69535991, mean(E): -22.76094185+0.02227416j, var(E): 5.99741863
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 10000/ t/epoch=0.85............. Loss: -1.48413005, mean(E): -22.84750241+0.25569268j, var(E): 5.29260693
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 10000/ t/epoch=0.85............. Loss: 0.24128453, mean(E): -22.55589495+0.04119717j, var(E): 6.94840619
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 10000/ t/epoch=0.85............. Loss: -1.35099123, mean(E): -22.74040271-0.11886508j, var(E): 4.05769362
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 10000/ t/epoch=0.85............. Loss: -0.48134048, mean(E): -22.88356661-0.12963391j, var(E): 6.62281376
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 10000/ t/epoch=0.85............. Loss: -2.48110465, mean(E): -22.49599012-0.15566108j, var(E): 7.39132013
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 10000/ t/epoch=0.85............. Loss: 0.09239075, mean(E): -22.65747501-0.03741670j, var(E): 5.95415754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 10000/ t/epoch=0.85............. Loss: 1.44510010, mean(E): -22.65168078-0.21583132j, var(E): 5.16575429
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 10000/ t/epoch=0.85............. Loss: 0.07053890, mean(E): -22.70880304+0.04631481j, var(E): 5.17080798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 10000/ t/epoch=0.85............. Loss: -1.04800296, mean(E): -22.80724029-0.19404099j, var(E): 4.07421877
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 10000/ t/epoch=0.85............. Loss: -3.09629588, mean(E): -22.82427923+0.08573855j, var(E): 6.94778815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 10000/ t/epoch=0.85............. Loss: 1.29351935, mean(E): -22.59596466+0.11469137j, var(E): 8.51495381
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 10000/ t/epoch=0.85............. Loss: -1.18851823, mean(E): -22.98709951+0.00230652j, var(E): 4.66807963
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 10000/ t/epoch=0.85............. Loss: -0.46713491, mean(E): -22.74777513+0.11185977j, var(E): 6.39196578
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 10000/ t/epoch=0.85............. Loss: 0.25878587, mean(E): -22.74324005-0.03902414j, var(E): 4.73796276
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 10000/ t/epoch=0.85............. Loss: -0.94656414, mean(E): -22.79417082-0.03676332j, var(E): 6.26020186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 10000/ t/epoch=0.85............. Loss: -1.12463259, mean(E): -22.73960541+0.05196433j, var(E): 7.56055817
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 10000/ t/epoch=0.85............. Loss: -0.39232456, mean(E): -23.02881961+0.05641094j, var(E): 6.76937947
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 10000/ t/epoch=0.85............. Loss: 0.36603123, mean(E): -23.07204016+0.02154593j, var(E): 5.51607487
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 10000/ t/epoch=0.85............. Loss: 0.25016910, mean(E): -22.59961982-0.19256574j, var(E): 5.20459991
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 10000/ t/epoch=0.85............. Loss: -4.09864631, mean(E): -22.77866307+0.21088473j, var(E): 5.58683518
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 10000/ t/epoch=0.85............. Loss: 1.56693861, mean(E): -22.75622370+0.10037643j, var(E): 5.35597203
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 10000/ t/epoch=0.88............. Loss: -2.80049841, mean(E): -22.60576726-0.00123121j, var(E): 10.12031549
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 10000/ t/epoch=0.85............. Loss: 0.20607671, mean(E): -22.97615278+0.04075990j, var(E): 2.92664483
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 10000/ t/epoch=0.85............. Loss: -1.19892482, mean(E): -22.75285109+0.16547558j, var(E): 6.40111259
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 10000/ t/epoch=0.85............. Loss: 1.63195429, mean(E): -22.71764133+0.04841949j, var(E): 5.20094482
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 10000/ t/epoch=0.85............. Loss: 0.34986030, mean(E): -22.92828427+0.10694041j, var(E): 5.99511063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 10000/ t/epoch=0.85............. Loss: 0.84763024, mean(E): -22.90310858+0.14712178j, var(E): 6.24754565
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 10000/ t/epoch=0.85............. Loss: -0.38674339, mean(E): -22.65559876-0.20319193j, var(E): 6.12177693
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 10000/ t/epoch=0.85............. Loss: -0.39351412, mean(E): -22.79039110-0.10191021j, var(E): 5.97885865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 10000/ t/epoch=0.85............. Loss: 0.17820027, mean(E): -22.82293337+0.09423722j, var(E): 4.25102027
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 10000/ t/epoch=0.85............. Loss: 1.08074486, mean(E): -22.88699784-0.09268722j, var(E): 4.51904252
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 10000/ t/epoch=0.85............. Loss: -0.28568398, mean(E): -22.70589378-0.11921944j, var(E): 5.28419559
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 10000/ t/epoch=0.85............. Loss: 1.04486274, mean(E): -22.62061183+0.04833675j, var(E): 4.98763827
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 10000/ t/epoch=0.85............. Loss: 0.25990153, mean(E): -22.70870650-0.03435679j, var(E): 5.58571483
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 10000/ t/epoch=0.85............. Loss: -0.38773546, mean(E): -22.86966085+0.08656686j, var(E): 3.73303618
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 10000/ t/epoch=0.85............. Loss: -0.20301746, mean(E): -22.56102222-0.01527539j, var(E): 6.56323438
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 10000/ t/epoch=0.85............. Loss: 1.53951884, mean(E): -22.84180842-0.09114874j, var(E): 6.41618497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 10000/ t/epoch=0.85............. Loss: -0.29305101, mean(E): -22.59113001+0.16437597j, var(E): 5.29499388
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 10000/ t/epoch=0.85............. Loss: 0.48063998, mean(E): -22.66022095-0.01786777j, var(E): 5.47958728
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 10000/ t/epoch=0.85............. Loss: -1.24589168, mean(E): -22.76106721-0.05485000j, var(E): 4.04521578
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 10000/ t/epoch=0.85............. Loss: -2.95254920, mean(E): -22.72388134-0.01934343j, var(E): 8.01630284
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 10000/ t/epoch=0.85............. Loss: 0.62621898, mean(E): -22.47235387+0.14227659j, var(E): 5.65121951
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 10000/ t/epoch=0.85............. Loss: -1.13284613, mean(E): -22.87484440+0.04157595j, var(E): 5.57352056
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 10000/ t/epoch=0.85............. Loss: -0.55296522, mean(E): -22.85807677+0.02059604j, var(E): 4.55103215
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 10000/ t/epoch=0.85............. Loss: 0.22819349, mean(E): -22.86183781-0.06165204j, var(E): 5.96101563
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 10000/ t/epoch=0.85............. Loss: 0.24474954, mean(E): -22.72217868+0.07637995j, var(E): 4.17405069
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 10000/ t/epoch=0.85............. Loss: -0.53260530, mean(E): -22.69297204+0.14982036j, var(E): 5.53458044
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 10000/ t/epoch=0.85............. Loss: 0.57941021, mean(E): -22.74562981+0.04322054j, var(E): 4.38732236
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 10000/ t/epoch=0.85............. Loss: 0.97924540, mean(E): -22.72788131+0.07745880j, var(E): 4.54810202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 10000/ t/epoch=0.85............. Loss: -2.62174044, mean(E): -22.49782467+0.09391889j, var(E): 8.07406298
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 10000/ t/epoch=0.85............. Loss: 0.65691988, mean(E): -22.63816136-0.15890171j, var(E): 5.70235685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 10000/ t/epoch=0.85............. Loss: 0.28147139, mean(E): -22.70473133+0.13556200j, var(E): 5.53748629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 10000/ t/epoch=0.85............. Loss: -3.31073349, mean(E): -22.88807894+0.07824431j, var(E): 9.61856836
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 10000/ t/epoch=0.85............. Loss: 0.71011156, mean(E): -22.83543986-0.15873113j, var(E): 5.25859004
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 10000/ t/epoch=0.85............. Loss: -0.16558531, mean(E): -22.58349276+0.04330933j, var(E): 5.07061038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 10000/ t/epoch=0.85............. Loss: -1.18475286, mean(E): -22.85119298-0.07967617j, var(E): 4.98516971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 10000/ t/epoch=0.85............. Loss: -0.12377003, mean(E): -22.85559187-0.04051233j, var(E): 5.64140246
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 10000/ t/epoch=0.85............. Loss: -0.48423936, mean(E): -22.76703468-0.10017565j, var(E): 5.81113807
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 10000/ t/epoch=0.85............. Loss: -0.11760388, mean(E): -22.74534041+0.03741925j, var(E): 4.02960335
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 10000/ t/epoch=0.85............. Loss: -0.44981396, mean(E): -23.05890651+0.03836653j, var(E): 5.50876049
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 10000/ t/epoch=0.85............. Loss: 1.58438760, mean(E): -22.56529791-0.00563903j, var(E): 4.16413551
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 10000/ t/epoch=0.85............. Loss: -0.90222623, mean(E): -22.71908358-0.02635594j, var(E): 5.93555437
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 10000/ t/epoch=0.85............. Loss: 0.80663190, mean(E): -22.74114599-0.20314175j, var(E): 6.35695553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 10000/ t/epoch=0.85............. Loss: -1.12288697, mean(E): -22.65736489+0.03594537j, var(E): 4.93542325
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 10000/ t/epoch=0.85............. Loss: -0.38539111, mean(E): -22.83720435+0.19505764j, var(E): 4.99979565
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 10000/ t/epoch=0.85............. Loss: -1.09240920, mean(E): -22.77018392-0.06361341j, var(E): 4.91851657
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 10000/ t/epoch=0.85............. Loss: 0.67274450, mean(E): -22.74972369+0.08692244j, var(E): 4.20367090
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 10000/ t/epoch=0.85............. Loss: 0.16246187, mean(E): -22.63023981+0.21435084j, var(E): 7.62586758
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 10000/ t/epoch=0.85............. Loss: -1.55197562, mean(E): -22.62305111+0.13709798j, var(E): 5.28659379
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 10000/ t/epoch=0.85............. Loss: 1.14899935, mean(E): -22.86877863+0.18686196j, var(E): 5.63905442
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 10000/ t/epoch=0.85............. Loss: -1.19295118, mean(E): -23.02958234+0.04270095j, var(E): 6.24340647
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 10000/ t/epoch=0.85............. Loss: -1.06467019, mean(E): -22.64259949-0.01125836j, var(E): 8.34820239
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 10000/ t/epoch=0.85............. Loss: -0.42066654, mean(E): -22.63223545+0.02079662j, var(E): 5.57376498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 10000/ t/epoch=0.85............. Loss: -0.12329357, mean(E): -22.79011442+0.04587583j, var(E): 5.44122658
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 10000/ t/epoch=0.85............. Loss: -0.16807836, mean(E): -22.85186053-0.04678296j, var(E): 8.22133945
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 10000/ t/epoch=0.85............. Loss: -2.20377926, mean(E): -22.76242442-0.02766919j, var(E): 6.24345646
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 10000/ t/epoch=0.85............. Loss: -0.19939175, mean(E): -22.64638056+0.17298353j, var(E): 6.84665205
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 10000/ t/epoch=0.85............. Loss: -0.24007565, mean(E): -22.75373773-0.00309770j, var(E): 6.67799071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 10000/ t/epoch=0.85............. Loss: 0.97507917, mean(E): -22.78995069-0.10822360j, var(E): 4.47639764
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 10000/ t/epoch=0.85............. Loss: 1.87146865, mean(E): -23.03142034-0.35235164j, var(E): 7.92402931
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 10000/ t/epoch=0.85............. Loss: -1.51397706, mean(E): -22.81436292+0.08022107j, var(E): 6.07256929
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 10000/ t/epoch=0.85............. Loss: -2.29614469, mean(E): -22.69936655-0.08900407j, var(E): 6.48363385
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 10000/ t/epoch=0.85............. Loss: 0.62348075, mean(E): -22.77839859+0.08021363j, var(E): 6.11726293
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 10000/ t/epoch=0.85............. Loss: -1.14597921, mean(E): -22.63773131-0.01882272j, var(E): 5.36241515
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 10000/ t/epoch=0.85............. Loss: -0.42767299, mean(E): -22.63739341-0.03277149j, var(E): 4.99065259
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 10000/ t/epoch=0.85............. Loss: -2.04573846, mean(E): -22.80537418-0.02864455j, var(E): 5.59449883
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 10000/ t/epoch=0.85............. Loss: -0.62748958, mean(E): -22.96766789-0.19395318j, var(E): 4.74466593
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 10000/ t/epoch=0.85............. Loss: -0.53349365, mean(E): -22.83660012-0.01059779j, var(E): 4.57182571
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 10000/ t/epoch=0.85............. Loss: 0.68365362, mean(E): -22.93297889-0.02307331j, var(E): 6.04054538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 10000/ t/epoch=0.85............. Loss: 1.74429777, mean(E): -22.95329146-0.25182306j, var(E): 6.62555950
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 10000/ t/epoch=0.85............. Loss: -2.45388714, mean(E): -22.81623693-0.09577878j, var(E): 5.72224257
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 10000/ t/epoch=0.85............. Loss: -1.66291352, mean(E): -22.77077153-0.06279956j, var(E): 5.21343617
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 10000/ t/epoch=0.85............. Loss: 0.75357409, mean(E): -22.56897938-0.14037417j, var(E): 4.40364278
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 10000/ t/epoch=0.85............. Loss: 1.12482378, mean(E): -22.80309645-0.23352527j, var(E): 4.74792661
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 10000/ t/epoch=0.85............. Loss: -1.62834919, mean(E): -22.76680576+0.05395300j, var(E): 4.52075244
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 10000/ t/epoch=0.85............. Loss: 0.70255462, mean(E): -22.88205398-0.01808295j, var(E): 4.98563654
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 10000/ t/epoch=0.85............. Loss: -0.64531865, mean(E): -22.64642660+0.00953919j, var(E): 5.91729779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 10000/ t/epoch=0.85............. Loss: -0.78215160, mean(E): -22.78297042+0.02894335j, var(E): 7.08426695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 10000/ t/epoch=0.85............. Loss: 0.00284851, mean(E): -23.09496594+0.04964654j, var(E): 4.51664846
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 10000/ t/epoch=0.85............. Loss: -1.34276182, mean(E): -22.89288106+0.08208421j, var(E): 6.02330439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 10000/ t/epoch=0.85............. Loss: 0.17177634, mean(E): -22.84908196+0.13293570j, var(E): 4.18433525
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 10000/ t/epoch=0.85............. Loss: -1.39879319, mean(E): -22.54974582+0.00655765j, var(E): 8.47946716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 10000/ t/epoch=0.85............. Loss: -0.28774890, mean(E): -22.83578728-0.07085230j, var(E): 7.18927309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 10000/ t/epoch=0.85............. Loss: -0.92139130, mean(E): -22.86596487+0.03529319j, var(E): 5.49471261
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 10000/ t/epoch=0.85............. Loss: -0.11028705, mean(E): -22.76759101-0.10056293j, var(E): 4.10704317
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 10000/ t/epoch=0.85............. Loss: -0.73842489, mean(E): -22.65269075+0.11680272j, var(E): 5.54373820
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 10000/ t/epoch=0.85............. Loss: -0.71882844, mean(E): -22.86488087+0.06887706j, var(E): 4.47705703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 10000/ t/epoch=0.85............. Loss: -1.22777315, mean(E): -22.77310990+0.10816680j, var(E): 4.17042612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 10000/ t/epoch=0.85............. Loss: -0.37016770, mean(E): -22.80414380-0.12465128j, var(E): 4.62412879
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 10000/ t/epoch=0.85............. Loss: -1.94496979, mean(E): -22.49418980-0.03049576j, var(E): 7.15317747
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 10000/ t/epoch=0.85............. Loss: -0.66957779, mean(E): -22.52412375-0.00378670j, var(E): 5.93582041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 10000/ t/epoch=0.85............. Loss: -0.19999216, mean(E): -22.72176954+0.05781914j, var(E): 3.84419975
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 10000/ t/epoch=0.85............. Loss: -2.00681765, mean(E): -22.61000887-0.08899215j, var(E): 5.66496179
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 10000/ t/epoch=0.85............. Loss: 0.83236478, mean(E): -22.81978988+0.02496187j, var(E): 6.43072784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 10000/ t/epoch=0.85............. Loss: -0.87388601, mean(E): -22.90451037+0.12007882j, var(E): 5.57885035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 10000/ t/epoch=0.85............. Loss: 0.50007528, mean(E): -22.81180838-0.17769589j, var(E): 4.47731507
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 10000/ t/epoch=0.85............. Loss: 2.42895659, mean(E): -22.85511899-0.06445729j, var(E): 4.98566735
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 10000/ t/epoch=0.85............. Loss: -0.53298510, mean(E): -22.70592876-0.07234846j, var(E): 4.14824944
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 10000/ t/epoch=0.85............. Loss: -0.39608534, mean(E): -22.91493811-0.08159357j, var(E): 5.07240089
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 10000/ t/epoch=0.85............. Loss: -0.27797464, mean(E): -22.66174863-0.05657011j, var(E): 5.27181048
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 10000/ t/epoch=0.85............. Loss: -0.40906422, mean(E): -22.76876531+0.01497069j, var(E): 4.09918249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 10000/ t/epoch=0.85............. Loss: -0.64180448, mean(E): -22.49355889+0.04736382j, var(E): 9.08420766
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 10000/ t/epoch=0.85............. Loss: -0.84692511, mean(E): -22.82934378-0.08196660j, var(E): 6.30456968
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 10000/ t/epoch=0.85............. Loss: 0.26667629, mean(E): -22.64272580-0.07282046j, var(E): 5.79824394
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 10000/ t/epoch=0.85............. Loss: -0.85480537, mean(E): -22.81415030-0.11236518j, var(E): 5.48997221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 10000/ t/epoch=0.85............. Loss: -0.58647016, mean(E): -22.78577887-0.15065527j, var(E): 4.17046648
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 10000/ t/epoch=0.85............. Loss: -0.22384977, mean(E): -22.68432630-0.03287225j, var(E): 5.85312168
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 10000/ t/epoch=0.85............. Loss: -0.15655458, mean(E): -22.88104642-0.03211912j, var(E): 3.90817514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 10000/ t/epoch=0.85............. Loss: -1.21212906, mean(E): -22.79749642-0.13299825j, var(E): 5.82185096
