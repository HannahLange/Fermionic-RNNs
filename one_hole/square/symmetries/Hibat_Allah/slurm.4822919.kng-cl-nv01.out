/var/spool/slurmd/job4822919/slurm_script: line 14: ../../ML_Environment/bin/activate: No such file or directory
1.13.1+cu117
GPU is available
Namespace(Jp=0.0, Jz=1.0, Nx=4, Ny=4, U=1.0, antisym=0.0, bounds=1, boundsx=0, boundsy=0, density=1.0, hd=70, load_model=0, sym=0.0, t=3.0)
4x4_qubits/periodic/Jp=0.0Jz=1.0t=0.0den=1.00/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 10000/ t/epoch=2.88............. Loss: 0.83245591, mean(E): -8.12500000+0.00000000j, var(E): 2.23052765
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 10000/ t/epoch=1.06............. Loss: 0.63206285, mean(E): -8.18000000+0.00000000j, var(E): 1.76643217
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 10000/ t/epoch=1.06............. Loss: 0.61001557, mean(E): -8.05000000+0.00000000j, var(E): 1.91708544
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 10000/ t/epoch=1.06............. Loss: 0.63661834, mean(E): -8.09000000+0.00000000j, var(E): 2.05216083
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 10000/ t/epoch=1.06............. Loss: 0.47413711, mean(E): -8.10000000+0.00000000j, var(E): 1.60804021
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 10000/ t/epoch=1.06............. Loss: 0.62558513, mean(E): -8.09500000+0.00000000j, var(E): 1.94570353
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(10.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 10000/ t/epoch=1.06............. Loss: 0.76658114, mean(E): -8.18000000+0.00000000j, var(E): 1.99758796
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 10000/ t/epoch=1.06............. Loss: 0.48493078, mean(E): -8.22500000+0.00000000j, var(E): 1.96419600
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 10000/ t/epoch=1.06............. Loss: 0.49539784, mean(E): -8.09500000+0.00000000j, var(E): 1.91555277
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 10000/ t/epoch=1.06............. Loss: 0.17936394, mean(E): -8.61500000+0.00000000j, var(E): 1.81585428
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 10000/ t/epoch=1.06............. Loss: -0.33805194, mean(E): -8.79500000+0.00000000j, var(E): 2.24419599
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 10000/ t/epoch=1.06............. Loss: -1.38610020, mean(E): -9.43500000+0.00000000j, var(E): 3.61384425
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 10000/ t/epoch=1.06............. Loss: -2.24470555, mean(E): -10.19000000+0.00000000j, var(E): 3.90341713
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 10000/ t/epoch=1.06............. Loss: -2.71952569, mean(E): -10.81500000+0.00000000j, var(E): 3.96057793
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(11.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 10000/ t/epoch=1.06............. Loss: -2.64874784, mean(E): -11.21500000+0.00000000j, var(E): 3.84801511
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 10000/ t/epoch=1.07............. Loss: -3.03054498, mean(E): -11.26500000+0.00000000j, var(E): 4.26610557
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 10000/ t/epoch=1.07............. Loss: -2.55452261, mean(E): -11.74500000+0.00000000j, var(E): 3.82912064
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 10000/ t/epoch=1.06............. Loss: -2.42242539, mean(E): -11.88000000+0.00000000j, var(E): 3.53326636
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 10000/ t/epoch=1.06............. Loss: -2.37399427, mean(E): -12.04000000+0.00000000j, var(E): 3.61648245
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 10000/ t/epoch=1.06............. Loss: -2.30693131, mean(E): -12.46500000+0.00000000j, var(E): 3.30530153
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 10000/ t/epoch=1.06............. Loss: -1.98647707, mean(E): -12.51500000+0.00000000j, var(E): 2.88419600
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 10000/ t/epoch=1.06............. Loss: -2.28195640, mean(E): -12.54500000+0.00000000j, var(E): 3.31454776
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 10000/ t/epoch=1.06............. Loss: -2.24323906, mean(E): -13.00000000+0.00000000j, var(E): 3.43718596
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 10000/ t/epoch=1.06............. Loss: -2.39927530, mean(E): -12.87000000+0.00000000j, var(E): 3.61115581
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 10000/ t/epoch=1.06............. Loss: -2.19815937, mean(E): -13.16500000+0.00000000j, var(E): 3.39474877
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(12.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 10000/ t/epoch=1.06............. Loss: -2.35039981, mean(E): -13.33500000+0.00000000j, var(E): 3.29927138
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 10000/ t/epoch=1.06............. Loss: -2.33816818, mean(E): -13.43500000+0.00000000j, var(E): 2.97062817
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 10000/ t/epoch=1.06............. Loss: -1.98194979, mean(E): -13.39500000+0.00000000j, var(E): 2.93364324
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 10000/ t/epoch=1.06............. Loss: -2.07378095, mean(E): -13.40000000+0.00000000j, var(E): 2.86432163
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 10000/ t/epoch=1.06............. Loss: -2.02986786, mean(E): -13.50500000+0.00000000j, var(E): 2.74369349
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 10000/ t/epoch=1.07............. Loss: -1.83762951, mean(E): -13.58000000+0.00000000j, var(E): 2.59658293
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 10000/ t/epoch=1.06............. Loss: -2.05503422, mean(E): -13.89500000+0.00000000j, var(E): 2.65726133
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 10000/ t/epoch=1.06............. Loss: -1.81529820, mean(E): -13.79500000+0.00000000j, var(E): 2.55575379
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 10000/ t/epoch=1.06............. Loss: -2.06879168, mean(E): -13.81500000+0.00000000j, var(E): 2.77464827
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 10000/ t/epoch=1.06............. Loss: -2.10101322, mean(E): -14.00000000+0.00000000j, var(E): 2.73366836
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 10000/ t/epoch=1.06............. Loss: -2.04111272, mean(E): -14.02000000+0.00000000j, var(E): 2.56241208
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 10000/ t/epoch=1.06............. Loss: -2.25584707, mean(E): -13.90000000+0.00000000j, var(E): 2.80402012
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 10000/ t/epoch=1.06............. Loss: -1.91297379, mean(E): -14.18000000+0.00000000j, var(E): 2.48000002
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 10000/ t/epoch=1.06............. Loss: -2.13562401, mean(E): -14.07500000+0.00000000j, var(E): 2.66268847
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 10000/ t/epoch=1.07............. Loss: -2.13977837, mean(E): -14.08500000+0.00000000j, var(E): 2.58067841
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 10000/ t/epoch=1.06............. Loss: -1.99658761, mean(E): -14.01500000+0.00000000j, var(E): 2.51736184
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 10000/ t/epoch=1.06............. Loss: -1.95015169, mean(E): -14.11000000+0.00000000j, var(E): 2.44010052
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 10000/ t/epoch=1.06............. Loss: -1.95708706, mean(E): -14.38500000+0.00000000j, var(E): 2.44902012
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 10000/ t/epoch=1.06............. Loss: -2.05121233, mean(E): -14.43000000+0.00000000j, var(E): 2.45738696
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 10000/ t/epoch=1.07............. Loss: -1.97740709, mean(E): -14.38500000+0.00000000j, var(E): 2.38871862
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 10000/ t/epoch=1.06............. Loss: -1.86508642, mean(E): -14.66000000+0.00000000j, var(E): 2.25567841
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 10000/ t/epoch=1.06............. Loss: -1.67433296, mean(E): -14.48500000+0.00000000j, var(E): 2.26108042
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 10000/ t/epoch=1.06............. Loss: -2.00982663, mean(E): -14.42000000+0.00000000j, var(E): 2.34532666
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 10000/ t/epoch=1.06............. Loss: -1.97681746, mean(E): -14.35500000+0.00000000j, var(E): 2.29042716
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 10000/ t/epoch=1.07............. Loss: -1.94020372, mean(E): -14.75000000+0.00000000j, var(E): 2.21859298
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(13.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 10000/ t/epoch=1.06............. Loss: -1.76519085, mean(E): -14.56000000+0.00000000j, var(E): 2.25768846
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 10000/ t/epoch=1.07............. Loss: -1.73224059, mean(E): -14.93500000+0.00000000j, var(E): 2.07113067
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 10000/ t/epoch=1.07............. Loss: -1.78008711, mean(E): -14.74000000+0.00000000j, var(E): 2.20341710
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 10000/ t/epoch=1.06............. Loss: -1.72738683, mean(E): -14.72500000+0.00000000j, var(E): 2.21042716
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 10000/ t/epoch=1.06............. Loss: -1.90473662, mean(E): -14.66500000+0.00000000j, var(E): 2.23394474
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 10000/ t/epoch=1.06............. Loss: -2.05258188, mean(E): -14.74500000+0.00000000j, var(E): 2.32158293
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 10000/ t/epoch=1.06............. Loss: -2.09172269, mean(E): -14.81000000+0.00000000j, var(E): 2.18482414
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 10000/ t/epoch=1.07............. Loss: -1.77058582, mean(E): -14.81000000+0.00000000j, var(E): 2.18482414
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 10000/ t/epoch=1.07............. Loss: -1.84093445, mean(E): -14.77000000+0.00000000j, var(E): 2.18804022
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 10000/ t/epoch=1.07............. Loss: -1.71299716, mean(E): -14.93500000+0.00000000j, var(E): 2.07113067
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 10000/ t/epoch=1.07............. Loss: -1.71430792, mean(E): -14.84500000+0.00000000j, var(E): 2.14168344
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 10000/ t/epoch=1.06............. Loss: -2.16077681, mean(E): -14.80500000+0.00000000j, var(E): 2.30851761
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 10000/ t/epoch=1.06............. Loss: -1.68570950, mean(E): -14.95000000+0.00000000j, var(E): 2.05778896
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 10000/ t/epoch=1.07............. Loss: -1.94015833, mean(E): -14.88000000+0.00000000j, var(E): 2.16643218
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 10000/ t/epoch=1.07............. Loss: -1.89649952, mean(E): -14.71000000+0.00000000j, var(E): 2.21698494
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 10000/ t/epoch=1.07............. Loss: -1.74572685, mean(E): -15.06000000+0.00000000j, var(E): 1.99638192
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 10000/ t/epoch=1.07............. Loss: -1.78222995, mean(E): -15.04000000+0.00000000j, var(E): 1.96824122
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 10000/ t/epoch=1.07............. Loss: -1.62528081, mean(E): -15.14500000+0.00000000j, var(E): 1.84319098
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 10000/ t/epoch=1.06............. Loss: -1.68359135, mean(E): -14.95000000+0.00000000j, var(E): 2.05778896
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 10000/ t/epoch=1.07............. Loss: -1.64362037, mean(E): -15.04000000+0.00000000j, var(E): 1.96824122
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 10000/ t/epoch=1.06............. Loss: -1.74906101, mean(E): -15.02500000+0.00000000j, var(E): 1.98429650
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 10000/ t/epoch=1.06............. Loss: -1.70943656, mean(E): -15.07000000+0.00000000j, var(E): 1.93477389
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 10000/ t/epoch=1.06............. Loss: -1.65681130, mean(E): -15.08500000+0.00000000j, var(E): 1.91736182
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 10000/ t/epoch=1.06............. Loss: -1.56600697, mean(E): -15.23500000+0.00000000j, var(E): 1.71836685
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 10000/ t/epoch=1.06............. Loss: -1.61320960, mean(E): -15.20500000+0.00000000j, var(E): 1.76178393
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 10000/ t/epoch=1.06............. Loss: -1.31648925, mean(E): -15.32500000+0.00000000j, var(E): 1.57726132
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 10000/ t/epoch=1.06............. Loss: -1.58173634, mean(E): -15.26500000+0.00000000j, var(E): 1.67314072
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 10000/ t/epoch=1.06............. Loss: -1.78333771, mean(E): -14.96500000+0.00000000j, var(E): 2.04399499
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 10000/ t/epoch=1.07............. Loss: -1.61254301, mean(E): -15.23500000+0.00000000j, var(E): 1.71836685
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 10000/ t/epoch=1.06............. Loss: -1.62203984, mean(E): -15.28000000+0.00000000j, var(E): 1.64984927
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 10000/ t/epoch=1.06............. Loss: -1.59601782, mean(E): -15.22000000+0.00000000j, var(E): 1.74030152
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 10000/ t/epoch=1.06............. Loss: -1.44022972, mean(E): -15.29500000+0.00000000j, var(E): 1.62610554
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 10000/ t/epoch=1.06............. Loss: -1.42108704, mean(E): -15.38500000+0.00000000j, var(E): 1.47414574
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 10000/ t/epoch=1.06............. Loss: -1.19456200, mean(E): -15.47500000+0.00000000j, var(E): 1.30590453
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 10000/ t/epoch=1.07............. Loss: -1.56145080, mean(E): -15.34000000+0.00000000j, var(E): 1.55216082
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(14.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 10000/ t/epoch=1.06............. Loss: -1.32866437, mean(E): -15.38500000+0.00000000j, var(E): 1.47414574
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 10000/ t/epoch=1.06............. Loss: -1.60296381, mean(E): -15.29500000+0.00000000j, var(E): 1.62610554
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 10000/ t/epoch=1.06............. Loss: -1.53895323, mean(E): -15.35500000+0.00000000j, var(E): 1.52660806
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 10000/ t/epoch=1.07............. Loss: -1.26751466, mean(E): -15.44500000+0.00000000j, var(E): 1.36379398
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 10000/ t/epoch=1.06............. Loss: -1.45734896, mean(E): -15.37000000+0.00000000j, var(E): 1.50060303
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 10000/ t/epoch=1.07............. Loss: -1.54148991, mean(E): -15.29500000+0.00000000j, var(E): 1.62610554
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 10000/ t/epoch=1.07............. Loss: -1.32986348, mean(E): -15.46000000+0.00000000j, var(E): 1.33507539
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 10000/ t/epoch=1.06............. Loss: -0.92764408, mean(E): -15.64000000+0.00000000j, var(E): 0.95517589
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 10000/ t/epoch=1.06............. Loss: -1.39409819, mean(E): -15.47500000+0.00000000j, var(E): 1.30590453
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 10000/ t/epoch=1.07............. Loss: -1.51759386, mean(E): -15.44500000+0.00000000j, var(E): 1.36379398
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 10000/ t/epoch=1.06............. Loss: -1.33635135, mean(E): -15.49000000+0.00000000j, var(E): 1.27628142
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 10000/ t/epoch=1.07............. Loss: -1.20074950, mean(E): -15.53500000+0.00000000j, var(E): 1.18469850
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 10000/ t/epoch=1.06............. Loss: -1.33761278, mean(E): -15.47500000+0.00000000j, var(E): 1.30590453
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 10000/ t/epoch=1.07............. Loss: -1.57800883, mean(E): -15.38500000+0.00000000j, var(E): 1.47414574
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 10000/ t/epoch=1.06............. Loss: -1.13849994, mean(E): -15.58000000+0.00000000j, var(E): 1.08904524
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 10000/ t/epoch=1.06............. Loss: -1.47051333, mean(E): -15.43000000+0.00000000j, var(E): 1.39206032
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 10000/ t/epoch=1.06............. Loss: -0.90402278, mean(E): -15.71500000+0.00000000j, var(E): 0.77766333
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 10000/ t/epoch=1.06............. Loss: -1.02945819, mean(E): -15.64000000+0.00000000j, var(E): 0.95517589
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 10000/ t/epoch=1.06............. Loss: -1.32253241, mean(E): -15.55000000+0.00000000j, var(E): 1.15326634
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 10000/ t/epoch=1.07............. Loss: -0.93372342, mean(E): -15.68500000+0.00000000j, var(E): 0.85002513
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 10000/ t/epoch=1.06............. Loss: -0.78250685, mean(E): -15.74500000+0.00000000j, var(E): 0.70349246
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 10000/ t/epoch=1.06............. Loss: -1.19092615, mean(E): -15.59500000+0.00000000j, var(E): 1.05625630
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 10000/ t/epoch=1.06............. Loss: -1.00631482, mean(E): -15.67000000+0.00000000j, var(E): 0.88552764
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 10000/ t/epoch=1.07............. Loss: -1.17339291, mean(E): -15.61000000+0.00000000j, var(E): 1.02301508
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 10000/ t/epoch=1.06............. Loss: -1.54780663, mean(E): -15.49000000+0.00000000j, var(E): 1.27628142
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 10000/ t/epoch=1.06............. Loss: -1.19529460, mean(E): -15.64000000+0.00000000j, var(E): 0.95517589
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 10000/ t/epoch=1.06............. Loss: -0.96736843, mean(E): -15.70000000+0.00000000j, var(E): 0.81407036
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 10000/ t/epoch=1.06............. Loss: -0.93042539, mean(E): -15.71500000+0.00000000j, var(E): 0.77766332
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 10000/ t/epoch=1.06............. Loss: -1.11293810, mean(E): -15.65500000+0.00000000j, var(E): 0.92057789
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 10000/ t/epoch=1.07............. Loss: -0.98944912, mean(E): -15.70000000+0.00000000j, var(E): 0.81407036
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 10000/ t/epoch=1.06............. Loss: -1.09299037, mean(E): -15.67000000+0.00000000j, var(E): 0.88552765
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 10000/ t/epoch=1.06............. Loss: -0.92028187, mean(E): -15.73000000+0.00000000j, var(E): 0.74080403
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 10000/ t/epoch=1.06............. Loss: -1.24460259, mean(E): -15.62500000+0.00000000j, var(E): 0.98932161
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(15.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 10000/ t/epoch=1.07............. Loss: -0.59743956, mean(E): -15.83500000+0.00000000j, var(E): 0.47012564
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 10000/ t/epoch=1.06............. Loss: -0.84947915, mean(E): -15.76000000+0.00000000j, var(E): 0.66572865
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 10000/ t/epoch=1.06............. Loss: -0.60769685, mean(E): -15.83500000+0.00000000j, var(E): 0.47012563
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 10000/ t/epoch=1.07............. Loss: -0.55709232, mean(E): -15.85000000+0.00000000j, var(E): 0.42964825
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 10000/ t/epoch=1.08............. Loss: -0.76921594, mean(E): -15.82000000+0.00000000j, var(E): 0.51015075
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 10000/ t/epoch=1.07............. Loss: -0.82626573, mean(E): -15.77500000+0.00000000j, var(E): 0.62751257
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 10000/ t/epoch=1.07............. Loss: -0.73361777, mean(E): -15.80500000+0.00000000j, var(E): 0.54972362
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 10000/ t/epoch=1.06............. Loss: -0.79347444, mean(E): -15.79000000+0.00000000j, var(E): 0.58884423
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 10000/ t/epoch=1.06............. Loss: -0.58228567, mean(E): -15.85000000+0.00000000j, var(E): 0.42964824
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 10000/ t/epoch=1.07............. Loss: -0.80450026, mean(E): -15.79000000+0.00000000j, var(E): 0.58884423
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 10000/ t/epoch=1.06............. Loss: -0.86604581, mean(E): -15.77500000+0.00000000j, var(E): 0.62751257
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 10000/ t/epoch=1.06............. Loss: -0.36471528, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 10000/ t/epoch=1.06............. Loss: -0.48380116, mean(E): -15.88000000+0.00000000j, var(E): 0.34733669
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 10000/ t/epoch=1.06............. Loss: -0.82963833, mean(E): -15.79000000+0.00000000j, var(E): 0.58884422
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 10000/ t/epoch=1.06............. Loss: -0.66770846, mean(E): -15.83500000+0.00000000j, var(E): 0.47012563
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 10000/ t/epoch=1.06............. Loss: -0.55623844, mean(E): -15.86500000+0.00000000j, var(E): 0.38871860
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 10000/ t/epoch=1.07............. Loss: -0.31726703, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 10000/ t/epoch=1.06............. Loss: -0.44224428, mean(E): -15.89500000+0.00000000j, var(E): 0.30550251
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 10000/ t/epoch=1.07............. Loss: -0.69005593, mean(E): -15.83500000+0.00000000j, var(E): 0.47012563
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 10000/ t/epoch=1.07............. Loss: -0.45148758, mean(E): -15.89500000+0.00000000j, var(E): 0.30550252
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 10000/ t/epoch=1.06............. Loss: -0.38848516, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 10000/ t/epoch=1.06............. Loss: -0.64090487, mean(E): -15.85000000+0.00000000j, var(E): 0.42964824
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 10000/ t/epoch=1.07............. Loss: -0.33143052, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 10000/ t/epoch=1.06............. Loss: -0.58626768, mean(E): -15.86500000+0.00000000j, var(E): 0.38871860
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 10000/ t/epoch=1.06............. Loss: -0.59125684, mean(E): -15.86500000+0.00000000j, var(E): 0.38871859
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 10000/ t/epoch=1.06............. Loss: -0.59505253, mean(E): -15.86500000+0.00000000j, var(E): 0.38871860
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 10000/ t/epoch=1.07............. Loss: -0.59928745, mean(E): -15.86500000+0.00000000j, var(E): 0.38871860
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 10000/ t/epoch=1.07............. Loss: -0.40935379, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 10000/ t/epoch=1.06............. Loss: -0.47716309, mean(E): -15.89500000+0.00000000j, var(E): 0.30550252
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 10000/ t/epoch=1.07............. Loss: -0.13990252, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 10000/ t/epoch=1.07............. Loss: -0.21124676, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 10000/ t/epoch=1.07............. Loss: -0.48491829, mean(E): -15.89500000+0.00000000j, var(E): 0.30550252
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 10000/ t/epoch=1.06............. Loss: -0.28377529, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 10000/ t/epoch=1.07............. Loss: -0.42249945, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 10000/ t/epoch=1.06............. Loss: -0.14358484, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 10000/ t/epoch=1.07............. Loss: -0.49539432, mean(E): -15.89500000+0.00000000j, var(E): 0.30550252
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 10000/ t/epoch=1.06............. Loss: -0.56497732, mean(E): -15.88000000+0.00000000j, var(E): 0.34733669
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 10000/ t/epoch=1.07............. Loss: -0.56809764, mean(E): -15.88000000+0.00000000j, var(E): 0.34733669
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 10000/ t/epoch=1.06............. Loss: -0.29158192, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 10000/ t/epoch=1.06............. Loss: -0.57670543, mean(E): -15.88000000+0.00000000j, var(E): 0.34733669
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 10000/ t/epoch=1.06............. Loss: -0.22317789, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 10000/ t/epoch=1.06............. Loss: -0.43974945, mean(E): -15.91000000+0.00000000j, var(E): 0.26321609
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(16.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 10000/ t/epoch=1.06............. Loss: -0.37055981, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 10000/ t/epoch=1.07............. Loss: -0.29919425, mean(E): -15.94000000+0.00000000j, var(E): 0.17728644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 10000/ t/epoch=1.06............. Loss: -0.37373446, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 10000/ t/epoch=1.07............. Loss: -0.37592001, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 10000/ t/epoch=1.06............. Loss: -0.22866009, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 10000/ t/epoch=1.07............. Loss: -0.15470190, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 10000/ t/epoch=1.07............. Loss: -0.37999558, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 10000/ t/epoch=1.07............. Loss: -0.23153036, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 10000/ t/epoch=1.06............. Loss: -0.15545877, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 10000/ t/epoch=1.06............. Loss: -0.46093034, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 10000/ t/epoch=1.06............. Loss: -0.31105410, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 10000/ t/epoch=1.07............. Loss: -0.15749709, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 10000/ t/epoch=1.06............. Loss: -0.08014413, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 10000/ t/epoch=1.07............. Loss: -0.39366925, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 10000/ t/epoch=1.07............. Loss: -0.23873678, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 10000/ t/epoch=1.07............. Loss: -0.23965616, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 10000/ t/epoch=1.07............. Loss: -0.39624396, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 10000/ t/epoch=1.07............. Loss: -0.08179890, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 10000/ t/epoch=1.06............. Loss: -0.24119642, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 10000/ t/epoch=1.06............. Loss: -0.16308473, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 10000/ t/epoch=1.07............. Loss: -0.32417925, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 10000/ t/epoch=1.06............. Loss: -0.16364410, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 10000/ t/epoch=1.07............. Loss: -0.24671900, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 10000/ t/epoch=1.06............. Loss: -0.48741565, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 10000/ t/epoch=1.06............. Loss: -0.24995562, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 10000/ t/epoch=1.07............. Loss: -0.16734186, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 10000/ t/epoch=1.07............. Loss: -0.25012375, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 10000/ t/epoch=1.06............. Loss: -0.41418375, mean(E): -15.92500000+0.00000000j, var(E): 0.22047739
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 10000/ t/epoch=1.06............. Loss: -0.16897864, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 10000/ t/epoch=1.06............. Loss: -0.16955793, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 10000/ t/epoch=1.06............. Loss: -0.50203231, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 10000/ t/epoch=1.06............. Loss: -0.17240006, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 10000/ t/epoch=1.06............. Loss: -0.50280331, mean(E): -15.91000000+0.00000000j, var(E): 0.26321608
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 10000/ t/epoch=1.07............. Loss: -0.17253935, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 10000/ t/epoch=1.07............. Loss: -0.17323869, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 10000/ t/epoch=1.07............. Loss: -0.34322832, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 10000/ t/epoch=1.07............. Loss: -0.26082779, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 10000/ t/epoch=1.07............. Loss: -0.34661170, mean(E): -15.94000000+0.00000000j, var(E): 0.17728644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 10000/ t/epoch=1.07............. Loss: -0.26070742, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 10000/ t/epoch=1.06............. Loss: -0.17622411, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 10000/ t/epoch=1.07............. Loss: -0.17752265, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 10000/ t/epoch=1.07............. Loss: -0.26432897, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 10000/ t/epoch=1.07............. Loss: -0.43665766, mean(E): -15.92500000+0.00000000j, var(E): 0.22047740
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 10000/ t/epoch=1.06............. Loss: -0.60803114, mean(E): -15.89500000+0.00000000j, var(E): 0.30550251
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 10000/ t/epoch=1.06............. Loss: -0.09018106, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 10000/ t/epoch=1.07............. Loss: -0.35530676, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 10000/ t/epoch=1.06............. Loss: -0.26880091, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 10000/ t/epoch=1.06............. Loss: -0.35955892, mean(E): -15.94000000+0.00000000j, var(E): 0.17728644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 10000/ t/epoch=1.07............. Loss: -0.18233615, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 10000/ t/epoch=1.06............. Loss: -0.27280384, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 10000/ t/epoch=1.07............. Loss: -0.36270379, mean(E): -15.94000000+0.00000000j, var(E): 0.17728644
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 10000/ t/epoch=1.06............. Loss: -0.27479697, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 10000/ t/epoch=1.07............. Loss: -0.18489994, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 10000/ t/epoch=1.06............. Loss: -0.09356269, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 10000/ t/epoch=1.07............. Loss: -0.09325238, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 10000/ t/epoch=1.06............. Loss: -0.18715564, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 10000/ t/epoch=1.07............. Loss: -0.18779441, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 10000/ t/epoch=1.06............. Loss: -0.18835182, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 10000/ t/epoch=1.07............. Loss: -0.09459624, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 10000/ t/epoch=1.06............. Loss: -0.28222675, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 10000/ t/epoch=1.07............. Loss: -0.18950630, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(17.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 10000/ t/epoch=1.06............. Loss: -0.19080874, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 10000/ t/epoch=1.07............. Loss: -0.28698231, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 10000/ t/epoch=1.07............. Loss: -0.28790649, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 10000/ t/epoch=1.07............. Loss: -0.09696799, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 10000/ t/epoch=1.06............. Loss: -0.19404625, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 10000/ t/epoch=1.06............. Loss: -0.09759177, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 10000/ t/epoch=1.06............. Loss: -0.09827616, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 10000/ t/epoch=1.07............. Loss: -0.38727638, mean(E): -15.94000000+0.00000000j, var(E): 0.17728643
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 10000/ t/epoch=1.06............. Loss: -0.09825460, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 10000/ t/epoch=1.06............. Loss: -0.09869966, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 10000/ t/epoch=1.07............. Loss: -0.29402983, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 10000/ t/epoch=1.07............. Loss: -0.09922406, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 10000/ t/epoch=1.07............. Loss: -0.19832201, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 10000/ t/epoch=1.07............. Loss: -0.19867012, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 10000/ t/epoch=1.07............. Loss: -0.10007099, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 10000/ t/epoch=1.07............. Loss: -0.20013830, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 10000/ t/epoch=1.06............. Loss: -0.10102846, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 10000/ t/epoch=1.07............. Loss: -0.10075468, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 10000/ t/epoch=1.06............. Loss: -0.10137546, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 10000/ t/epoch=1.07............. Loss: -0.10153405, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 10000/ t/epoch=1.07............. Loss: -0.10150977, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 10000/ t/epoch=1.07............. Loss: -0.10172910, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 10000/ t/epoch=1.07............. Loss: -0.20272159, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 10000/ t/epoch=1.07............. Loss: -0.20322239, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.2991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 10000/ t/epoch=1.07............. Loss: -0.10231316, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 10000/ t/epoch=1.07............. Loss: -0.20425713, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 10000/ t/epoch=1.06............. Loss: -0.10345109, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 10000/ t/epoch=1.07............. Loss: -0.10343130, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 10000/ t/epoch=1.06............. Loss: -0.10411613, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 10000/ t/epoch=1.07............. Loss: -0.10486604, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 10000/ t/epoch=1.07............. Loss: -0.31184306, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 10000/ t/epoch=1.06............. Loss: -0.10535460, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 10000/ t/epoch=1.07............. Loss: -0.10597821, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 10000/ t/epoch=1.06............. Loss: -0.10565365, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 10000/ t/epoch=1.07............. Loss: -0.21124074, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 10000/ t/epoch=1.06............. Loss: -0.10620964, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 10000/ t/epoch=1.07............. Loss: -0.10635822, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 10000/ t/epoch=1.06............. Loss: -0.10680075, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 10000/ t/epoch=1.06............. Loss: -0.10664272, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 10000/ t/epoch=1.07............. Loss: -0.10709677, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 10000/ t/epoch=1.06............. Loss: -0.10747128, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 10000/ t/epoch=1.06............. Loss: -0.10702589, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 10000/ t/epoch=1.1............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 10000/ t/epoch=1.07............. Loss: -0.21411243, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 10000/ t/epoch=1.07............. Loss: -0.21376608, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 10000/ t/epoch=1.07............. Loss: -0.10766060, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 10000/ t/epoch=1.07............. Loss: -0.21455657, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 10000/ t/epoch=1.06............. Loss: -0.10829885, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 10000/ t/epoch=1.07............. Loss: -0.10863130, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 10000/ t/epoch=1.07............. Loss: -0.10914852, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 10000/ t/epoch=1.07............. Loss: -0.10939714, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 10000/ t/epoch=1.07............. Loss: -0.10952165, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 10000/ t/epoch=1.07............. Loss: -0.21854212, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 10000/ t/epoch=1.07............. Loss: -0.11031951, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 10000/ t/epoch=1.07............. Loss: -0.11105542, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 10000/ t/epoch=1.07............. Loss: -0.11057401, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 10000/ t/epoch=1.07............. Loss: -0.11123607, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 10000/ t/epoch=1.06............. Loss: -0.11156879, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 10000/ t/epoch=1.07............. Loss: -0.11168287, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 10000/ t/epoch=1.07............. Loss: -0.22322646, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 10000/ t/epoch=1.06............. Loss: -0.22303963, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 10000/ t/epoch=1.07............. Loss: -0.22330646, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 10000/ t/epoch=1.07............. Loss: -0.11244201, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 10000/ t/epoch=1.07............. Loss: -0.11259874, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 10000/ t/epoch=1.07............. Loss: -0.11316647, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 10000/ t/epoch=1.07............. Loss: -0.11382837, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 10000/ t/epoch=1.07............. Loss: -0.11350455, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 10000/ t/epoch=1.06............. Loss: -0.11420917, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 10000/ t/epoch=1.07............. Loss: -0.11391719, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 10000/ t/epoch=1.07............. Loss: -0.11398232, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 10000/ t/epoch=1.07............. Loss: -0.11468704, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 10000/ t/epoch=1.07............. Loss: -0.22834250, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 10000/ t/epoch=1.06............. Loss: -0.11556155, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 10000/ t/epoch=1.07............. Loss: -0.11526981, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 10000/ t/epoch=1.07............. Loss: -0.11609277, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 10000/ t/epoch=1.06............. Loss: -0.11665987, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 10000/ t/epoch=1.07............. Loss: -0.11704788, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 10000/ t/epoch=1.06............. Loss: -0.11717430, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 10000/ t/epoch=1.06............. Loss: -0.11618935, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 10000/ t/epoch=1.06............. Loss: -0.11652296, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 10000/ t/epoch=1.07............. Loss: -0.11686831, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 10000/ t/epoch=1.07............. Loss: -0.11693132, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(18.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 10000/ t/epoch=1.07............. Loss: -0.11823199, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 10000/ t/epoch=1.07............. Loss: -0.11838895, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 10000/ t/epoch=1.07............. Loss: -0.11866626, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 10000/ t/epoch=1.07............. Loss: -0.11873538, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 10000/ t/epoch=1.07............. Loss: -0.11901467, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 10000/ t/epoch=1.07............. Loss: -0.11903639, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 10000/ t/epoch=1.06............. Loss: -0.11937494, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 10000/ t/epoch=1.07............. Loss: -0.11975040, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 10000/ t/epoch=1.07............. Loss: -0.12009234, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 10000/ t/epoch=1.07............. Loss: -0.12014704, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 10000/ t/epoch=1.07............. Loss: -0.23975697, mean(E): -15.97000000+0.00000000j, var(E): 0.08954774
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 10000/ t/epoch=1.07............. Loss: -0.12071569, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 10000/ t/epoch=1.07............. Loss: -0.35926101, mean(E): -15.95500000+0.00000000j, var(E): 0.13364322
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 10000/ t/epoch=1.07............. Loss: -0.12129056, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 10000/ t/epoch=1.07............. Loss: -0.12138257, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 10000/ t/epoch=1.07............. Loss: -0.12173036, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 10000/ t/epoch=1.07............. Loss: -0.12209414, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 10000/ t/epoch=1.07............. Loss: -0.12261554, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 10000/ t/epoch=1.07............. Loss: -0.12273344, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 10000/ t/epoch=1.07............. Loss: -0.12298058, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 10000/ t/epoch=1.07............. Loss: -0.12342054, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 10000/ t/epoch=1.07............. Loss: -0.12352255, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 10000/ t/epoch=1.07............. Loss: -0.12376535, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 10000/ t/epoch=1.06............. Loss: -0.12401811, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 10000/ t/epoch=1.07............. Loss: -0.12494343, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 10000/ t/epoch=1.06............. Loss: -0.12526251, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 10000/ t/epoch=1.07............. Loss: -0.12579698, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 10000/ t/epoch=1.07............. Loss: -0.12634717, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 10000/ t/epoch=1.06............. Loss: -0.12710444, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 10000/ t/epoch=1.07............. Loss: -0.12708529, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 10000/ t/epoch=1.07............. Loss: -0.12868560, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 10000/ t/epoch=1.07............. Loss: -0.13198176, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 10000/ t/epoch=1.07............. Loss: -0.13120416, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 10000/ t/epoch=1.07............. Loss: -0.13175583, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 10000/ t/epoch=1.07............. Loss: -0.13247499, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 10000/ t/epoch=1.07............. Loss: -0.13380251, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 10000/ t/epoch=1.07............. Loss: -0.13408558, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 10000/ t/epoch=1.1............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 10000/ t/epoch=1.07............. Loss: -0.13430729, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 10000/ t/epoch=1.06............. Loss: -0.13538553, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 10000/ t/epoch=1.07............. Loss: -0.13579756, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 10000/ t/epoch=1.06............. Loss: -0.13658973, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 10000/ t/epoch=1.07............. Loss: -0.13686555, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 10000/ t/epoch=1.07............. Loss: -0.13699297, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 10000/ t/epoch=1.07............. Loss: -0.13727056, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 10000/ t/epoch=1.07............. Loss: -0.13852826, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 10000/ t/epoch=1.07............. Loss: -0.13966954, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 10000/ t/epoch=1.06............. Loss: -0.14029954, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 10000/ t/epoch=1.07............. Loss: -0.14064029, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 10000/ t/epoch=1.07............. Loss: -0.14224093, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 10000/ t/epoch=1.07............. Loss: -0.14228207, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(19.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 10000/ t/epoch=1.07............. Loss: -0.14326361, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 10000/ t/epoch=1.07............. Loss: -0.14443096, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 10000/ t/epoch=1.06............. Loss: -0.14543572, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 10000/ t/epoch=1.07............. Loss: -0.14582926, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 10000/ t/epoch=1.07............. Loss: -0.14685337, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 10000/ t/epoch=1.07............. Loss: -0.14802522, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 10000/ t/epoch=1.07............. Loss: -0.14862436, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 10000/ t/epoch=1.06............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 10000/ t/epoch=1.07............. Loss: -0.14819509, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 10000/ t/epoch=1.08............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 10000/ t/epoch=1.11............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 10000/ t/epoch=1.07............. Loss: -0.15361697, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 10000/ t/epoch=1.07............. Loss: -0.15457559, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 10000/ t/epoch=1.07............. Loss: -0.15589212, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 10000/ t/epoch=1.07............. Loss: -0.15613991, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 10000/ t/epoch=1.11............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 10000/ t/epoch=1.07............. Loss: -0.15665140, mean(E): -15.98500000+0.00000000j, var(E): 0.04500000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([32, 200, 4, 4])
tensor(20.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 10000/ t/epoch=1.07............. Loss: 0.00000000, mean(E): -16.00000000+0.00000000j, var(E): 0.00000000
