/var/spool/slurmd/job4822920/slurm_script: line 14: ../../ML_Environment/bin/activate: No such file or directory
1.13.1+cu117
GPU is available
Namespace(Jp=0.0, Jz=1.0, Nx=4, Ny=4, U=1.0, antisym=0.0, bounds=1, boundsx=0, boundsy=0, density=0.9375, hd=70, load_model=0, sym=0.0, t=3.0)
4x4_qubits/periodic/Jp=0.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 58800
rnn.b1: 70
rnn.W2: 58800
rnn.b2: 70
rnn.Wmerge: 9800
lin1.weight: 210
lin1.bias: 3
lin2.weight: 210
lin2.bias: 3
Total number of parameters in the network: 127966
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 10000/ t/epoch=3.7............. Loss: 3.81567878, mean(E): -17.68672123-0.00785648j, var(E): 15.84817499
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 10000/ t/epoch=1.95............. Loss: 2.95894979, mean(E): -17.80627748-0.01515709j, var(E): 13.96842010
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 10000/ t/epoch=1.96............. Loss: 2.90804568, mean(E): -17.95809972-0.01458209j, var(E): 13.37030917
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 10000/ t/epoch=1.95............. Loss: 3.59085974, mean(E): -17.60154060-0.01642818j, var(E): 15.94329928
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 10000/ t/epoch=1.95............. Loss: 3.04049804, mean(E): -17.96767350-0.01978311j, var(E): 14.05557802
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 10000/ t/epoch=1.95............. Loss: 2.48008376, mean(E): -17.71042322-0.01898480j, var(E): 10.89119290
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 10000/ t/epoch=1.95............. Loss: 3.22707760, mean(E): -17.84397538-0.00973829j, var(E): 14.01255037
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(10.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 10000/ t/epoch=1.95............. Loss: 2.89542561, mean(E): -17.65941314-0.01590248j, var(E): 12.11774473
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 10000/ t/epoch=1.95............. Loss: 2.86678135, mean(E): -17.35981244-0.00335639j, var(E): 11.63021061
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.1943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 10000/ t/epoch=1.95............. Loss: 2.86312067, mean(E): -17.68409813+0.02048582j, var(E): 12.32557823
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 10000/ t/epoch=1.95............. Loss: 2.88279008, mean(E): -17.72178806+0.02754041j, var(E): 13.07906191
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 10000/ t/epoch=1.95............. Loss: 2.59732942, mean(E): -17.82360539+0.01370035j, var(E): 12.93179152
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 10000/ t/epoch=1.95............. Loss: 2.25795045, mean(E): -18.34673199+0.09391879j, var(E): 13.70264244
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 10000/ t/epoch=1.95............. Loss: 1.82168686, mean(E): -18.47536118+0.16028434j, var(E): 13.06798800
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 10000/ t/epoch=1.95............. Loss: 1.26446112, mean(E): -18.58975796-0.11484735j, var(E): 13.29935801
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 10000/ t/epoch=1.95............. Loss: 2.18223031, mean(E): -18.68289919+0.06043958j, var(E): 15.84740813
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 10000/ t/epoch=1.95............. Loss: 2.28029921, mean(E): -18.83883624+0.02141867j, var(E): 14.82043116
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 10000/ t/epoch=1.95............. Loss: 1.30374545, mean(E): -18.72869297+0.01004924j, var(E): 11.63047796
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 10000/ t/epoch=1.95............. Loss: 1.03212632, mean(E): -19.06141163+0.01039539j, var(E): 11.39527489
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 10000/ t/epoch=1.95............. Loss: 0.65755983, mean(E): -19.06778568+0.05307280j, var(E): 12.65025005
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 10000/ t/epoch=1.96............. Loss: 1.60974156, mean(E): -19.26720256+0.10575177j, var(E): 15.28910097
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 10000/ t/epoch=1.95............. Loss: 1.71215501, mean(E): -19.56795547+0.16172757j, var(E): 15.05742665
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 10000/ t/epoch=1.98............. Loss: 1.12823203, mean(E): -19.73545096+0.07975410j, var(E): 14.08338566
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 10000/ t/epoch=1.95............. Loss: 0.30283063, mean(E): -19.40778263+0.01523738j, var(E): 12.59093680
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 10000/ t/epoch=1.96............. Loss: 0.54486622, mean(E): -19.40318007+0.03759144j, var(E): 10.50080007
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(11.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 10000/ t/epoch=1.96............. Loss: 0.35238001, mean(E): -19.64787756+0.00917708j, var(E): 13.05483930
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 10000/ t/epoch=1.96............. Loss: 0.58471951, mean(E): -20.10109058-0.15953236j, var(E): 11.14729784
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 10000/ t/epoch=1.96............. Loss: 0.38848331, mean(E): -20.16079579+0.02530559j, var(E): 12.72919645
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 10000/ t/epoch=1.95............. Loss: 1.26807460, mean(E): -20.08331094+0.04720391j, var(E): 12.75413789
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 10000/ t/epoch=1.96............. Loss: 0.96515340, mean(E): -20.25886889+0.08079768j, var(E): 11.30170501
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 10000/ t/epoch=1.95............. Loss: 0.47493471, mean(E): -19.80479842+0.06408749j, var(E): 10.34355776
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 10000/ t/epoch=1.96............. Loss: 1.54626602, mean(E): -20.28539737+0.02633411j, var(E): 10.16564470
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 10000/ t/epoch=1.96............. Loss: 0.21137587, mean(E): -19.87204783-0.01602200j, var(E): 8.49009742
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 10000/ t/epoch=1.95............. Loss: 1.30426172, mean(E): -20.11564840-0.04766070j, var(E): 10.54921603
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 10000/ t/epoch=1.96............. Loss: 0.04552762, mean(E): -20.56064600-0.00715281j, var(E): 11.39050994
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 10000/ t/epoch=1.96............. Loss: 0.22595223, mean(E): -20.33232652+0.01247976j, var(E): 9.81389322
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 10000/ t/epoch=1.95............. Loss: -0.26010908, mean(E): -19.93534420-0.01716963j, var(E): 8.81385271
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 10000/ t/epoch=1.95............. Loss: 0.06269520, mean(E): -20.24102293-0.03778395j, var(E): 7.60218040
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 10000/ t/epoch=1.96............. Loss: -0.24101605, mean(E): -20.68176893+0.07712306j, var(E): 7.11611745
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 10000/ t/epoch=1.96............. Loss: 0.06763868, mean(E): -20.50506186+0.00128813j, var(E): 7.55099196
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 10000/ t/epoch=1.96............. Loss: -0.20724845, mean(E): -20.45550360+0.01329743j, var(E): 7.79997008
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 10000/ t/epoch=1.95............. Loss: -0.55677741, mean(E): -20.36157807+0.01000651j, var(E): 6.37244249
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 10000/ t/epoch=1.95............. Loss: -0.04416690, mean(E): -20.29321064+0.01254469j, var(E): 6.58696742
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 10000/ t/epoch=1.96............. Loss: -0.32438844, mean(E): -20.26980716-0.03179139j, var(E): 7.42883635
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 10000/ t/epoch=1.95............. Loss: 0.00520225, mean(E): -20.51275313-0.07369795j, var(E): 6.82775595
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 10000/ t/epoch=1.95............. Loss: -1.04472231, mean(E): -20.28202667-0.05921160j, var(E): 6.95811247
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 10000/ t/epoch=1.95............. Loss: -0.42599648, mean(E): -20.43675710-0.06529916j, var(E): 7.07894734
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 10000/ t/epoch=1.96............. Loss: -0.15932385, mean(E): -20.24533106+0.00694564j, var(E): 6.73815054
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 10000/ t/epoch=1.96............. Loss: -0.14263117, mean(E): -20.44955334-0.10533115j, var(E): 6.45236179
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 10000/ t/epoch=1.95............. Loss: -0.59932935, mean(E): -20.43440848-0.00143758j, var(E): 6.40384507
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 10000/ t/epoch=1.96............. Loss: -0.47629081, mean(E): -20.71475123-0.01122774j, var(E): 8.76921331
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 10000/ t/epoch=1.97............. Loss: 0.11364313, mean(E): -20.72937944-0.05478926j, var(E): 5.27258806
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 10000/ t/epoch=1.96............. Loss: 0.03784009, mean(E): -20.57923528+0.03981658j, var(E): 7.12479597
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 10000/ t/epoch=1.96............. Loss: -0.91786858, mean(E): -20.24137288-0.01920210j, var(E): 4.09470573
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 10000/ t/epoch=1.96............. Loss: -0.18931031, mean(E): -20.69574750+0.00272066j, var(E): 5.81234230
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 10000/ t/epoch=1.96............. Loss: -0.41105034, mean(E): -20.58084552-0.03942859j, var(E): 6.56475716
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 10000/ t/epoch=1.95............. Loss: -0.63447694, mean(E): -20.61668769-0.00836416j, var(E): 5.48741774
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 10000/ t/epoch=1.95............. Loss: 0.32519781, mean(E): -20.64969434-0.00606977j, var(E): 7.16389512
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 10000/ t/epoch=1.96............. Loss: -0.58519041, mean(E): -20.62598089+0.07045407j, var(E): 5.52966538
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 10000/ t/epoch=1.96............. Loss: -0.01313877, mean(E): -20.53943133+0.00753019j, var(E): 6.01812678
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 10000/ t/epoch=1.96............. Loss: -0.14203961, mean(E): -20.82809235-0.01176835j, var(E): 5.12041719
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 10000/ t/epoch=1.96............. Loss: -0.26314146, mean(E): -20.87220508+0.00306105j, var(E): 4.80255724
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 10000/ t/epoch=1.96............. Loss: -1.63263210, mean(E): -20.22558008-0.04184011j, var(E): 4.64271975
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 10000/ t/epoch=1.96............. Loss: -0.77153078, mean(E): -20.64297519-0.04333079j, var(E): 5.17226232
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 10000/ t/epoch=1.95............. Loss: -1.15286966, mean(E): -20.51781627+0.00548687j, var(E): 4.58388995
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 10000/ t/epoch=1.96............. Loss: -0.79930200, mean(E): -20.54866074-0.02101975j, var(E): 5.26327235
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 10000/ t/epoch=1.96............. Loss: -0.22276381, mean(E): -20.77999834+0.00166348j, var(E): 7.70791334
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 10000/ t/epoch=1.96............. Loss: -0.46237728, mean(E): -20.88977898-0.03215719j, var(E): 4.99148952
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 10000/ t/epoch=1.95............. Loss: -0.44039878, mean(E): -20.60273911-0.03807217j, var(E): 4.90407131
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 10000/ t/epoch=1.96............. Loss: -0.25481466, mean(E): -20.97097587-0.00028341j, var(E): 5.53953203
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 10000/ t/epoch=1.96............. Loss: 0.39869441, mean(E): -21.04781472+0.00593424j, var(E): 6.73410088
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 10000/ t/epoch=1.96............. Loss: -0.00954834, mean(E): -20.71304168-0.05144291j, var(E): 3.86605037
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 10000/ t/epoch=1.95............. Loss: -0.28071986, mean(E): -20.79494038-0.00892600j, var(E): 4.14870945
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 10000/ t/epoch=1.96............. Loss: -0.32235263, mean(E): -20.94356359-0.03249846j, var(E): 5.37955253
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 10000/ t/epoch=1.96............. Loss: -0.08725862, mean(E): -21.06629792+0.00710903j, var(E): 4.85267828
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 10000/ t/epoch=1.96............. Loss: -0.61080175, mean(E): -20.97434880+0.00715111j, var(E): 5.78414022
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 10000/ t/epoch=1.96............. Loss: 0.25731223, mean(E): -21.16883028+0.03259281j, var(E): 4.81251964
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(12.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 10000/ t/epoch=1.96............. Loss: -0.72168988, mean(E): -20.68624163+0.04188076j, var(E): 4.39736160
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 10000/ t/epoch=1.95............. Loss: -1.19204681, mean(E): -20.77667400+0.01961911j, var(E): 5.34863014
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 10000/ t/epoch=1.96............. Loss: -0.41440173, mean(E): -21.03266137+0.04360874j, var(E): 6.34407425
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 10000/ t/epoch=1.96............. Loss: -1.35419692, mean(E): -20.64633227-0.00891872j, var(E): 4.98187394
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 10000/ t/epoch=1.96............. Loss: -0.82730710, mean(E): -20.72260152+0.01408868j, var(E): 5.81001511
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 10000/ t/epoch=1.96............. Loss: -0.13379340, mean(E): -20.75715628-0.03973539j, var(E): 4.95482933
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 10000/ t/epoch=1.96............. Loss: 0.77384283, mean(E): -21.43651040-0.03633178j, var(E): 4.64874454
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 10000/ t/epoch=1.96............. Loss: 0.38047507, mean(E): -21.09698005+0.04003415j, var(E): 7.44869084
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 10000/ t/epoch=1.96............. Loss: -0.81706583, mean(E): -21.04960537-0.03093515j, var(E): 4.47052677
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 10000/ t/epoch=1.96............. Loss: -0.24196356, mean(E): -20.92897251-0.03137831j, var(E): 5.85350414
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 10000/ t/epoch=1.96............. Loss: -1.06695813, mean(E): -20.86039409+0.05096778j, var(E): 3.72638952
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 10000/ t/epoch=1.96............. Loss: -0.07927648, mean(E): -21.14921890-0.04010838j, var(E): 4.53046324
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 10000/ t/epoch=1.96............. Loss: -0.28959030, mean(E): -21.13878858-0.00315505j, var(E): 3.61159514
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 10000/ t/epoch=1.96............. Loss: 0.00732244, mean(E): -21.15007704-0.00321800j, var(E): 3.69130752
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 10000/ t/epoch=1.96............. Loss: -0.94905424, mean(E): -20.91692033+0.01115126j, var(E): 3.17782806
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 10000/ t/epoch=1.96............. Loss: -0.75797991, mean(E): -21.03119281-0.05522672j, var(E): 3.88818995
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 10000/ t/epoch=1.95............. Loss: -0.37648681, mean(E): -20.96325020+0.00433895j, var(E): 4.56493280
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 10000/ t/epoch=1.96............. Loss: 0.26008205, mean(E): -21.28636817+0.00848331j, var(E): 5.12174221
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 10000/ t/epoch=1.96............. Loss: -0.81787445, mean(E): -21.05525188+0.00379818j, var(E): 4.71259897
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 10000/ t/epoch=1.96............. Loss: -0.13393004, mean(E): -21.18575829+0.00884991j, var(E): 3.70969467
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 10000/ t/epoch=1.96............. Loss: -0.04590741, mean(E): -21.07190840-0.03501544j, var(E): 4.15487016
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 10000/ t/epoch=1.96............. Loss: -0.17229912, mean(E): -21.13195977-0.02396962j, var(E): 3.80681697
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 10000/ t/epoch=1.96............. Loss: 0.16385661, mean(E): -21.45605531+0.03446917j, var(E): 5.28686538
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 10000/ t/epoch=1.96............. Loss: -0.54267104, mean(E): -20.98497155-0.01683859j, var(E): 4.49249702
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 10000/ t/epoch=1.96............. Loss: -0.76221415, mean(E): -21.00568124-0.01230328j, var(E): 3.79357096
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 10000/ t/epoch=1.96............. Loss: -1.03955987, mean(E): -20.91406561-0.05455032j, var(E): 4.03751343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 10000/ t/epoch=1.96............. Loss: -0.22664651, mean(E): -21.09048861-0.03591902j, var(E): 4.45758548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 10000/ t/epoch=1.96............. Loss: -0.62162869, mean(E): -21.04460593+0.00952147j, var(E): 4.12654618
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 10000/ t/epoch=1.96............. Loss: -0.85972670, mean(E): -21.01553385-0.01664470j, var(E): 4.49638622
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 10000/ t/epoch=1.96............. Loss: -0.62705737, mean(E): -20.97981182+0.06890313j, var(E): 3.71965940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 10000/ t/epoch=1.96............. Loss: -0.48390167, mean(E): -21.05126987-0.01508719j, var(E): 3.23382769
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 10000/ t/epoch=1.96............. Loss: -0.52211951, mean(E): -21.21183569+0.02362445j, var(E): 3.20166029
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 10000/ t/epoch=1.96............. Loss: -0.66037036, mean(E): -21.29408378-0.00028923j, var(E): 3.46161421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 10000/ t/epoch=1.96............. Loss: -0.18218924, mean(E): -21.15395505+0.04715388j, var(E): 3.60857697
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 10000/ t/epoch=1.96............. Loss: -0.25026533, mean(E): -21.32754871-0.01549551j, var(E): 3.07024574
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 10000/ t/epoch=1.96............. Loss: -0.30851520, mean(E): -21.30614795-0.02510156j, var(E): 2.78365114
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 10000/ t/epoch=1.96............. Loss: -0.92800868, mean(E): -21.22804884-0.02509834j, var(E): 3.48102963
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 10000/ t/epoch=1.96............. Loss: -0.63216543, mean(E): -21.21242987-0.04957645j, var(E): 3.06203140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 10000/ t/epoch=1.96............. Loss: -0.37744644, mean(E): -21.21517124-0.00229361j, var(E): 2.37130419
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 10000/ t/epoch=1.96............. Loss: -0.61414914, mean(E): -21.19810048-0.02924051j, var(E): 3.37031386
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 10000/ t/epoch=1.96............. Loss: -0.42818045, mean(E): -21.23705484-0.02188661j, var(E): 2.92025399
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 10000/ t/epoch=1.96............. Loss: -0.45549253, mean(E): -21.15904058-0.02829378j, var(E): 2.61286419
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 10000/ t/epoch=1.96............. Loss: -0.76356327, mean(E): -21.18922731-0.00034863j, var(E): 1.95678074
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 10000/ t/epoch=1.96............. Loss: -0.47258057, mean(E): -21.13298180-0.04816568j, var(E): 3.63592765
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 10000/ t/epoch=1.95............. Loss: -0.70062517, mean(E): -21.25613871+0.01435527j, var(E): 3.54284868
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 10000/ t/epoch=1.95............. Loss: -0.03314720, mean(E): -21.23963969+0.00660260j, var(E): 3.30892241
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 10000/ t/epoch=1.97............. Loss: -0.22883274, mean(E): -21.38470715+0.00691003j, var(E): 3.67786616
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 10000/ t/epoch=1.96............. Loss: 0.05522277, mean(E): -21.40970910-0.02223407j, var(E): 2.99741901
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 10000/ t/epoch=1.96............. Loss: 0.26433279, mean(E): -21.47579424-0.01040136j, var(E): 3.08903688
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 10000/ t/epoch=1.96............. Loss: -0.51442652, mean(E): -21.36320584-0.02072482j, var(E): 2.95954095
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 10000/ t/epoch=1.96............. Loss: 0.08193675, mean(E): -21.31963934-0.00009345j, var(E): 3.94054453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 10000/ t/epoch=1.96............. Loss: 0.08717747, mean(E): -21.34690200-0.01092897j, var(E): 3.72512531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 10000/ t/epoch=1.96............. Loss: -0.05429173, mean(E): -21.37638387-0.00916899j, var(E): 2.78202032
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 10000/ t/epoch=1.96............. Loss: -0.61611208, mean(E): -21.19616940+0.01082021j, var(E): 2.74644318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 10000/ t/epoch=1.98............. Loss: -0.66473234, mean(E): -21.31325916-0.00023091j, var(E): 2.30595416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 10000/ t/epoch=1.96............. Loss: -0.27638731, mean(E): -21.21298039-0.01325824j, var(E): 4.59635305
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 10000/ t/epoch=1.97............. Loss: -0.14817983, mean(E): -21.41978648-0.00728465j, var(E): 2.32570627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 10000/ t/epoch=1.96............. Loss: -0.92032866, mean(E): -21.36353497-0.00204545j, var(E): 2.15076313
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 10000/ t/epoch=1.96............. Loss: -1.00744134, mean(E): -21.17340839-0.01276168j, var(E): 3.91312036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 10000/ t/epoch=1.96............. Loss: 0.06977545, mean(E): -21.41791393+0.01561194j, var(E): 2.33821813
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 10000/ t/epoch=1.96............. Loss: 0.14666244, mean(E): -21.47916028-0.00619815j, var(E): 2.94940144
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 10000/ t/epoch=1.96............. Loss: -0.06526103, mean(E): -21.40915518+0.00981281j, var(E): 2.00450221
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 10000/ t/epoch=1.96............. Loss: -0.24017785, mean(E): -21.51026154+0.01536356j, var(E): 2.77313101
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 10000/ t/epoch=1.96............. Loss: -1.12585903, mean(E): -21.21896837-0.03529270j, var(E): 2.32585136
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 10000/ t/epoch=1.96............. Loss: -0.65900970, mean(E): -21.37003486-0.01232703j, var(E): 2.40488926
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 10000/ t/epoch=1.96............. Loss: -0.16383515, mean(E): -21.34266138-0.01369233j, var(E): 2.55866080
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 10000/ t/epoch=1.96............. Loss: 0.12414204, mean(E): -21.57718084-0.01658707j, var(E): 2.00143973
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 10000/ t/epoch=1.96............. Loss: -0.33069685, mean(E): -21.39070704+0.04459189j, var(E): 1.69041736
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 10000/ t/epoch=1.96............. Loss: -0.44306004, mean(E): -21.34702245+0.01718298j, var(E): 2.79193363
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 10000/ t/epoch=1.96............. Loss: 0.08699869, mean(E): -21.43729374+0.04091230j, var(E): 3.74447770
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 10000/ t/epoch=1.95............. Loss: 0.31993502, mean(E): -21.57757161+0.00062190j, var(E): 1.90719795
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 10000/ t/epoch=1.96............. Loss: -1.03260232, mean(E): -21.18741334+0.02394109j, var(E): 1.93701651
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 10000/ t/epoch=1.96............. Loss: 0.31850533, mean(E): -21.53495808-0.00212913j, var(E): 3.07065008
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 10000/ t/epoch=1.97............. Loss: -0.22610831, mean(E): -21.46841202-0.01833746j, var(E): 2.13352945
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 10000/ t/epoch=1.96............. Loss: -0.54122248, mean(E): -21.33933341+0.01881075j, var(E): 1.58205437
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 10000/ t/epoch=1.99............. Loss: -0.15779162, mean(E): -21.37972752-0.01724843j, var(E): 2.26959342
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 10000/ t/epoch=1.96............. Loss: 0.00943776, mean(E): -21.42238577-0.01513587j, var(E): 3.04485506
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 10000/ t/epoch=1.96............. Loss: -0.79103843, mean(E): -21.33489670-0.04396888j, var(E): 2.34243506
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 10000/ t/epoch=1.96............. Loss: -0.02418999, mean(E): -21.39007909-0.02476330j, var(E): 1.15198958
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 10000/ t/epoch=1.96............. Loss: -0.17876070, mean(E): -21.35288484+0.01420148j, var(E): 1.81767355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 10000/ t/epoch=1.96............. Loss: -0.28245774, mean(E): -21.50715169-0.01569740j, var(E): 1.73741360
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 10000/ t/epoch=1.96............. Loss: 0.28448594, mean(E): -21.63584166-0.02690416j, var(E): 1.68608916
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 10000/ t/epoch=1.96............. Loss: -0.11889371, mean(E): -21.54652688+0.00367680j, var(E): 2.00220816
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 10000/ t/epoch=1.96............. Loss: 0.08209927, mean(E): -21.61528367+0.01640063j, var(E): 1.74398245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 10000/ t/epoch=1.95............. Loss: 0.78198265, mean(E): -21.68443769+0.01664700j, var(E): 1.91144892
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 10000/ t/epoch=1.96............. Loss: -0.07558439, mean(E): -21.37300690-0.00553993j, var(E): 1.74018616
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 10000/ t/epoch=1.96............. Loss: -0.96356798, mean(E): -21.40153327-0.02558367j, var(E): 1.74375666
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 10000/ t/epoch=1.96............. Loss: 0.10737501, mean(E): -21.59797143+0.03339714j, var(E): 0.97860525
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 10000/ t/epoch=1.96............. Loss: -0.60418008, mean(E): -21.41169146+0.05632220j, var(E): 2.16498882
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 10000/ t/epoch=1.96............. Loss: 0.33409030, mean(E): -21.51457105-0.02903648j, var(E): 1.97394793
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 10000/ t/epoch=1.96............. Loss: -0.18855774, mean(E): -21.43035340-0.01493836j, var(E): 2.40459368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 10000/ t/epoch=1.96............. Loss: 0.22320045, mean(E): -21.52377809+0.02290041j, var(E): 2.21200337
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 10000/ t/epoch=1.96............. Loss: -0.13372775, mean(E): -21.55362250-0.04141478j, var(E): 2.03580059
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 10000/ t/epoch=1.96............. Loss: -0.41002064, mean(E): -21.53561102+0.00596219j, var(E): 1.54691566
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 10000/ t/epoch=1.96............. Loss: 0.08521981, mean(E): -21.50231579+0.02603448j, var(E): 1.79221283
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 10000/ t/epoch=1.96............. Loss: -0.13596593, mean(E): -21.49975975+0.00699760j, var(E): 0.99094100
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 10000/ t/epoch=1.95............. Loss: -0.28847626, mean(E): -21.36760398-0.01101022j, var(E): 1.47972711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 10000/ t/epoch=1.96............. Loss: 0.28802754, mean(E): -21.51215220-0.06806183j, var(E): 1.61899189
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 10000/ t/epoch=1.96............. Loss: 0.60245091, mean(E): -21.68030255-0.02839501j, var(E): 1.08386781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(13.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 10000/ t/epoch=1.97............. Loss: -0.24158112, mean(E): -21.43704414-0.00861060j, var(E): 0.87422194
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 10000/ t/epoch=1.96............. Loss: 0.62580654, mean(E): -21.57039774+0.00304911j, var(E): 2.76203560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 10000/ t/epoch=1.97............. Loss: -0.37581702, mean(E): -21.42496056+0.01694716j, var(E): 1.45880311
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 10000/ t/epoch=1.96............. Loss: -0.58639149, mean(E): -21.38764326-0.01364860j, var(E): 1.09505384
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 10000/ t/epoch=1.96............. Loss: -0.45409497, mean(E): -21.46043282+0.01231206j, var(E): 1.97452247
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 10000/ t/epoch=1.96............. Loss: -0.71263933, mean(E): -21.46444353-0.01700269j, var(E): 1.27742745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 10000/ t/epoch=1.96............. Loss: -0.01087603, mean(E): -21.45018750+0.01883718j, var(E): 2.60670591
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 10000/ t/epoch=1.96............. Loss: -0.21594749, mean(E): -21.51348247+0.03062663j, var(E): 1.40535412
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 10000/ t/epoch=1.96............. Loss: -0.04832102, mean(E): -21.55091494-0.02280804j, var(E): 2.62066102
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 10000/ t/epoch=1.96............. Loss: -0.40482099, mean(E): -21.42195656+0.00101416j, var(E): 1.95418020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 10000/ t/epoch=1.96............. Loss: -0.81969905, mean(E): -21.34928307-0.01336228j, var(E): 2.24420647
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 10000/ t/epoch=1.96............. Loss: -0.42851645, mean(E): -21.48807825+0.00015749j, var(E): 1.40833140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 10000/ t/epoch=1.96............. Loss: -0.39885382, mean(E): -21.44454350+0.01663329j, var(E): 3.15333784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 10000/ t/epoch=1.96............. Loss: -0.47763717, mean(E): -21.47063799+0.02058333j, var(E): 2.11068177
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 10000/ t/epoch=1.96............. Loss: -0.54709154, mean(E): -21.42659145+0.02624310j, var(E): 0.84254264
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 10000/ t/epoch=1.96............. Loss: -0.00657987, mean(E): -21.57040761+0.01002055j, var(E): 1.27622935
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 10000/ t/epoch=1.96............. Loss: -0.07914632, mean(E): -21.53307333+0.02080112j, var(E): 0.89653096
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 10000/ t/epoch=1.96............. Loss: -0.49312848, mean(E): -21.41417403+0.01095170j, var(E): 0.78758991
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 10000/ t/epoch=1.96............. Loss: -0.80468641, mean(E): -21.40044178-0.01499638j, var(E): 1.11945899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 10000/ t/epoch=1.96............. Loss: -0.51333770, mean(E): -21.43533415+0.02243154j, var(E): 0.88086778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 10000/ t/epoch=1.96............. Loss: -0.37163947, mean(E): -21.48109373-0.00549099j, var(E): 1.13937767
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 10000/ t/epoch=1.97............. Loss: -0.58481898, mean(E): -21.46068240-0.00964186j, var(E): 0.93559051
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 10000/ t/epoch=1.96............. Loss: 0.00383173, mean(E): -21.55147494+0.05437529j, var(E): 1.69845290
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 10000/ t/epoch=1.96............. Loss: 0.24740957, mean(E): -21.57454981-0.05588991j, var(E): 3.15153294
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 10000/ t/epoch=1.96............. Loss: 0.29075610, mean(E): -21.56502503-0.01976002j, var(E): 1.28719931
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 10000/ t/epoch=1.96............. Loss: 0.15328444, mean(E): -21.60150930-0.00857915j, var(E): 1.02528266
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 10000/ t/epoch=1.96............. Loss: -0.46641249, mean(E): -21.42345944-0.01807325j, var(E): 1.51658110
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 10000/ t/epoch=1.96............. Loss: 0.22372146, mean(E): -21.60182612-0.00803907j, var(E): 0.79834813
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 10000/ t/epoch=1.96............. Loss: 0.01324444, mean(E): -21.52970338+0.02095348j, var(E): 2.18109204
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 10000/ t/epoch=1.96............. Loss: -0.19829051, mean(E): -21.54577105+0.00048722j, var(E): 1.02390567
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 10000/ t/epoch=1.96............. Loss: -0.40696058, mean(E): -21.55813292+0.00875055j, var(E): 1.27743042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 10000/ t/epoch=1.96............. Loss: 0.04120583, mean(E): -21.53740847-0.02383459j, var(E): 1.40823320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 10000/ t/epoch=1.96............. Loss: -0.68071426, mean(E): -21.46800168-0.03006429j, var(E): 1.20369343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 10000/ t/epoch=1.95............. Loss: 0.20934312, mean(E): -21.52159609-0.00591400j, var(E): 0.94618896
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 10000/ t/epoch=1.96............. Loss: 0.04133567, mean(E): -21.53073955+0.00792060j, var(E): 0.91878018
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 10000/ t/epoch=1.96............. Loss: -0.35855741, mean(E): -21.48400105-0.04725582j, var(E): 0.77962021
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 10000/ t/epoch=1.96............. Loss: -0.30025509, mean(E): -21.47600162-0.00634291j, var(E): 0.77887191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 10000/ t/epoch=1.96............. Loss: 0.29539099, mean(E): -21.61454962-0.01774209j, var(E): 2.63883527
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 10000/ t/epoch=1.96............. Loss: 0.35233093, mean(E): -21.63520103+0.02190164j, var(E): 2.62802150
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 10000/ t/epoch=1.96............. Loss: -0.33520652, mean(E): -21.57929762+0.00430415j, var(E): 1.40577539
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 10000/ t/epoch=1.96............. Loss: -0.36984265, mean(E): -21.52063469+0.02602405j, var(E): 0.80561494
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 10000/ t/epoch=1.96............. Loss: 1.47022218, mean(E): -21.72080463+0.02869674j, var(E): 2.86127153
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 10000/ t/epoch=1.96............. Loss: 0.29011041, mean(E): -21.59552908+0.00698111j, var(E): 1.20787387
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 10000/ t/epoch=1.96............. Loss: -0.11009318, mean(E): -21.55144460+0.00896181j, var(E): 1.14366835
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 10000/ t/epoch=1.96............. Loss: -0.77844306, mean(E): -21.44415681+0.01917757j, var(E): 1.19019514
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 10000/ t/epoch=1.96............. Loss: -0.57887237, mean(E): -21.45061454-0.02009253j, var(E): 1.31227548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 10000/ t/epoch=1.95............. Loss: -0.02024876, mean(E): -21.57350742+0.02193709j, var(E): 1.73762978
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 10000/ t/epoch=1.96............. Loss: 0.29694987, mean(E): -21.59633013+0.05066223j, var(E): 1.33394162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 10000/ t/epoch=1.96............. Loss: 0.37356383, mean(E): -21.62872208+0.01156506j, var(E): 1.23607701
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 10000/ t/epoch=1.96............. Loss: -0.02574217, mean(E): -21.55319756+0.01011122j, var(E): 1.90317888
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 10000/ t/epoch=1.96............. Loss: -0.17090770, mean(E): -21.55883439-0.01118179j, var(E): 1.03240098
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 10000/ t/epoch=1.96............. Loss: 0.33841879, mean(E): -21.59351954+0.01150990j, var(E): 1.49915636
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 10000/ t/epoch=1.96............. Loss: -0.35168068, mean(E): -21.52817613-0.03213283j, var(E): 1.21465915
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 10000/ t/epoch=1.96............. Loss: 0.40311641, mean(E): -21.62384092-0.01637486j, var(E): 2.18793828
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 10000/ t/epoch=1.96............. Loss: -0.01663091, mean(E): -21.55085517-0.00517681j, var(E): 1.13290789
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 10000/ t/epoch=1.96............. Loss: 0.02875840, mean(E): -21.62018087+0.02068879j, var(E): 1.53676705
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 10000/ t/epoch=1.96............. Loss: -0.30165588, mean(E): -21.46446812+0.02398619j, var(E): 0.88081222
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 10000/ t/epoch=1.96............. Loss: -0.12200518, mean(E): -21.48386464+0.01856302j, var(E): 1.53428736
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 10000/ t/epoch=1.96............. Loss: -0.50747804, mean(E): -21.46448842+0.03313479j, var(E): 0.83436957
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 10000/ t/epoch=1.96............. Loss: -0.75614233, mean(E): -21.43769778+0.02693518j, var(E): 1.24887662
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 10000/ t/epoch=1.96............. Loss: -0.27811883, mean(E): -21.58580411+0.05439959j, var(E): 1.92591506
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 10000/ t/epoch=1.96............. Loss: -0.47668463, mean(E): -21.51149329+0.02192410j, var(E): 1.19568646
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 10000/ t/epoch=1.96............. Loss: 0.12378297, mean(E): -21.61858293-0.00516889j, var(E): 0.75158910
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 10000/ t/epoch=1.97............. Loss: -0.49964662, mean(E): -21.47237716+0.01472534j, var(E): 0.96034492
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 10000/ t/epoch=1.96............. Loss: -0.36910729, mean(E): -21.55898431+0.01814109j, var(E): 0.93033509
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 10000/ t/epoch=1.96............. Loss: 0.34860971, mean(E): -21.61210327+0.01352421j, var(E): 1.11856332
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 10000/ t/epoch=1.96............. Loss: 0.30173086, mean(E): -21.59722987-0.03677799j, var(E): 0.90460567
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 10000/ t/epoch=1.96............. Loss: -0.17687333, mean(E): -21.55383751+0.02239963j, var(E): 0.99946381
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 10000/ t/epoch=1.96............. Loss: 0.10314682, mean(E): -21.57814636+0.04122688j, var(E): 1.07644307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 10000/ t/epoch=1.96............. Loss: 0.07914446, mean(E): -21.55846560-0.01548920j, var(E): 1.00257267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 10000/ t/epoch=1.96............. Loss: -0.78091222, mean(E): -21.54487060+0.02413202j, var(E): 2.12710564
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 10000/ t/epoch=1.96............. Loss: -0.53874742, mean(E): -21.47504607+0.01149223j, var(E): 0.79802298
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 10000/ t/epoch=1.96............. Loss: 0.05961898, mean(E): -21.61376161+0.02850630j, var(E): 1.07333666
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 10000/ t/epoch=1.96............. Loss: -0.18254240, mean(E): -21.56272144+0.02748174j, var(E): 1.05525187
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 10000/ t/epoch=1.96............. Loss: 0.39618514, mean(E): -21.64914602+0.00772046j, var(E): 0.76740403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 10000/ t/epoch=1.96............. Loss: -0.07638896, mean(E): -21.60171867+0.01263642j, var(E): 0.33637022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 10000/ t/epoch=1.96............. Loss: -0.14749083, mean(E): -21.58820241+0.02763472j, var(E): 1.44766160
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 10000/ t/epoch=1.96............. Loss: -0.35481064, mean(E): -21.53168148+0.01269969j, var(E): 1.05006630
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 10000/ t/epoch=1.95............. Loss: -0.07778461, mean(E): -21.54560894-0.01811655j, var(E): 2.00370244
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 10000/ t/epoch=1.96............. Loss: 0.52428578, mean(E): -21.69038039-0.01486360j, var(E): 0.92093083
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 10000/ t/epoch=1.97............. Loss: -0.69452955, mean(E): -21.46340306+0.02193566j, var(E): 0.87654596
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 10000/ t/epoch=1.96............. Loss: -0.06945398, mean(E): -21.61217437-0.03548888j, var(E): 1.11099431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 10000/ t/epoch=1.96............. Loss: 0.14449122, mean(E): -21.58875934-0.00605595j, var(E): 2.04659427
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 10000/ t/epoch=1.96............. Loss: 1.15725418, mean(E): -21.83928001+0.00356761j, var(E): 2.24783371
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 10000/ t/epoch=1.96............. Loss: 1.57066893, mean(E): -21.78344031-0.03368337j, var(E): 3.11674875
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 10000/ t/epoch=1.96............. Loss: -0.43539347, mean(E): -21.51352179-0.02130673j, var(E): 0.67655131
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 10000/ t/epoch=1.96............. Loss: 0.04450471, mean(E): -21.57456759-0.00630007j, var(E): 0.83790582
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 10000/ t/epoch=1.96............. Loss: -0.42692676, mean(E): -21.46113876+0.01825945j, var(E): 1.19523534
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 10000/ t/epoch=1.96............. Loss: -0.23706929, mean(E): -21.57087534+0.03533777j, var(E): 0.54402185
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 10000/ t/epoch=1.96............. Loss: -0.24550448, mean(E): -21.54324034+0.02261905j, var(E): 1.44892687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 10000/ t/epoch=1.96............. Loss: -0.18121460, mean(E): -21.54606985-0.01041239j, var(E): 0.87198390
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 10000/ t/epoch=1.96............. Loss: 0.46569498, mean(E): -21.55730091+0.01956600j, var(E): 1.46763059
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 10000/ t/epoch=1.96............. Loss: 0.46911411, mean(E): -21.69948643-0.00298070j, var(E): 0.94486097
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 10000/ t/epoch=1.96............. Loss: 0.27442031, mean(E): -21.66593439+0.00723137j, var(E): 1.02633636
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 10000/ t/epoch=1.96............. Loss: -0.02955266, mean(E): -21.58656822+0.02215849j, var(E): 1.13479313
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 10000/ t/epoch=1.96............. Loss: -0.09752923, mean(E): -21.57396507+0.00510230j, var(E): 0.55318215
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 10000/ t/epoch=1.96............. Loss: -0.50514523, mean(E): -21.47072520+0.03157414j, var(E): 1.06246082
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 10000/ t/epoch=1.97............. Loss: -0.37781757, mean(E): -21.53949284+0.01259540j, var(E): 0.94212883
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 10000/ t/epoch=1.96............. Loss: -0.62006335, mean(E): -21.51273849+0.01054751j, var(E): 0.77553485
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 10000/ t/epoch=1.96............. Loss: -0.17090702, mean(E): -21.51544058-0.03892239j, var(E): 0.92938300
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 10000/ t/epoch=1.96............. Loss: 0.10765860, mean(E): -21.61108540-0.03503413j, var(E): 0.67068770
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 10000/ t/epoch=1.96............. Loss: -0.11041596, mean(E): -21.57192971+0.01079706j, var(E): 1.00191482
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 10000/ t/epoch=1.96............. Loss: 0.28840220, mean(E): -21.63106445+0.01155650j, var(E): 0.78505453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 10000/ t/epoch=1.96............. Loss: 0.43715771, mean(E): -21.69267020+0.04444972j, var(E): 2.85727883
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 10000/ t/epoch=1.96............. Loss: -0.12287122, mean(E): -21.52412836-0.00713531j, var(E): 0.92170711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 10000/ t/epoch=1.96............. Loss: 0.01999296, mean(E): -21.61631671-0.00875005j, var(E): 0.83030466
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 10000/ t/epoch=1.96............. Loss: -0.15519271, mean(E): -21.60348399+0.02476669j, var(E): 0.78011611
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 10000/ t/epoch=1.96............. Loss: -0.02049478, mean(E): -21.60359551+0.01795712j, var(E): 1.37413748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 10000/ t/epoch=1.96............. Loss: -0.24710313, mean(E): -21.52899405-0.02970990j, var(E): 0.80483067
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 10000/ t/epoch=1.95............. Loss: 0.01308070, mean(E): -21.62419524-0.00984867j, var(E): 1.21569143
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 10000/ t/epoch=1.96............. Loss: 0.60427482, mean(E): -21.70487627+0.03720568j, var(E): 1.43874361
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 10000/ t/epoch=1.97............. Loss: 0.38717705, mean(E): -21.60435454-0.00173232j, var(E): 1.81210668
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 10000/ t/epoch=1.98............. Loss: -0.11588561, mean(E): -21.54789749-0.00132643j, var(E): 1.16409971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 10000/ t/epoch=1.96............. Loss: -0.36175587, mean(E): -21.53925081-0.00514278j, var(E): 0.69329365
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 10000/ t/epoch=1.96............. Loss: -0.85128762, mean(E): -21.45814544-0.01869007j, var(E): 0.90409819
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 10000/ t/epoch=1.96............. Loss: 0.29034622, mean(E): -21.58748029+0.01269360j, var(E): 1.20718077
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 10000/ t/epoch=1.96............. Loss: -0.53719244, mean(E): -21.47600223-0.00672736j, var(E): 1.11950786
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 10000/ t/epoch=1.96............. Loss: -0.23293915, mean(E): -21.56578043+0.03123407j, var(E): 0.73161423
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 10000/ t/epoch=1.96............. Loss: -0.41594423, mean(E): -21.57944282+0.02715063j, var(E): 1.06765696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 10000/ t/epoch=1.96............. Loss: -0.34322517, mean(E): -21.51391404+0.03742319j, var(E): 0.52775979
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 10000/ t/epoch=1.96............. Loss: -0.23871602, mean(E): -21.55346036-0.00476499j, var(E): 1.09021022
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 10000/ t/epoch=1.96............. Loss: 0.21693930, mean(E): -21.65620355+0.02180914j, var(E): 0.48062173
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 10000/ t/epoch=1.99............. Loss: -0.69095969, mean(E): -21.55920220+0.02238752j, var(E): 1.44530042
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 10000/ t/epoch=1.96............. Loss: 0.25595552, mean(E): -21.64739944+0.00341142j, var(E): 1.09647318
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 10000/ t/epoch=1.96............. Loss: -0.29530637, mean(E): -21.53075174+0.00264353j, var(E): 0.61804553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 10000/ t/epoch=1.96............. Loss: 0.40927264, mean(E): -21.67013191+0.01552804j, var(E): 1.53981867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 10000/ t/epoch=1.96............. Loss: 0.27806278, mean(E): -21.59782461+0.01811898j, var(E): 1.49360478
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 10000/ t/epoch=1.95............. Loss: 0.03903472, mean(E): -21.58961344-0.00542209j, var(E): 1.29656939
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 10000/ t/epoch=1.96............. Loss: -0.38017002, mean(E): -21.59512191+0.00363854j, var(E): 0.73117651
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 10000/ t/epoch=1.96............. Loss: 0.19291195, mean(E): -21.69213387+0.03284187j, var(E): 0.96269629
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 10000/ t/epoch=1.96............. Loss: -0.02088888, mean(E): -21.63192352+0.01947963j, var(E): 0.59020760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 10000/ t/epoch=1.96............. Loss: 0.13362544, mean(E): -21.57502286-0.02016475j, var(E): 1.36414314
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 10000/ t/epoch=1.96............. Loss: -0.57116814, mean(E): -21.57339715+0.00561887j, var(E): 1.23868186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 10000/ t/epoch=1.96............. Loss: -0.22814162, mean(E): -21.53167993+0.00543445j, var(E): 0.53773738
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 10000/ t/epoch=1.96............. Loss: -0.15705642, mean(E): -21.54912951-0.00948179j, var(E): 1.12003662
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 10000/ t/epoch=1.96............. Loss: -0.27130131, mean(E): -21.57391633-0.00553007j, var(E): 1.35466383
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 10000/ t/epoch=1.96............. Loss: -0.05868609, mean(E): -21.61804181-0.03116901j, var(E): 0.41118140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 10000/ t/epoch=1.96............. Loss: -0.14234890, mean(E): -21.62661016-0.02198498j, var(E): 1.13181417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 10000/ t/epoch=1.96............. Loss: -0.00957500, mean(E): -21.61881117+0.03714679j, var(E): 0.56218339
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 10000/ t/epoch=1.96............. Loss: -0.17483983, mean(E): -21.62286097-0.00076665j, var(E): 0.80325062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 10000/ t/epoch=1.96............. Loss: -0.26437564, mean(E): -21.60239319-0.00943285j, var(E): 0.98361539
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 10000/ t/epoch=1.96............. Loss: 0.02507357, mean(E): -21.59848126+0.00511076j, var(E): 0.66845647
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 10000/ t/epoch=1.95............. Loss: -0.22862513, mean(E): -21.58620616-0.00925991j, var(E): 0.73769020
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 10000/ t/epoch=1.96............. Loss: -0.36841593, mean(E): -21.54583308+0.01138021j, var(E): 0.77748191
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 10000/ t/epoch=1.97............. Loss: 0.23359095, mean(E): -21.68275355-0.00779811j, var(E): 0.56971202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 10000/ t/epoch=1.96............. Loss: 0.01826558, mean(E): -21.59985898+0.01996436j, var(E): 0.60393421
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 10000/ t/epoch=1.96............. Loss: 0.09109952, mean(E): -21.65324162+0.02079992j, var(E): 0.72260873
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 10000/ t/epoch=1.96............. Loss: -0.35187852, mean(E): -21.58919548-0.01168875j, var(E): 1.23702459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 10000/ t/epoch=1.96............. Loss: -0.04273397, mean(E): -21.65965198-0.00213420j, var(E): 0.68996809
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 10000/ t/epoch=1.96............. Loss: -0.19320287, mean(E): -21.60775852-0.00626078j, var(E): 0.57099727
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 10000/ t/epoch=1.96............. Loss: -0.30732296, mean(E): -21.54027772+0.02167933j, var(E): 1.31500300
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 10000/ t/epoch=1.96............. Loss: -0.60904959, mean(E): -21.55393848+0.03327975j, var(E): 0.83732937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 10000/ t/epoch=1.96............. Loss: -0.62225599, mean(E): -21.56703884-0.02034706j, var(E): 0.67670816
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 10000/ t/epoch=1.96............. Loss: -0.68096381, mean(E): -21.48285520+0.00994456j, var(E): 1.63564026
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 10000/ t/epoch=1.96............. Loss: -0.56883743, mean(E): -21.48097894-0.01330292j, var(E): 1.09125960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 10000/ t/epoch=1.96............. Loss: -0.45436024, mean(E): -21.59307981+0.01620199j, var(E): 1.44052266
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 10000/ t/epoch=1.96............. Loss: 0.27933010, mean(E): -21.62083064+0.06568273j, var(E): 1.61540787
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 10000/ t/epoch=1.96............. Loss: -0.27725560, mean(E): -21.57962664-0.00148750j, var(E): 0.84280999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 10000/ t/epoch=1.96............. Loss: -0.57727980, mean(E): -21.53307874-0.00037457j, var(E): 0.63388269
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 10000/ t/epoch=1.96............. Loss: -0.61964986, mean(E): -21.51676596-0.01640998j, var(E): 0.60250286
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 10000/ t/epoch=1.96............. Loss: -0.35774301, mean(E): -21.59739638+0.00319822j, var(E): 0.81640086
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 10000/ t/epoch=1.96............. Loss: -0.16427584, mean(E): -21.60617423-0.01003689j, var(E): 1.18484349
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 10000/ t/epoch=1.96............. Loss: 0.09741537, mean(E): -21.61873159-0.00448191j, var(E): 0.81683202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 10000/ t/epoch=1.96............. Loss: -0.33132949, mean(E): -21.53387433+0.00609052j, var(E): 0.89904151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 10000/ t/epoch=1.97............. Loss: -0.19040343, mean(E): -21.58328109-0.00002153j, var(E): 0.78023498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 10000/ t/epoch=1.96............. Loss: -0.03213973, mean(E): -21.64786343+0.00586087j, var(E): 0.79081271
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 10000/ t/epoch=1.96............. Loss: -0.06502239, mean(E): -21.60248746-0.00839476j, var(E): 1.11166758
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 10000/ t/epoch=1.96............. Loss: 0.06276459, mean(E): -21.65662134+0.03926246j, var(E): 1.21690690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 10000/ t/epoch=1.96............. Loss: -0.39542955, mean(E): -21.55597717+0.03016498j, var(E): 0.74034381
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 10000/ t/epoch=1.96............. Loss: 0.15703317, mean(E): -21.63433800-0.01895563j, var(E): 1.46088632
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 10000/ t/epoch=1.96............. Loss: -0.39291034, mean(E): -21.57397843+0.00861379j, var(E): 0.64729977
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 10000/ t/epoch=1.96............. Loss: 0.57479784, mean(E): -21.69378549+0.03505197j, var(E): 1.02296504
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 10000/ t/epoch=1.96............. Loss: 0.16972669, mean(E): -21.65211583-0.01870790j, var(E): 0.86612724
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 10000/ t/epoch=1.96............. Loss: 0.42634726, mean(E): -21.70117843+0.00172964j, var(E): 1.42399265
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 10000/ t/epoch=1.96............. Loss: -0.19223802, mean(E): -21.58003867+0.01822590j, var(E): 0.51630320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 10000/ t/epoch=1.96............. Loss: -0.00328902, mean(E): -21.64581479+0.00080328j, var(E): 0.39231888
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 10000/ t/epoch=1.96............. Loss: 0.10908299, mean(E): -21.69203375-0.00588163j, var(E): 1.24337503
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 10000/ t/epoch=1.96............. Loss: -0.08081240, mean(E): -21.60185651+0.00788339j, var(E): 0.67370093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 10000/ t/epoch=1.96............. Loss: 0.25189023, mean(E): -21.69079593-0.01109443j, var(E): 0.47659324
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 10000/ t/epoch=1.96............. Loss: 0.37889355, mean(E): -21.64707805-0.01060964j, var(E): 1.34931748
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 10000/ t/epoch=1.96............. Loss: -0.25421472, mean(E): -21.50078788-0.00443203j, var(E): 1.32429911
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 10000/ t/epoch=1.96............. Loss: 0.49401749, mean(E): -21.70954792-0.00019519j, var(E): 0.71882112
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 10000/ t/epoch=1.96............. Loss: -0.69975379, mean(E): -21.50818269-0.00868471j, var(E): 0.94654832
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 10000/ t/epoch=1.96............. Loss: -0.44543951, mean(E): -21.56079170+0.01949342j, var(E): 0.86627456
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 10000/ t/epoch=1.96............. Loss: 1.88716077, mean(E): -21.80385972+0.04981596j, var(E): 2.92311302
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 10000/ t/epoch=1.96............. Loss: -0.06417035, mean(E): -21.66946277+0.00604032j, var(E): 1.20416213
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 10000/ t/epoch=1.96............. Loss: 0.61397532, mean(E): -21.72954539+0.01513416j, var(E): 1.79381721
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 10000/ t/epoch=1.96............. Loss: 0.18783278, mean(E): -21.67239677-0.01795650j, var(E): 0.73651568
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 10000/ t/epoch=1.96............. Loss: -0.78445942, mean(E): -21.48848728-0.02656310j, var(E): 1.20175073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 10000/ t/epoch=1.96............. Loss: 0.27495618, mean(E): -21.66270989-0.01760183j, var(E): 0.88727916
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 10000/ t/epoch=1.96............. Loss: 0.68439963, mean(E): -21.68150218+0.00227375j, var(E): 3.53211311
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 10000/ t/epoch=1.96............. Loss: -0.31653094, mean(E): -21.55232388-0.00416175j, var(E): 0.77758652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 10000/ t/epoch=1.96............. Loss: -0.14184563, mean(E): -21.59092999+0.01774904j, var(E): 0.70687886
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 10000/ t/epoch=1.96............. Loss: -0.37014450, mean(E): -21.62695059+0.02044885j, var(E): 0.74058182
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 10000/ t/epoch=1.97............. Loss: -0.11142677, mean(E): -21.62882119+0.02488128j, var(E): 0.82448513
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 10000/ t/epoch=1.97............. Loss: -0.91298851, mean(E): -21.52268658+0.00819667j, var(E): 1.42927309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 10000/ t/epoch=1.97............. Loss: -0.27416895, mean(E): -21.62901191+0.00810269j, var(E): 0.94151867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 10000/ t/epoch=1.96............. Loss: 0.21839937, mean(E): -21.62869219-0.00913166j, var(E): 1.53537790
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 10000/ t/epoch=1.96............. Loss: 0.32184849, mean(E): -21.71955091+0.03328967j, var(E): 0.55430469
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 10000/ t/epoch=1.96............. Loss: -0.08996984, mean(E): -21.65873663+0.01196932j, var(E): 0.66995262
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 10000/ t/epoch=1.96............. Loss: -0.23909499, mean(E): -21.61211363+0.02427191j, var(E): 1.23086520
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 10000/ t/epoch=1.96............. Loss: 0.30184518, mean(E): -21.66432783+0.01526933j, var(E): 0.93451294
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 10000/ t/epoch=1.96............. Loss: -0.25957063, mean(E): -21.57582262-0.00867564j, var(E): 0.75924548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 10000/ t/epoch=1.96............. Loss: 0.28595206, mean(E): -21.69726723+0.01373421j, var(E): 0.54547005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 10000/ t/epoch=1.96............. Loss: -0.18910023, mean(E): -21.62165397+0.00934605j, var(E): 0.82505889
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 10000/ t/epoch=1.96............. Loss: 0.23013726, mean(E): -21.67457517-0.00188868j, var(E): 0.52706951
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 10000/ t/epoch=1.96............. Loss: 0.01046696, mean(E): -21.62294571-0.03074258j, var(E): 0.75294560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 10000/ t/epoch=1.96............. Loss: -0.20773787, mean(E): -21.56745785+0.00337595j, var(E): 0.65094259
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 10000/ t/epoch=1.96............. Loss: -0.49730479, mean(E): -21.54182882-0.00847517j, var(E): 0.60470640
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 10000/ t/epoch=1.96............. Loss: -0.17710698, mean(E): -21.58452738-0.00756005j, var(E): 0.51621245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 10000/ t/epoch=1.96............. Loss: 0.06233262, mean(E): -21.62063298-0.01641391j, var(E): 0.95930632
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 10000/ t/epoch=1.96............. Loss: -0.01252954, mean(E): -21.61873147-0.00685892j, var(E): 0.62003737
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 10000/ t/epoch=1.96............. Loss: -0.67592255, mean(E): -21.57729801-0.00782378j, var(E): 0.68110338
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 10000/ t/epoch=1.96............. Loss: -0.13972961, mean(E): -21.66600132-0.00193117j, var(E): 0.84210132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 10000/ t/epoch=1.96............. Loss: 0.32979961, mean(E): -21.71483055-0.02298265j, var(E): 0.49815531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 10000/ t/epoch=1.96............. Loss: 0.17300617, mean(E): -21.65321351-0.00261043j, var(E): 0.83703038
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 10000/ t/epoch=1.96............. Loss: -0.29918724, mean(E): -21.60769525-0.00688977j, var(E): 1.42241052
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 10000/ t/epoch=1.96............. Loss: -0.31342267, mean(E): -21.63133286-0.01495613j, var(E): 0.79778709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 10000/ t/epoch=1.96............. Loss: 0.00903286, mean(E): -21.64147867-0.01839300j, var(E): 0.45502763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 10000/ t/epoch=1.96............. Loss: -0.11341039, mean(E): -21.59483531+0.00386255j, var(E): 0.65889798
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 10000/ t/epoch=1.96............. Loss: 0.49335172, mean(E): -21.71396838-0.05483430j, var(E): 1.43712284
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 10000/ t/epoch=1.96............. Loss: 0.61572049, mean(E): -21.68826028+0.02956682j, var(E): 1.17976316
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 10000/ t/epoch=1.96............. Loss: 0.35106221, mean(E): -21.65685465-0.01453524j, var(E): 0.93592717
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 10000/ t/epoch=1.96............. Loss: 0.41134661, mean(E): -21.71545102+0.00477075j, var(E): 0.79353068
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 10000/ t/epoch=1.96............. Loss: -0.78909107, mean(E): -21.53272819+0.01418276j, var(E): 0.67351342
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 10000/ t/epoch=1.96............. Loss: -0.46874151, mean(E): -21.53965427-0.01549123j, var(E): 1.20163225
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 10000/ t/epoch=1.96............. Loss: 0.06436351, mean(E): -21.62782612+0.01094108j, var(E): 0.97262586
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 10000/ t/epoch=1.96............. Loss: 0.30734884, mean(E): -21.66785492-0.02583463j, var(E): 0.86278359
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 10000/ t/epoch=1.97............. Loss: 0.11584585, mean(E): -21.65633727+0.01342085j, var(E): 0.70418000
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 10000/ t/epoch=1.97............. Loss: 0.15398836, mean(E): -21.69072559-0.00136489j, var(E): 0.51438700
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 10000/ t/epoch=1.96............. Loss: -0.12998276, mean(E): -21.58325067-0.00739894j, var(E): 0.57960288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 10000/ t/epoch=1.96............. Loss: -0.48116254, mean(E): -21.55705759-0.01244851j, var(E): 0.62618965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 10000/ t/epoch=1.96............. Loss: -0.24668441, mean(E): -21.59098434-0.00384139j, var(E): 1.08925228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 10000/ t/epoch=1.96............. Loss: -0.06941365, mean(E): -21.68489732+0.02663980j, var(E): 0.74611426
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 10000/ t/epoch=1.96............. Loss: -0.41132317, mean(E): -21.55221526+0.01060525j, var(E): 0.86026445
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 10000/ t/epoch=1.96............. Loss: 0.41986100, mean(E): -21.79359718-0.00872455j, var(E): 1.13412051
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 10000/ t/epoch=1.96............. Loss: -0.35536831, mean(E): -21.62340208+0.01203227j, var(E): 1.23020931
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 10000/ t/epoch=1.96............. Loss: -0.02413513, mean(E): -21.64205829+0.01144770j, var(E): 0.51586427
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 10000/ t/epoch=1.96............. Loss: 0.26649802, mean(E): -21.70878627-0.02293227j, var(E): 0.63548612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 10000/ t/epoch=1.96............. Loss: -0.75629975, mean(E): -21.51529320-0.00950881j, var(E): 0.73719592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 10000/ t/epoch=1.96............. Loss: 0.08351499, mean(E): -21.59379024-0.01313647j, var(E): 0.85337996
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 10000/ t/epoch=1.96............. Loss: 0.43646949, mean(E): -21.71934262-0.05081650j, var(E): 0.76477869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 10000/ t/epoch=1.96............. Loss: -0.14709692, mean(E): -21.61429644+0.01788063j, var(E): 0.83256985
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 10000/ t/epoch=1.96............. Loss: -0.33154361, mean(E): -21.60977037-0.00396872j, var(E): 0.94653347
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 10000/ t/epoch=1.96............. Loss: 0.41961834, mean(E): -21.69147595-0.01743427j, var(E): 0.65762913
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 10000/ t/epoch=1.96............. Loss: -0.18993829, mean(E): -21.61955951+0.00974164j, var(E): 0.64364718
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 10000/ t/epoch=1.96............. Loss: -0.74346503, mean(E): -21.53057347-0.01046733j, var(E): 0.67873323
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 10000/ t/epoch=1.96............. Loss: -0.07864912, mean(E): -21.58352540-0.00266830j, var(E): 0.64192867
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 10000/ t/epoch=1.96............. Loss: 0.15368543, mean(E): -21.68425315+0.01340830j, var(E): 1.19668623
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 10000/ t/epoch=1.96............. Loss: 0.76385895, mean(E): -21.76849925+0.01583051j, var(E): 1.24210946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 10000/ t/epoch=1.96............. Loss: 0.30529088, mean(E): -21.69169710+0.00818088j, var(E): 0.72668431
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 10000/ t/epoch=1.96............. Loss: -0.30074696, mean(E): -21.62413250-0.02954899j, var(E): 0.86843531
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 10000/ t/epoch=1.96............. Loss: 0.56844117, mean(E): -21.71277619+0.00214647j, var(E): 1.30679809
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 10000/ t/epoch=1.96............. Loss: -0.10381019, mean(E): -21.68448201-0.01199404j, var(E): 0.75492846
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 10000/ t/epoch=1.96............. Loss: -0.34198531, mean(E): -21.56157588-0.01479160j, var(E): 1.25447093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 10000/ t/epoch=1.96............. Loss: 0.14482917, mean(E): -21.70467379+0.00079005j, var(E): 0.91209865
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 10000/ t/epoch=1.96............. Loss: -0.00248783, mean(E): -21.64495669+0.01131397j, var(E): 0.44380855
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 10000/ t/epoch=1.96............. Loss: 0.07540058, mean(E): -21.64000653-0.01063784j, var(E): 0.60129601
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 10000/ t/epoch=1.96............. Loss: -0.06363957, mean(E): -21.63760909+0.01028778j, var(E): 0.69825400
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 10000/ t/epoch=1.96............. Loss: 0.44332760, mean(E): -21.70579143-0.01576058j, var(E): 0.89992645
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 10000/ t/epoch=1.96............. Loss: -0.01147273, mean(E): -21.63243166-0.02065224j, var(E): 0.52116354
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 10000/ t/epoch=1.96............. Loss: -0.07231163, mean(E): -21.68018673+0.00433979j, var(E): 1.27615467
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 10000/ t/epoch=1.96............. Loss: -0.58309344, mean(E): -21.57299708-0.02243742j, var(E): 1.23669436
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 10000/ t/epoch=1.96............. Loss: -0.24860550, mean(E): -21.60242864+0.02324231j, var(E): 0.45149726
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 10000/ t/epoch=1.96............. Loss: -0.02693360, mean(E): -21.58452998+0.00434044j, var(E): 1.13902200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 10000/ t/epoch=1.96............. Loss: 0.07854566, mean(E): -21.67650739+0.01814590j, var(E): 0.75143118
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 10000/ t/epoch=1.96............. Loss: 0.64986764, mean(E): -21.75266223+0.04812668j, var(E): 1.42919868
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 10000/ t/epoch=1.96............. Loss: -0.12824987, mean(E): -21.68266427+0.03403516j, var(E): 0.73702135
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 10000/ t/epoch=1.96............. Loss: -0.19510563, mean(E): -21.60301040-0.00448027j, var(E): 0.66756498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 10000/ t/epoch=1.96............. Loss: -0.07020877, mean(E): -21.64587362-0.03972657j, var(E): 0.76803946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 10000/ t/epoch=1.96............. Loss: -0.46003015, mean(E): -21.54009178-0.02422865j, var(E): 1.88884055
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 10000/ t/epoch=1.96............. Loss: -0.28442207, mean(E): -21.62323635+0.00519065j, var(E): 0.51745492
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 10000/ t/epoch=1.96............. Loss: -0.16294491, mean(E): -21.64392871-0.00932774j, var(E): 0.28827950
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 10000/ t/epoch=2.06............. Loss: -0.04737274, mean(E): -21.66900008+0.02428083j, var(E): 0.46709430
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 10000/ t/epoch=1.96............. Loss: -0.23189183, mean(E): -21.58916138-0.02154000j, var(E): 0.58967162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 10000/ t/epoch=1.96............. Loss: -0.10649709, mean(E): -21.64668113-0.00974363j, var(E): 0.31260496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 10000/ t/epoch=1.96............. Loss: 0.23612661, mean(E): -21.67331043-0.01462555j, var(E): 0.41775230
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 10000/ t/epoch=1.96............. Loss: -0.24602581, mean(E): -21.61116852-0.02984053j, var(E): 0.62073453
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 10000/ t/epoch=1.96............. Loss: -0.08006140, mean(E): -21.64397572+0.01770930j, var(E): 0.85418730
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 10000/ t/epoch=1.96............. Loss: -0.16684537, mean(E): -21.63755457-0.01874652j, var(E): 0.31657965
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 10000/ t/epoch=1.96............. Loss: 0.02464796, mean(E): -21.67275834+0.00342804j, var(E): 0.38442034
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 10000/ t/epoch=1.96............. Loss: -0.26325913, mean(E): -21.58164666+0.02158712j, var(E): 0.49441920
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 10000/ t/epoch=1.96............. Loss: -0.43917271, mean(E): -21.57373213+0.00767500j, var(E): 0.42866041
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 10000/ t/epoch=1.96............. Loss: -0.26303358, mean(E): -21.61451105+0.01363499j, var(E): 0.58442530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 10000/ t/epoch=1.96............. Loss: -0.36767466, mean(E): -21.58040822-0.00202360j, var(E): 0.60092503
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 10000/ t/epoch=1.96............. Loss: 0.27746840, mean(E): -21.69393094-0.02887045j, var(E): 0.50275140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 10000/ t/epoch=1.96............. Loss: -0.09111281, mean(E): -21.63558542-0.03604620j, var(E): 0.42778731
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 10000/ t/epoch=1.96............. Loss: -0.06203098, mean(E): -21.63430938+0.02529314j, var(E): 0.99238585
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 10000/ t/epoch=1.96............. Loss: -0.02173384, mean(E): -21.61557795-0.01348535j, var(E): 0.98280870
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 10000/ t/epoch=1.96............. Loss: 0.15236866, mean(E): -21.68016775-0.00102325j, var(E): 0.80668327
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 10000/ t/epoch=1.96............. Loss: -0.23642277, mean(E): -21.63173998-0.01052060j, var(E): 0.42884894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 10000/ t/epoch=1.96............. Loss: -0.76231819, mean(E): -21.52417410+0.01771445j, var(E): 0.60791942
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 10000/ t/epoch=1.96............. Loss: -0.05341256, mean(E): -21.64551095-0.03026678j, var(E): 0.63265940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 10000/ t/epoch=1.96............. Loss: -0.27946866, mean(E): -21.62286820+0.02060389j, var(E): 0.48929277
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 10000/ t/epoch=1.96............. Loss: 0.14080354, mean(E): -21.69495797+0.01059085j, var(E): 1.10898842
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 10000/ t/epoch=1.95............. Loss: -0.27123348, mean(E): -21.61919345+0.00956997j, var(E): 0.78764900
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 10000/ t/epoch=1.96............. Loss: -0.00061315, mean(E): -21.62463093-0.00256064j, var(E): 0.81415173
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 10000/ t/epoch=1.96............. Loss: -0.00066963, mean(E): -21.68541101-0.00613956j, var(E): 0.26408658
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 10000/ t/epoch=1.96............. Loss: 0.22379418, mean(E): -21.70110111+0.01730971j, var(E): 0.38515264
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 10000/ t/epoch=1.96............. Loss: -0.64839592, mean(E): -21.53361077-0.00947552j, var(E): 0.44885660
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 10000/ t/epoch=1.96............. Loss: -0.74321798, mean(E): -21.54955250+0.02964102j, var(E): 0.62988211
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 10000/ t/epoch=1.96............. Loss: 0.16092349, mean(E): -21.69403459-0.00613282j, var(E): 1.07841484
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 10000/ t/epoch=1.96............. Loss: -0.63833795, mean(E): -21.61722607+0.00842330j, var(E): 1.18455477
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 10000/ t/epoch=1.96............. Loss: 0.03770459, mean(E): -21.68251696+0.01096722j, var(E): 1.11850223
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 10000/ t/epoch=1.96............. Loss: -0.13042529, mean(E): -21.59655993+0.00884926j, var(E): 1.94717907
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 10000/ t/epoch=1.96............. Loss: -0.05785648, mean(E): -21.67532777+0.01937024j, var(E): 0.92923891
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 10000/ t/epoch=1.96............. Loss: -0.24255866, mean(E): -21.65404217+0.01874479j, var(E): 0.97076307
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 10000/ t/epoch=1.96............. Loss: -0.14465683, mean(E): -21.62974569+0.02406688j, var(E): 0.25516754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 10000/ t/epoch=1.96............. Loss: -0.90136496, mean(E): -21.46490755+0.02429944j, var(E): 0.63165294
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 10000/ t/epoch=1.96............. Loss: 0.08579103, mean(E): -21.64293479+0.02337147j, var(E): 0.41107419
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 10000/ t/epoch=1.96............. Loss: -0.07186097, mean(E): -21.65975018+0.00274167j, var(E): 0.24314861
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 10000/ t/epoch=1.96............. Loss: -0.36840092, mean(E): -21.61133660-0.01209730j, var(E): 0.74233933
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 10000/ t/epoch=1.97............. Loss: -0.03511838, mean(E): -21.68013724+0.01440544j, var(E): 0.20430656
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 10000/ t/epoch=1.97............. Loss: -0.05653087, mean(E): -21.69808157-0.02220941j, var(E): 0.78042377
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 10000/ t/epoch=1.96............. Loss: -0.27172122, mean(E): -21.64901481+0.00436642j, var(E): 0.42856570
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 10000/ t/epoch=1.96............. Loss: 0.18855919, mean(E): -21.72502928-0.03810231j, var(E): 1.34690892
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 10000/ t/epoch=1.96............. Loss: -0.16184021, mean(E): -21.64175224-0.00067364j, var(E): 0.50491560
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 10000/ t/epoch=1.96............. Loss: -0.09318829, mean(E): -21.66991835-0.01384362j, var(E): 0.85125986
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 10000/ t/epoch=1.96............. Loss: 0.60501742, mean(E): -21.81069209+0.04257550j, var(E): 0.78354614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 10000/ t/epoch=1.96............. Loss: -0.36592308, mean(E): -21.59064475-0.00205304j, var(E): 0.59592583
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 10000/ t/epoch=1.96............. Loss: 0.04213540, mean(E): -21.66311870-0.01423643j, var(E): 0.43010684
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 10000/ t/epoch=1.96............. Loss: -0.50147324, mean(E): -21.60774377+0.00370071j, var(E): 0.94018091
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 10000/ t/epoch=1.96............. Loss: -0.46173169, mean(E): -21.61288699+0.02290352j, var(E): 1.25580977
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 10000/ t/epoch=1.96............. Loss: -0.40570777, mean(E): -21.60068982-0.01475289j, var(E): 0.78535200
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 10000/ t/epoch=1.96............. Loss: -0.24065488, mean(E): -21.59849843-0.00641315j, var(E): 0.52567690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 10000/ t/epoch=1.96............. Loss: 0.49327899, mean(E): -21.70856275+0.00404634j, var(E): 1.30723497
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 10000/ t/epoch=1.96............. Loss: -0.17724685, mean(E): -21.65350944+0.03348734j, var(E): 0.74792147
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 10000/ t/epoch=1.96............. Loss: 0.08918287, mean(E): -21.67550341-0.02344435j, var(E): 0.48820434
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 10000/ t/epoch=1.96............. Loss: 0.25812881, mean(E): -21.65266632+0.00068726j, var(E): 0.88323496
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 10000/ t/epoch=1.99............. Loss: -0.57545755, mean(E): -21.57462876-0.00848457j, var(E): 0.76403959
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 10000/ t/epoch=1.95............. Loss: -0.16779837, mean(E): -21.62693797+0.01481861j, var(E): 0.32215742
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 10000/ t/epoch=1.95............. Loss: -0.61046899, mean(E): -21.54911698+0.04579100j, var(E): 0.92672994
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 10000/ t/epoch=1.97............. Loss: -0.29360699, mean(E): -21.61871289+0.02051433j, var(E): 1.02572206
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 10000/ t/epoch=1.97............. Loss: 0.24568759, mean(E): -21.69624929+0.01236868j, var(E): 0.54430614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 10000/ t/epoch=1.96............. Loss: -0.19735480, mean(E): -21.62552220+0.01493834j, var(E): 0.46497439
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 10000/ t/epoch=1.96............. Loss: 0.14054329, mean(E): -21.68404966-0.00052121j, var(E): 0.32953606
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 10000/ t/epoch=1.96............. Loss: -0.22459716, mean(E): -21.62795250+0.00948869j, var(E): 0.35573687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 10000/ t/epoch=1.96............. Loss: 0.66273870, mean(E): -21.76956576+0.04780590j, var(E): 0.93834210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 10000/ t/epoch=1.96............. Loss: -0.20929922, mean(E): -21.61549485-0.00492086j, var(E): 0.85317964
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 10000/ t/epoch=1.96............. Loss: -0.18147548, mean(E): -21.69455661+0.03840809j, var(E): 0.85643814
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 10000/ t/epoch=1.96............. Loss: 0.29667890, mean(E): -21.73867307+0.01849809j, var(E): 0.61201760
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 10000/ t/epoch=1.95............. Loss: -0.31872469, mean(E): -21.56449143+0.02445305j, var(E): 0.52900110
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 10000/ t/epoch=1.96............. Loss: -0.47699637, mean(E): -21.61383657+0.02602492j, var(E): 0.36643716
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 10000/ t/epoch=1.96............. Loss: 1.27143848, mean(E): -21.86430132+0.00427270j, var(E): 1.82711878
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 10000/ t/epoch=1.96............. Loss: -0.26946221, mean(E): -21.59526747+0.03211257j, var(E): 0.62735484
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 10000/ t/epoch=1.96............. Loss: -0.61990466, mean(E): -21.58015795-0.01821331j, var(E): 0.83853530
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 10000/ t/epoch=1.96............. Loss: -0.27896221, mean(E): -21.64864978+0.02003317j, var(E): 0.95865069
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 10000/ t/epoch=1.96............. Loss: -0.25741550, mean(E): -21.65410662+0.01619780j, var(E): 0.80072894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 10000/ t/epoch=1.96............. Loss: 0.12862561, mean(E): -21.69922617+0.01120842j, var(E): 0.54654104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 10000/ t/epoch=1.95............. Loss: -0.15944326, mean(E): -21.64669131-0.00314730j, var(E): 0.60435738
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 10000/ t/epoch=1.96............. Loss: -0.21366049, mean(E): -21.67191884+0.01269495j, var(E): 0.95751070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 10000/ t/epoch=1.96............. Loss: -0.20767986, mean(E): -21.56665381+0.00843933j, var(E): 0.46588443
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 10000/ t/epoch=1.96............. Loss: 0.61074948, mean(E): -21.70727444+0.04358352j, var(E): 1.35412285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 10000/ t/epoch=1.96............. Loss: -0.34267974, mean(E): -21.58649308+0.02687500j, var(E): 0.40132459
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 10000/ t/epoch=1.96............. Loss: 0.11421852, mean(E): -21.70966082+0.02973292j, var(E): 0.71384119
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 10000/ t/epoch=1.96............. Loss: 0.01661157, mean(E): -21.68353270+0.03786325j, var(E): 0.80267007
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 10000/ t/epoch=1.96............. Loss: 0.39421264, mean(E): -21.77077248-0.01211233j, var(E): 0.66397551
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 10000/ t/epoch=1.96............. Loss: -0.60910801, mean(E): -21.58000091+0.00912031j, var(E): 0.58507651
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 10000/ t/epoch=1.96............. Loss: -0.33291677, mean(E): -21.57813838+0.02822624j, var(E): 0.47016745
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 10000/ t/epoch=1.95............. Loss: -0.58610537, mean(E): -21.60135625+0.02776919j, var(E): 0.67323281
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 10000/ t/epoch=1.96............. Loss: -0.82334363, mean(E): -21.53107339-0.01408496j, var(E): 0.73095548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 10000/ t/epoch=1.96............. Loss: 0.09784070, mean(E): -21.61775860+0.02105977j, var(E): 1.58164805
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 10000/ t/epoch=1.96............. Loss: 0.48343357, mean(E): -21.73573545+0.02647721j, var(E): 2.49653035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 10000/ t/epoch=1.96............. Loss: -0.43623268, mean(E): -21.60894260-0.02238391j, var(E): 0.67112093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 10000/ t/epoch=1.96............. Loss: -0.54728151, mean(E): -21.57680039-0.01225359j, var(E): 0.44815771
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 10000/ t/epoch=1.96............. Loss: -0.31219555, mean(E): -21.62578961-0.03820721j, var(E): 0.68061131
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 10000/ t/epoch=1.96............. Loss: 0.02580744, mean(E): -21.67544337-0.00153897j, var(E): 0.32376334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 10000/ t/epoch=1.96............. Loss: 0.43438470, mean(E): -21.71781693-0.01333472j, var(E): 1.27847382
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 10000/ t/epoch=1.96............. Loss: 0.14888448, mean(E): -21.70055763-0.01638431j, var(E): 0.46039021
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 10000/ t/epoch=1.95............. Loss: 0.11241591, mean(E): -21.69599963-0.01458972j, var(E): 1.84977937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 10000/ t/epoch=1.96............. Loss: -0.27771597, mean(E): -21.63889675+0.01290836j, var(E): 0.94326602
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 10000/ t/epoch=1.96............. Loss: -0.02305384, mean(E): -21.68112926-0.00812891j, var(E): 0.25972757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 10000/ t/epoch=1.96............. Loss: 0.62332159, mean(E): -21.76722589-0.00075139j, var(E): 1.28769845
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 10000/ t/epoch=1.96............. Loss: 0.29006869, mean(E): -21.72409132+0.01478721j, var(E): 0.29068210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 10000/ t/epoch=1.96............. Loss: 0.03998200, mean(E): -21.69566945+0.00831994j, var(E): 1.16176477
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 10000/ t/epoch=1.96............. Loss: -0.25673132, mean(E): -21.67426413+0.00176814j, var(E): 0.66455282
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 10000/ t/epoch=1.96............. Loss: 0.09424617, mean(E): -21.68855050+0.01255916j, var(E): 0.70396277
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 10000/ t/epoch=1.96............. Loss: 0.08683341, mean(E): -21.70858728-0.00041278j, var(E): 0.42755962
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 10000/ t/epoch=1.96............. Loss: 0.31941340, mean(E): -21.76045035-0.02146850j, var(E): 0.53363587
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 10000/ t/epoch=1.96............. Loss: -0.40172581, mean(E): -21.62370711+0.00070761j, var(E): 0.54418532
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 10000/ t/epoch=1.96............. Loss: 0.43189444, mean(E): -21.77098758+0.00820218j, var(E): 0.76179779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 10000/ t/epoch=1.96............. Loss: 0.29548530, mean(E): -21.70039108+0.00121616j, var(E): 0.32336675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 10000/ t/epoch=1.96............. Loss: -0.06582019, mean(E): -21.68220993+0.00488755j, var(E): 0.57530847
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 10000/ t/epoch=1.96............. Loss: -0.14914945, mean(E): -21.64552203-0.00356111j, var(E): 0.55508575
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 10000/ t/epoch=1.96............. Loss: 0.28278874, mean(E): -21.72714538+0.01301918j, var(E): 0.54499510
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 10000/ t/epoch=1.96............. Loss: 0.05793133, mean(E): -21.67556102+0.00885732j, var(E): 0.33621924
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 10000/ t/epoch=1.95............. Loss: 0.20863134, mean(E): -21.71867464+0.01418811j, var(E): 0.71849690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 10000/ t/epoch=1.96............. Loss: 0.11856017, mean(E): -21.70613387+0.01246482j, var(E): 1.08094070
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 10000/ t/epoch=1.96............. Loss: 0.04136187, mean(E): -21.70424971-0.00650118j, var(E): 0.65167754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 10000/ t/epoch=1.96............. Loss: -0.02537753, mean(E): -21.69823392+0.00581742j, var(E): 0.79197752
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 10000/ t/epoch=1.96............. Loss: -0.45638993, mean(E): -21.60918551-0.00446450j, var(E): 0.47703213
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 10000/ t/epoch=1.96............. Loss: -0.71023154, mean(E): -21.57502476-0.01003295j, var(E): 0.62391007
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 10000/ t/epoch=1.96............. Loss: -0.46353107, mean(E): -21.59044429-0.01637357j, var(E): 0.48882381
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 10000/ t/epoch=1.96............. Loss: 0.42359652, mean(E): -21.74817754+0.01893377j, var(E): 0.63510015
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 10000/ t/epoch=1.96............. Loss: -0.16342602, mean(E): -21.68389543+0.00186602j, var(E): 0.21194585
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 10000/ t/epoch=1.96............. Loss: -0.50348303, mean(E): -21.56756100+0.00447990j, var(E): 0.48212542
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 10000/ t/epoch=1.97............. Loss: -0.16836603, mean(E): -21.68204158+0.01734294j, var(E): 0.58766053
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 10000/ t/epoch=1.96............. Loss: -0.19215537, mean(E): -21.65415079-0.00520636j, var(E): 0.86117309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 10000/ t/epoch=1.96............. Loss: -0.17893268, mean(E): -21.66282510+0.00091739j, var(E): 0.67897471
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 10000/ t/epoch=1.96............. Loss: 0.22145069, mean(E): -21.73239959-0.01122049j, var(E): 0.64231073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 10000/ t/epoch=1.99............. Loss: -0.09773738, mean(E): -21.66238458+0.02983606j, var(E): 0.74308489
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 10000/ t/epoch=1.96............. Loss: 0.16509993, mean(E): -21.70013590-0.00841239j, var(E): 0.71967698
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 10000/ t/epoch=1.96............. Loss: -0.77630752, mean(E): -21.56774698+0.03437503j, var(E): 1.00679609
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 10000/ t/epoch=1.96............. Loss: -0.58848421, mean(E): -21.60521856-0.02525118j, var(E): 0.99911060
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 10000/ t/epoch=1.96............. Loss: -0.67694221, mean(E): -21.58109577+0.01930901j, var(E): 0.45370170
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 10000/ t/epoch=1.95............. Loss: -0.19599350, mean(E): -21.69195855-0.00340526j, var(E): 1.57237596
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 10000/ t/epoch=1.96............. Loss: 0.13474851, mean(E): -21.69881049+0.02938106j, var(E): 0.92140210
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 10000/ t/epoch=1.97............. Loss: -0.57662546, mean(E): -21.58727683+0.00113937j, var(E): 0.49274956
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 10000/ t/epoch=1.97............. Loss: -0.44687136, mean(E): -21.59164856+0.00840955j, var(E): 1.10555003
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 10000/ t/epoch=1.96............. Loss: -0.78978740, mean(E): -21.55811804+0.02282653j, var(E): 0.87906859
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 10000/ t/epoch=1.96............. Loss: -0.07328553, mean(E): -21.64418472-0.00043189j, var(E): 0.59622588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 10000/ t/epoch=1.96............. Loss: 0.13319470, mean(E): -21.68989604-0.00625490j, var(E): 0.52226320
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 10000/ t/epoch=1.96............. Loss: -0.47230296, mean(E): -21.61746231+0.00334781j, var(E): 0.80298659
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 10000/ t/epoch=1.96............. Loss: 0.31582650, mean(E): -21.70572835+0.02195648j, var(E): 0.74593987
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 10000/ t/epoch=1.96............. Loss: -0.75865916, mean(E): -21.56845345+0.00944016j, var(E): 0.58089417
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 10000/ t/epoch=1.96............. Loss: 0.43038278, mean(E): -21.74340856+0.02601690j, var(E): 0.95320309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 10000/ t/epoch=1.96............. Loss: -0.34418798, mean(E): -21.62881663+0.00968244j, var(E): 0.54576151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 10000/ t/epoch=1.96............. Loss: 0.21011992, mean(E): -21.67629638+0.02346133j, var(E): 0.60221062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 10000/ t/epoch=1.96............. Loss: 0.52359313, mean(E): -21.70646259+0.03788600j, var(E): 2.31395011
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 10000/ t/epoch=1.96............. Loss: 0.05769222, mean(E): -21.72125674+0.02649911j, var(E): 0.40879283
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 10000/ t/epoch=1.96............. Loss: -0.18525281, mean(E): -21.66971137+0.00196326j, var(E): 0.60672285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 10000/ t/epoch=1.96............. Loss: 0.19644184, mean(E): -21.73094944+0.01479661j, var(E): 1.03686261
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 10000/ t/epoch=1.96............. Loss: -0.02371108, mean(E): -21.63309384-0.01308991j, var(E): 0.73708467
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 10000/ t/epoch=1.96............. Loss: -0.07583686, mean(E): -21.68195848-0.01962835j, var(E): 0.58055140
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 10000/ t/epoch=1.96............. Loss: -0.04835293, mean(E): -21.68966421-0.02153209j, var(E): 0.41273592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 10000/ t/epoch=1.96............. Loss: -0.17051509, mean(E): -21.64930599+0.01482728j, var(E): 0.50936545
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 10000/ t/epoch=1.96............. Loss: -0.48757198, mean(E): -21.57369312-0.01160924j, var(E): 1.30072903
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 10000/ t/epoch=1.96............. Loss: -0.15641071, mean(E): -21.65629335-0.00188275j, var(E): 0.33398330
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 10000/ t/epoch=1.96............. Loss: -0.81610668, mean(E): -21.58329738+0.00988502j, var(E): 0.91331606
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 10000/ t/epoch=1.96............. Loss: 0.32160178, mean(E): -21.72803218-0.02162702j, var(E): 0.83922296
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 10000/ t/epoch=1.96............. Loss: 0.18571779, mean(E): -21.68112595-0.02075945j, var(E): 0.42415559
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 10000/ t/epoch=1.96............. Loss: -0.22391504, mean(E): -21.66154654+0.01319115j, var(E): 0.56153407
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 10000/ t/epoch=1.96............. Loss: -0.15801919, mean(E): -21.66798357-0.00402540j, var(E): 0.30085146
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 10000/ t/epoch=1.96............. Loss: 0.40909283, mean(E): -21.73834209+0.01937016j, var(E): 0.85191940
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 10000/ t/epoch=1.96............. Loss: 0.06859179, mean(E): -21.70283801+0.03676705j, var(E): 0.38798703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 10000/ t/epoch=1.96............. Loss: 0.91480520, mean(E): -21.75100126+0.01119911j, var(E): 3.07554766
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 10000/ t/epoch=1.96............. Loss: -0.38793350, mean(E): -21.61639122+0.00949038j, var(E): 0.56764994
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 10000/ t/epoch=1.96............. Loss: 0.08616627, mean(E): -21.73338722-0.00215245j, var(E): 0.50424184
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 10000/ t/epoch=1.96............. Loss: -0.47128416, mean(E): -21.62558066+0.02589340j, var(E): 0.62063725
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 10000/ t/epoch=1.96............. Loss: -0.51680753, mean(E): -21.59270774+0.00763045j, var(E): 0.77004338
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 10000/ t/epoch=1.96............. Loss: -0.06889515, mean(E): -21.63821088+0.01548305j, var(E): 0.96647393
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 10000/ t/epoch=1.96............. Loss: -0.20953017, mean(E): -21.64589197-0.00686915j, var(E): 1.02079008
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 10000/ t/epoch=1.96............. Loss: 0.12477223, mean(E): -21.66134832-0.00053637j, var(E): 0.90036684
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 10000/ t/epoch=1.96............. Loss: -0.03594126, mean(E): -21.68856590-0.01226264j, var(E): 0.49172342
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 10000/ t/epoch=1.96............. Loss: -0.21180205, mean(E): -21.61819303+0.01036025j, var(E): 0.57414797
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 10000/ t/epoch=1.96............. Loss: 0.35462408, mean(E): -21.76137903+0.00478391j, var(E): 1.08387988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 10000/ t/epoch=1.97............. Loss: -0.13099143, mean(E): -21.68418170+0.01211947j, var(E): 0.11693575
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 10000/ t/epoch=1.96............. Loss: 0.32933088, mean(E): -21.71417754+0.01209214j, var(E): 1.69544175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 10000/ t/epoch=1.96............. Loss: -0.03569931, mean(E): -21.69574648-0.00632533j, var(E): 0.33599014
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 10000/ t/epoch=1.96............. Loss: -0.62622151, mean(E): -21.61286907+0.01856570j, var(E): 0.57499086
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 10000/ t/epoch=1.96............. Loss: -0.05965482, mean(E): -21.69185180+0.02086459j, var(E): 0.28355812
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 10000/ t/epoch=1.96............. Loss: 0.45245638, mean(E): -21.74639261+0.00959054j, var(E): 0.68300725
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 10000/ t/epoch=1.96............. Loss: -0.23361134, mean(E): -21.65579305+0.00648150j, var(E): 0.29547690
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 10000/ t/epoch=1.96............. Loss: 0.16863423, mean(E): -21.72915925+0.00327316j, var(E): 0.63833199
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 10000/ t/epoch=1.96............. Loss: -0.21737802, mean(E): -21.66338422+0.00467486j, var(E): 0.49517963
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 10000/ t/epoch=1.96............. Loss: 0.00239548, mean(E): -21.70565337-0.02066068j, var(E): 0.34385051
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 10000/ t/epoch=1.96............. Loss: 0.09760822, mean(E): -21.70699781-0.00073934j, var(E): 0.55504824
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 10000/ t/epoch=1.96............. Loss: 0.12714263, mean(E): -21.70398507-0.01262041j, var(E): 0.63734448
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 10000/ t/epoch=1.95............. Loss: 0.00538101, mean(E): -21.66249914-0.01343325j, var(E): 0.37893537
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 10000/ t/epoch=1.96............. Loss: -0.18213054, mean(E): -21.64649954-0.01178674j, var(E): 0.77587639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 10000/ t/epoch=1.97............. Loss: -0.52782970, mean(E): -21.56274184-0.01574519j, var(E): 0.48253105
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 10000/ t/epoch=1.96............. Loss: -0.02212949, mean(E): -21.68328960+0.00474673j, var(E): 0.26619804
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 10000/ t/epoch=1.96............. Loss: -0.18283419, mean(E): -21.66620784+0.00357064j, var(E): 0.52949722
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 10000/ t/epoch=1.96............. Loss: 0.13294815, mean(E): -21.70302689+0.00144980j, var(E): 0.41544486
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 10000/ t/epoch=1.96............. Loss: -0.06212626, mean(E): -21.68611429-0.00675666j, var(E): 0.46060682
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 10000/ t/epoch=1.96............. Loss: 0.01509977, mean(E): -21.69509876+0.02040315j, var(E): 0.44292010
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 10000/ t/epoch=1.96............. Loss: -0.33274056, mean(E): -21.65928210+0.00352530j, var(E): 0.94917612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 10000/ t/epoch=1.96............. Loss: 0.15294560, mean(E): -21.72412511-0.03287313j, var(E): 0.61182784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 10000/ t/epoch=1.96............. Loss: -0.45698351, mean(E): -21.61917295-0.00660051j, var(E): 1.25562054
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 10000/ t/epoch=1.96............. Loss: 0.12311334, mean(E): -21.66873531-0.00725373j, var(E): 0.53251202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 10000/ t/epoch=1.96............. Loss: -0.35164552, mean(E): -21.57061614-0.00541891j, var(E): 0.82153169
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 10000/ t/epoch=1.95............. Loss: 0.09455293, mean(E): -21.67352509+0.00480160j, var(E): 0.52664979
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 10000/ t/epoch=1.96............. Loss: -0.09483993, mean(E): -21.67042783+0.02110411j, var(E): 0.75414458
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 10000/ t/epoch=1.97............. Loss: 0.07172546, mean(E): -21.71164233+0.02044329j, var(E): 1.38733211
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 10000/ t/epoch=1.97............. Loss: 0.03370202, mean(E): -21.68761840-0.00510302j, var(E): 0.40934442
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 10000/ t/epoch=1.96............. Loss: -0.25193134, mean(E): -21.64652310+0.00291547j, var(E): 0.73927401
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 10000/ t/epoch=1.96............. Loss: -0.17529969, mean(E): -21.65938490+0.03210736j, var(E): 0.61169687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 10000/ t/epoch=1.96............. Loss: 0.10301213, mean(E): -21.69339036+0.01036992j, var(E): 0.96571354
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 10000/ t/epoch=1.96............. Loss: 0.89242507, mean(E): -21.83371049+0.03870575j, var(E): 0.99281643
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 10000/ t/epoch=1.96............. Loss: -0.01058089, mean(E): -21.70427734+0.03377630j, var(E): 0.43526869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 10000/ t/epoch=1.96............. Loss: 0.33339280, mean(E): -21.68366538+0.03061147j, var(E): 1.59678652
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 10000/ t/epoch=1.97............. Loss: -0.29706112, mean(E): -21.63245798+0.03746909j, var(E): 0.32638217
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 10000/ t/epoch=1.96............. Loss: 0.33922911, mean(E): -21.71171631+0.01301121j, var(E): 0.67061676
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 10000/ t/epoch=1.96............. Loss: -0.60418808, mean(E): -21.59003485+0.00498310j, var(E): 0.65560403
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 10000/ t/epoch=1.96............. Loss: -0.37729654, mean(E): -21.65165766-0.00996924j, var(E): 0.42825983
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 10000/ t/epoch=1.96............. Loss: -0.22162645, mean(E): -21.63685435+0.00232812j, var(E): 0.52101138
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 10000/ t/epoch=1.96............. Loss: -0.37563946, mean(E): -21.64269826+0.02173169j, var(E): 0.47951104
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 10000/ t/epoch=1.96............. Loss: -0.05922337, mean(E): -21.67510215+0.01843588j, var(E): 0.61458162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 10000/ t/epoch=1.96............. Loss: -0.41688660, mean(E): -21.64715600+0.02720050j, var(E): 1.13797860
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 10000/ t/epoch=1.96............. Loss: -0.03546191, mean(E): -21.70392093-0.00682202j, var(E): 0.96363077
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 10000/ t/epoch=1.96............. Loss: -0.00751644, mean(E): -21.68641906-0.00833882j, var(E): 0.33231035
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 10000/ t/epoch=1.96............. Loss: -0.26318593, mean(E): -21.64497037-0.00652601j, var(E): 0.39893248
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 10000/ t/epoch=1.97............. Loss: -0.30698818, mean(E): -21.65840466+0.00855036j, var(E): 0.52508355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 10000/ t/epoch=1.96............. Loss: 0.44286543, mean(E): -21.79115330+0.00048849j, var(E): 0.54372675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 10000/ t/epoch=1.96............. Loss: -0.19340772, mean(E): -21.69691850+0.02077737j, var(E): 0.70771262
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 10000/ t/epoch=2.0............. Loss: 0.05280315, mean(E): -21.69948962+0.00109882j, var(E): 1.03254237
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 10000/ t/epoch=1.96............. Loss: 0.21428488, mean(E): -21.71091336+0.00617142j, var(E): 0.89035685
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 10000/ t/epoch=1.96............. Loss: 0.11860737, mean(E): -21.70036077-0.00401868j, var(E): 0.46188005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 10000/ t/epoch=1.96............. Loss: -0.12007512, mean(E): -21.69988342+0.00393635j, var(E): 0.31283135
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 10000/ t/epoch=1.96............. Loss: -0.04707675, mean(E): -21.66790486-0.00980627j, var(E): 0.46234359
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 10000/ t/epoch=1.96............. Loss: -0.22947666, mean(E): -21.64778057+0.00474292j, var(E): 0.58036296
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 10000/ t/epoch=1.96............. Loss: -0.11932196, mean(E): -21.65847000+0.04052354j, var(E): 0.18622326
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 10000/ t/epoch=1.96............. Loss: 0.17651083, mean(E): -21.70538512+0.00840599j, var(E): 0.51351869
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 10000/ t/epoch=1.96............. Loss: -0.09398394, mean(E): -21.68242789+0.02959520j, var(E): 0.50748761
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 10000/ t/epoch=1.95............. Loss: -0.11540111, mean(E): -21.69018650-0.00118973j, var(E): 0.55587993
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 10000/ t/epoch=1.96............. Loss: 0.04886881, mean(E): -21.68806919+0.01125551j, var(E): 0.45983631
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 10000/ t/epoch=1.96............. Loss: 0.12650378, mean(E): -21.73355161+0.00546410j, var(E): 0.67563630
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 10000/ t/epoch=1.96............. Loss: -0.16475406, mean(E): -21.65821848+0.03371847j, var(E): 0.40307833
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 10000/ t/epoch=1.96............. Loss: 0.02970779, mean(E): -21.70748215-0.01071429j, var(E): 0.23649388
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 10000/ t/epoch=1.96............. Loss: -0.00257096, mean(E): -21.66902688+0.02466496j, var(E): 0.65896287
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 10000/ t/epoch=1.97............. Loss: -0.17321524, mean(E): -21.66632436-0.01104143j, var(E): 0.39928673
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 10000/ t/epoch=1.96............. Loss: 0.22910447, mean(E): -21.65970707+0.00020629j, var(E): 0.79045425
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 10000/ t/epoch=1.96............. Loss: -0.06553835, mean(E): -21.70593324+0.01764798j, var(E): 0.21477987
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 10000/ t/epoch=1.96............. Loss: 0.36315255, mean(E): -21.70073494+0.00298190j, var(E): 0.55244388
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 10000/ t/epoch=1.96............. Loss: 0.16326846, mean(E): -21.74724272-0.00862410j, var(E): 0.36155734
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 10000/ t/epoch=1.96............. Loss: 0.29706558, mean(E): -21.74263517+0.00866904j, var(E): 0.30720054
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 10000/ t/epoch=1.96............. Loss: 0.25718328, mean(E): -21.73134769+0.03128123j, var(E): 0.52474627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 10000/ t/epoch=1.96............. Loss: -0.06503408, mean(E): -21.68009398-0.01725671j, var(E): 0.53421784
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 10000/ t/epoch=1.96............. Loss: -0.14054888, mean(E): -21.70292784-0.01445821j, var(E): 0.43288704
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 10000/ t/epoch=1.96............. Loss: -0.20622237, mean(E): -21.66500188-0.00292681j, var(E): 0.64695756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 10000/ t/epoch=1.96............. Loss: 0.03054620, mean(E): -21.72779680+0.01240397j, var(E): 0.37324084
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 10000/ t/epoch=1.96............. Loss: 0.34506442, mean(E): -21.73884079+0.02311824j, var(E): 0.59255627
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 10000/ t/epoch=1.96............. Loss: 0.21133175, mean(E): -21.73200933+0.02088544j, var(E): 0.64092754
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 10000/ t/epoch=1.96............. Loss: -0.18110378, mean(E): -21.65463171+0.00191593j, var(E): 0.55268999
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 10000/ t/epoch=1.96............. Loss: 0.12393579, mean(E): -21.72229128-0.02638541j, var(E): 0.62737683
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 10000/ t/epoch=1.96............. Loss: -0.32808190, mean(E): -21.66064450+0.02479677j, var(E): 0.66282813
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 10000/ t/epoch=1.96............. Loss: 0.64847777, mean(E): -21.80374526+0.00722225j, var(E): 1.06891988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 10000/ t/epoch=1.96............. Loss: -0.30108639, mean(E): -21.66751708+0.01907947j, var(E): 0.26501355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 10000/ t/epoch=1.96............. Loss: 0.03962588, mean(E): -21.68563268-0.00281578j, var(E): 0.68882062
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 10000/ t/epoch=1.96............. Loss: -0.36528519, mean(E): -21.65694578+0.00928688j, var(E): 0.38578661
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 10000/ t/epoch=1.96............. Loss: 0.25370634, mean(E): -21.77989611+0.00150111j, var(E): 0.34815671
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 10000/ t/epoch=1.96............. Loss: -0.26741593, mean(E): -21.68849626+0.00873817j, var(E): 0.53179270
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 10000/ t/epoch=1.96............. Loss: -0.11352984, mean(E): -21.66569728+0.00991768j, var(E): 0.39439490
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 10000/ t/epoch=1.96............. Loss: -0.02169748, mean(E): -21.69056438-0.01604751j, var(E): 0.40032571
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 10000/ t/epoch=1.96............. Loss: -0.06017114, mean(E): -21.63659904-0.00603744j, var(E): 0.63769087
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 10000/ t/epoch=1.96............. Loss: -0.03227485, mean(E): -21.68261803-0.01938453j, var(E): 0.51688198
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 10000/ t/epoch=1.96............. Loss: -0.08297235, mean(E): -21.69050920+0.00678733j, var(E): 0.56869186
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 10000/ t/epoch=1.96............. Loss: 1.27649361, mean(E): -21.86923012-0.02049773j, var(E): 1.61575665
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 10000/ t/epoch=1.96............. Loss: 0.21380146, mean(E): -21.75141495+0.02821013j, var(E): 0.22646336
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 10000/ t/epoch=1.96............. Loss: -0.37015961, mean(E): -21.62046428+0.00007122j, var(E): 1.12532911
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 10000/ t/epoch=1.96............. Loss: 0.56870139, mean(E): -21.72111252+0.00297436j, var(E): 1.28515709
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 10000/ t/epoch=1.96............. Loss: 0.08843669, mean(E): -21.73495924+0.00515459j, var(E): 0.40208785
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 10000/ t/epoch=1.96............. Loss: 0.08558196, mean(E): -21.70886845-0.01146751j, var(E): 0.72038351
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 10000/ t/epoch=1.96............. Loss: 0.28544334, mean(E): -21.72164093+0.02875787j, var(E): 0.44214389
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 10000/ t/epoch=1.96............. Loss: 0.05789946, mean(E): -21.72343244+0.01204655j, var(E): 0.62770635
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 10000/ t/epoch=2.0............. Loss: -0.33175384, mean(E): -21.63869935-0.00459254j, var(E): 0.33176139
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 10000/ t/epoch=1.96............. Loss: 1.79618145, mean(E): -21.80784090-0.00777607j, var(E): 5.13056908
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 10000/ t/epoch=1.96............. Loss: 0.46408744, mean(E): -21.76192965+0.01969887j, var(E): 0.74641887
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 10000/ t/epoch=1.96............. Loss: -0.51933832, mean(E): -21.62680647+0.00363393j, var(E): 1.00241792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 10000/ t/epoch=1.96............. Loss: -0.19831521, mean(E): -21.65270730+0.00503229j, var(E): 0.63588295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 10000/ t/epoch=1.96............. Loss: 1.05732546, mean(E): -21.84471237-0.01013003j, var(E): 1.42408029
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 10000/ t/epoch=1.96............. Loss: -0.05412560, mean(E): -21.69200875-0.02858461j, var(E): 0.44494593
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 10000/ t/epoch=1.97............. Loss: -0.28971020, mean(E): -21.66869865-0.02501929j, var(E): 0.58102645
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 10000/ t/epoch=1.96............. Loss: -0.15838566, mean(E): -21.66108264+0.00093554j, var(E): 0.22381092
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 10000/ t/epoch=1.96............. Loss: -0.11949288, mean(E): -21.67154482-0.00965248j, var(E): 0.72461971
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 10000/ t/epoch=1.96............. Loss: -0.04318383, mean(E): -21.66020802-0.01019809j, var(E): 0.91116254
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 10000/ t/epoch=1.96............. Loss: 0.01691675, mean(E): -21.74053419+0.01588396j, var(E): 0.55283633
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 10000/ t/epoch=1.96............. Loss: -0.60997654, mean(E): -21.56794009-0.00883122j, var(E): 0.73407392
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 10000/ t/epoch=1.96............. Loss: -0.00085501, mean(E): -21.63788637+0.00090132j, var(E): 0.78556382
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 10000/ t/epoch=1.96............. Loss: -0.08407088, mean(E): -21.64593940-0.01781988j, var(E): 0.68566643
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 10000/ t/epoch=1.96............. Loss: 0.11214921, mean(E): -21.68844583-0.00057891j, var(E): 0.52228195
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 10000/ t/epoch=1.96............. Loss: 0.31296066, mean(E): -21.74111476-0.01266010j, var(E): 0.71064449
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 10000/ t/epoch=1.96............. Loss: 0.18273515, mean(E): -21.72255103+0.00960196j, var(E): 0.18080368
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 10000/ t/epoch=1.96............. Loss: 0.49852751, mean(E): -21.77448406-0.02097835j, var(E): 0.87355017
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 10000/ t/epoch=1.96............. Loss: -0.06736999, mean(E): -21.69740658-0.00221415j, var(E): 0.52364614
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 10000/ t/epoch=1.96............. Loss: 0.17065060, mean(E): -21.72792398+0.00918056j, var(E): 0.53053007
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 10000/ t/epoch=1.96............. Loss: -0.37388900, mean(E): -21.64434503-0.01033940j, var(E): 0.29828624
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 10000/ t/epoch=1.96............. Loss: -0.18026762, mean(E): -21.72012074+0.00931725j, var(E): 0.74867733
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 10000/ t/epoch=1.96............. Loss: -0.35398475, mean(E): -21.61459312-0.00530486j, var(E): 0.54200559
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 10000/ t/epoch=1.96............. Loss: 0.07547197, mean(E): -21.67270410+0.01827815j, var(E): 0.54517312
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 10000/ t/epoch=1.96............. Loss: -0.55659727, mean(E): -21.57978028-0.00143640j, var(E): 0.58074279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 10000/ t/epoch=1.97............. Loss: 0.09283463, mean(E): -21.69988801+0.00270768j, var(E): 0.35951247
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 10000/ t/epoch=1.96............. Loss: 0.80813828, mean(E): -21.82811913+0.00443793j, var(E): 0.65871615
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 10000/ t/epoch=1.96............. Loss: -0.07662138, mean(E): -21.67481661+0.00885933j, var(E): 0.36946872
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 10000/ t/epoch=1.96............. Loss: 0.00553931, mean(E): -21.69836815+0.02783379j, var(E): 0.53656785
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 10000/ t/epoch=1.96............. Loss: 0.06353246, mean(E): -21.65490058-0.01441267j, var(E): 1.27862162
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 10000/ t/epoch=1.96............. Loss: -0.36978966, mean(E): -21.65837579-0.00299843j, var(E): 0.72929179
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 10000/ t/epoch=1.96............. Loss: 0.36485568, mean(E): -21.77334600+0.02972033j, var(E): 0.24505894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 10000/ t/epoch=1.96............. Loss: -0.86440402, mean(E): -21.58901650+0.01393335j, var(E): 0.65218602
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 10000/ t/epoch=1.96............. Loss: 0.14674410, mean(E): -21.73939429+0.01304324j, var(E): 0.50861567
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 10000/ t/epoch=1.96............. Loss: -0.34151483, mean(E): -21.61038641+0.01741764j, var(E): 0.48993242
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 10000/ t/epoch=1.96............. Loss: 0.38274949, mean(E): -21.74335390+0.03074064j, var(E): 0.27356005
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 10000/ t/epoch=1.96............. Loss: 0.01745090, mean(E): -21.71855284+0.03948988j, var(E): 0.27225937
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 10000/ t/epoch=1.96............. Loss: 0.49530124, mean(E): -21.72633875+0.00093553j, var(E): 0.50458592
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 10000/ t/epoch=1.96............. Loss: 0.13910152, mean(E): -21.73881310+0.02099866j, var(E): 0.23413476
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 10000/ t/epoch=1.96............. Loss: -0.59314282, mean(E): -21.58462496+0.01167554j, var(E): 0.58895347
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 10000/ t/epoch=1.96............. Loss: 0.01117692, mean(E): -21.70094964+0.01730787j, var(E): 0.23322228
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 10000/ t/epoch=1.97............. Loss: -0.22711874, mean(E): -21.66180237+0.00547724j, var(E): 0.35626199
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 10000/ t/epoch=1.96............. Loss: -0.57484178, mean(E): -21.59128888+0.01772563j, var(E): 0.58606024
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 10000/ t/epoch=1.96............. Loss: 0.27446287, mean(E): -21.73806984+0.00994863j, var(E): 0.95748703
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 10000/ t/epoch=1.96............. Loss: -0.63062273, mean(E): -21.62851899+0.00894855j, var(E): 0.93037271
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 10000/ t/epoch=1.96............. Loss: 0.71884127, mean(E): -21.77770561+0.02572726j, var(E): 1.19444639
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 10000/ t/epoch=1.96............. Loss: 0.46546413, mean(E): -21.77142392+0.00988431j, var(E): 0.56815778
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 10000/ t/epoch=1.96............. Loss: 0.00555570, mean(E): -21.71182836+0.00068387j, var(E): 0.47847288
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 10000/ t/epoch=1.96............. Loss: -0.04776910, mean(E): -21.69841170+0.00302467j, var(E): 0.29720416
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 10000/ t/epoch=1.96............. Loss: -0.30003860, mean(E): -21.63971548+0.00773491j, var(E): 0.46470871
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 10000/ t/epoch=1.96............. Loss: 0.20114752, mean(E): -21.71716753+0.00899023j, var(E): 0.39114761
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 10000/ t/epoch=1.96............. Loss: -0.49448694, mean(E): -21.59123093+0.01268619j, var(E): 0.77641101
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 10000/ t/epoch=1.96............. Loss: 0.26210231, mean(E): -21.77657779-0.00607102j, var(E): 0.82782245
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 10000/ t/epoch=1.96............. Loss: -0.18377002, mean(E): -21.66414407+0.01609016j, var(E): 0.60742224
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 10000/ t/epoch=1.96............. Loss: -0.41149728, mean(E): -21.66106206+0.02558223j, var(E): 0.81430714
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 10000/ t/epoch=1.96............. Loss: 0.14611313, mean(E): -21.72348950-0.00479770j, var(E): 0.51888462
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 10000/ t/epoch=1.96............. Loss: -0.18653979, mean(E): -21.68545907+0.03001196j, var(E): 0.44077169
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 10000/ t/epoch=1.96............. Loss: -0.12467106, mean(E): -21.68013918-0.00305421j, var(E): 0.35647763
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 10000/ t/epoch=1.96............. Loss: 0.56339861, mean(E): -21.77043738-0.00563899j, var(E): 0.69078167
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 10000/ t/epoch=1.96............. Loss: -0.33946586, mean(E): -21.62926312+0.02590507j, var(E): 0.57782340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 10000/ t/epoch=1.96............. Loss: 0.34242120, mean(E): -21.75740211+0.00475104j, var(E): 0.29753177
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 10000/ t/epoch=1.96............. Loss: 0.55857667, mean(E): -21.74937568+0.01577259j, var(E): 1.27209063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 10000/ t/epoch=1.96............. Loss: 0.23917007, mean(E): -21.71987486+0.02516607j, var(E): 0.63611755
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 10000/ t/epoch=1.96............. Loss: 0.57075630, mean(E): -21.80177017+0.00797757j, var(E): 0.59219756
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 10000/ t/epoch=1.96............. Loss: 0.01449826, mean(E): -21.66602943+0.01056002j, var(E): 1.01806508
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 10000/ t/epoch=1.96............. Loss: -0.11529195, mean(E): -21.68308210+0.00859359j, var(E): 0.23933961
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 10000/ t/epoch=1.96............. Loss: -0.15073676, mean(E): -21.68180343+0.01183464j, var(E): 0.30835069
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 10000/ t/epoch=1.96............. Loss: -0.28903881, mean(E): -21.63462007+0.02855078j, var(E): 0.35949728
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 10000/ t/epoch=1.96............. Loss: -0.74743092, mean(E): -21.55591749+0.01642757j, var(E): 0.77189803
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 10000/ t/epoch=1.96............. Loss: -0.06413963, mean(E): -21.69901647+0.00535712j, var(E): 0.24443785
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 10000/ t/epoch=1.96............. Loss: -0.12549834, mean(E): -21.68570008+0.02037221j, var(E): 0.37292871
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 10000/ t/epoch=1.97............. Loss: -0.24960603, mean(E): -21.68107695+0.01894358j, var(E): 0.40113151
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 10000/ t/epoch=1.96............. Loss: 0.05755101, mean(E): -21.68400388+0.01656858j, var(E): 0.38576113
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 10000/ t/epoch=1.96............. Loss: 0.37344017, mean(E): -21.75271849+0.00763825j, var(E): 0.79520344
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 10000/ t/epoch=1.96............. Loss: -0.03000516, mean(E): -21.69186430+0.01747580j, var(E): 0.28953757
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 10000/ t/epoch=1.96............. Loss: -0.00048288, mean(E): -21.67598360-0.00515702j, var(E): 0.17613776
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 10000/ t/epoch=1.96............. Loss: -0.34902150, mean(E): -21.66974811+0.00117798j, var(E): 0.82205064
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 10000/ t/epoch=1.96............. Loss: -0.13085085, mean(E): -21.66843452-0.01970601j, var(E): 0.39667154
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 10000/ t/epoch=1.96............. Loss: 0.62124855, mean(E): -21.80793882+0.03981046j, var(E): 1.12593781
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 10000/ t/epoch=1.96............. Loss: -0.29309572, mean(E): -21.62205069-0.00147795j, var(E): 0.56741192
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 10000/ t/epoch=1.96............. Loss: 0.50098005, mean(E): -21.81935657+0.00569290j, var(E): 0.77729800
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 10000/ t/epoch=1.96............. Loss: -0.26747017, mean(E): -21.67051094+0.02801169j, var(E): 0.39410400
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 10000/ t/epoch=1.96............. Loss: 0.14705315, mean(E): -21.74381759-0.00188762j, var(E): 0.36520343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 10000/ t/epoch=1.96............. Loss: 0.09330114, mean(E): -21.70597971+0.02581432j, var(E): 0.35351410
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 10000/ t/epoch=1.96............. Loss: -0.11435817, mean(E): -21.68534968+0.03184711j, var(E): 0.46948404
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 10000/ t/epoch=1.96............. Loss: 0.09008779, mean(E): -21.72982553+0.01776960j, var(E): 0.42384029
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 10000/ t/epoch=1.96............. Loss: -0.36873192, mean(E): -21.65539190+0.00619864j, var(E): 0.51844516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 10000/ t/epoch=1.96............. Loss: -0.06764538, mean(E): -21.68281536+0.02340032j, var(E): 0.51180386
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 10000/ t/epoch=1.96............. Loss: -0.08816402, mean(E): -21.66470347-0.00881254j, var(E): 0.91312308
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 10000/ t/epoch=1.97............. Loss: -0.60787095, mean(E): -21.59936814-0.00412331j, var(E): 0.67094717
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 10000/ t/epoch=1.97............. Loss: 0.00283451, mean(E): -21.72379023+0.00465530j, var(E): 0.48711590
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 10000/ t/epoch=1.97............. Loss: -0.40363211, mean(E): -21.69406244-0.00472507j, var(E): 0.92815027
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 10000/ t/epoch=1.97............. Loss: -0.63857195, mean(E): -21.59583086+0.01136447j, var(E): 0.59697819
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 10000/ t/epoch=1.97............. Loss: -0.16021408, mean(E): -21.68570919+0.01706518j, var(E): 0.89102553
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 10000/ t/epoch=1.96............. Loss: -0.29415044, mean(E): -21.65900647+0.00439899j, var(E): 0.53896944
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 10000/ t/epoch=1.96............. Loss: 0.22646075, mean(E): -21.77030964+0.00959698j, var(E): 0.62866926
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 10000/ t/epoch=1.96............. Loss: -0.31522405, mean(E): -21.70391056+0.03000922j, var(E): 0.43034081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 10000/ t/epoch=1.97............. Loss: 0.31220532, mean(E): -21.76169984+0.00897741j, var(E): 0.70651678
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 10000/ t/epoch=1.96............. Loss: 0.10490944, mean(E): -21.71263468+0.00564308j, var(E): 0.17093535
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 10000/ t/epoch=1.96............. Loss: 0.08310160, mean(E): -21.73546980+0.01925223j, var(E): 0.89731894
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 10000/ t/epoch=1.96............. Loss: 0.14063730, mean(E): -21.72774659+0.01019186j, var(E): 0.30342505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 10000/ t/epoch=1.96............. Loss: -0.37522716, mean(E): -21.65391507-0.00682701j, var(E): 0.69917753
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 10000/ t/epoch=1.96............. Loss: -0.18365495, mean(E): -21.66291154-0.01621415j, var(E): 0.60707267
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 10000/ t/epoch=1.96............. Loss: 0.10939354, mean(E): -21.72876995+0.01239459j, var(E): 0.36788028
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 10000/ t/epoch=1.96............. Loss: 0.56444396, mean(E): -21.79384527-0.02939044j, var(E): 1.48946695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 10000/ t/epoch=1.96............. Loss: -0.10248332, mean(E): -21.70467965-0.00041265j, var(E): 0.29575175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 10000/ t/epoch=1.96............. Loss: -0.13546326, mean(E): -21.69667839+0.00473659j, var(E): 0.36689264
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 10000/ t/epoch=1.96............. Loss: 0.33004115, mean(E): -21.75315812-0.00291795j, var(E): 0.68406643
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 10000/ t/epoch=1.96............. Loss: 0.07063070, mean(E): -21.74096666+0.00501297j, var(E): 0.50641949
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 10000/ t/epoch=1.96............. Loss: 0.15142948, mean(E): -21.73112622-0.02396314j, var(E): 0.42544255
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 10000/ t/epoch=1.96............. Loss: -0.16049554, mean(E): -21.69311091+0.00482255j, var(E): 0.45831612
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 10000/ t/epoch=1.96............. Loss: -0.16111841, mean(E): -21.66691691+0.00837477j, var(E): 0.37710091
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 10000/ t/epoch=1.96............. Loss: -0.12064078, mean(E): -21.69734453-0.00443644j, var(E): 0.26405673
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 10000/ t/epoch=1.96............. Loss: -0.03434410, mean(E): -21.67652466+0.00435505j, var(E): 0.33451168
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 10000/ t/epoch=1.97............. Loss: -0.52835862, mean(E): -21.63302288-0.00229550j, var(E): 0.49569687
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 10000/ t/epoch=1.97............. Loss: -0.10591062, mean(E): -21.69928789+0.00590140j, var(E): 0.55793944
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 10000/ t/epoch=1.96............. Loss: -0.10971527, mean(E): -21.72222019-0.02601525j, var(E): 1.06864008
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 10000/ t/epoch=1.96............. Loss: -0.24319447, mean(E): -21.68405146+0.01719184j, var(E): 0.50283227
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 10000/ t/epoch=1.96............. Loss: -0.17230154, mean(E): -21.70072554+0.01980743j, var(E): 0.46654863
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 10000/ t/epoch=1.96............. Loss: 0.26890134, mean(E): -21.73795353-0.00998278j, var(E): 0.71659988
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 10000/ t/epoch=1.96............. Loss: -0.38312092, mean(E): -21.65162445+0.03882413j, var(E): 0.30866036
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 10000/ t/epoch=1.96............. Loss: -0.07740779, mean(E): -21.67864590-0.01257164j, var(E): 0.28592541
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 10000/ t/epoch=1.96............. Loss: -0.08462201, mean(E): -21.66752921+0.00900742j, var(E): 0.20319597
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 10000/ t/epoch=1.96............. Loss: -0.24484420, mean(E): -21.66653191+0.01979869j, var(E): 0.23778451
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 10000/ t/epoch=1.96............. Loss: 0.43383020, mean(E): -21.79419494+0.00687071j, var(E): 0.43225199
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 10000/ t/epoch=1.96............. Loss: 0.17658902, mean(E): -21.74658350+0.01514736j, var(E): 0.40345174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 10000/ t/epoch=1.96............. Loss: -0.80345129, mean(E): -21.59046941-0.03468617j, var(E): 0.69748015
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 10000/ t/epoch=1.96............. Loss: 0.10568402, mean(E): -21.72203632+0.02410048j, var(E): 0.30013815
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 10000/ t/epoch=1.96............. Loss: 0.05182748, mean(E): -21.72182129+0.01294728j, var(E): 0.22467279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 10000/ t/epoch=1.96............. Loss: -0.40483708, mean(E): -21.60696984+0.00678393j, var(E): 1.08905533
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 10000/ t/epoch=1.96............. Loss: -0.35807555, mean(E): -21.65608644-0.00033480j, var(E): 0.43012455
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 10000/ t/epoch=1.96............. Loss: 0.16259927, mean(E): -21.73603387+0.02034284j, var(E): 0.82574090
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 10000/ t/epoch=1.96............. Loss: 0.02994649, mean(E): -21.71745117+0.02895111j, var(E): 0.31476323
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 10000/ t/epoch=1.96............. Loss: -0.34292622, mean(E): -21.66641134-0.00035557j, var(E): 0.51594329
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 10000/ t/epoch=1.96............. Loss: -0.49206567, mean(E): -21.61921974+0.00998243j, var(E): 0.38994383
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 10000/ t/epoch=1.96............. Loss: -0.48859733, mean(E): -21.62884507+0.00739746j, var(E): 0.64716516
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 10000/ t/epoch=1.96............. Loss: -0.31675123, mean(E): -21.62644486+0.02529279j, var(E): 0.53040378
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 10000/ t/epoch=1.96............. Loss: 0.66596367, mean(E): -21.80967046+0.02398541j, var(E): 0.99592939
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 10000/ t/epoch=1.96............. Loss: 0.28825754, mean(E): -21.74223471+0.01142842j, var(E): 0.61170588
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 10000/ t/epoch=1.96............. Loss: -0.11241075, mean(E): -21.69845758+0.02155783j, var(E): 0.59629198
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 10000/ t/epoch=1.96............. Loss: -0.09324764, mean(E): -21.69193112-0.00777140j, var(E): 0.27349185
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 10000/ t/epoch=1.96............. Loss: 0.14843563, mean(E): -21.73948981+0.01653431j, var(E): 0.26764842
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 10000/ t/epoch=1.96............. Loss: -0.17217161, mean(E): -21.68116028-0.00471894j, var(E): 0.64172111
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 10000/ t/epoch=1.96............. Loss: 0.18501726, mean(E): -21.72037171-0.00199981j, var(E): 1.37647102
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 10000/ t/epoch=1.96............. Loss: -0.22126251, mean(E): -21.65145116-0.01941518j, var(E): 0.74549289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 10000/ t/epoch=1.96............. Loss: 0.41640674, mean(E): -21.78522883+0.01333239j, var(E): 0.77176093
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 10000/ t/epoch=1.96............. Loss: 0.16313349, mean(E): -21.72835089+0.00069659j, var(E): 0.30291498
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 10000/ t/epoch=2.0............. Loss: -0.35818127, mean(E): -21.64298750+0.02850887j, var(E): 0.70161343
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 10000/ t/epoch=1.96............. Loss: -0.10953952, mean(E): -21.67072142-0.01111017j, var(E): 0.38599098
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 10000/ t/epoch=1.96............. Loss: 0.41182093, mean(E): -21.79133002-0.01025378j, var(E): 0.47965353
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 10000/ t/epoch=1.96............. Loss: -0.34004471, mean(E): -21.66732785+0.00061432j, var(E): 0.69027501
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 10000/ t/epoch=1.96............. Loss: 0.39101547, mean(E): -21.72517141+0.01855504j, var(E): 1.42980295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 10000/ t/epoch=1.96............. Loss: -0.15992357, mean(E): -21.68868871+0.01715408j, var(E): 1.13294874
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 10000/ t/epoch=1.96............. Loss: -0.19271385, mean(E): -21.69459707-0.00678024j, var(E): 0.32407899
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 10000/ t/epoch=1.96............. Loss: -0.16049235, mean(E): -21.66598279+0.05356897j, var(E): 0.57119132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 10000/ t/epoch=1.97............. Loss: 0.11881478, mean(E): -21.74063062-0.01815357j, var(E): 0.47403548
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 10000/ t/epoch=1.96............. Loss: 0.25873832, mean(E): -21.74253621+0.01353127j, var(E): 0.68811696
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 10000/ t/epoch=1.96............. Loss: -0.42316935, mean(E): -21.64172613+0.00540598j, var(E): 0.38980026
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 10000/ t/epoch=1.96............. Loss: 0.45546339, mean(E): -21.74454492+0.00581437j, var(E): 0.47430934
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 10000/ t/epoch=1.96............. Loss: -0.28159939, mean(E): -21.66098020+0.01529276j, var(E): 0.68696906
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 10000/ t/epoch=1.96............. Loss: 0.06847525, mean(E): -21.74803565-0.00677491j, var(E): 0.47769303
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 10000/ t/epoch=1.96............. Loss: -0.60015929, mean(E): -21.60922453+0.00936781j, var(E): 0.66436127
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 10000/ t/epoch=1.96............. Loss: -0.06315214, mean(E): -21.67873628+0.00084439j, var(E): 0.21523855
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 10000/ t/epoch=1.96............. Loss: -0.23837816, mean(E): -21.62904877+0.01254605j, var(E): 0.24209171
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 10000/ t/epoch=1.96............. Loss: 0.11634925, mean(E): -21.71488098+0.02975864j, var(E): 0.43866454
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 10000/ t/epoch=1.96............. Loss: 0.49734587, mean(E): -21.76697686+0.00042972j, var(E): 0.37757171
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 10000/ t/epoch=1.96............. Loss: 0.20188412, mean(E): -21.74958862-0.00355022j, var(E): 0.54410002
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 10000/ t/epoch=1.96............. Loss: 1.04326353, mean(E): -21.83463986+0.01668159j, var(E): 2.01925040
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 10000/ t/epoch=1.96............. Loss: -0.55575039, mean(E): -21.66234984-0.00578641j, var(E): 0.59923675
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 10000/ t/epoch=1.96............. Loss: 0.35461339, mean(E): -21.73072891+0.01571294j, var(E): 0.57062838
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 10000/ t/epoch=1.96............. Loss: 0.02200972, mean(E): -21.68393107+0.01095363j, var(E): 1.26022946
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 10000/ t/epoch=2.0............. Loss: 0.02549006, mean(E): -21.70237948+0.00872118j, var(E): 0.97078000
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 10000/ t/epoch=1.96............. Loss: 0.00202526, mean(E): -21.70083427+0.00514739j, var(E): 0.30440960
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 10000/ t/epoch=1.96............. Loss: -0.33862447, mean(E): -21.63848174+0.01449669j, var(E): 0.22929513
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 10000/ t/epoch=1.96............. Loss: -0.78340867, mean(E): -21.57198667+0.00973622j, var(E): 0.68465337
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 10000/ t/epoch=1.96............. Loss: -0.17039902, mean(E): -21.66054355-0.02688269j, var(E): 0.35751373
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 10000/ t/epoch=1.96............. Loss: 0.08556751, mean(E): -21.72910420+0.01663209j, var(E): 0.77055054
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 10000/ t/epoch=1.96............. Loss: -0.04012799, mean(E): -21.73572928+0.02491374j, var(E): 0.80259202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 10000/ t/epoch=1.96............. Loss: 0.13164368, mean(E): -21.72826281-0.00505961j, var(E): 0.17727388
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 10000/ t/epoch=1.96............. Loss: -0.34395570, mean(E): -21.64751265+0.03059570j, var(E): 0.77496900
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 10000/ t/epoch=1.96............. Loss: 0.32462190, mean(E): -21.74533975-0.00961212j, var(E): 0.59826928
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 10000/ t/epoch=1.96............. Loss: -0.24576548, mean(E): -21.68608980+0.00154176j, var(E): 0.50490071
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 10000/ t/epoch=1.96............. Loss: 0.42188718, mean(E): -21.71739654+0.01006060j, var(E): 0.79977526
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 10000/ t/epoch=1.96............. Loss: -0.42064817, mean(E): -21.66987751+0.02003860j, var(E): 0.45123512
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 10000/ t/epoch=1.96............. Loss: -0.12496588, mean(E): -21.67236234+0.01797629j, var(E): 0.26043954
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 10000/ t/epoch=1.96............. Loss: -0.49071353, mean(E): -21.58358376+0.02954006j, var(E): 0.50181050
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 10000/ t/epoch=1.96............. Loss: 0.55556974, mean(E): -21.77215931+0.01721732j, var(E): 0.84757847
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 10000/ t/epoch=1.96............. Loss: 0.20592479, mean(E): -21.73931292+0.00955547j, var(E): 0.78824419
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 10000/ t/epoch=1.96............. Loss: -0.03701838, mean(E): -21.69952122+0.00917434j, var(E): 0.13714503
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 10000/ t/epoch=1.96............. Loss: 0.33489403, mean(E): -21.71915156-0.01409019j, var(E): 0.56175594
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 10000/ t/epoch=1.96............. Loss: -0.08742572, mean(E): -21.69319668+0.01770006j, var(E): 0.30572648
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 10000/ t/epoch=1.96............. Loss: -0.22611626, mean(E): -21.67319643-0.01008804j, var(E): 0.49160521
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 10000/ t/epoch=1.96............. Loss: -0.16793394, mean(E): -21.70532527+0.00611755j, var(E): 0.28809631
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 10000/ t/epoch=1.96............. Loss: -0.10526717, mean(E): -21.65795248+0.01246694j, var(E): 0.55083160
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 10000/ t/epoch=1.96............. Loss: -0.29819209, mean(E): -21.70983288+0.00984623j, var(E): 0.67822792
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 10000/ t/epoch=1.96............. Loss: 0.02559727, mean(E): -21.70556232+0.03548767j, var(E): 0.51152490
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 10000/ t/epoch=1.96............. Loss: 0.02583056, mean(E): -21.71309123+0.04108364j, var(E): 0.37691183
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 10000/ t/epoch=1.96............. Loss: 0.29516761, mean(E): -21.74651856+0.00753084j, var(E): 1.11446235
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 10000/ t/epoch=1.96............. Loss: 0.16142735, mean(E): -21.73002822+0.00654071j, var(E): 0.17774924
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 10000/ t/epoch=1.96............. Loss: -0.04814393, mean(E): -21.71223497-0.00537042j, var(E): 0.22545295
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 10000/ t/epoch=1.96............. Loss: -0.28074970, mean(E): -21.65131732+0.00560252j, var(E): 0.41313910
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 10000/ t/epoch=1.96............. Loss: -0.09713947, mean(E): -21.66809353+0.00060753j, var(E): 0.19734804
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 10000/ t/epoch=1.96............. Loss: -0.67419556, mean(E): -21.58067650+0.01036474j, var(E): 0.92786711
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 10000/ t/epoch=1.96............. Loss: -0.32842164, mean(E): -21.64127449+0.01245812j, var(E): 0.69021695
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 10000/ t/epoch=1.97............. Loss: -0.39524802, mean(E): -21.65390330-0.02227682j, var(E): 0.36371734
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 10000/ t/epoch=1.96............. Loss: -0.33504227, mean(E): -21.67152725+0.01742509j, var(E): 0.76201334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 10000/ t/epoch=1.96............. Loss: -0.13877044, mean(E): -21.66051361-0.01120084j, var(E): 0.57489402
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 10000/ t/epoch=1.96............. Loss: -0.54899263, mean(E): -21.64739291+0.00407807j, var(E): 0.61242595
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 10000/ t/epoch=1.96............. Loss: 0.47832416, mean(E): -21.73137529+0.00496910j, var(E): 1.04930717
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 10000/ t/epoch=1.96............. Loss: -0.06449507, mean(E): -21.69089857+0.02316310j, var(E): 0.40618689
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 10000/ t/epoch=1.96............. Loss: -0.25605659, mean(E): -21.72346287-0.01434440j, var(E): 0.77760890
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 10000/ t/epoch=1.96............. Loss: -0.63663174, mean(E): -21.63616246-0.00513535j, var(E): 0.68300336
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 10000/ t/epoch=1.96............. Loss: 0.15481508, mean(E): -21.70531799+0.00494456j, var(E): 0.33084722
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 10000/ t/epoch=1.96............. Loss: -0.32233607, mean(E): -21.65082780-0.00968063j, var(E): 0.75372334
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 10000/ t/epoch=1.96............. Loss: 0.51571615, mean(E): -21.79255351-0.00567476j, var(E): 0.73932174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 10000/ t/epoch=1.96............. Loss: -0.16125961, mean(E): -21.69386198-0.01182713j, var(E): 0.36704812
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 10000/ t/epoch=1.96............. Loss: -0.16656941, mean(E): -21.66844544+0.00483648j, var(E): 0.21501473
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 10000/ t/epoch=1.96............. Loss: 0.13932932, mean(E): -21.74884897-0.01109719j, var(E): 0.28547546
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 10000/ t/epoch=1.95............. Loss: 0.60825564, mean(E): -21.78535118-0.00196830j, var(E): 1.20784202
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 10000/ t/epoch=1.96............. Loss: 0.08901428, mean(E): -21.71800915+0.00362324j, var(E): 0.28855885
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 10000/ t/epoch=1.96............. Loss: 0.34583553, mean(E): -21.76826763+0.00190453j, var(E): 1.50018557
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 10000/ t/epoch=1.96............. Loss: 0.30629566, mean(E): -21.75788908+0.00018492j, var(E): 0.75880279
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 10000/ t/epoch=1.96............. Loss: 0.13513611, mean(E): -21.75109181+0.00152026j, var(E): 0.37415900
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 10000/ t/epoch=1.96............. Loss: 0.23201057, mean(E): -21.73564845+0.00716772j, var(E): 0.61853462
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 10000/ t/epoch=1.96............. Loss: 0.17563842, mean(E): -21.73939958-0.00411392j, var(E): 1.17516581
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 10000/ t/epoch=1.96............. Loss: -0.14760221, mean(E): -21.70661119+0.00214618j, var(E): 0.38694902
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 10000/ t/epoch=1.96............. Loss: -0.24373211, mean(E): -21.67778362+0.02367468j, var(E): 0.24835049
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(14.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 10000/ t/epoch=1.96............. Loss: 0.09245140, mean(E): -21.73923057+0.00110897j, var(E): 0.48568823
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 10000/ t/epoch=1.96............. Loss: 0.14424747, mean(E): -21.74177958-0.00369830j, var(E): 0.28671063
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 10000/ t/epoch=1.96............. Loss: 0.20541111, mean(E): -21.73687695+0.01266811j, var(E): 0.65772152
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 10000/ t/epoch=1.96............. Loss: 1.21811677, mean(E): -21.86395262+0.00158089j, var(E): 1.95302073
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 10000/ t/epoch=1.96............. Loss: -0.12108490, mean(E): -21.70157427+0.00445324j, var(E): 0.72197735
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 10000/ t/epoch=1.96............. Loss: 1.21372256, mean(E): -21.85847184-0.00418489j, var(E): 3.29593252
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 10000/ t/epoch=1.96............. Loss: -0.21680529, mean(E): -21.67362787+0.01341453j, var(E): 0.27445249
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 10000/ t/epoch=1.96............. Loss: 0.28318873, mean(E): -21.73938018-0.01730596j, var(E): 0.57385176
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 10000/ t/epoch=1.96............. Loss: 0.04539368, mean(E): -21.72828297+0.03163794j, var(E): 0.38991050
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 10000/ t/epoch=1.96............. Loss: 0.15948398, mean(E): -21.71371639-0.00030395j, var(E): 0.90398380
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 10000/ t/epoch=1.96............. Loss: -0.09685359, mean(E): -21.66204207+0.01109226j, var(E): 1.13383460
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 10000/ t/epoch=1.96............. Loss: -0.09703313, mean(E): -21.69282410-0.01148756j, var(E): 0.56399132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 10000/ t/epoch=1.96............. Loss: -0.24864011, mean(E): -21.68213191+0.00428980j, var(E): 0.24870106
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 10000/ t/epoch=1.96............. Loss: -0.24718304, mean(E): -21.66958826+0.01350238j, var(E): 0.32018355
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 10000/ t/epoch=1.96............. Loss: -0.25430602, mean(E): -21.68875019+0.01004480j, var(E): 0.55787523
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 10000/ t/epoch=1.96............. Loss: -0.09727504, mean(E): -21.67996137-0.01504731j, var(E): 0.41489770
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 10000/ t/epoch=1.96............. Loss: 0.27917508, mean(E): -21.74712595+0.00055053j, var(E): 0.53322549
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 10000/ t/epoch=1.96............. Loss: 0.40347767, mean(E): -21.76465603+0.01463554j, var(E): 0.32235081
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 10000/ t/epoch=1.96............. Loss: -0.42518886, mean(E): -21.66162393+0.01711411j, var(E): 0.45921116
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 10000/ t/epoch=1.96............. Loss: 0.36894415, mean(E): -21.78582884+0.01481331j, var(E): 0.33681352
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 10000/ t/epoch=1.96............. Loss: 0.35634372, mean(E): -21.73847387+0.04372171j, var(E): 1.27476147
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 10000/ t/epoch=1.96............. Loss: 0.05647263, mean(E): -21.73850169-0.00956429j, var(E): 0.61656735
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 10000/ t/epoch=1.96............. Loss: 1.01555760, mean(E): -21.82047877+0.04261883j, var(E): 1.25292615
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 10000/ t/epoch=1.95............. Loss: 0.43654786, mean(E): -21.76629895-0.00029140j, var(E): 0.33692220
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 10000/ t/epoch=1.96............. Loss: 0.53547254, mean(E): -21.79717629-0.00340570j, var(E): 0.54061608
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 10000/ t/epoch=1.96............. Loss: -0.16241033, mean(E): -21.67518037+0.01084383j, var(E): 0.39861843
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 10000/ t/epoch=1.96............. Loss: -0.34581618, mean(E): -21.67030235+0.03246395j, var(E): 0.26292174
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 10000/ t/epoch=1.96............. Loss: -0.29224236, mean(E): -21.71627146+0.01608398j, var(E): 0.85738491
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 10000/ t/epoch=1.96............. Loss: 0.21463904, mean(E): -21.71274477-0.01328402j, var(E): 0.60064538
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 10000/ t/epoch=1.96............. Loss: 0.28064880, mean(E): -21.76085129-0.00474345j, var(E): 0.92816339
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 10000/ t/epoch=1.96............. Loss: 1.46358398, mean(E): -21.91335123+0.02580809j, var(E): 1.77405289
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 10000/ t/epoch=1.96............. Loss: -0.23236101, mean(E): -21.68018134-0.01257866j, var(E): 0.23878490
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 10000/ t/epoch=1.96............. Loss: -0.31934891, mean(E): -21.67150666+0.01120896j, var(E): 0.54303340
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 10000/ t/epoch=1.96............. Loss: 0.08929476, mean(E): -21.71749696+0.01193261j, var(E): 0.13155691
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 10000/ t/epoch=1.96............. Loss: -0.24603023, mean(E): -21.65601455+0.01186829j, var(E): 0.48614132
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 10000/ t/epoch=1.96............. Loss: 0.15605856, mean(E): -21.75851468+0.03907174j, var(E): 0.58956523
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 10000/ t/epoch=1.96............. Loss: 0.04619738, mean(E): -21.71329442-0.00387548j, var(E): 0.40101742
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 10000/ t/epoch=1.96............. Loss: -0.33283334, mean(E): -21.65097203+0.01404062j, var(E): 0.71729015
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 10000/ t/epoch=1.96............. Loss: -0.20472927, mean(E): -21.66463633-0.01403962j, var(E): 0.31455558
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 10000/ t/epoch=1.96............. Loss: 0.01241385, mean(E): -21.69576079-0.00310443j, var(E): 0.37830309
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 10000/ t/epoch=1.96............. Loss: -0.09761281, mean(E): -21.70176934-0.00512881j, var(E): 1.42236505
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 10000/ t/epoch=1.96............. Loss: 0.16941500, mean(E): -21.72305369+0.01899281j, var(E): 0.24620779
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 10000/ t/epoch=1.96............. Loss: 0.24125507, mean(E): -21.75741672+0.00034241j, var(E): 0.51046577
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 10000/ t/epoch=1.96............. Loss: -0.16712597, mean(E): -21.65891240+0.00741394j, var(E): 0.18337285
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 10000/ t/epoch=1.96............. Loss: 0.09955229, mean(E): -21.71578083-0.00037074j, var(E): 0.35838113
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 10000/ t/epoch=1.96............. Loss: 0.47227317, mean(E): -21.77404212-0.01640909j, var(E): 0.57062229
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 10000/ t/epoch=1.96............. Loss: 0.56671779, mean(E): -21.80296159+0.00662628j, var(E): 0.69610175
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 10000/ t/epoch=1.96............. Loss: -0.10183322, mean(E): -21.69131610+0.01535327j, var(E): 0.41011400
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 10000/ t/epoch=1.96............. Loss: 0.36634335, mean(E): -21.77716885+0.02372038j, var(E): 0.72504855
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 10000/ t/epoch=1.96............. Loss: 0.17691229, mean(E): -21.77083683+0.02422395j, var(E): 0.56638580
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 10000/ t/epoch=1.96............. Loss: 0.68729780, mean(E): -21.82959586-0.01043686j, var(E): 0.88431018
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
torch.Size([200, 4, 4])
torch.Size([64, 200, 4, 4])
tensor(15.0220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 10000/ t/epoch=1.95............. Loss: -0.15376157, mean(E): -21.66819541+0.00543768j, var(E): 0.36801013
