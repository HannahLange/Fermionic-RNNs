1.13.1+cu117
GPU is available
Namespace(Jp=0.0, Jz=1.0, U=1.0, t=3.0, density=0.9375, Nx=4, Ny=4, bounds=1, boundsx=0, boundsy=0, load_model=0, sym=0.0, antisym=0.0, hd=50)
4x4_qubits/periodic/Jp=0.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 30000
rnn.b1: 50
rnn.W2: 30000
rnn.b2: 50
rnn.Wmerge: 5000
lin1.weight: 150
lin1.bias: 3
lin2.weight: 150
lin2.bias: 3
Total number of parameters in the network: 65406
0.0
tensor(9.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=4.83............. Loss: 5.36908421, mean(E): -15.50113233-0.00226971j, var(E): 30.01039814
0.0
tensor(9.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=2.62............. Loss: 4.33224338, mean(E): -15.33291209+0.00118671j, var(E): 19.88591156
0.0
tensor(9.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=2.63............. Loss: 5.59855404, mean(E): -16.66366425+0.00232356j, var(E): 30.45725113
0.0
tensor(10.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=2.65............. Loss: 3.30365039, mean(E): -16.95402371-0.01307649j, var(E): 25.54954894
0.0
tensor(10.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=2.66............. Loss: 1.79343348, mean(E): -17.89634910+0.00065280j, var(E): 15.10555422
0.0
tensor(10.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=2.68............. Loss: 1.49526084, mean(E): -18.77697905+0.00107646j, var(E): 15.32173108
0.0
tensor(11.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=2.71............. Loss: 0.80269630, mean(E): -19.21203796+0.00307905j, var(E): 14.19591782
0.0
tensor(11.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=2.73............. Loss: 1.76719337, mean(E): -19.79193898+0.00225774j, var(E): 15.02781329
0.0
tensor(11.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(11.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=2.73............. Loss: 0.82372804, mean(E): -19.83256994+0.00325119j, var(E): 10.02393939
0.0
tensor(12.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=2.73............. Loss: 0.74184033, mean(E): -20.12517444-0.00727751j, var(E): 9.36246406
0.0
tensor(12.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=2.73............. Loss: 1.08351851, mean(E): -20.48584971-0.00678068j, var(E): 8.85901557
0.0
tensor(12.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=2.73............. Loss: 0.57748777, mean(E): -20.37144303-0.00729543j, var(E): 8.07185679
0.0
tensor(12.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=2.73............. Loss: 0.44118345, mean(E): -20.41901365-0.00220326j, var(E): 6.97336340
0.0
tensor(12.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=2.73............. Loss: 0.89079589, mean(E): -20.55703307-0.00173164j, var(E): 7.73441458
0.0
tensor(12.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=2.73............. Loss: 0.25123334, mean(E): -20.48710805-0.00128937j, var(E): 5.94306212
0.0
tensor(12.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=2.72............. Loss: 0.56422891, mean(E): -20.59991497+0.00352477j, var(E): 6.02820906
0.0
tensor(12.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=2.73............. Loss: 0.98021064, mean(E): -20.78399951-0.00226655j, var(E): 6.30366123
0.0
tensor(12.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=2.72............. Loss: 0.84859452, mean(E): -20.71997893+0.00713720j, var(E): 7.62087980
0.0
tensor(12.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=2.73............. Loss: 0.79874544, mean(E): -20.93499216-0.00971975j, var(E): 4.94918840
0.0
tensor(12.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(12.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=2.73............. Loss: 0.59175275, mean(E): -20.87419415-0.00704351j, var(E): 5.38538994
0.0
tensor(13.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=2.72............. Loss: 0.44965559, mean(E): -20.83133843-0.01775940j, var(E): 3.76110047
0.0
tensor(13.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=2.72............. Loss: 0.23097689, mean(E): -21.07708202+0.00221701j, var(E): 4.19531082
0.0
tensor(13.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=2.73............. Loss: 0.04921438, mean(E): -21.01177973-0.00216373j, var(E): 4.04665040
0.0
tensor(13.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=2.73............. Loss: 0.34962600, mean(E): -21.05181016+0.00399769j, var(E): 3.65741272
0.0
tensor(13.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=2.73............. Loss: 0.28796681, mean(E): -21.06677045+0.01836225j, var(E): 3.35406161
0.0
tensor(13.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=2.72............. Loss: -0.10588141, mean(E): -21.03121979+0.00792991j, var(E): 3.59922463
0.0
tensor(13.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=2.73............. Loss: -0.08063821, mean(E): -21.13082950+0.01992390j, var(E): 3.74497556
0.0
tensor(13.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=2.72............. Loss: 0.05968597, mean(E): -21.10750296+0.00042939j, var(E): 2.57721359
0.0
tensor(13.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=2.71............. Loss: 0.47501252, mean(E): -21.14626468+0.01676949j, var(E): 2.97018197
0.0
tensor(13.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=2.71............. Loss: 0.78260853, mean(E): -21.34851428+0.01978214j, var(E): 4.88014257
0.0
tensor(13.7749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=2.72............. Loss: 0.49487109, mean(E): -21.34762034+0.03090753j, var(E): 4.01429659
0.0
tensor(13.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=2.72............. Loss: 0.51253496, mean(E): -21.37959514-0.01573589j, var(E): 3.30706818
0.0
tensor(13.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=2.71............. Loss: -0.19132605, mean(E): -21.22457272-0.00694523j, var(E): 2.96548162
0.0
tensor(13.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(13.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=2.73............. Loss: -0.14362163, mean(E): -21.25538295+0.00101604j, var(E): 2.31587145
0.0
tensor(14.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=2.73............. Loss: 0.10555351, mean(E): -21.36142936+0.00922124j, var(E): 2.92712310
0.0
tensor(14.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=2.72............. Loss: -0.13167235, mean(E): -21.35415061+0.01871913j, var(E): 2.84874082
0.0
tensor(14.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=2.73............. Loss: 0.15420311, mean(E): -21.34092613-0.01134424j, var(E): 2.55659822
0.0
tensor(14.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.1987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=2.71............. Loss: -0.30023106, mean(E): -21.34241985+0.00717801j, var(E): 2.32432618
0.0
tensor(14.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=2.72............. Loss: -0.14669484, mean(E): -21.36580080-0.00860865j, var(E): 2.14096199
0.0
tensor(14.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=2.73............. Loss: 0.04844963, mean(E): -21.36938895-0.01677270j, var(E): 2.04857891
0.0
tensor(14.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=2.72............. Loss: -0.17244858, mean(E): -21.36434885-0.00436047j, var(E): 2.05015239
0.0
tensor(14.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=2.71............. Loss: -0.09029438, mean(E): -21.41052001+0.01563884j, var(E): 2.21303813
0.0
tensor(14.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=2.72............. Loss: 0.00042038, mean(E): -21.39985466-0.00056976j, var(E): 1.64081120
0.0
tensor(14.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=2.72............. Loss: 0.12727583, mean(E): -21.41968268-0.00020863j, var(E): 2.20845513
0.0
tensor(14.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=2.71............. Loss: -0.18210438, mean(E): -21.39414102-0.01696181j, var(E): 2.16108301
0.0
tensor(14.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=2.73............. Loss: 0.07705328, mean(E): -21.41632689-0.00358207j, var(E): 1.72139459
0.0
tensor(14.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=2.71............. Loss: 0.09363106, mean(E): -21.47085193+0.00728933j, var(E): 2.04730383
0.0
tensor(14.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=2.72............. Loss: -0.08052197, mean(E): -21.43661114-0.02796664j, var(E): 2.07310242
0.0
tensor(14.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=2.72............. Loss: -0.17795431, mean(E): -21.47317228-0.00161894j, var(E): 2.10433237
0.0
tensor(14.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=2.72............. Loss: 0.01827751, mean(E): -21.45867212+0.01478443j, var(E): 1.81974480
0.0
tensor(14.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=2.72............. Loss: -0.24603029, mean(E): -21.46924049-0.00290838j, var(E): 1.68488398
0.0
tensor(14.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=2.71............. Loss: -0.21867593, mean(E): -21.49225294-0.00146968j, var(E): 1.28859889
0.0
tensor(14.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=2.72............. Loss: 0.06070292, mean(E): -21.46289376+0.02153971j, var(E): 1.80951673
0.0
tensor(14.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=2.72............. Loss: 0.18157787, mean(E): -21.48679792+0.00583582j, var(E): 2.16015447
0.0
tensor(14.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=2.7............. Loss: -0.21811359, mean(E): -21.45173772+0.01037666j, var(E): 1.71948140
0.0
tensor(14.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=2.71............. Loss: -0.39116985, mean(E): -21.42716232-0.00611698j, var(E): 1.66827035
0.0
tensor(14.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=2.71............. Loss: -0.11801943, mean(E): -21.47401205+0.00425294j, var(E): 1.58775139
0.0
tensor(14.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=2.71............. Loss: -0.13986882, mean(E): -21.49659934+0.00168378j, var(E): 1.57520885
0.0
tensor(14.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=2.72............. Loss: -0.27173311, mean(E): -21.48979144+0.00873987j, var(E): 1.35670499
0.0
tensor(14.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=2.71............. Loss: 0.33403691, mean(E): -21.58005388+0.01641994j, var(E): 2.11922420
0.0
tensor(14.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(14.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=2.72............. Loss: 0.33035771, mean(E): -21.58395378-0.00861096j, var(E): 1.86922134
0.0
tensor(15.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=2.72............. Loss: 0.02984089, mean(E): -21.51649550-0.01194402j, var(E): 1.74097552
0.0
tensor(15.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=2.72............. Loss: -0.09111786, mean(E): -21.53664506+0.02233202j, var(E): 1.53587738
0.0
tensor(15.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=2.73............. Loss: -0.25384702, mean(E): -21.44173802+0.01853915j, var(E): 1.45079530
0.0
tensor(15.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=2.72............. Loss: 0.11206669, mean(E): -21.55503940-0.00422874j, var(E): 1.58294566
0.0
tensor(15.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=2.72............. Loss: -0.00799572, mean(E): -21.54625688-0.00735922j, var(E): 1.55648151
0.0
tensor(15.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=2.71............. Loss: 0.11499626, mean(E): -21.53471774+0.00671506j, var(E): 1.88018096
0.0
tensor(15.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=2.71............. Loss: 0.27301736, mean(E): -21.56598508+0.01134647j, var(E): 1.47494985
0.0
tensor(15.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=2.72............. Loss: 0.35043911, mean(E): -21.55699332-0.01057322j, var(E): 1.72980646
0.0
tensor(15.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=2.72............. Loss: -0.19333380, mean(E): -21.55265666-0.01720964j, var(E): 1.28449649
0.0
tensor(15.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=2.72............. Loss: -0.24779288, mean(E): -21.51376613-0.00221572j, var(E): 1.66406604
0.0
tensor(15.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=2.72............. Loss: 0.19165768, mean(E): -21.61758012+0.00157244j, var(E): 1.20060255
0.0
tensor(15.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=2.73............. Loss: -0.09800806, mean(E): -21.55927443+0.00411284j, var(E): 1.45483576
0.0
tensor(15.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=2.71............. Loss: -0.49825716, mean(E): -21.44087693-0.01101420j, var(E): 1.07608072
0.0
tensor(15.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=2.73............. Loss: 0.02968663, mean(E): -21.59952171-0.00007430j, var(E): 1.29180925
0.0
tensor(15.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=2.72............. Loss: -0.13934435, mean(E): -21.54968912-0.01366375j, var(E): 0.93391729
0.0
tensor(15.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=2.71............. Loss: -0.28950453, mean(E): -21.56282227+0.00756547j, var(E): 1.15916540
0.0
tensor(15.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=2.72............. Loss: 0.25173508, mean(E): -21.59378200+0.00102130j, var(E): 1.14715456
0.0
tensor(15.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=2.71............. Loss: -0.01088202, mean(E): -21.57570925+0.00151030j, var(E): 1.43156726
0.0
tensor(15.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=2.71............. Loss: -0.06182427, mean(E): -21.60870342-0.01782414j, var(E): 1.62784286
0.0
tensor(15.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=2.71............. Loss: -0.06908003, mean(E): -21.58234123+0.00933625j, var(E): 1.88820193
0.0
tensor(15.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=2.71............. Loss: 0.04537825, mean(E): -21.55518015+0.00387343j, var(E): 0.87096269
0.0
tensor(15.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=2.72............. Loss: -0.13798234, mean(E): -21.55523652-0.02178222j, var(E): 1.46418705
0.0
tensor(15.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=2.71............. Loss: -0.05897556, mean(E): -21.57032722+0.01099435j, var(E): 1.18923696
0.0
tensor(15.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=2.72............. Loss: -0.17399207, mean(E): -21.57171887+0.00804207j, var(E): 0.99116017
0.0
tensor(15.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=2.72............. Loss: 0.05449968, mean(E): -21.64105463+0.00531258j, var(E): 1.24066810
0.0
tensor(15.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=2.72............. Loss: -0.17031536, mean(E): -21.56478902-0.00884711j, var(E): 1.07026740
0.0
tensor(15.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=2.73............. Loss: 0.05340002, mean(E): -21.62969742+0.00018810j, var(E): 1.35347768
0.0
tensor(15.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=2.71............. Loss: -0.02403956, mean(E): -21.59280758-0.00193795j, var(E): 1.07691207
0.0
tensor(15.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=2.73............. Loss: 0.12286436, mean(E): -21.58078352+0.00904462j, var(E): 1.39648747
0.0
tensor(15.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=2.73............. Loss: -0.15371368, mean(E): -21.59840405-0.01260750j, var(E): 1.39414740
0.0
tensor(15.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=2.71............. Loss: -0.18407101, mean(E): -21.59631238+0.00592568j, var(E): 1.17272694
0.0
tensor(15.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=2.73............. Loss: -0.12153754, mean(E): -21.57236880+0.01274434j, var(E): 1.13976339
0.0
tensor(15.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=2.73............. Loss: -0.05140948, mean(E): -21.61335718+0.01537137j, var(E): 1.19654903
0.0
tensor(15.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=2.73............. Loss: -0.05169521, mean(E): -21.59585531-0.01038128j, var(E): 1.34185150
0.0
tensor(15.8618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=2.71............. Loss: -0.10356848, mean(E): -21.62131886+0.00435492j, var(E): 1.05245158
0.0
tensor(15.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=2.73............. Loss: -0.00345931, mean(E): -21.59170040+0.00035812j, var(E): 1.02900575
0.0
tensor(15.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=2.72............. Loss: -0.11432688, mean(E): -21.60205766+0.00079502j, var(E): 1.11742762
0.0
tensor(15.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=2.72............. Loss: 0.09578704, mean(E): -21.66946032-0.01146955j, var(E): 0.99071607
0.0
tensor(15.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=2.71............. Loss: 0.32429486, mean(E): -21.65719297+0.00664499j, var(E): 1.57571215
0.0
tensor(15.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(15.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(16.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=2.72............. Loss: -0.02551085, mean(E): -21.60888232+0.00252138j, var(E): 1.44028189
-0.0
tensor(16.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=2.72............. Loss: -0.37098344, mean(E): -21.57689784+0.00381369j, var(E): 1.11170724
-0.0
tensor(16.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=2.72............. Loss: 0.02736012, mean(E): -21.60594758+0.00057090j, var(E): 1.04394548
-0.0
tensor(16.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=2.72............. Loss: -0.11255743, mean(E): -21.60598341+0.00265428j, var(E): 1.10787084
-0.0
tensor(16.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=2.71............. Loss: 0.08272517, mean(E): -21.63908708-0.00851158j, var(E): 1.55278914
-0.0
tensor(16.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=2.71............. Loss: -0.05157542, mean(E): -21.64891525+0.01003345j, var(E): 0.85322199
-0.0
tensor(16.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=2.72............. Loss: 0.34199549, mean(E): -21.64794111+0.00262410j, var(E): 1.23194680
-0.0
tensor(16.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=2.71............. Loss: 0.00867623, mean(E): -21.65912289+0.00340936j, var(E): 1.02592318
-0.0
tensor(16.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=2.71............. Loss: 0.04553954, mean(E): -21.62872455+0.00656595j, var(E): 1.71437363
-0.0
tensor(16.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=2.72............. Loss: 0.12831886, mean(E): -21.66842221-0.00273798j, var(E): 1.25802556
-0.0
tensor(16.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=2.71............. Loss: 0.05166143, mean(E): -21.61122700+0.01730559j, var(E): 1.03509168
-0.0
tensor(16.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=2.72............. Loss: -0.18972601, mean(E): -21.59407376+0.00152951j, var(E): 0.99224474
-0.0
tensor(16.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=2.73............. Loss: 0.20442531, mean(E): -21.65892759+0.00446461j, var(E): 1.01600608
-0.0
tensor(16.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=2.72............. Loss: -0.12524294, mean(E): -21.61995060+0.00258997j, var(E): 0.76403367
-0.0
tensor(16.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=2.72............. Loss: 0.02671691, mean(E): -21.60919997-0.00047772j, var(E): 1.13007569
-0.0
tensor(16.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=2.72............. Loss: -0.02154545, mean(E): -21.65784166-0.00094497j, var(E): 0.91890027
-0.0
tensor(16.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=2.72............. Loss: 0.23125870, mean(E): -21.66172328-0.00744421j, var(E): 1.05624294
-0.0
tensor(16.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=2.72............. Loss: 0.06617833, mean(E): -21.67965741+0.00460045j, var(E): 1.13989539
-0.0
tensor(16.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=2.71............. Loss: 0.08618153, mean(E): -21.68176011-0.00532285j, var(E): 0.85934468
-0.0
tensor(16.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=2.71............. Loss: -0.14941873, mean(E): -21.61946292-0.01771245j, var(E): 0.60990236
-0.0
tensor(16.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=2.72............. Loss: 0.02628823, mean(E): -21.66849823+0.00821922j, var(E): 1.00581189
-0.0
tensor(16.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=2.72............. Loss: -0.13963499, mean(E): -21.59518025+0.01204253j, var(E): 0.94846406
-0.0
tensor(16.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=2.73............. Loss: 0.00151970, mean(E): -21.63665935+0.00166060j, var(E): 0.76221142
-0.0
tensor(16.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=2.71............. Loss: -0.11922653, mean(E): -21.64520446+0.00149562j, var(E): 0.95596757
-0.0
tensor(16.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=2.72............. Loss: -0.06699414, mean(E): -21.63551974+0.00112504j, var(E): 0.97150843
-0.0
tensor(16.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=2.72............. Loss: 0.22466142, mean(E): -21.62262253+0.00372745j, var(E): 1.05402182
-0.0
tensor(16.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=2.71............. Loss: 0.06491051, mean(E): -21.65267889+0.00081050j, var(E): 1.08975219
-0.0
tensor(16.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=2.73............. Loss: -0.04402492, mean(E): -21.67109442+0.00021246j, var(E): 1.03231545
-0.0
tensor(16.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=2.72............. Loss: -0.32896473, mean(E): -21.60000204-0.00738179j, var(E): 0.93395502
-0.0
tensor(16.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=2.72............. Loss: -0.02870238, mean(E): -21.64625827+0.00867698j, var(E): 0.86126642
-0.0
tensor(16.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=2.72............. Loss: -0.17589506, mean(E): -21.63253463+0.00553665j, var(E): 0.82820980
-0.0
tensor(16.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=2.72............. Loss: -0.11754337, mean(E): -21.64413405-0.01059336j, var(E): 0.92615672
-0.0
tensor(16.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=2.71............. Loss: 0.06917709, mean(E): -21.66323681+0.00642228j, var(E): 0.68386972
-0.0
tensor(16.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=2.71............. Loss: -0.00806221, mean(E): -21.66294102+0.00438547j, var(E): 0.97407070
-0.0
tensor(16.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=2.72............. Loss: -0.31416563, mean(E): -21.60980682-0.00439709j, var(E): 0.98035971
-0.0
tensor(16.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=2.71............. Loss: -0.07766269, mean(E): -21.66023143-0.00214170j, var(E): 0.94629902
-0.0
tensor(16.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=2.73............. Loss: -0.30949491, mean(E): -21.60794282+0.00385937j, var(E): 0.75598701
-0.0
tensor(16.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=2.72............. Loss: 0.04207472, mean(E): -21.68020597-0.01059470j, var(E): 0.83077367
-0.0
tensor(16.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.7995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=2.73............. Loss: -0.01341225, mean(E): -21.65014804+0.02064542j, var(E): 1.20789442
-0.0
tensor(16.8037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=2.71............. Loss: 0.17946581, mean(E): -21.72169921-0.00467360j, var(E): 1.00630712
-0.0
tensor(16.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=2.73............. Loss: -0.17106950, mean(E): -21.65004424-0.00137094j, var(E): 0.91251595
-0.0
tensor(16.8459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=2.73............. Loss: 0.11741088, mean(E): -21.71112042-0.00620998j, var(E): 1.23589883
-0.0
tensor(16.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=2.71............. Loss: 0.00152167, mean(E): -21.69288877-0.00013456j, var(E): 0.81389295
-0.0
tensor(16.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=2.72............. Loss: -0.00052413, mean(E): -21.69949078-0.00077667j, var(E): 0.85538743
-0.0
tensor(16.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=2.73............. Loss: 0.31877800, mean(E): -21.72744507+0.00623043j, var(E): 1.15156429
-0.0
tensor(16.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=2.73............. Loss: -0.17913519, mean(E): -21.64442005+0.00657363j, var(E): 0.72342861
-0.0
tensor(16.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=2.72............. Loss: -0.27332018, mean(E): -21.62974243+0.00415796j, var(E): 0.82346956
-0.0
tensor(16.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=2.73............. Loss: 0.02696861, mean(E): -21.67956522+0.01560717j, var(E): 0.94316944
-0.0
tensor(16.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(16.9998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=2.72............. Loss: -0.03055445, mean(E): -21.67907729+0.00705380j, var(E): 0.72907828
-0.0
tensor(17.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=2.72............. Loss: -0.04280385, mean(E): -21.64282642-0.00022890j, var(E): 0.98635624
-0.0
tensor(17.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=2.73............. Loss: 0.32587020, mean(E): -21.67440290-0.00219458j, var(E): 0.98832992
-0.0
tensor(17.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=2.73............. Loss: -0.16302999, mean(E): -21.68553610-0.00428022j, var(E): 0.76242527
-0.0
tensor(17.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=2.73............. Loss: -0.30442594, mean(E): -21.66287451+0.00209199j, var(E): 0.84650772
-0.0
tensor(17.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=2.73............. Loss: -0.12741702, mean(E): -21.67639761+0.00612922j, var(E): 0.96286438
-0.0
tensor(17.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=2.73............. Loss: -0.05247679, mean(E): -21.69396041-0.00258502j, var(E): 0.71127450
-0.0
tensor(17.1082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=2.72............. Loss: -0.14791309, mean(E): -21.63984716+0.00158160j, var(E): 1.08781691
-0.0
tensor(17.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=2.73............. Loss: 0.15038283, mean(E): -21.70652709+0.00006961j, var(E): 0.70568353
-0.0
tensor(17.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=2.72............. Loss: 0.06291616, mean(E): -21.69935286-0.00056721j, var(E): 0.93474494
-0.0
tensor(17.1512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=2.71............. Loss: 0.02833159, mean(E): -21.69801194+0.00332245j, var(E): 0.72863998
-0.0
tensor(17.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=2.71............. Loss: 0.08888373, mean(E): -21.66594907-0.00044328j, var(E): 1.33640961
-0.0
tensor(17.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=2.71............. Loss: -0.12236190, mean(E): -21.65862517-0.00577713j, var(E): 0.78428047
-0.0
tensor(17.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=2.71............. Loss: -0.11366185, mean(E): -21.67810020-0.00260932j, var(E): 0.71881101
-0.0
tensor(17.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=2.71............. Loss: -0.04248348, mean(E): -21.69314556+0.00678877j, var(E): 0.83090914
-0.0
tensor(17.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=2.73............. Loss: 0.04162835, mean(E): -21.71159890-0.00069529j, var(E): 0.46961489
-0.0
tensor(17.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=2.73............. Loss: -0.06207001, mean(E): -21.69294173-0.00399317j, var(E): 0.95236944
-0.0
tensor(17.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=2.73............. Loss: 0.03893037, mean(E): -21.67716298-0.00091934j, var(E): 0.85994772
-0.0
tensor(17.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=2.72............. Loss: 0.04247894, mean(E): -21.71467645+0.00404331j, var(E): 0.73449989
-0.0
tensor(17.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=2.73............. Loss: -0.03071289, mean(E): -21.69208892+0.00568018j, var(E): 0.81976007
-0.0
tensor(17.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=2.73............. Loss: -0.18998293, mean(E): -21.69673544-0.00260242j, var(E): 0.82274782
-0.0
tensor(17.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=2.73............. Loss: -0.05516778, mean(E): -21.69257406-0.00266000j, var(E): 0.73687539
-0.0
tensor(17.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=2.71............. Loss: -0.04180634, mean(E): -21.71104106-0.00189861j, var(E): 0.82790731
-0.0
tensor(17.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=2.73............. Loss: 0.11342099, mean(E): -21.70535649-0.01064896j, var(E): 0.82558395
-0.0
tensor(17.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=2.71............. Loss: 0.06086608, mean(E): -21.69752280+0.00117935j, var(E): 0.97175457
-0.0
tensor(17.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=2.73............. Loss: 0.07336096, mean(E): -21.70004206-0.00575530j, var(E): 0.56810870
-0.0
tensor(17.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=2.73............. Loss: 0.29709977, mean(E): -21.72346108+0.00135351j, var(E): 1.22181318
-0.0
tensor(17.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=2.72............. Loss: -0.09687516, mean(E): -21.65738449-0.00620440j, var(E): 0.55988951
-0.0
tensor(17.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=2.73............. Loss: -0.10412893, mean(E): -21.67863563+0.00278683j, var(E): 0.68119563
-0.0
tensor(17.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=2.73............. Loss: -0.03262099, mean(E): -21.69286306-0.00305865j, var(E): 0.48254313
-0.0
tensor(17.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=2.72............. Loss: 0.11359137, mean(E): -21.74759327-0.00062180j, var(E): 1.02165778
-0.0
tensor(17.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=2.72............. Loss: -0.01721463, mean(E): -21.69198155+0.00223088j, var(E): 0.54093730
-0.0
tensor(17.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=2.73............. Loss: 0.00586054, mean(E): -21.70549847-0.00523223j, var(E): 0.86297213
-0.0
tensor(17.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=2.73............. Loss: -0.16380708, mean(E): -21.67932766-0.00581312j, var(E): 0.71007518
-0.0
tensor(17.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=2.71............. Loss: 0.01776643, mean(E): -21.63754486+0.01011935j, var(E): 1.07761700
-0.0
tensor(17.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=2.72............. Loss: -0.13218222, mean(E): -21.67885854+0.01108415j, var(E): 0.64780567
-0.0
tensor(17.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=2.72............. Loss: -0.05707474, mean(E): -21.70662698-0.00293452j, var(E): 0.82069075
-0.0
tensor(17.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=2.72............. Loss: -0.00128176, mean(E): -21.70631694-0.00721327j, var(E): 0.66207207
-0.0
tensor(17.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=2.72............. Loss: -0.12945095, mean(E): -21.69057592+0.00124324j, var(E): 0.64716489
-0.0
tensor(17.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=2.72............. Loss: 0.11988689, mean(E): -21.70563208-0.00087272j, var(E): 0.70114026
-0.0
tensor(17.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=2.73............. Loss: 0.31417762, mean(E): -21.74172087-0.00061865j, var(E): 1.13436815
-0.0
tensor(17.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=2.73............. Loss: -0.42560911, mean(E): -21.63253087+0.00343994j, var(E): 0.71792607
-0.0
tensor(17.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=2.73............. Loss: -0.10333084, mean(E): -21.71166254+0.00343939j, var(E): 0.62809379
-0.0
tensor(17.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=2.73............. Loss: -0.03992859, mean(E): -21.70497547-0.00806589j, var(E): 0.76228064
-0.0
tensor(17.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=2.73............. Loss: -0.06319519, mean(E): -21.70407678+0.00044185j, var(E): 0.83694125
-0.0
tensor(17.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=2.72............. Loss: 0.03423290, mean(E): -21.69783348+0.00969959j, var(E): 0.59609359
-0.0
tensor(17.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=2.73............. Loss: -0.03734700, mean(E): -21.69293586-0.00084968j, var(E): 0.63565546
-0.0
tensor(17.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=2.73............. Loss: 0.05685758, mean(E): -21.70266628-0.00073214j, var(E): 0.67515485
-0.0
tensor(17.7864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=2.73............. Loss: -0.17616732, mean(E): -21.67807662+0.00256701j, var(E): 0.49425358
-0.0
tensor(17.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=2.71............. Loss: -0.07084641, mean(E): -21.70531627+0.00199431j, var(E): 0.49474699
-0.0
tensor(17.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=2.73............. Loss: -0.22335680, mean(E): -21.69592743-0.00289042j, var(E): 0.85302453
-0.0
tensor(17.8446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=2.73............. Loss: 0.16147651, mean(E): -21.74012774-0.00201646j, var(E): 0.93325594
-0.0
tensor(17.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=2.73............. Loss: -0.30866104, mean(E): -21.67074293-0.00363321j, var(E): 0.84359951
-0.0
tensor(17.8692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=2.73............. Loss: 0.08948627, mean(E): -21.73523136-0.00662245j, var(E): 0.75401919
-0.0
tensor(17.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=2.72............. Loss: 0.00669881, mean(E): -21.71945805+0.01531522j, var(E): 0.61229105
-0.0
tensor(17.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=2.73............. Loss: 0.21435296, mean(E): -21.74922859+0.00235310j, var(E): 1.03128258
-0.0
tensor(17.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=2.72............. Loss: 0.02884469, mean(E): -21.73029554-0.00317486j, var(E): 0.65587802
-0.0
tensor(17.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=2.72............. Loss: 0.03671193, mean(E): -21.72764536-0.00644129j, var(E): 0.54688286
-0.0
tensor(17.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=2.73............. Loss: 0.05382658, mean(E): -21.73312209-0.00762495j, var(E): 0.57777709
-0.0
tensor(17.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=2.73............. Loss: -0.15061846, mean(E): -21.69226886+0.00187725j, var(E): 0.85296448
-0.0
tensor(17.9378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=2.72............. Loss: -0.28843871, mean(E): -21.68010379-0.00035724j, var(E): 0.68775084
-0.0
tensor(17.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=2.72............. Loss: 0.03803931, mean(E): -21.72042965-0.00283500j, var(E): 0.66446560
-0.0
tensor(17.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=2.71............. Loss: 0.55769531, mean(E): -21.76217373+0.00157075j, var(E): 1.48992912
-0.0
tensor(17.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=2.71............. Loss: 0.02809815, mean(E): -21.71862935-0.00848721j, var(E): 0.53500518
-0.0
tensor(17.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(17.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=2.72............. Loss: 0.01564817, mean(E): -21.72345228+0.00089459j, var(E): 0.65886773
-0.0
tensor(18.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=2.73............. Loss: -0.02973487, mean(E): -21.70834169-0.00502519j, var(E): 0.69826173
-0.0
tensor(18.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=2.73............. Loss: -0.24236283, mean(E): -21.65311492-0.00490334j, var(E): 0.56166297
-0.0
tensor(18.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=2.73............. Loss: -0.28479017, mean(E): -21.67637449+0.00450780j, var(E): 0.67774432
-0.0
tensor(18.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=2.72............. Loss: 0.08613748, mean(E): -21.72573327-0.00088241j, var(E): 0.49146124
-0.0
tensor(18.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=2.73............. Loss: -0.06914235, mean(E): -21.68606618-0.00447508j, var(E): 0.63670876
-0.0
tensor(18.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=2.72............. Loss: 0.12090912, mean(E): -21.74162778-0.00066813j, var(E): 0.80275693
-0.0
tensor(18.1107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=2.73............. Loss: 0.49252136, mean(E): -21.77893051-0.00934504j, var(E): 1.13777738
-0.0
tensor(18.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=2.72............. Loss: -0.22533420, mean(E): -21.68336518+0.00199439j, var(E): 0.67683009
-0.0
tensor(18.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=2.73............. Loss: 0.04283466, mean(E): -21.71258949+0.00487060j, var(E): 0.81049431
-0.0
tensor(18.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=2.73............. Loss: -0.18151736, mean(E): -21.69204057-0.00425718j, var(E): 0.67977676
-0.0
tensor(18.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=2.72............. Loss: -0.21250625, mean(E): -21.67617081+0.00411045j, var(E): 0.87850268
-0.0
tensor(18.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=2.72............. Loss: -0.16618994, mean(E): -21.71111215-0.01053439j, var(E): 0.80079219
-0.0
tensor(18.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=2.72............. Loss: 0.18492378, mean(E): -21.73666516-0.00644567j, var(E): 0.54946429
-0.0
tensor(18.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=2.73............. Loss: 0.00021783, mean(E): -21.71807693+0.00633842j, var(E): 0.71056462
-0.0
tensor(18.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=2.73............. Loss: 0.09948052, mean(E): -21.74463674+0.00949186j, var(E): 0.75096391
-0.0
tensor(18.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=2.73............. Loss: -0.12575852, mean(E): -21.69856651+0.00602128j, var(E): 0.47741839
-0.0
tensor(18.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=2.72............. Loss: -0.19766995, mean(E): -21.69226176-0.00543025j, var(E): 0.75852939
-0.0
tensor(18.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=2.73............. Loss: -0.31323351, mean(E): -21.66506049+0.00530786j, var(E): 0.86839294
-0.0
tensor(18.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=2.71............. Loss: 0.02112532, mean(E): -21.71859112+0.00764438j, var(E): 0.85636280
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=2.72............. Loss: -0.10177619, mean(E): -21.70447404+0.00133387j, var(E): 0.65647460
-0.0
tensor(18.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=2.73............. Loss: 0.13573252, mean(E): -21.73705354+0.00438925j, var(E): 0.72981447
-0.0
tensor(18.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=2.71............. Loss: -0.11381494, mean(E): -21.70581604+0.00060785j, var(E): 0.70063823
-0.0
tensor(18.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=2.72............. Loss: 0.05102580, mean(E): -21.73516414+0.00870628j, var(E): 0.63037780
-0.0
tensor(18.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=2.72............. Loss: 0.10363242, mean(E): -21.73509552-0.01149569j, var(E): 0.40677811
-0.0
tensor(18.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=2.72............. Loss: 0.00078858, mean(E): -21.68803023+0.00589439j, var(E): 0.66871385
-0.0
tensor(18.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=2.72............. Loss: -0.41767901, mean(E): -21.67804098-0.00171889j, var(E): 0.78012285
-0.0
tensor(18.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=2.73............. Loss: 0.04912850, mean(E): -21.74106436-0.00327015j, var(E): 0.83662894
-0.0
tensor(18.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=2.72............. Loss: 0.07255681, mean(E): -21.74387263-0.00472912j, var(E): 0.79043767
-0.0
tensor(18.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=2.71............. Loss: 0.11096326, mean(E): -21.73046627+0.00253075j, var(E): 0.89670774
-0.0
tensor(18.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=2.72............. Loss: 0.04187105, mean(E): -21.72514517+0.00158700j, var(E): 0.68140627
-0.0
tensor(18.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=2.72............. Loss: 0.07076102, mean(E): -21.73622990-0.00537180j, var(E): 0.71466691
-0.0
tensor(18.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=2.72............. Loss: 0.03550373, mean(E): -21.73467658-0.00070504j, var(E): 0.69120469
-0.0
tensor(18.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=2.73............. Loss: 0.03916000, mean(E): -21.70097445+0.00115880j, var(E): 1.16783419
-0.0
tensor(18.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=2.72............. Loss: 0.01996925, mean(E): -21.73083134-0.00974060j, var(E): 0.46729250
-0.0
tensor(18.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=2.73............. Loss: -0.13974284, mean(E): -21.69420457+0.00324644j, var(E): 0.73450694
-0.0
tensor(18.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=2.73............. Loss: 0.14512298, mean(E): -21.74690113-0.00117896j, var(E): 0.49154579
-0.0
tensor(18.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=2.73............. Loss: -0.25196738, mean(E): -21.70062234-0.00128619j, var(E): 0.49552282
-0.0
tensor(18.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=2.72............. Loss: -0.07043054, mean(E): -21.71879068+0.00189360j, var(E): 0.67817351
-0.0
tensor(18.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=2.73............. Loss: -0.10388867, mean(E): -21.69860769-0.00578673j, var(E): 0.83035381
-0.0
tensor(18.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=2.72............. Loss: 0.05064384, mean(E): -21.74716410+0.00909802j, var(E): 0.66574436
-0.0
tensor(18.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=2.73............. Loss: -0.07381263, mean(E): -21.72860533-0.00100761j, var(E): 0.47306219
-0.0
tensor(18.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=2.73............. Loss: 0.04795711, mean(E): -21.73505978+0.00339227j, var(E): 0.68843461
-0.0
tensor(18.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=2.72............. Loss: 0.04095461, mean(E): -21.74390887+0.00680756j, var(E): 0.84175556
-0.0
tensor(18.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=2.73............. Loss: 0.19787677, mean(E): -21.77106704+0.00072148j, var(E): 0.61089800
-0.0
tensor(18.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=2.73............. Loss: 0.03670430, mean(E): -21.73933718-0.00293445j, var(E): 0.49585082
-0.0
tensor(18.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=2.72............. Loss: -0.11113269, mean(E): -21.73978806+0.00049241j, var(E): 0.35260913
-0.0
tensor(18.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=2.73............. Loss: -0.01560651, mean(E): -21.71264797-0.00070951j, var(E): 0.64306786
-0.0
tensor(18.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=2.71............. Loss: 0.28598374, mean(E): -21.78415250+0.00885068j, var(E): 0.74985737
-0.0
tensor(18.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=2.72............. Loss: -0.09859506, mean(E): -21.71225712+0.01174604j, var(E): 0.55586574
-0.0
tensor(18.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=2.73............. Loss: 0.04364119, mean(E): -21.75335254+0.00226623j, var(E): 0.47267551
-0.0
tensor(18.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=2.72............. Loss: 0.09469215, mean(E): -21.76289601+0.00352577j, var(E): 0.53176993
-0.0
tensor(18.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=2.72............. Loss: 0.12170336, mean(E): -21.73463127+0.00475869j, var(E): 0.61830751
-0.0
tensor(18.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=2.73............. Loss: -0.26587607, mean(E): -21.70474424+0.00463442j, var(E): 0.53281123
-0.0
tensor(18.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=2.73............. Loss: -0.08704625, mean(E): -21.71495324-0.00622968j, var(E): 0.46653159
-0.0
tensor(18.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=2.72............. Loss: -0.21366932, mean(E): -21.71433534-0.00035358j, var(E): 0.52157730
-0.0
tensor(18.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=2.73............. Loss: 0.09466915, mean(E): -21.73251242-0.00700864j, var(E): 0.90438607
-0.0
tensor(18.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=2.73............. Loss: -0.05901724, mean(E): -21.70316538+0.00202095j, var(E): 0.71538510
-0.0
tensor(18.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=2.72............. Loss: 0.21758492, mean(E): -21.76222500+0.00215418j, var(E): 0.54299416
-0.0
tensor(18.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=2.73............. Loss: -0.10523387, mean(E): -21.72394606-0.00199201j, var(E): 0.47127061
-0.0
tensor(18.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=2.72............. Loss: -0.18946159, mean(E): -21.73278823+0.00434079j, var(E): 0.48675332
-0.0
tensor(18.8273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=2.73............. Loss: 0.07967979, mean(E): -21.73789279+0.00147290j, var(E): 0.61357984
-0.0
tensor(18.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=2.71............. Loss: -0.43830804, mean(E): -21.68171192-0.00240641j, var(E): 0.54758461
-0.0
tensor(18.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=2.72............. Loss: -0.16639280, mean(E): -21.71003823+0.00148349j, var(E): 0.53924875
-0.0
tensor(18.8578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=2.73............. Loss: 0.03311950, mean(E): -21.74861183+0.00060331j, var(E): 0.88370497
-0.0
tensor(18.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=2.73............. Loss: 0.01141257, mean(E): -21.72219222+0.00343849j, var(E): 0.44993574
-0.0
tensor(18.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=2.73............. Loss: 0.05995415, mean(E): -21.74321661+0.00240683j, var(E): 0.76565742
-0.0
tensor(18.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=2.73............. Loss: -0.06933623, mean(E): -21.72559352+0.00007661j, var(E): 0.55026426
-0.0
tensor(18.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=2.73............. Loss: 0.21572789, mean(E): -21.76201485-0.00185371j, var(E): 0.38341738
-0.0
tensor(18.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=2.73............. Loss: -0.10708124, mean(E): -21.70644141-0.00066286j, var(E): 0.69633338
-0.0
tensor(18.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=2.73............. Loss: 0.00159467, mean(E): -21.73360659+0.00010610j, var(E): 0.34649031
-0.0
tensor(18.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=2.73............. Loss: 0.16267486, mean(E): -21.75411686-0.00939826j, var(E): 0.85660715
-0.0
tensor(18.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=2.73............. Loss: -0.04052928, mean(E): -21.75098588-0.00353013j, var(E): 0.81302394
-0.0
tensor(18.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=2.72............. Loss: -0.29404419, mean(E): -21.73751761-0.00179521j, var(E): 0.70967913
-0.0
tensor(18.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=2.72............. Loss: -0.23539190, mean(E): -21.71622102-0.00030443j, var(E): 0.68054545
-0.0
tensor(18.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=2.72............. Loss: -0.12123905, mean(E): -21.72382921+0.00903718j, var(E): 0.45691526
-0.0
tensor(18.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(18.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=2.72............. Loss: -0.11554335, mean(E): -21.72078785-0.00279969j, var(E): 0.69055113
-0.0
tensor(19.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=2.73............. Loss: 0.03160249, mean(E): -21.71776550+0.00101806j, var(E): 0.81744834
-0.0
tensor(19.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=2.72............. Loss: -0.20448033, mean(E): -21.70118339+0.00264485j, var(E): 0.34813814
-0.0
tensor(19.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=2.73............. Loss: -0.14496338, mean(E): -21.72084999+0.00355246j, var(E): 0.55395672
-0.0
tensor(19.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=2.72............. Loss: -0.11694282, mean(E): -21.70000349+0.00699016j, var(E): 0.67126362
-0.0
tensor(19.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=2.71............. Loss: -0.06187443, mean(E): -21.72856173+0.00583930j, var(E): 0.60601008
-0.0
tensor(19.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=2.72............. Loss: -0.00604935, mean(E): -21.72902569+0.00229093j, var(E): 0.60861946
-0.0
tensor(19.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.0998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=2.71............. Loss: 0.08715947, mean(E): -21.75728847-0.00559927j, var(E): 0.38991766
-0.0
tensor(19.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=2.71............. Loss: -0.01497593, mean(E): -21.74399517+0.00246624j, var(E): 0.69571038
-0.0
tensor(19.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=2.72............. Loss: -0.03601243, mean(E): -21.73657788+0.00515297j, var(E): 0.46781896
-0.0
tensor(19.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=2.72............. Loss: -0.07665170, mean(E): -21.72706397-0.00311860j, var(E): 0.49310505
-0.0
tensor(19.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=2.72............. Loss: 0.11431855, mean(E): -21.75173938-0.00270830j, var(E): 0.57380537
-0.0
tensor(19.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=2.71............. Loss: -0.20127935, mean(E): -21.73130682-0.00098449j, var(E): 0.53155037
-0.0
tensor(19.1325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=2.72............. Loss: 0.09387389, mean(E): -21.72756731-0.00912243j, var(E): 0.83396316
-0.0
tensor(19.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=2.72............. Loss: -0.35350075, mean(E): -21.70966797+0.00305698j, var(E): 0.63108564
-0.0
tensor(19.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=2.72............. Loss: 0.17954936, mean(E): -21.75046510+0.00042214j, var(E): 0.90680317
-0.0
tensor(19.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=2.72............. Loss: 0.08777468, mean(E): -21.75256726-0.00425206j, var(E): 0.90490568
-0.0
tensor(19.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=2.73............. Loss: -0.21679838, mean(E): -21.73729032+0.00139422j, var(E): 0.68625571
-0.0
tensor(19.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=2.72............. Loss: 0.05968543, mean(E): -21.74596818+0.00833660j, var(E): 0.57728154
-0.0
tensor(19.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=2.71............. Loss: -0.10669162, mean(E): -21.70862283+0.00299753j, var(E): 0.36820886
-0.0
tensor(19.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=2.71............. Loss: 0.04479921, mean(E): -21.75803424-0.00086789j, var(E): 0.43262421
-0.0
tensor(19.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=2.73............. Loss: 0.11393291, mean(E): -21.77820292+0.01040849j, var(E): 0.66852013
-0.0
tensor(19.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=2.72............. Loss: -0.03448683, mean(E): -21.75523199+0.00886653j, var(E): 0.62330775
-0.0
tensor(19.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=2.72............. Loss: -0.13560828, mean(E): -21.73596607-0.00344166j, var(E): 0.39408508
-0.0
tensor(19.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=2.72............. Loss: 0.25327092, mean(E): -21.78595101+0.00451666j, var(E): 0.52552311
-0.0
tensor(19.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=2.71............. Loss: -0.10658553, mean(E): -21.71392302-0.00234214j, var(E): 0.50814984
-0.0
tensor(19.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=2.72............. Loss: -0.22942244, mean(E): -21.70306194-0.00272115j, var(E): 0.84802444
-0.0
tensor(19.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=2.71............. Loss: -0.21177279, mean(E): -21.72195910-0.00058392j, var(E): 0.40867704
-0.0
tensor(19.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=2.71............. Loss: -0.17701244, mean(E): -21.72263398-0.00245069j, var(E): 0.48746326
-0.0
tensor(19.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=2.71............. Loss: 0.16571844, mean(E): -21.76975917-0.00215766j, var(E): 0.51269845
-0.0
tensor(19.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=2.73............. Loss: 0.18419968, mean(E): -21.77635749+0.00239097j, var(E): 0.76039568
-0.0
tensor(19.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=2.73............. Loss: -0.21056393, mean(E): -21.72040124-0.00748552j, var(E): 0.43938066
-0.0
tensor(19.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=2.73............. Loss: -0.01227759, mean(E): -21.75829072-0.00186640j, var(E): 0.55755193
-0.0
tensor(19.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=2.73............. Loss: -0.01688550, mean(E): -21.73322200-0.00020231j, var(E): 0.59957680
-0.0
tensor(19.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=2.73............. Loss: -0.00636121, mean(E): -21.74975248+0.00608571j, var(E): 0.45528842
-0.0
tensor(19.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=2.73............. Loss: 0.06529761, mean(E): -21.74183126-0.00456732j, var(E): 0.50426063
-0.0
tensor(19.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=2.73............. Loss: 0.16384137, mean(E): -21.75864572+0.00100877j, var(E): 0.41098182
-0.0
tensor(19.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=2.73............. Loss: -0.09652968, mean(E): -21.74681707+0.00275184j, var(E): 0.58440854
-0.0
tensor(19.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=2.73............. Loss: 0.23180508, mean(E): -21.77109541+0.00028602j, var(E): 0.48230280
-0.0
tensor(19.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=2.71............. Loss: -0.17460511, mean(E): -21.71121443+0.00636679j, var(E): 0.62739312
-0.0
tensor(19.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=2.73............. Loss: 0.07365114, mean(E): -21.76498632+0.00782316j, var(E): 0.40652956
-0.0
tensor(19.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=2.73............. Loss: 0.31943636, mean(E): -21.76922843-0.00243347j, var(E): 0.53934092
-0.0
tensor(19.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=2.73............. Loss: -0.00639733, mean(E): -21.75571708+0.00231766j, var(E): 0.56969135
-0.0
tensor(19.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=2.72............. Loss: 0.42521717, mean(E): -21.79220671-0.00294065j, var(E): 0.61049537
-0.0
tensor(19.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=2.73............. Loss: -0.10289825, mean(E): -21.72924442-0.00196924j, var(E): 0.42781404
-0.0
tensor(19.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=2.73............. Loss: 0.25455522, mean(E): -21.77251035-0.01129129j, var(E): 0.48811603
-0.0
tensor(19.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=2.73............. Loss: -0.05374164, mean(E): -21.74285541+0.00304429j, var(E): 0.69908601
-0.0
tensor(19.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=2.73............. Loss: -0.25340125, mean(E): -21.71679131-0.00083843j, var(E): 0.44623550
-0.0
tensor(19.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=2.73............. Loss: 0.02605977, mean(E): -21.76492342+0.00021383j, var(E): 0.45475063
-0.0
tensor(19.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=2.73............. Loss: -0.03771132, mean(E): -21.76669740-0.00180809j, var(E): 0.39844067
-0.0
tensor(19.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=2.71............. Loss: -0.23012848, mean(E): -21.68956288+0.00236771j, var(E): 0.49728060
-0.0
tensor(19.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=2.72............. Loss: 0.13760409, mean(E): -21.73211095-0.00070974j, var(E): 0.65199608
-0.0
tensor(19.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=2.71............. Loss: 0.06955581, mean(E): -21.73012712+0.00111941j, var(E): 0.39738209
-0.0
tensor(19.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=2.71............. Loss: -0.06257343, mean(E): -21.74542348-0.00707511j, var(E): 0.32300908
-0.0
tensor(19.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=2.72............. Loss: 0.16303586, mean(E): -21.77375174+0.00532270j, var(E): 0.35660376
-0.0
tensor(19.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=2.73............. Loss: -0.01442704, mean(E): -21.72400942-0.00257069j, var(E): 0.62195027
-0.0
tensor(19.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=2.73............. Loss: 0.01136355, mean(E): -21.74336927-0.00195407j, var(E): 0.48987036
-0.0
tensor(19.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=2.71............. Loss: -0.05454911, mean(E): -21.75671649+0.00360898j, var(E): 0.58259514
-0.0
tensor(19.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=2.73............. Loss: -0.05472443, mean(E): -21.73178162+0.00122017j, var(E): 0.52113035
-0.0
tensor(19.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=2.73............. Loss: -0.04967092, mean(E): -21.76390878-0.00108252j, var(E): 0.38087660
-0.0
tensor(19.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=2.73............. Loss: 0.11499782, mean(E): -21.78028393+0.00488210j, var(E): 0.43648889
-0.0
tensor(19.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=2.73............. Loss: -0.14365858, mean(E): -21.74468796-0.00597448j, var(E): 0.38971890
-0.0
tensor(19.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=2.73............. Loss: -0.05185500, mean(E): -21.76496606+0.00197001j, var(E): 0.49905983
-0.0
tensor(19.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=2.73............. Loss: -0.25221885, mean(E): -21.73089975+0.00670457j, var(E): 0.54412520
-0.0
tensor(19.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=2.73............. Loss: -0.12987408, mean(E): -21.72398607-0.01256634j, var(E): 0.57743426
-0.0
tensor(19.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=2.71............. Loss: -0.12195830, mean(E): -21.73918600+0.00161674j, var(E): 0.51708309
-0.0
tensor(19.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=2.72............. Loss: -0.35816883, mean(E): -21.69970907-0.00440011j, var(E): 0.47705236
-0.0
tensor(19.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=2.71............. Loss: -0.02034014, mean(E): -21.75086091-0.00059743j, var(E): 0.37722893
-0.0
tensor(19.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=2.72............. Loss: -0.07075755, mean(E): -21.74055707+0.00294551j, var(E): 0.41687359
-0.0
tensor(19.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=2.73............. Loss: -0.18137245, mean(E): -21.74240322-0.00379285j, var(E): 0.35007093
-0.0
tensor(19.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=2.72............. Loss: -0.04905776, mean(E): -21.73932325-0.00015780j, var(E): 0.33210805
-0.0
tensor(19.7848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=2.73............. Loss: 0.07393236, mean(E): -21.76055713-0.00504580j, var(E): 0.34552873
-0.0
tensor(19.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=2.72............. Loss: 0.09622187, mean(E): -21.78533939+0.00474295j, var(E): 0.42579608
-0.0
tensor(19.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=2.73............. Loss: -0.13135994, mean(E): -21.73273731+0.00008228j, var(E): 0.50638890
-0.0
tensor(19.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=2.72............. Loss: -0.03582082, mean(E): -21.76055861-0.00185695j, var(E): 0.27213793
-0.0
tensor(19.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=2.72............. Loss: -0.19544233, mean(E): -21.73381039-0.00154233j, var(E): 0.46899184
-0.0
tensor(19.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=2.71............. Loss: -0.16373086, mean(E): -21.73280089+0.00208026j, var(E): 0.56882797
-0.0
tensor(19.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=2.71............. Loss: -0.16425562, mean(E): -21.73677656-0.00006246j, var(E): 0.63398135
-0.0
tensor(19.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=2.71............. Loss: -0.00547954, mean(E): -21.74359510+0.00377923j, var(E): 0.42735222
-0.0
tensor(19.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=2.72............. Loss: -0.29526461, mean(E): -21.69007888-0.00125042j, var(E): 0.37509494
-0.0
tensor(19.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=2.71............. Loss: -0.18777658, mean(E): -21.71020345-0.00370816j, var(E): 0.38155991
-0.0
tensor(19.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=2.73............. Loss: -0.10625904, mean(E): -21.73736779+0.00024959j, var(E): 0.36595454
-0.0
tensor(19.9349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=2.73............. Loss: -0.07112357, mean(E): -21.74414269-0.00187797j, var(E): 0.37386407
-0.0
tensor(19.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=2.73............. Loss: 0.44014534, mean(E): -21.79927145+0.00138834j, var(E): 1.21737996
-0.0
tensor(19.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=2.72............. Loss: -0.22246885, mean(E): -21.73380708-0.00139285j, var(E): 0.40568177
-0.0
tensor(19.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=2.73............. Loss: 0.07277198, mean(E): -21.78182166+0.00383066j, var(E): 0.44464213
-0.0
tensor(19.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=2.73............. Loss: -0.04736592, mean(E): -21.73469703-0.00109487j, var(E): 0.53267819
-0.0
tensor(19.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=2.71............. Loss: 0.12088541, mean(E): -21.76260566-0.00382499j, var(E): 0.64445630
-0.0
tensor(19.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=2.73............. Loss: -0.08159189, mean(E): -21.73984228+0.00136059j, var(E): 0.31961570
-0.0
tensor(19.9973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(19.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=2.73............. Loss: -0.18665820, mean(E): -21.73552532-0.00117609j, var(E): 0.48173577
-0.0
tensor(20.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=2.73............. Loss: 0.11846044, mean(E): -21.77600752+0.00592043j, var(E): 0.33311011
-0.0
tensor(20.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=2.73............. Loss: 0.14252363, mean(E): -21.75124156-0.00808370j, var(E): 0.59421523
-0.0
tensor(20.0276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=2.71............. Loss: -0.08957432, mean(E): -21.74275732+0.00149833j, var(E): 0.37846609
-0.0
tensor(20.0366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=2.73............. Loss: 0.28385250, mean(E): -21.79779964+0.00393169j, var(E): 0.57714616
-0.0
tensor(20.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=2.73............. Loss: 0.09953377, mean(E): -21.76121202-0.00372189j, var(E): 0.60501271
-0.0
tensor(20.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=2.73............. Loss: -0.10094597, mean(E): -21.72829384+0.00259042j, var(E): 0.63986877
-0.0
tensor(20.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=2.72............. Loss: -0.12557211, mean(E): -21.73294947+0.00290497j, var(E): 0.32751094
-0.0
tensor(20.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=2.72............. Loss: 0.01906177, mean(E): -21.75187680+0.00159987j, var(E): 0.45380887
-0.0
tensor(20.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=2.73............. Loss: -0.08149299, mean(E): -21.73377016+0.00114202j, var(E): 0.35466052
-0.0
tensor(20.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=2.73............. Loss: 0.09259681, mean(E): -21.76874666-0.00425438j, var(E): 0.50499849
-0.0
tensor(20.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=2.73............. Loss: -0.10226357, mean(E): -21.72951076-0.00471089j, var(E): 0.45696778
-0.0
tensor(20.1166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=2.73............. Loss: 0.03876113, mean(E): -21.74851232-0.00370697j, var(E): 0.49167730
-0.0
tensor(20.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=2.72............. Loss: -0.12164957, mean(E): -21.73839915+0.00199649j, var(E): 0.42110597
-0.0
tensor(20.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=2.72............. Loss: -0.01203353, mean(E): -21.76699569+0.00072890j, var(E): 0.42563092
-0.0
tensor(20.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=2.71............. Loss: -0.11725488, mean(E): -21.75702345-0.00293988j, var(E): 0.40699242
-0.0
tensor(20.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=2.72............. Loss: -0.12409750, mean(E): -21.73819209-0.00176850j, var(E): 0.42142015
-0.0
tensor(20.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=2.72............. Loss: 0.02771493, mean(E): -21.75652682-0.00565196j, var(E): 0.41522311
-0.0
tensor(20.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=2.71............. Loss: -0.18657731, mean(E): -21.72207468+0.00117478j, var(E): 0.38611361
-0.0
tensor(20.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=2.73............. Loss: -0.07725006, mean(E): -21.73700026+0.00124692j, var(E): 0.43360688
-0.0
tensor(20.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=2.73............. Loss: 0.02538468, mean(E): -21.75093511-0.00066565j, var(E): 0.44555971
-0.0
tensor(20.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=2.72............. Loss: -0.18526342, mean(E): -21.72868433-0.00071876j, var(E): 0.37542769
-0.0
tensor(20.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=2.73............. Loss: -0.36178639, mean(E): -21.69928212+0.00006989j, var(E): 0.54234323
-0.0
tensor(20.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=2.73............. Loss: -0.03480391, mean(E): -21.74735142+0.00158174j, var(E): 0.39900792
-0.0
tensor(20.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=2.72............. Loss: -0.04197166, mean(E): -21.72967396-0.00226123j, var(E): 0.35424510
-0.0
tensor(20.2432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=2.73............. Loss: 0.01186922, mean(E): -21.75104057-0.00293152j, var(E): 0.55745151
-0.0
tensor(20.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=2.73............. Loss: -0.03017440, mean(E): -21.75896936+0.00063131j, var(E): 0.58273398
-0.0
tensor(20.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=2.73............. Loss: 0.03836568, mean(E): -21.75631048+0.00199431j, var(E): 0.37848135
-0.0
tensor(20.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=2.72............. Loss: 0.02792308, mean(E): -21.76816908+0.00442540j, var(E): 0.32743575
-0.0
tensor(20.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=2.73............. Loss: -0.19745078, mean(E): -21.76630003+0.00259720j, var(E): 0.46517965
-0.0
tensor(20.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=2.71............. Loss: -0.02938664, mean(E): -21.75295761+0.00152109j, var(E): 0.43383756
-0.0
tensor(20.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=2.73............. Loss: 0.10110017, mean(E): -21.74402635-0.00395647j, var(E): 0.65595132
-0.0
tensor(20.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=2.73............. Loss: 0.20950175, mean(E): -21.76576633+0.00289988j, var(E): 1.20851815
-0.0
tensor(20.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=2.72............. Loss: 0.16179623, mean(E): -21.79517665-0.00020591j, var(E): 0.74855573
-0.0
tensor(20.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=2.72............. Loss: -0.12720737, mean(E): -21.72821840+0.00196323j, var(E): 0.38778583
-0.0
tensor(20.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=2.73............. Loss: 0.15855914, mean(E): -21.76616062-0.00612794j, var(E): 0.38749486
-0.0
tensor(20.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=2.73............. Loss: -0.04811325, mean(E): -21.75889726-0.00292714j, var(E): 0.65327021
-0.0
tensor(20.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=2.73............. Loss: -0.18052371, mean(E): -21.74033213+0.00080361j, var(E): 0.39068006
-0.0
tensor(20.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=2.72............. Loss: -0.01002157, mean(E): -21.75336732-0.00617011j, var(E): 0.32421678
-0.0
tensor(20.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=2.71............. Loss: -0.11470349, mean(E): -21.73338791-0.00262263j, var(E): 0.34641482
-0.0
tensor(20.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=2.71............. Loss: -0.05840878, mean(E): -21.75086297+0.00350219j, var(E): 0.26234075
-0.0
tensor(20.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=2.72............. Loss: -0.31059072, mean(E): -21.70429798-0.00068938j, var(E): 0.42872483
-0.0
tensor(20.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=2.71............. Loss: 0.00662745, mean(E): -21.76353149+0.00172561j, var(E): 0.29597900
-0.0
tensor(20.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=2.71............. Loss: 0.03038532, mean(E): -21.75390263+0.00127738j, var(E): 0.26990297
-0.0
tensor(20.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=2.73............. Loss: 0.12167013, mean(E): -21.77622520-0.00229189j, var(E): 0.21547593
-0.0
tensor(20.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=2.73............. Loss: -0.09208481, mean(E): -21.74921650+0.00277140j, var(E): 0.38095874
-0.0
tensor(20.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=2.73............. Loss: -0.17913172, mean(E): -21.74856200+0.00068563j, var(E): 0.63443988
-0.0
tensor(20.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=2.73............. Loss: -0.03131658, mean(E): -21.76399560-0.00083195j, var(E): 0.43014879
-0.0
tensor(20.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=2.72............. Loss: -0.06791816, mean(E): -21.74290130+0.00381021j, var(E): 0.45117296
-0.0
tensor(20.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=2.73............. Loss: -0.21705455, mean(E): -21.75035020+0.00021558j, var(E): 0.28272120
-0.0
tensor(20.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=2.72............. Loss: 0.14955372, mean(E): -21.79742933+0.00066849j, var(E): 0.36289417
-0.0
tensor(20.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=2.73............. Loss: -0.10646463, mean(E): -21.76225471+0.00153901j, var(E): 0.47331769
-0.0
tensor(20.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=2.73............. Loss: -0.08828511, mean(E): -21.76199693-0.00385650j, var(E): 0.35507423
-0.0
tensor(20.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=2.72............. Loss: 0.23956343, mean(E): -21.77328002+0.00296225j, var(E): 0.87359385
-0.0
tensor(20.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=2.73............. Loss: -0.11584732, mean(E): -21.76029648+0.00289807j, var(E): 0.35133958
-0.0
tensor(20.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=2.73............. Loss: -0.09059226, mean(E): -21.74509109-0.00101689j, var(E): 0.21212934
-0.0
tensor(20.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=2.71............. Loss: -0.01858212, mean(E): -21.75462862-0.00014413j, var(E): 0.28990232
-0.0
tensor(20.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=2.73............. Loss: -0.34624616, mean(E): -21.72569697+0.00018164j, var(E): 0.41937465
-0.0
tensor(20.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=2.73............. Loss: 0.01336846, mean(E): -21.76058334-0.00271846j, var(E): 0.37045759
-0.0
tensor(20.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=2.73............. Loss: -0.12167987, mean(E): -21.73051192-0.00289749j, var(E): 0.42464070
-0.0
tensor(20.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=2.73............. Loss: 0.02438614, mean(E): -21.74122143-0.00114127j, var(E): 0.27206716
-0.0
tensor(20.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=2.73............. Loss: 0.23954516, mean(E): -21.79575732+0.00513998j, var(E): 0.50882446
-0.0
tensor(20.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=2.73............. Loss: 0.13504843, mean(E): -21.77832639-0.00736727j, var(E): 0.45983327
-0.0
tensor(20.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=2.73............. Loss: 0.03488324, mean(E): -21.74790839+0.00053035j, var(E): 0.54952992
-0.0
tensor(20.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=2.71............. Loss: 0.07825741, mean(E): -21.75467644-0.00307507j, var(E): 0.47403709
-0.0
tensor(20.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=2.71............. Loss: -0.11283232, mean(E): -21.75288029+0.00120719j, var(E): 0.37472903
-0.0
tensor(20.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=2.72............. Loss: 0.18519695, mean(E): -21.78717655-0.00266273j, var(E): 0.50480738
-0.0
tensor(20.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=2.71............. Loss: 0.08698742, mean(E): -21.77484712-0.00041771j, var(E): 0.41533767
-0.0
tensor(20.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=2.72............. Loss: 0.22721914, mean(E): -21.76885265+0.00190720j, var(E): 0.42355837
-0.0
tensor(20.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=2.73............. Loss: 0.10318868, mean(E): -21.75649746+0.00428945j, var(E): 0.48826201
-0.0
tensor(20.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=2.73............. Loss: -0.06650191, mean(E): -21.76235075+0.00076509j, var(E): 0.39431307
-0.0
tensor(20.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=2.73............. Loss: -0.10005179, mean(E): -21.75332625+0.00080484j, var(E): 0.35313701
-0.0
tensor(20.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=2.73............. Loss: 0.06105721, mean(E): -21.77375216+0.00015892j, var(E): 0.22780834
-0.0
tensor(20.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=2.73............. Loss: -0.02859084, mean(E): -21.74459917-0.00126871j, var(E): 0.40758245
-0.0
tensor(20.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=2.73............. Loss: 0.16500016, mean(E): -21.78719876-0.00209192j, var(E): 0.49324167
-0.0
tensor(20.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=2.71............. Loss: -0.04421158, mean(E): -21.74977737+0.00274053j, var(E): 0.38435397
-0.0
tensor(20.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=2.72............. Loss: -0.09045566, mean(E): -21.76242423-0.00242495j, var(E): 0.24659451
-0.0
tensor(20.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=2.73............. Loss: -0.24061502, mean(E): -21.72498342+0.00211000j, var(E): 0.34338920
-0.0
tensor(20.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=2.73............. Loss: -0.05075742, mean(E): -21.75487757+0.00280821j, var(E): 0.21721821
-0.0
tensor(20.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=2.73............. Loss: 0.16131338, mean(E): -21.78028750+0.00075347j, var(E): 0.21638742
-0.0
tensor(20.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=2.73............. Loss: -0.08561558, mean(E): -21.74638248-0.00197477j, var(E): 0.27161652
-0.0
tensor(20.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=2.72............. Loss: -0.14891863, mean(E): -21.74195009+0.00107299j, var(E): 0.30222141
-0.0
tensor(20.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=2.73............. Loss: 0.28138588, mean(E): -21.79737472-0.00230229j, var(E): 0.42796368
-0.0
tensor(20.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=2.73............. Loss: -0.16333911, mean(E): -21.72658331-0.00270429j, var(E): 0.23273099
-0.0
tensor(20.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=2.73............. Loss: -0.04195316, mean(E): -21.75999994+0.00052231j, var(E): 0.25637293
-0.0
tensor(20.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=2.72............. Loss: -0.09731880, mean(E): -21.74254998+0.00017992j, var(E): 0.31968369
-0.0
tensor(20.8227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=2.72............. Loss: -0.01766180, mean(E): -21.75084542+0.00375095j, var(E): 0.33311973
-0.0
tensor(20.8318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=2.73............. Loss: 0.06598595, mean(E): -21.77402222-0.00005192j, var(E): 0.39128177
-0.0
tensor(20.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=2.73............. Loss: -0.08377739, mean(E): -21.75653580-0.00193032j, var(E): 0.33763640
-0.0
tensor(20.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=2.73............. Loss: 0.06525502, mean(E): -21.78650687-0.00123584j, var(E): 0.37448113
-0.0
tensor(20.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=2.72............. Loss: -0.14024075, mean(E): -21.75013843+0.00207326j, var(E): 0.34933358
-0.0
tensor(20.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=2.72............. Loss: -0.09321209, mean(E): -21.75123863+0.00296485j, var(E): 0.44276732
-0.0
tensor(20.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=2.72............. Loss: -0.06716508, mean(E): -21.76979915+0.00199184j, var(E): 0.30840951
-0.0
tensor(20.8831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=2.71............. Loss: 0.07762384, mean(E): -21.75848172-0.00407246j, var(E): 0.42053751
-0.0
tensor(20.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=2.71............. Loss: 0.19151803, mean(E): -21.77022635-0.00053644j, var(E): 0.51295271
-0.0
tensor(20.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=2.73............. Loss: 0.25179109, mean(E): -21.79523643+0.00125323j, var(E): 0.59761646
-0.0
tensor(20.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=2.73............. Loss: 0.12840145, mean(E): -21.78531120+0.00142929j, var(E): 0.28627319
-0.0
tensor(20.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=2.72............. Loss: -0.32529581, mean(E): -21.73449237-0.00129581j, var(E): 0.52909914
-0.0
tensor(20.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=2.73............. Loss: -0.12196446, mean(E): -21.74828881-0.00218452j, var(E): 0.31956047
-0.0
tensor(20.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=2.73............. Loss: 0.01124250, mean(E): -21.74860513-0.00401769j, var(E): 0.26156841
-0.0
tensor(20.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=2.73............. Loss: -0.27081640, mean(E): -21.74557916+0.00055298j, var(E): 0.36233698
-0.0
tensor(20.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=2.73............. Loss: 0.03113613, mean(E): -21.76902689-0.00112914j, var(E): 0.35655048
-0.0
tensor(20.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=2.71............. Loss: -0.07009403, mean(E): -21.77221665-0.00131137j, var(E): 0.47738316
-0.0
tensor(20.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=2.71............. Loss: 0.15551048, mean(E): -21.76543134+0.00352086j, var(E): 0.36240452
-0.0
tensor(20.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(20.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=2.73............. Loss: 0.12918305, mean(E): -21.76221084+0.00065861j, var(E): 0.68308401
-0.0
tensor(21.0046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=2.73............. Loss: -0.08090048, mean(E): -21.75506283-0.00076306j, var(E): 0.36842585
-0.0
tensor(21.0122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=2.73............. Loss: -0.06908182, mean(E): -21.72926997+0.00194302j, var(E): 0.41494791
-0.0
tensor(21.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=2.73............. Loss: 0.10725271, mean(E): -21.76344563-0.00219820j, var(E): 0.44916332
-0.0
tensor(21.0269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=2.73............. Loss: -0.07992180, mean(E): -21.75066306-0.00015034j, var(E): 0.37670039
-0.0
tensor(21.0467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=2.72............. Loss: 0.00182423, mean(E): -21.75090843-0.00082878j, var(E): 0.35679806
-0.0
tensor(21.0567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=2.73............. Loss: 0.14442155, mean(E): -21.78725160-0.00277519j, var(E): 0.47061959
-0.0
tensor(21.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=2.72............. Loss: 0.03202072, mean(E): -21.78260033+0.00191171j, var(E): 0.35741099
-0.0
tensor(21.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=2.71............. Loss: -0.06155957, mean(E): -21.75166345+0.00072453j, var(E): 0.45067914
-0.0
tensor(21.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=2.73............. Loss: -0.03643131, mean(E): -21.76500048+0.00091030j, var(E): 0.49910252
-0.0
tensor(21.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=2.72............. Loss: 0.09798714, mean(E): -21.78953383+0.00089188j, var(E): 0.57795285
-0.0
tensor(21.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=2.72............. Loss: -0.12562328, mean(E): -21.75051941+0.00055724j, var(E): 0.31573715
-0.0
tensor(21.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=2.72............. Loss: 0.11755728, mean(E): -21.78882078-0.00262156j, var(E): 0.26220310
-0.0
tensor(21.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=2.71............. Loss: -0.04748811, mean(E): -21.74256782+0.00144706j, var(E): 0.41330135
-0.0
tensor(21.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=2.71............. Loss: -0.15277084, mean(E): -21.73987566-0.00085748j, var(E): 0.42385015
-0.0
tensor(21.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=2.72............. Loss: -0.07888113, mean(E): -21.76224351+0.00495232j, var(E): 0.25427822
-0.0
tensor(21.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=2.72............. Loss: -0.09979137, mean(E): -21.75436081+0.00196462j, var(E): 0.34022162
-0.0
tensor(21.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=2.73............. Loss: -0.02881290, mean(E): -21.77303956+0.00119924j, var(E): 0.34919525
-0.0
tensor(21.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=2.73............. Loss: -0.20025034, mean(E): -21.74825889+0.00452169j, var(E): 0.38694448
-0.0
tensor(21.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=2.73............. Loss: -0.09480855, mean(E): -21.74194759-0.00089165j, var(E): 0.36260301
-0.0
tensor(21.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=2.73............. Loss: 0.08251421, mean(E): -21.77788493-0.00037727j, var(E): 0.84754752
-0.0
tensor(21.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=2.73............. Loss: -0.31719805, mean(E): -21.74469940+0.00168843j, var(E): 0.46064317
-0.0
tensor(21.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=2.73............. Loss: 0.10010547, mean(E): -21.78790740+0.00214626j, var(E): 0.30778926
-0.0
tensor(21.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=2.73............. Loss: -0.19480667, mean(E): -21.71980896+0.00017742j, var(E): 0.64204305
-0.0
tensor(21.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=2.71............. Loss: -0.07136364, mean(E): -21.75861710+0.00057443j, var(E): 0.29438893
-0.0
tensor(21.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=2.71............. Loss: 0.14661149, mean(E): -21.79420069+0.00099218j, var(E): 0.28286761
-0.0
tensor(21.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=2.71............. Loss: 0.30854200, mean(E): -21.78484707-0.00336800j, var(E): 1.09784348
-0.0
tensor(21.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=2.73............. Loss: 0.00383632, mean(E): -21.77421238-0.00054444j, var(E): 0.27750917
-0.0
tensor(21.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=2.73............. Loss: 0.09638084, mean(E): -21.77824575-0.00028456j, var(E): 0.24365135
-0.0
tensor(21.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=2.72............. Loss: -0.05624005, mean(E): -21.77754044-0.00067901j, var(E): 0.27168249
-0.0
tensor(21.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=2.73............. Loss: 0.12669711, mean(E): -21.78352335+0.00208735j, var(E): 0.35657246
-0.0
tensor(21.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=2.72............. Loss: 0.10893765, mean(E): -21.78616180+0.00126240j, var(E): 0.24320021
-0.0
tensor(21.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=2.72............. Loss: -0.09883785, mean(E): -21.75492624-0.00076125j, var(E): 0.23838084
-0.0
tensor(21.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=2.73............. Loss: -0.25170174, mean(E): -21.73639035-0.00048961j, var(E): 0.36159427
-0.0
tensor(21.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=2.72............. Loss: -0.11073833, mean(E): -21.75343151+0.00253747j, var(E): 0.26368810
-0.0
tensor(21.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=2.73............. Loss: 0.38702157, mean(E): -21.82127659-0.00306045j, var(E): 0.94531985
-0.0
tensor(21.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=2.72............. Loss: -0.28137645, mean(E): -21.72524953-0.00030416j, var(E): 0.44595037
-0.0
tensor(21.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=2.72............. Loss: -0.00641945, mean(E): -21.76429481-0.00241224j, var(E): 0.23021223
-0.0
tensor(21.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=2.72............. Loss: 0.04060763, mean(E): -21.79588870+0.00029939j, var(E): 0.32447258
-0.0
tensor(21.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=2.71............. Loss: 0.06194679, mean(E): -21.77414171-0.00046862j, var(E): 0.45407391
-0.0
tensor(21.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=2.73............. Loss: -0.02288325, mean(E): -21.76132744+0.00047519j, var(E): 0.43732164
-0.0
tensor(21.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=2.71............. Loss: -0.07137700, mean(E): -21.75679819-0.00060598j, var(E): 0.30337903
-0.0
tensor(21.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=2.73............. Loss: -0.06077243, mean(E): -21.75206537-0.00198799j, var(E): 0.30701340
-0.0
tensor(21.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=2.72............. Loss: -0.01130296, mean(E): -21.77155781+0.00062594j, var(E): 0.31698530
-0.0
tensor(21.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=2.73............. Loss: -0.26731289, mean(E): -21.73746455+0.00167449j, var(E): 0.28349234
-0.0
tensor(21.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=2.73............. Loss: 0.04012119, mean(E): -21.77623980+0.00102983j, var(E): 0.27234955
-0.0
tensor(21.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=2.73............. Loss: 0.01877663, mean(E): -21.76866727-0.00118027j, var(E): 0.27084899
-0.0
tensor(21.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=2.73............. Loss: -0.10033331, mean(E): -21.76337418-0.00011509j, var(E): 0.27396289
-0.0
tensor(21.3655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=2.73............. Loss: -0.00504770, mean(E): -21.77211981-0.00073576j, var(E): 0.30850677
-0.0
tensor(21.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=2.73............. Loss: -0.08209699, mean(E): -21.76106909+0.00041598j, var(E): 0.37097621
-0.0
tensor(21.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=2.73............. Loss: 0.09569427, mean(E): -21.77262600+0.00276088j, var(E): 0.28503465
-0.0
tensor(21.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=2.72............. Loss: 0.00968760, mean(E): -21.75740661-0.00016462j, var(E): 0.21695024
-0.0
tensor(21.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=2.73............. Loss: 0.03220215, mean(E): -21.78485785-0.00141679j, var(E): 0.25870597
-0.0
tensor(21.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=2.73............. Loss: -0.10478602, mean(E): -21.74691036+0.00103141j, var(E): 0.26695025
-0.0
tensor(21.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=2.73............. Loss: 0.20371636, mean(E): -21.78873739+0.00054415j, var(E): 0.43559814
-0.0
tensor(21.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=2.71............. Loss: -0.18490776, mean(E): -21.74345518+0.00112094j, var(E): 0.25774058
-0.0
tensor(21.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=2.73............. Loss: -0.04499628, mean(E): -21.77382288+0.00149163j, var(E): 0.27717040
-0.0
tensor(21.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=2.73............. Loss: -0.29057123, mean(E): -21.74098243-0.00039949j, var(E): 0.31204710
-0.0
tensor(21.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=2.73............. Loss: 0.07436609, mean(E): -21.77212469+0.00271871j, var(E): 0.16694474
-0.0
tensor(21.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=2.73............. Loss: -0.11279832, mean(E): -21.75188817+0.00075395j, var(E): 0.38267120
-0.0
tensor(21.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=2.73............. Loss: -0.07496191, mean(E): -21.76593337-0.00040799j, var(E): 0.25937274
-0.0
tensor(21.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=2.72............. Loss: -0.16450527, mean(E): -21.73985539+0.00149996j, var(E): 0.27267698
-0.0
tensor(21.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=2.73............. Loss: 0.24638198, mean(E): -21.80642153+0.00079017j, var(E): 0.31693154
-0.0
tensor(21.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=2.73............. Loss: -0.03176972, mean(E): -21.77368928-0.00097560j, var(E): 0.27533164
-0.0
tensor(21.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=2.73............. Loss: -0.00794231, mean(E): -21.77764541+0.00147406j, var(E): 0.24905320
-0.0
tensor(21.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=2.71............. Loss: 0.02998235, mean(E): -21.78010136-0.00070977j, var(E): 0.22231227
-0.0
tensor(21.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=2.71............. Loss: -0.18198501, mean(E): -21.75997626-0.00009809j, var(E): 0.28891154
-0.0
tensor(21.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=2.73............. Loss: -0.05084318, mean(E): -21.76851487+0.00025593j, var(E): 0.41120566
-0.0
tensor(21.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=2.72............. Loss: -0.21157106, mean(E): -21.75849933+0.00034320j, var(E): 0.33618536
-0.0
tensor(21.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=2.73............. Loss: -0.17746943, mean(E): -21.75745816+0.00013670j, var(E): 0.20137331
-0.0
tensor(21.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=2.73............. Loss: 0.01037367, mean(E): -21.77006534+0.00111885j, var(E): 0.22084895
-0.0
tensor(21.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=2.73............. Loss: 0.04444382, mean(E): -21.78434950-0.00013528j, var(E): 0.28955907
-0.0
tensor(21.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=2.71............. Loss: -0.17266182, mean(E): -21.75540627-0.00055826j, var(E): 0.35737426
-0.0
tensor(21.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=2.73............. Loss: -0.04011820, mean(E): -21.76327505+0.00082612j, var(E): 0.24987246
-0.0
tensor(21.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=2.73............. Loss: -0.12979809, mean(E): -21.74529045+0.00036403j, var(E): 0.18384796
-0.0
tensor(21.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=2.72............. Loss: 0.05860655, mean(E): -21.78159052+0.00042789j, var(E): 0.22966349
-0.0
tensor(21.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=2.73............. Loss: 0.11164873, mean(E): -21.79719943+0.00005763j, var(E): 0.16973812
-0.0
tensor(21.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=2.73............. Loss: -0.15607892, mean(E): -21.76396902-0.00081845j, var(E): 0.24401921
-0.0
tensor(21.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=2.73............. Loss: 0.07898291, mean(E): -21.77664260-0.00293486j, var(E): 0.33982259
-0.0
tensor(21.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=2.72............. Loss: 0.07593578, mean(E): -21.80217265+0.00030441j, var(E): 0.26811976
-0.0
tensor(21.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=2.73............. Loss: -0.00161111, mean(E): -21.77509519+0.00116678j, var(E): 0.40537890
-0.0
tensor(21.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=2.73............. Loss: 0.05885994, mean(E): -21.78212073-0.00025198j, var(E): 0.22111136
-0.0
tensor(21.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=2.73............. Loss: 0.02085352, mean(E): -21.76985903-0.00150844j, var(E): 0.27772294
-0.0
tensor(21.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=2.73............. Loss: 0.30984006, mean(E): -21.79642626-0.00058167j, var(E): 1.65148099
-0.0
tensor(21.5557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=2.73............. Loss: 0.04147101, mean(E): -21.79181020-0.00161252j, var(E): 0.23854825
-0.0
tensor(21.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=2.73............. Loss: -0.00244748, mean(E): -21.76592731+0.00033785j, var(E): 0.19691960
-0.0
tensor(21.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=2.72............. Loss: 0.03230075, mean(E): -21.77769351-0.00085063j, var(E): 0.29351837
-0.0
tensor(21.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=2.73............. Loss: 0.12138226, mean(E): -21.79622562-0.00107391j, var(E): 0.23501771
-0.0
tensor(21.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=2.73............. Loss: -0.10928579, mean(E): -21.75829121+0.00021011j, var(E): 0.15948671
-0.0
tensor(21.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=2.73............. Loss: -0.11620151, mean(E): -21.75499075+0.00039809j, var(E): 0.22553451
-0.0
tensor(21.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=2.72............. Loss: -0.05271250, mean(E): -21.77689032+0.00022856j, var(E): 0.22812033
-0.0
tensor(21.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=2.71............. Loss: -0.08827828, mean(E): -21.75110512-0.00003569j, var(E): 0.27853299
-0.0
tensor(21.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=2.71............. Loss: -0.00787953, mean(E): -21.77558459-0.00102038j, var(E): 0.14005046
-0.0
tensor(21.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=2.73............. Loss: 0.18642558, mean(E): -21.78969102+0.00039771j, var(E): 0.49438579
-0.0
tensor(21.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=2.72............. Loss: -0.18476991, mean(E): -21.76173705+0.00120577j, var(E): 0.21237535
-0.0
tensor(21.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=2.73............. Loss: 0.10943040, mean(E): -21.80218599+0.00070010j, var(E): 0.18299118
-0.0
tensor(21.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=2.73............. Loss: -0.06750494, mean(E): -21.75799410-0.00095085j, var(E): 0.25206193
-0.0
tensor(21.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=2.73............. Loss: -0.00385794, mean(E): -21.76900647-0.00090826j, var(E): 0.20491227
-0.0
tensor(21.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=2.73............. Loss: -0.19163194, mean(E): -21.73901700+0.00191668j, var(E): 0.24560161
-0.0
tensor(21.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=2.73............. Loss: -0.22313512, mean(E): -21.74944232+0.00085472j, var(E): 0.25156077
-0.0
tensor(21.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=2.73............. Loss: 0.12007760, mean(E): -21.78190922-0.00022796j, var(E): 0.33807885
-0.0
tensor(21.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=2.72............. Loss: 0.04641718, mean(E): -21.76676490-0.00026817j, var(E): 0.30257336
-0.0
tensor(21.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=2.73............. Loss: 0.01181447, mean(E): -21.78245608+0.00074747j, var(E): 0.27681954
-0.0
tensor(21.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=2.73............. Loss: 0.11929876, mean(E): -21.80476670-0.00024895j, var(E): 0.33235003
-0.0
tensor(21.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=2.73............. Loss: -0.05535421, mean(E): -21.77768397+0.00057060j, var(E): 0.30507955
-0.0
tensor(21.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=2.72............. Loss: -0.11193639, mean(E): -21.77103268+0.00038928j, var(E): 0.37250006
-0.0
tensor(21.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=2.73............. Loss: 0.06148271, mean(E): -21.77317287-0.00025600j, var(E): 0.27233334
-0.0
tensor(21.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=2.73............. Loss: -0.02939909, mean(E): -21.76997549-0.00013716j, var(E): 0.29933822
-0.0
tensor(21.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=2.73............. Loss: 0.04829493, mean(E): -21.78156301-0.00019165j, var(E): 0.18153950
-0.0
tensor(21.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=2.73............. Loss: -0.02006903, mean(E): -21.76484532+0.00012402j, var(E): 0.24376072
-0.0
tensor(21.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=2.72............. Loss: -0.05040460, mean(E): -21.76510239-0.00093526j, var(E): 0.12397966
-0.0
tensor(21.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=2.72............. Loss: -0.01640426, mean(E): -21.77433150-0.00014245j, var(E): 0.24475102
-0.0
tensor(21.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=2.72............. Loss: 0.05002984, mean(E): -21.77935393+0.00053202j, var(E): 0.21196961
-0.0
tensor(21.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=2.73............. Loss: 0.15009543, mean(E): -21.79931675-0.00024803j, var(E): 0.25691179
-0.0
tensor(21.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=2.71............. Loss: -0.01336802, mean(E): -21.77658987-0.00068599j, var(E): 0.23404948
-0.0
tensor(21.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=2.73............. Loss: 0.08336272, mean(E): -21.79333477-0.00013622j, var(E): 0.33862052
-0.0
tensor(21.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=2.71............. Loss: 0.04085327, mean(E): -21.77741061-0.00025335j, var(E): 0.30697732
-0.0
tensor(21.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=2.72............. Loss: 0.06729949, mean(E): -21.77644143-0.00035872j, var(E): 0.31890460
-0.0
tensor(21.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=2.72............. Loss: -0.20227627, mean(E): -21.76612196-0.00031947j, var(E): 0.22384113
-0.0
tensor(21.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=2.72............. Loss: 0.16358082, mean(E): -21.80853523-0.00016781j, var(E): 0.24370493
-0.0
tensor(21.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=2.72............. Loss: 0.01102833, mean(E): -21.77652316+0.00067214j, var(E): 0.22822253
-0.0
tensor(21.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=2.73............. Loss: -0.09859854, mean(E): -21.76981611-0.00025230j, var(E): 0.26890236
-0.0
tensor(21.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=2.73............. Loss: -0.00681043, mean(E): -21.77470018+0.00055492j, var(E): 0.27710489
-0.0
tensor(21.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=2.73............. Loss: -0.08772286, mean(E): -21.77017859+0.00015952j, var(E): 0.17111553
-0.0
tensor(21.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=2.73............. Loss: -0.00624838, mean(E): -21.78772127-0.00010126j, var(E): 0.19316563
-0.0
tensor(21.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=2.72............. Loss: -0.13314964, mean(E): -21.75467153+0.00042468j, var(E): 0.23560533
-0.0
tensor(21.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=2.73............. Loss: 0.00673526, mean(E): -21.76396586+0.00050565j, var(E): 0.25955746
-0.0
tensor(21.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=2.73............. Loss: -0.02251341, mean(E): -21.77409306+0.00008017j, var(E): 0.20086546
-0.0
tensor(21.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=2.73............. Loss: 0.02852054, mean(E): -21.79020996+0.00060523j, var(E): 0.27921241
-0.0
tensor(21.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=2.73............. Loss: 0.09569357, mean(E): -21.78366071+0.00003699j, var(E): 0.21917204
-0.0
tensor(21.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=2.73............. Loss: -0.04532893, mean(E): -21.76625215+0.00045927j, var(E): 0.33275163
-0.0
tensor(21.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=2.73............. Loss: 0.06262932, mean(E): -21.79379125+0.00008704j, var(E): 0.25809382
-0.0
tensor(21.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=2.73............. Loss: -0.08842634, mean(E): -21.76885150+0.00078341j, var(E): 0.15814397
-0.0
tensor(21.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=2.72............. Loss: 0.03323932, mean(E): -21.78140926-0.00029083j, var(E): 0.18324851
-0.0
tensor(21.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=2.72............. Loss: 0.14847027, mean(E): -21.77159058+0.00003024j, var(E): 0.34480652
-0.0
tensor(21.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=2.72............. Loss: -0.03796782, mean(E): -21.76047672+0.00023344j, var(E): 0.22296958
-0.0
tensor(21.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=2.73............. Loss: 0.10793895, mean(E): -21.79386037-0.00088321j, var(E): 0.29368504
-0.0
tensor(21.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=2.73............. Loss: 0.04876056, mean(E): -21.79453482-0.00015404j, var(E): 0.28839008
-0.0
tensor(21.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=2.73............. Loss: -0.01550558, mean(E): -21.77546858-0.00004141j, var(E): 0.24060495
-0.0
tensor(21.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=2.73............. Loss: 0.06153920, mean(E): -21.77137421-0.00000064j, var(E): 0.21454380
-0.0
tensor(21.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=2.73............. Loss: -0.17587556, mean(E): -21.74705152-0.00014074j, var(E): 0.20738108
-0.0
tensor(21.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=2.73............. Loss: -0.20994986, mean(E): -21.74873473-0.00014234j, var(E): 0.24245553
-0.0
tensor(21.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=2.73............. Loss: 0.03440992, mean(E): -21.78609680+0.00071786j, var(E): 0.19526822
-0.0
tensor(21.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=2.72............. Loss: 0.04290168, mean(E): -21.76988383-0.00004076j, var(E): 0.29181434
-0.0
tensor(21.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=2.73............. Loss: 0.00494656, mean(E): -21.78061902-0.00003619j, var(E): 0.26896311
-0.0
tensor(21.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=2.71............. Loss: 0.14390749, mean(E): -21.80588190+0.00002323j, var(E): 0.42003692
-0.0
tensor(21.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=2.72............. Loss: -0.13469017, mean(E): -21.77043421-0.00001574j, var(E): 0.20769749
-0.0
tensor(21.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=2.73............. Loss: 0.05186955, mean(E): -21.77650717+0.00004888j, var(E): 0.35914987
-0.0
tensor(21.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=2.73............. Loss: -0.06500186, mean(E): -21.78329609-0.00002138j, var(E): 0.21922971
-0.0
tensor(21.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=2.73............. Loss: -0.11583627, mean(E): -21.75732167+0.00011817j, var(E): 0.35157779
-0.0
tensor(21.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=2.72............. Loss: -0.07618752, mean(E): -21.76599989+0.00030641j, var(E): 0.21070224
-0.0
tensor(21.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=2.73............. Loss: -0.21747647, mean(E): -21.75614524+0.00022204j, var(E): 0.31090106
-0.0
tensor(21.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=2.73............. Loss: -0.03985445, mean(E): -21.78074450+0.00001918j, var(E): 0.15503635
-0.0
tensor(21.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=2.73............. Loss: 0.09526240, mean(E): -21.79537932+0.00035311j, var(E): 0.27406041
-0.0
tensor(21.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=2.72............. Loss: 0.13936734, mean(E): -21.80944171+0.00010143j, var(E): 0.24558806
-0.0
tensor(21.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=2.73............. Loss: -0.18283664, mean(E): -21.75801526-0.00038442j, var(E): 0.35062961
-0.0
tensor(21.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=2.72............. Loss: -0.11712666, mean(E): -21.75983750+0.00018882j, var(E): 0.15809929
-0.0
tensor(21.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=2.72............. Loss: -0.01878413, mean(E): -21.77863039-0.00025662j, var(E): 0.28953042
-0.0
tensor(21.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=2.73............. Loss: -0.04988127, mean(E): -21.75011865+0.00007164j, var(E): 0.31345861
-0.0
tensor(21.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=2.73............. Loss: 0.06005668, mean(E): -21.76688528-0.00017322j, var(E): 0.23906819
-0.0
tensor(21.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=2.73............. Loss: -0.07519867, mean(E): -21.76402952-0.00012508j, var(E): 0.24661072
-0.0
tensor(21.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=2.73............. Loss: 0.06644238, mean(E): -21.79368884+0.00023464j, var(E): 0.19502039
-0.0
tensor(21.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=2.73............. Loss: 0.02555594, mean(E): -21.79182565+0.00003461j, var(E): 0.22256094
-0.0
tensor(21.8501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=2.73............. Loss: 0.01115081, mean(E): -21.76997770-0.00031067j, var(E): 0.29914935
-0.0
tensor(21.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=2.73............. Loss: -0.07632018, mean(E): -21.77608566+0.00009583j, var(E): 0.16914702
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=2.73............. Loss: -0.16345243, mean(E): -21.74323244+0.00002500j, var(E): 0.23144609
-0.0
tensor(21.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=2.73............. Loss: 0.02162297, mean(E): -21.77324360+0.00011139j, var(E): 0.27437255
-0.0
tensor(21.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=2.72............. Loss: 0.05848537, mean(E): -21.79102632+0.00008123j, var(E): 0.30084783
-0.0
tensor(21.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=2.73............. Loss: -0.07471424, mean(E): -21.77571058+0.00009049j, var(E): 0.23323624
-0.0
tensor(21.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=2.71............. Loss: 0.00998972, mean(E): -21.77768351-0.00000509j, var(E): 0.14805199
-0.0
tensor(21.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=2.71............. Loss: -0.16836315, mean(E): -21.76203287+0.00007558j, var(E): 0.20846420
-0.0
tensor(21.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=2.71............. Loss: -0.20509401, mean(E): -21.75310656-0.00043328j, var(E): 0.17858989
-0.0
tensor(21.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=2.73............. Loss: 0.07322365, mean(E): -21.79859041+0.00012507j, var(E): 0.19305807
-0.0
tensor(21.9006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=2.72............. Loss: -0.12553930, mean(E): -21.76911579+0.00002344j, var(E): 0.13919363
-0.0
tensor(21.9056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=2.73............. Loss: -0.10973170, mean(E): -21.77490933-0.00001583j, var(E): 0.25919615
-0.0
tensor(21.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=2.73............. Loss: -0.07018743, mean(E): -21.77923227+0.00031728j, var(E): 0.16153447
-0.0
tensor(21.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=2.71............. Loss: -0.11600854, mean(E): -21.77293849-0.00005436j, var(E): 0.24387722
-0.0
tensor(21.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=2.72............. Loss: 0.06465199, mean(E): -21.77899285+0.00005304j, var(E): 0.25409611
-0.0
tensor(21.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=2.73............. Loss: 0.03177007, mean(E): -21.78366347-0.00000592j, var(E): 0.15704489
-0.0
tensor(21.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=2.73............. Loss: -0.08708851, mean(E): -21.75906759-0.00042015j, var(E): 0.54627332
-0.0
tensor(21.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=2.72............. Loss: -0.05244856, mean(E): -21.74699477+0.00013955j, var(E): 0.15533305
-0.0
tensor(21.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=2.73............. Loss: 0.01747840, mean(E): -21.78581865-0.00019064j, var(E): 0.21342100
-0.0
tensor(21.9361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=2.73............. Loss: -0.13767015, mean(E): -21.76993086-0.00003353j, var(E): 0.16156523
-0.0
tensor(21.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=2.73............. Loss: 0.21268879, mean(E): -21.80128183-0.00000487j, var(E): 0.83354632
-0.0
tensor(21.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=2.73............. Loss: 0.05519106, mean(E): -21.78284537-0.00009978j, var(E): 0.13467260
-0.0
tensor(21.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=2.72............. Loss: -0.13882928, mean(E): -21.76876504-0.00007481j, var(E): 0.17724910
-0.0
tensor(21.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=2.73............. Loss: -0.01712566, mean(E): -21.77283403-0.00015638j, var(E): 0.17136769
-0.0
tensor(21.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=2.73............. Loss: -0.14021025, mean(E): -21.75641335+0.00011919j, var(E): 0.32833083
-0.0
tensor(21.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=2.73............. Loss: -0.06601360, mean(E): -21.76577194-0.00027752j, var(E): 0.15039564
-0.0
tensor(21.9404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=2.73............. Loss: 0.14166421, mean(E): -21.79884595-0.00005426j, var(E): 0.22998597
-0.0
tensor(21.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=2.73............. Loss: 0.11396717, mean(E): -21.79965314+0.00004641j, var(E): 0.16950310
-0.0
tensor(21.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=2.73............. Loss: 0.09473570, mean(E): -21.78656503-0.00001522j, var(E): 0.27446062
-0.0
tensor(21.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=2.73............. Loss: -0.05841801, mean(E): -21.77807811+0.00003568j, var(E): 0.22980904
-0.0
tensor(21.9542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=2.71............. Loss: 0.09021291, mean(E): -21.77810760-0.00000719j, var(E): 0.25493128
-0.0
tensor(21.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=2.72............. Loss: 0.13986568, mean(E): -21.79768376+0.00008226j, var(E): 0.20265213
-0.0
tensor(21.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=2.72............. Loss: -0.01308156, mean(E): -21.77525980+0.00005363j, var(E): 0.22414549
-0.0
tensor(21.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=2.72............. Loss: 0.13497708, mean(E): -21.80799922-0.00016583j, var(E): 0.30055101
-0.0
tensor(21.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=2.73............. Loss: -0.04808415, mean(E): -21.77698199+0.00002690j, var(E): 0.19325233
-0.0
tensor(21.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=2.73............. Loss: -0.11320480, mean(E): -21.76912809+0.00000498j, var(E): 0.20593163
-0.0
tensor(21.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=2.73............. Loss: 0.12071399, mean(E): -21.81415328+0.00011873j, var(E): 0.25244555
-0.0
tensor(21.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=2.73............. Loss: 0.32617661, mean(E): -21.81873383+0.00016671j, var(E): 0.60136899
-0.0
tensor(21.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=2.73............. Loss: -0.02363677, mean(E): -21.77212681-0.00002292j, var(E): 0.14486731
-0.0
tensor(21.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=2.71............. Loss: 0.13945689, mean(E): -21.78570511+0.00008753j, var(E): 0.23232843
-0.0
tensor(21.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=2.71............. Loss: -0.02627216, mean(E): -21.76872683-0.00001964j, var(E): 0.25438055
-0.0
tensor(21.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=2.73............. Loss: 0.04852893, mean(E): -21.78996746-0.00000033j, var(E): 0.32686647
-0.0
tensor(21.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(21.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=2.72............. Loss: -0.08997768, mean(E): -21.76621138-0.00014159j, var(E): 0.20715939
-0.0
tensor(22.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=2.73............. Loss: -0.15192185, mean(E): -21.76434979-0.00000227j, var(E): 0.18651086
-0.0
tensor(22.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=2.73............. Loss: -0.13611560, mean(E): -21.76397825+0.00014059j, var(E): 0.18808798
-0.0
tensor(22.0130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=2.73............. Loss: 0.09684695, mean(E): -21.78844385-0.00001223j, var(E): 0.09506017
-0.0
tensor(22.0158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=2.73............. Loss: -0.11634419, mean(E): -21.76837766-0.00006006j, var(E): 0.18754268
-0.0
tensor(22.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=2.73............. Loss: 0.06978475, mean(E): -21.79476005+0.00006500j, var(E): 0.17607212
-0.0
tensor(22.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=2.73............. Loss: 0.06828464, mean(E): -21.78364874+0.00003423j, var(E): 0.16133421
-0.0
tensor(22.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=2.72............. Loss: 0.16131919, mean(E): -21.80233477-0.00005869j, var(E): 0.20862284
-0.0
tensor(22.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=2.73............. Loss: 0.13726334, mean(E): -21.79980980-0.00001714j, var(E): 0.17205985
-0.0
tensor(22.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=2.72............. Loss: -0.04990948, mean(E): -21.77673976+0.00001061j, var(E): 0.16999822
-0.0
tensor(22.0334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=2.73............. Loss: -0.01055738, mean(E): -21.78120640-0.00001620j, var(E): 0.17344630
-0.0
tensor(22.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=2.73............. Loss: -0.04651318, mean(E): -21.77009386-0.00006686j, var(E): 0.17470477
-0.0
tensor(22.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=2.73............. Loss: 0.16285225, mean(E): -21.80296706-0.00002931j, var(E): 0.17481715
-0.0
tensor(22.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=2.73............. Loss: 0.05667307, mean(E): -21.78731286+0.00000459j, var(E): 0.18040312
-0.0
tensor(22.0420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=2.71............. Loss: 0.15372838, mean(E): -21.78714209+0.00002029j, var(E): 0.31951758
-0.0
tensor(22.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=2.71............. Loss: 0.04963377, mean(E): -21.79037015-0.00009884j, var(E): 0.17970697
-0.0
tensor(22.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=2.72............. Loss: 0.14842036, mean(E): -21.80714243-0.00008567j, var(E): 0.16411144
-0.0
tensor(22.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=2.73............. Loss: 0.00941047, mean(E): -21.77803606-0.00001628j, var(E): 0.11715595
-0.0
tensor(22.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=2.73............. Loss: -0.07103151, mean(E): -21.77201735-0.00002856j, var(E): 0.12201484
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=2.73............. Loss: 0.06549648, mean(E): -21.78735826+0.00003307j, var(E): 0.16703835
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=2.73............. Loss: 0.11784557, mean(E): -21.80562979-0.00004096j, var(E): 0.18611972
-0.0
tensor(22.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=2.73............. Loss: -0.12285237, mean(E): -21.77292057+0.00000027j, var(E): 0.21131802
-0.0
tensor(22.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=2.73............. Loss: -0.02120052, mean(E): -21.78154265-0.00004415j, var(E): 0.14740820
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=2.73............. Loss: 0.02940330, mean(E): -21.77156076-0.00001333j, var(E): 0.19660394
-0.0
tensor(22.0643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=2.72............. Loss: 0.15431777, mean(E): -21.79544084-0.00001010j, var(E): 0.26063935
-0.0
tensor(22.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=2.72............. Loss: 0.09306279, mean(E): -21.79973675+0.00001475j, var(E): 0.15726737
-0.0
tensor(22.0711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=2.72............. Loss: 0.17339466, mean(E): -21.79010563+0.00000908j, var(E): 0.29479760
-0.0
tensor(22.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=2.73............. Loss: -0.07025246, mean(E): -21.76935869+0.00001322j, var(E): 0.21557208
-0.0
tensor(22.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=2.72............. Loss: 0.00521332, mean(E): -21.77805492+0.00006294j, var(E): 0.24746250
-0.0
tensor(22.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=2.73............. Loss: -0.06831466, mean(E): -21.77333755-0.00001780j, var(E): 0.18662704
-0.0
tensor(22.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=2.73............. Loss: 0.13390482, mean(E): -21.79485946-0.00004499j, var(E): 0.25753690
-0.0
tensor(22.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=2.73............. Loss: -0.04635669, mean(E): -21.77939240-0.00002622j, var(E): 0.23034586
-0.0
tensor(22.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=2.73............. Loss: -0.13200564, mean(E): -21.76289481-0.00001758j, var(E): 0.29167462
-0.0
tensor(22.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=2.73............. Loss: 0.03285051, mean(E): -21.79320542+0.00003022j, var(E): 0.16221912
-0.0
tensor(22.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=2.73............. Loss: 0.07730541, mean(E): -21.79742569+0.00000247j, var(E): 0.08621310
-0.0
tensor(22.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=2.73............. Loss: 0.15013774, mean(E): -21.80922370+0.00002179j, var(E): 0.28678240
-0.0
tensor(22.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=2.73............. Loss: 0.02346481, mean(E): -21.78296595-0.00003009j, var(E): 0.27203902
-0.0
tensor(22.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=2.72............. Loss: 0.10853091, mean(E): -21.79862672-0.00001998j, var(E): 0.20318957
-0.0
tensor(22.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=2.73............. Loss: -0.01578421, mean(E): -21.77473271+0.00000692j, var(E): 0.26718698
-0.0
tensor(22.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=2.73............. Loss: -0.13987395, mean(E): -21.76116205+0.00000005j, var(E): 0.13540487
-0.0
tensor(22.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=2.72............. Loss: -0.04412923, mean(E): -21.78313152+0.00001922j, var(E): 0.28689511
-0.0
tensor(22.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=2.72............. Loss: -0.10540661, mean(E): -21.76746202-0.00000245j, var(E): 0.15888932
-0.0
tensor(22.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=2.72............. Loss: -0.11599875, mean(E): -21.76113613+0.00000049j, var(E): 0.21827176
-0.0
tensor(22.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=2.72............. Loss: 0.01711818, mean(E): -21.78094163+0.00003681j, var(E): 0.27525989
-0.0
tensor(22.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=2.73............. Loss: 0.07023733, mean(E): -21.79743176+0.00000423j, var(E): 0.10604743
-0.0
tensor(22.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=2.73............. Loss: -0.14678382, mean(E): -21.76254130-0.00000752j, var(E): 0.21693240
-0.0
tensor(22.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=2.72............. Loss: -0.03870193, mean(E): -21.77387925+0.00000313j, var(E): 0.26184765
-0.0
tensor(22.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=2.73............. Loss: -0.04671780, mean(E): -21.77593311-0.00000359j, var(E): 0.18385280
-0.0
tensor(22.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=2.73............. Loss: -0.04893410, mean(E): -21.78141894-0.00001603j, var(E): 0.18691369
-0.0
tensor(22.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=2.73............. Loss: -0.09226844, mean(E): -21.77975191-0.00001227j, var(E): 0.17525499
-0.0
tensor(22.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=2.73............. Loss: -0.13056729, mean(E): -21.76810684-0.00000469j, var(E): 0.24153029
-0.0
tensor(22.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=2.73............. Loss: 0.00392091, mean(E): -21.78760325+0.00002654j, var(E): 0.22505377
-0.0
tensor(22.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=2.73............. Loss: -0.01320914, mean(E): -21.77750070-0.00000608j, var(E): 0.19048944
-0.0
tensor(22.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=2.73............. Loss: -0.00617436, mean(E): -21.78879867+0.00000969j, var(E): 0.22051047
-0.0
tensor(22.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=2.73............. Loss: 0.00945389, mean(E): -21.78200977-0.00000061j, var(E): 0.18197052
-0.0
tensor(22.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=2.73............. Loss: -0.02656803, mean(E): -21.77847664-0.00001268j, var(E): 0.12967663
-0.0
tensor(22.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=2.73............. Loss: -0.03197947, mean(E): -21.78172647-0.00001481j, var(E): 0.19026766
-0.0
tensor(22.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=2.73............. Loss: 0.23228045, mean(E): -21.80091933-0.00000035j, var(E): 0.19561201
-0.0
tensor(22.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=2.73............. Loss: -0.04707180, mean(E): -21.77850358-0.00000295j, var(E): 0.12055245
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=2.73............. Loss: 0.06846594, mean(E): -21.78893874-0.00000032j, var(E): 0.25690357
-0.0
tensor(22.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=2.73............. Loss: -0.00290505, mean(E): -21.78528252+0.00000158j, var(E): 0.14068897
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=2.73............. Loss: 0.02001960, mean(E): -21.78602300+0.00000330j, var(E): 0.11208019
-0.0
tensor(22.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=2.73............. Loss: 0.13667112, mean(E): -21.79648893+0.00000014j, var(E): 0.24267989
-0.0
tensor(22.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=2.73............. Loss: -0.28124599, mean(E): -21.75227803+0.00000593j, var(E): 0.24329160
-0.0
tensor(22.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=2.73............. Loss: -0.11237316, mean(E): -21.77534579-0.00001132j, var(E): 0.19880255
-0.0
tensor(22.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=2.73............. Loss: -0.12054522, mean(E): -21.75968266+0.00000280j, var(E): 0.13706515
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=2.71............. Loss: -0.07731411, mean(E): -21.78867931+0.00000847j, var(E): 0.10890008
-0.0
tensor(22.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=2.72............. Loss: -0.08229535, mean(E): -21.76456469-0.00000824j, var(E): 0.08770535
-0.0
tensor(22.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=2.72............. Loss: -0.05810420, mean(E): -21.77105253+0.00000429j, var(E): 0.22855929
-0.0
tensor(22.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=2.73............. Loss: -0.01579458, mean(E): -21.78191294-0.00000768j, var(E): 0.22096123
-0.0
tensor(22.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=2.71............. Loss: 0.26321718, mean(E): -21.81144662-0.00000415j, var(E): 0.87223204
-0.0
tensor(22.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=2.73............. Loss: -0.06109774, mean(E): -21.77665301+0.00000441j, var(E): 0.15295206
-0.0
tensor(22.1673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=2.73............. Loss: -0.03093040, mean(E): -21.78399279-0.00000171j, var(E): 0.12981547
-0.0
tensor(22.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=2.72............. Loss: 0.00510198, mean(E): -21.77974957-0.00000642j, var(E): 0.12453728
-0.0
tensor(22.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=2.73............. Loss: -0.15670164, mean(E): -21.76428930+0.00000191j, var(E): 0.13147611
-0.0
tensor(22.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=2.72............. Loss: 0.00834148, mean(E): -21.79166775+0.00000493j, var(E): 0.19914127
-0.0
tensor(22.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=2.71............. Loss: -0.13946664, mean(E): -21.76990718-0.00000041j, var(E): 0.18849125
-0.0
tensor(22.1774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=2.71............. Loss: -0.29007060, mean(E): -21.73805749-0.00000027j, var(E): 0.28862900
-0.0
tensor(22.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=2.73............. Loss: 0.08092212, mean(E): -21.79511903+0.00000325j, var(E): 0.25851786
-0.0
tensor(22.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=2.71............. Loss: 0.07027956, mean(E): -21.79382010+0.00000055j, var(E): 0.23355572
-0.0
tensor(22.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=2.72............. Loss: -0.03491398, mean(E): -21.76845336-0.00000554j, var(E): 0.12985286
-0.0
tensor(22.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=2.72............. Loss: 0.15411135, mean(E): -21.80071199+0.00000123j, var(E): 0.24972660
-0.0
tensor(22.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=2.73............. Loss: 0.00341022, mean(E): -21.78040699+0.00000484j, var(E): 0.14956972
-0.0
tensor(22.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=2.71............. Loss: -0.19767197, mean(E): -21.76197141-0.00000157j, var(E): 0.22886525
-0.0
tensor(22.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=2.73............. Loss: 0.01415999, mean(E): -21.78898283-0.00000514j, var(E): 0.18508266
-0.0
tensor(22.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=2.73............. Loss: 0.06701343, mean(E): -21.77903915+0.00000407j, var(E): 0.17438466
-0.0
tensor(22.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=2.72............. Loss: -0.03520207, mean(E): -21.77758756-0.00000061j, var(E): 0.10367820
-0.0
tensor(22.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=2.71............. Loss: 0.05964676, mean(E): -21.78988760+0.00000010j, var(E): 0.21762145
-0.0
tensor(22.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=2.73............. Loss: -0.13979280, mean(E): -21.76378572-0.00000339j, var(E): 0.18272642
-0.0
tensor(22.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=2.72............. Loss: -0.00025590, mean(E): -21.78507352+0.00000095j, var(E): 0.11874574
-0.0
tensor(22.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=2.73............. Loss: 0.04453407, mean(E): -21.78916501+0.00000082j, var(E): 0.16776762
-0.0
tensor(22.2147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=2.71............. Loss: 0.06112321, mean(E): -21.80052353-0.00000009j, var(E): 0.16372906
-0.0
tensor(22.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=2.71............. Loss: -0.11368983, mean(E): -21.76209423+0.00000086j, var(E): 0.18887384
-0.0
tensor(22.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=2.72............. Loss: -0.03559592, mean(E): -21.77915025+0.00000228j, var(E): 0.31444717
-0.0
tensor(22.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=2.71............. Loss: 0.22614697, mean(E): -21.81127951+0.00000024j, var(E): 0.30810500
-0.0
tensor(22.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=2.72............. Loss: 0.10625595, mean(E): -21.78950795+0.00000247j, var(E): 0.23638505
-0.0
tensor(22.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=2.71............. Loss: -0.00106540, mean(E): -21.79351917-0.00000011j, var(E): 0.13177905
-0.0
tensor(22.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=2.73............. Loss: 0.08114932, mean(E): -21.79584145-0.00000447j, var(E): 0.20156706
-0.0
tensor(22.2272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=2.73............. Loss: -0.12527584, mean(E): -21.76557741-0.00000088j, var(E): 0.19060585
-0.0
tensor(22.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=2.73............. Loss: -0.07640419, mean(E): -21.76780684+0.00000226j, var(E): 0.17104256
-0.0
tensor(22.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=2.73............. Loss: 0.15954458, mean(E): -21.80649478+0.00000145j, var(E): 0.22115283
-0.0
tensor(22.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=2.72............. Loss: 0.09232364, mean(E): -21.78776259+0.00000029j, var(E): 0.23907155
-0.0
tensor(22.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=2.73............. Loss: -0.11372433, mean(E): -21.76445810+0.00000074j, var(E): 0.11108018
-0.0
tensor(22.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=2.71............. Loss: -0.03175406, mean(E): -21.77125135+0.00000065j, var(E): 0.15732838
-0.0
tensor(22.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=2.72............. Loss: 0.24986999, mean(E): -21.81456230-0.00000013j, var(E): 0.21715165
-0.0
tensor(22.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=2.73............. Loss: -0.01727110, mean(E): -21.77150545+0.00000176j, var(E): 0.31424067
-0.0
tensor(22.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=2.73............. Loss: 0.06900568, mean(E): -21.79530229+0.00000028j, var(E): 0.23311754
-0.0
tensor(22.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=2.71............. Loss: -0.13690289, mean(E): -21.76141123+0.00000162j, var(E): 0.23342021
-0.0
tensor(22.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=2.72............. Loss: 0.10056045, mean(E): -21.80178374+0.00000007j, var(E): 0.17770844
-0.0
tensor(22.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=2.72............. Loss: -0.22662963, mean(E): -21.75653694+0.00000081j, var(E): 0.17293146
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=2.71............. Loss: -0.01060450, mean(E): -21.78744814+0.00000033j, var(E): 0.11098436
-0.0
tensor(22.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=2.72............. Loss: 0.07993436, mean(E): -21.79572696+0.00000055j, var(E): 0.26747001
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=2.72............. Loss: -0.06467792, mean(E): -21.77581581-0.00000096j, var(E): 0.17342243
-0.0
tensor(22.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=2.71............. Loss: -0.01004814, mean(E): -21.78035181-0.00000044j, var(E): 0.18052259
-0.0
tensor(22.2602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=2.71............. Loss: 0.01875589, mean(E): -21.77933709+0.00000042j, var(E): 0.17817157
-0.0
tensor(22.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=2.73............. Loss: 0.09517612, mean(E): -21.79924419-0.00000030j, var(E): 0.35435042
-0.0
tensor(22.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=2.72............. Loss: 0.04156487, mean(E): -21.79091213-0.00000059j, var(E): 0.18611570
-0.0
tensor(22.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=2.71............. Loss: 0.01031868, mean(E): -21.79286844+0.00000034j, var(E): 0.19952286
-0.0
tensor(22.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=2.71............. Loss: -0.13266855, mean(E): -21.76949603+0.00000030j, var(E): 0.21485690
-0.0
tensor(22.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=2.71............. Loss: 0.03930572, mean(E): -21.78347170-0.00000057j, var(E): 0.21621390
-0.0
tensor(22.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=2.71............. Loss: 0.03455639, mean(E): -21.80052458+0.00000046j, var(E): 0.21873202
-0.0
tensor(22.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=2.72............. Loss: -0.05388998, mean(E): -21.78661458+0.00000061j, var(E): 0.29538535
-0.0
tensor(22.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=2.73............. Loss: -0.16334469, mean(E): -21.75873361-0.00000030j, var(E): 0.16698182
-0.0
tensor(22.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=2.73............. Loss: -0.11470120, mean(E): -21.77826315-0.00000010j, var(E): 0.13639547
-0.0
tensor(22.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=2.72............. Loss: -0.02009090, mean(E): -21.77517831+0.00000018j, var(E): 0.11056142
-0.0
tensor(22.2816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=2.73............. Loss: -0.00640023, mean(E): -21.79387967+0.00000024j, var(E): 0.16316609
-0.0
tensor(22.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=2.71............. Loss: -0.06211987, mean(E): -21.77672408-0.00000010j, var(E): 0.15242808
-0.0
tensor(22.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=2.71............. Loss: 0.23739051, mean(E): -21.80687558-0.00000009j, var(E): 0.20423644
-0.0
tensor(22.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=2.71............. Loss: -0.00657269, mean(E): -21.78890833+0.00000010j, var(E): 0.20718506
-0.0
tensor(22.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=2.71............. Loss: 0.05209887, mean(E): -21.79507560+0.00000007j, var(E): 0.16525154
-0.0
tensor(22.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=2.73............. Loss: -0.03176399, mean(E): -21.77695012+0.00000051j, var(E): 0.16347989
-0.0
tensor(22.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=2.73............. Loss: 0.08913053, mean(E): -21.79011160-0.00000041j, var(E): 0.19315199
-0.0
tensor(22.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=2.73............. Loss: -0.06540831, mean(E): -21.77850203-0.00000041j, var(E): 0.09030516
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=2.73............. Loss: -0.02965929, mean(E): -21.79587544-0.00000036j, var(E): 0.29882318
-0.0
tensor(22.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=2.73............. Loss: 0.01472735, mean(E): -21.78490931+0.00000018j, var(E): 0.22947156
-0.0
tensor(22.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=2.73............. Loss: 0.10630814, mean(E): -21.79885865-0.00000030j, var(E): 0.34380617
-0.0
tensor(22.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=2.73............. Loss: 0.06327031, mean(E): -21.79301417+0.00000028j, var(E): 0.12191182
-0.0
tensor(22.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=2.73............. Loss: -0.10353660, mean(E): -21.76953878+0.00000023j, var(E): 0.25244684
-0.0
tensor(22.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=2.73............. Loss: -0.10639385, mean(E): -21.78380652-0.00000013j, var(E): 0.26699525
-0.0
tensor(22.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=2.73............. Loss: -0.05252429, mean(E): -21.76909585+0.00000014j, var(E): 0.18765443
-0.0
tensor(22.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=2.73............. Loss: 0.01970788, mean(E): -21.77489012+0.00000021j, var(E): 0.28666719
-0.0
tensor(22.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=2.72............. Loss: 0.08860431, mean(E): -21.79473627+0.00000023j, var(E): 0.17521979
-0.0
tensor(22.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=2.73............. Loss: 0.05206184, mean(E): -21.79824061+0.00000010j, var(E): 0.16868073
-0.0
tensor(22.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=2.73............. Loss: -0.08387274, mean(E): -21.77521432-0.00000013j, var(E): 0.17476065
-0.0
tensor(22.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=2.73............. Loss: -0.12333377, mean(E): -21.77060760+0.00000021j, var(E): 0.12629810
-0.0
tensor(22.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=2.72............. Loss: 0.02222516, mean(E): -21.78362532-0.00000015j, var(E): 0.10577572
-0.0
tensor(22.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=2.71............. Loss: 0.09728068, mean(E): -21.80440101-0.00000005j, var(E): 0.12720829
-0.0
tensor(22.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=2.72............. Loss: 0.04896007, mean(E): -21.80095775-0.00000013j, var(E): 0.13547350
-0.0
tensor(22.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=2.71............. Loss: -0.02120414, mean(E): -21.77495243+0.00000003j, var(E): 0.11210205
-0.0
tensor(22.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=2.73............. Loss: -0.13869369, mean(E): -21.76717158+0.00000009j, var(E): 0.16456776
-0.0
tensor(22.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=2.73............. Loss: 0.11662519, mean(E): -21.79893100-0.00000006j, var(E): 0.25119065
-0.0
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=2.73............. Loss: -0.03312886, mean(E): -21.78286896-0.00000014j, var(E): 0.22422484
-0.0
tensor(22.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=2.72............. Loss: -0.03615846, mean(E): -21.77886761+0.00000005j, var(E): 0.16877699
-0.0
tensor(22.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=2.72............. Loss: -0.07134720, mean(E): -21.77364313-0.00000007j, var(E): 0.17967237
-0.0
tensor(22.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=2.73............. Loss: 0.06814299, mean(E): -21.79276906-0.00000004j, var(E): 0.26556075
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=2.73............. Loss: -0.07789415, mean(E): -21.77436033-0.00000007j, var(E): 0.17185311
-0.0
tensor(22.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=2.72............. Loss: 0.06543357, mean(E): -21.78896839+0.00000010j, var(E): 0.23501978
-0.0
tensor(22.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=2.73............. Loss: -0.14666643, mean(E): -21.77739990+0.00000002j, var(E): 0.22276428
-0.0
tensor(22.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=2.73............. Loss: -0.09935850, mean(E): -21.77702259+0.00000002j, var(E): 0.22674443
-0.0
tensor(22.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=2.73............. Loss: -0.12916923, mean(E): -21.76552843+0.00000003j, var(E): 0.14832471
-0.0
tensor(22.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=2.73............. Loss: -0.02673211, mean(E): -21.78793223-0.00000002j, var(E): 0.07973339
-0.0
tensor(22.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=2.73............. Loss: 0.08133414, mean(E): -21.79455440+0.00000001j, var(E): 0.13711935
-0.0
tensor(22.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=2.71............. Loss: -0.00736769, mean(E): -21.79060284+0.00000002j, var(E): 0.12534825
-0.0
tensor(22.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=2.71............. Loss: -0.01072956, mean(E): -21.78500294+0.00000000j, var(E): 0.11009702
-0.0
tensor(22.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=2.72............. Loss: -0.12961915, mean(E): -21.77299485-0.00000002j, var(E): 0.13143361
-0.0
tensor(22.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=2.73............. Loss: -0.08813369, mean(E): -21.76927666-0.00000000j, var(E): 0.17192144
-0.0
tensor(22.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=2.73............. Loss: -0.08090671, mean(E): -21.77987259-0.00000002j, var(E): 0.18133831
-0.0
tensor(22.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=2.73............. Loss: 0.09731597, mean(E): -21.78395080+0.00000002j, var(E): 0.37788212
-0.0
tensor(22.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=2.73............. Loss: 0.02431228, mean(E): -21.77773337-0.00000002j, var(E): 0.11270054
-0.0
tensor(22.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=2.72............. Loss: -0.03066091, mean(E): -21.77636003+0.00000000j, var(E): 0.17740323
-0.0
tensor(22.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=2.73............. Loss: -0.14668492, mean(E): -21.77135404-0.00000002j, var(E): 0.15300449
-0.0
tensor(22.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=2.71............. Loss: -0.07942611, mean(E): -21.76513578+0.00000001j, var(E): 0.13727762
-0.0
tensor(22.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=2.71............. Loss: 0.01285416, mean(E): -21.79357347+0.00000001j, var(E): 0.12567304
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=2.72............. Loss: 0.05190305, mean(E): -21.79474013-0.00000000j, var(E): 0.23315895
-0.0
tensor(22.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=2.72............. Loss: -0.02299389, mean(E): -21.77949574+0.00000001j, var(E): 0.11447614
-0.0
tensor(22.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=2.73............. Loss: -0.00564573, mean(E): -21.78497811+0.00000000j, var(E): 0.19105169
-0.0
tensor(22.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=2.73............. Loss: -0.01203873, mean(E): -21.78111232+0.00000001j, var(E): 0.12530202
-0.0
tensor(22.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=2.73............. Loss: 0.00438289, mean(E): -21.78433132+0.00000001j, var(E): 0.15041298
-0.0
tensor(22.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=2.73............. Loss: -0.01533506, mean(E): -21.77745037+0.00000000j, var(E): 0.16788332
-0.0
tensor(22.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=2.73............. Loss: 0.02591889, mean(E): -21.79794286-0.00000000j, var(E): 0.10262906
-0.0
tensor(22.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=2.72............. Loss: -0.12224464, mean(E): -21.78019896+0.00000000j, var(E): 0.16658555
-0.0
tensor(22.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=2.72............. Loss: 0.14617132, mean(E): -21.80998237-0.00000000j, var(E): 0.10968192
-0.0
tensor(22.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=2.73............. Loss: 0.15948690, mean(E): -21.80440801-0.00000000j, var(E): 0.27420341
-0.0
tensor(22.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=2.73............. Loss: 0.05683106, mean(E): -21.79138407+0.00000000j, var(E): 0.16221220
-0.0
tensor(22.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=2.73............. Loss: 0.11081583, mean(E): -21.79566172-0.00000000j, var(E): 0.20828954
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=2.73............. Loss: -0.01823745, mean(E): -21.78815107+0.00000001j, var(E): 0.14171254
-0.0
tensor(22.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=2.71............. Loss: -0.12203635, mean(E): -21.77044269+0.00000000j, var(E): 0.20933258
-0.0
tensor(22.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=2.73............. Loss: -0.09850678, mean(E): -21.77250008-0.00000000j, var(E): 0.10721216
-0.0
tensor(22.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=2.73............. Loss: -0.17410625, mean(E): -21.77988170-0.00000000j, var(E): 0.30712858
-0.0
tensor(22.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=2.73............. Loss: -0.03036280, mean(E): -21.77245402+0.00000000j, var(E): 0.12562116
-0.0
tensor(22.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=2.72............. Loss: -0.04537611, mean(E): -21.77402457+0.00000000j, var(E): 0.20803517
-0.0
tensor(22.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=2.73............. Loss: 0.05872684, mean(E): -21.79247295-0.00000000j, var(E): 0.13055638
-0.0
tensor(22.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=2.73............. Loss: -0.09994010, mean(E): -21.76616503-0.00000000j, var(E): 0.22693401
-0.0
tensor(22.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=2.73............. Loss: -0.04522679, mean(E): -21.77084591+0.00000000j, var(E): 0.16424734
-0.0
tensor(22.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=2.73............. Loss: 0.11131660, mean(E): -21.80359727-0.00000001j, var(E): 0.12937549
-0.0
tensor(22.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=2.73............. Loss: -0.00041122, mean(E): -21.78164337+0.00000000j, var(E): 0.29404650
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=2.73............. Loss: -0.08084374, mean(E): -21.78000324+0.00000000j, var(E): 0.18972528
-0.0
tensor(22.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=2.71............. Loss: -0.07873148, mean(E): -21.77472078+0.00000000j, var(E): 0.15267129
-0.0
tensor(22.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=2.73............. Loss: -0.06805948, mean(E): -21.78062149+0.00000000j, var(E): 0.20823450
-0.0
tensor(22.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=2.73............. Loss: 0.11475502, mean(E): -21.79878172-0.00000000j, var(E): 0.22421853
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=2.73............. Loss: -0.00628419, mean(E): -21.78484482-0.00000000j, var(E): 0.29763193
-0.0
tensor(22.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=2.73............. Loss: 0.01505292, mean(E): -21.79581794+0.00000000j, var(E): 0.16180993
-0.0
tensor(22.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=2.73............. Loss: -0.04437314, mean(E): -21.77891197-0.00000000j, var(E): 0.17197635
-0.0
tensor(22.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=2.73............. Loss: 0.06432653, mean(E): -21.79468315-0.00000000j, var(E): 0.16770177
-0.0
tensor(22.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=2.73............. Loss: -0.01656880, mean(E): -21.77590333-0.00000000j, var(E): 0.10544897
-0.0
tensor(22.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=2.73............. Loss: 0.00239680, mean(E): -21.78233052+0.00000000j, var(E): 0.10147066
-0.0
tensor(22.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=2.73............. Loss: -0.00373390, mean(E): -21.78177922+0.00000000j, var(E): 0.13652539
-0.0
tensor(22.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=2.73............. Loss: -0.06904549, mean(E): -21.78416564+0.00000000j, var(E): 0.11545018
-0.0
tensor(22.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=2.71............. Loss: -0.10328889, mean(E): -21.77484928-0.00000000j, var(E): 0.13836048
-0.0
tensor(22.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=2.73............. Loss: -0.05230214, mean(E): -21.76596517+0.00000000j, var(E): 0.10876178
-0.0
tensor(22.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=2.73............. Loss: 0.05221925, mean(E): -21.78764158+0.00000000j, var(E): 0.17894270
-0.0
tensor(22.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=2.73............. Loss: 0.02644703, mean(E): -21.79028127+0.00000000j, var(E): 0.12816862
-0.0
tensor(22.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=2.73............. Loss: -0.07378981, mean(E): -21.77460584-0.00000000j, var(E): 0.17066501
-0.0
tensor(22.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=2.71............. Loss: -0.00483795, mean(E): -21.78811491-0.00000000j, var(E): 0.13703497
-0.0
tensor(22.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=2.72............. Loss: 0.02171687, mean(E): -21.78554921+0.00000000j, var(E): 0.36420217
-0.0
tensor(22.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=2.72............. Loss: 0.00768461, mean(E): -21.79056699-0.00000000j, var(E): 0.13336993
-0.0
tensor(22.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=2.72............. Loss: -0.03149027, mean(E): -21.77412676-0.00000000j, var(E): 0.10719801
-0.0
tensor(22.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=2.71............. Loss: -0.09002246, mean(E): -21.77425527+0.00000000j, var(E): 0.13233024
-0.0
tensor(22.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=2.73............. Loss: 0.12058832, mean(E): -21.80029861+0.00000000j, var(E): 0.26899249
-0.0
tensor(22.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=2.72............. Loss: 0.08557619, mean(E): -21.79937405-0.00000000j, var(E): 0.18336524
-0.0
tensor(22.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=2.73............. Loss: 0.06725099, mean(E): -21.80350892-0.00000000j, var(E): 0.21803561
-0.0
tensor(22.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=2.71............. Loss: -0.09490049, mean(E): -21.76972880+0.00000000j, var(E): 0.14908750
-0.0
tensor(22.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=2.72............. Loss: -0.03036833, mean(E): -21.78478478-0.00000000j, var(E): 0.20333736
-0.0
tensor(22.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=2.72............. Loss: 0.14917274, mean(E): -21.79989142+0.00000000j, var(E): 0.16646810
-0.0
tensor(22.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=2.72............. Loss: 0.02089755, mean(E): -21.77669447-0.00000000j, var(E): 0.22595195
-0.0
tensor(22.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=2.72............. Loss: -0.09359147, mean(E): -21.77601485+0.00000000j, var(E): 0.16204688
-0.0
tensor(22.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=2.71............. Loss: 0.04965712, mean(E): -21.78063319+0.00000000j, var(E): 0.13695403
-0.0
tensor(22.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=2.73............. Loss: 0.11625518, mean(E): -21.79294440+0.00000000j, var(E): 0.21871138
-0.0
tensor(22.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=2.73............. Loss: -0.08440806, mean(E): -21.77694736-0.00000000j, var(E): 0.16908833
-0.0
tensor(22.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=2.72............. Loss: 0.05232940, mean(E): -21.79260106-0.00000000j, var(E): 0.20130358
-0.0
tensor(22.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=2.73............. Loss: -0.12796664, mean(E): -21.77263764-0.00000000j, var(E): 0.13732531
-0.0
tensor(22.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=2.72............. Loss: 0.06735783, mean(E): -21.79278961-0.00000000j, var(E): 0.09669599
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=2.72............. Loss: -0.13445956, mean(E): -21.75612495-0.00000000j, var(E): 0.12127087
-0.0
tensor(22.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=2.73............. Loss: 0.08095147, mean(E): -21.79451285+0.00000000j, var(E): 0.16674372
-0.0
tensor(22.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=2.73............. Loss: 0.01229645, mean(E): -21.78677844+0.00000000j, var(E): 0.06700904
-0.0
tensor(22.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=2.73............. Loss: 0.00064954, mean(E): -21.78730308-0.00000000j, var(E): 0.13357035
-0.0
tensor(22.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=2.72............. Loss: -0.07508638, mean(E): -21.77836202-0.00000000j, var(E): 0.18774048
-0.0
tensor(22.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=2.72............. Loss: -0.10311374, mean(E): -21.76826948-0.00000000j, var(E): 0.13457470
-0.0
tensor(22.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=2.71............. Loss: 0.04145297, mean(E): -21.78811838+0.00000000j, var(E): 0.26007057
-0.0
tensor(22.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=2.72............. Loss: 0.02987964, mean(E): -21.79348849-0.00000000j, var(E): 0.09944078
-0.0
tensor(22.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=2.72............. Loss: -0.01544638, mean(E): -21.78976374+0.00000000j, var(E): 0.17981737
-0.0
tensor(22.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=2.72............. Loss: 0.06636252, mean(E): -21.78812295-0.00000000j, var(E): 0.13630912
-0.0
tensor(22.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=2.71............. Loss: 0.02008806, mean(E): -21.78354496+0.00000000j, var(E): 0.10014934
-0.0
tensor(22.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=2.71............. Loss: -0.22098750, mean(E): -21.74711740-0.00000000j, var(E): 0.20672879
-0.0
tensor(22.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=2.71............. Loss: -0.09045992, mean(E): -21.77478072+0.00000000j, var(E): 0.16435293
-0.0
tensor(22.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=2.72............. Loss: 0.06043990, mean(E): -21.79971389-0.00000000j, var(E): 0.17788032
-0.0
tensor(22.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=2.71............. Loss: -0.00230161, mean(E): -21.78762111+0.00000000j, var(E): 0.14737862
-0.0
tensor(22.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=2.71............. Loss: -0.16736423, mean(E): -21.75925864+0.00000000j, var(E): 0.16075380
-0.0
tensor(22.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=2.72............. Loss: 0.12603305, mean(E): -21.81611260+0.00000000j, var(E): 0.21100868
-0.0
tensor(22.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=2.72............. Loss: -0.13766973, mean(E): -21.76584392+0.00000000j, var(E): 0.15098683
-0.0
tensor(22.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=2.72............. Loss: 0.09756209, mean(E): -21.78563804-0.00000000j, var(E): 0.28937739
-0.0
tensor(22.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=2.72............. Loss: -0.13040996, mean(E): -21.77190892-0.00000000j, var(E): 0.15798143
-0.0
tensor(22.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=2.72............. Loss: 0.03044797, mean(E): -21.78633090-0.00000000j, var(E): 0.16710262
-0.0
tensor(22.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=2.72............. Loss: 0.00639770, mean(E): -21.79055861-0.00000000j, var(E): 0.14842881
-0.0
tensor(22.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=2.72............. Loss: -0.06160745, mean(E): -21.78011675-0.00000000j, var(E): 0.12890891
-0.0
tensor(22.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=2.73............. Loss: 0.02053305, mean(E): -21.78260545-0.00000000j, var(E): 0.13658500
-0.0
tensor(22.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=2.73............. Loss: 0.01943400, mean(E): -21.79621205-0.00000000j, var(E): 0.09877944
-0.0
tensor(22.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=2.72............. Loss: 0.11332746, mean(E): -21.79731926-0.00000000j, var(E): 0.33749027
-0.0
tensor(22.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=2.73............. Loss: 0.15045987, mean(E): -21.81157521+0.00000000j, var(E): 0.35959847
-0.0
tensor(22.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=2.73............. Loss: -0.06887694, mean(E): -21.76668098-0.00000000j, var(E): 0.14093517
-0.0
tensor(22.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=2.73............. Loss: 0.12436913, mean(E): -21.79603399-0.00000000j, var(E): 0.11102655
-0.0
tensor(22.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=2.71............. Loss: -0.11697220, mean(E): -21.76697563+0.00000000j, var(E): 0.22197315
-0.0
tensor(22.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=2.72............. Loss: -0.07832853, mean(E): -21.77483996-0.00000000j, var(E): 0.23157480
-0.0
tensor(22.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=2.72............. Loss: -0.06573396, mean(E): -21.77793846+0.00000000j, var(E): 0.08010053
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=2.72............. Loss: -0.10250751, mean(E): -21.78069607+0.00000000j, var(E): 0.17653894
-0.0
tensor(22.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=2.72............. Loss: -0.03664406, mean(E): -21.77778416+0.00000000j, var(E): 0.09882055
-0.0
tensor(22.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=2.72............. Loss: 0.17242180, mean(E): -21.79754855-0.00000000j, var(E): 0.27033868
-0.0
tensor(22.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=2.73............. Loss: -0.00236659, mean(E): -21.78131851+0.00000000j, var(E): 0.18206008
-0.0
tensor(22.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=2.72............. Loss: 0.01596915, mean(E): -21.78884690-0.00000000j, var(E): 0.18913167
-0.0
tensor(22.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=2.7............. Loss: 0.13344954, mean(E): -21.79563481+0.00000000j, var(E): 0.34802048
-0.0
tensor(22.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=2.72............. Loss: -0.02211242, mean(E): -21.79118454+0.00000000j, var(E): 0.11477363
-0.0
tensor(22.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=2.72............. Loss: -0.09476229, mean(E): -21.76920346+0.00000000j, var(E): 0.19603201
-0.0
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=2.71............. Loss: -0.07932072, mean(E): -21.77704412-0.00000000j, var(E): 0.16720260
-0.0
tensor(22.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=2.73............. Loss: -0.04847185, mean(E): -21.78203602-0.00000000j, var(E): 0.10109019
-0.0
tensor(22.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=2.71............. Loss: 0.05445344, mean(E): -21.80297069-0.00000000j, var(E): 0.09273447
-0.0
tensor(22.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=2.71............. Loss: -0.07909687, mean(E): -21.77775819-0.00000000j, var(E): 0.14870725
-0.0
tensor(22.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=2.72............. Loss: -0.06204129, mean(E): -21.78143084-0.00000000j, var(E): 0.09041554
-0.0
tensor(22.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=2.72............. Loss: -0.09518097, mean(E): -21.77558256+0.00000000j, var(E): 0.16125982
-0.0
tensor(22.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=2.71............. Loss: -0.06467793, mean(E): -21.76878883-0.00000000j, var(E): 0.08467072
-0.0
tensor(22.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=2.71............. Loss: -0.12500012, mean(E): -21.77299274+0.00000000j, var(E): 0.10884518
-0.0
tensor(22.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=2.73............. Loss: 0.01691738, mean(E): -21.78357892+0.00000000j, var(E): 0.08827176
-0.0
tensor(22.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=2.72............. Loss: 0.04939270, mean(E): -21.79977010-0.00000000j, var(E): 0.14582539
-0.0
tensor(22.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=2.72............. Loss: 0.10012582, mean(E): -21.79156998-0.00000000j, var(E): 0.15806068
-0.0
tensor(22.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=2.71............. Loss: 0.02726447, mean(E): -21.78040557-0.00000000j, var(E): 0.23756652
-0.0
tensor(22.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=2.72............. Loss: -0.05429619, mean(E): -21.77001511-0.00000000j, var(E): 0.27920226
-0.0
tensor(22.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=2.71............. Loss: 0.22261868, mean(E): -21.79540075+0.00000000j, var(E): 0.32556810
-0.0
tensor(22.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=2.72............. Loss: -0.07558905, mean(E): -21.76861204-0.00000000j, var(E): 0.10461947
-0.0
tensor(22.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=2.71............. Loss: 0.03628159, mean(E): -21.78615588+0.00000000j, var(E): 0.11340961
-0.0
tensor(22.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=2.72............. Loss: -0.13428596, mean(E): -21.77824138-0.00000000j, var(E): 0.15098606
-0.0
tensor(22.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=2.72............. Loss: -0.05894262, mean(E): -21.76810933+0.00000000j, var(E): 0.15883321
-0.0
tensor(22.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=2.73............. Loss: -0.18490209, mean(E): -21.75880086+0.00000000j, var(E): 0.12259494
-0.0
tensor(22.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=2.73............. Loss: 0.04222162, mean(E): -21.79327556-0.00000000j, var(E): 0.18560592
-0.0
tensor(22.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=2.73............. Loss: 0.02945391, mean(E): -21.79621802+0.00000000j, var(E): 0.18680831
-0.0
tensor(22.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=2.73............. Loss: -0.12466109, mean(E): -21.77753052-0.00000000j, var(E): 0.22083336
-0.0
tensor(22.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=2.71............. Loss: -0.22847846, mean(E): -21.75651696+0.00000000j, var(E): 0.15428626
-0.0
tensor(22.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=2.72............. Loss: 0.04636741, mean(E): -21.79749268+0.00000000j, var(E): 0.23434161
-0.0
tensor(22.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=2.72............. Loss: -0.04110276, mean(E): -21.77102826+0.00000000j, var(E): 0.10909469
-0.0
tensor(22.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=2.71............. Loss: 0.01609873, mean(E): -21.78682423-0.00000000j, var(E): 0.07617202
-0.0
tensor(22.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=2.73............. Loss: -0.03935941, mean(E): -21.77776619+0.00000000j, var(E): 0.10711277
-0.0
tensor(22.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=2.71............. Loss: 0.01369102, mean(E): -21.78706962-0.00000000j, var(E): 0.17851696
-0.0
tensor(22.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=2.72............. Loss: -0.03782869, mean(E): -21.78547269-0.00000000j, var(E): 0.14078853
-0.0
tensor(22.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=2.72............. Loss: -0.04721890, mean(E): -21.77706589-0.00000000j, var(E): 0.16037112
-0.0
tensor(22.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=2.72............. Loss: -0.08456902, mean(E): -21.78067442-0.00000000j, var(E): 0.10228951
-0.0
tensor(22.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=2.71............. Loss: -0.17657795, mean(E): -21.76218767-0.00000000j, var(E): 0.24438334
-0.0
tensor(22.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=2.72............. Loss: 0.08933917, mean(E): -21.79196897-0.00000000j, var(E): 0.18953612
-0.0
tensor(22.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=2.73............. Loss: 0.04874384, mean(E): -21.79803344+0.00000000j, var(E): 0.19381136
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=2.73............. Loss: 0.07365685, mean(E): -21.79308725-0.00000000j, var(E): 0.22847224
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=2.73............. Loss: -0.19213253, mean(E): -21.76252653-0.00000000j, var(E): 0.16998354
-0.0
tensor(22.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=2.73............. Loss: 0.10145918, mean(E): -21.80402093+0.00000000j, var(E): 0.25963800
-0.0
tensor(22.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=2.73............. Loss: 0.00731396, mean(E): -21.78188551-0.00000000j, var(E): 0.19932446
-0.0
tensor(22.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=2.72............. Loss: -0.09444101, mean(E): -21.78308066-0.00000000j, var(E): 0.15780776
-0.0
tensor(22.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=2.71............. Loss: 0.02610290, mean(E): -21.79736170+0.00000000j, var(E): 0.14961496
-0.0
tensor(22.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=2.71............. Loss: 0.04729564, mean(E): -21.79868449+0.00000000j, var(E): 0.14202865
-0.0
tensor(22.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=2.72............. Loss: -0.00924799, mean(E): -21.78383101+0.00000000j, var(E): 0.14568439
-0.0
tensor(22.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=2.72............. Loss: -0.09636199, mean(E): -21.77058172-0.00000000j, var(E): 0.21520566
-0.0
tensor(22.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=2.72............. Loss: 0.16033833, mean(E): -21.80979724-0.00000000j, var(E): 0.24047673
-0.0
tensor(22.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=2.73............. Loss: 0.01148418, mean(E): -21.78522675-0.00000000j, var(E): 0.08417104
-0.0
tensor(22.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=2.72............. Loss: 0.02056961, mean(E): -21.79667215+0.00000000j, var(E): 0.12172859
-0.0
tensor(22.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=2.73............. Loss: -0.17270453, mean(E): -21.75584495-0.00000000j, var(E): 0.12893393
-0.0
tensor(22.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=2.72............. Loss: 0.04629865, mean(E): -21.79497603+0.00000000j, var(E): 0.17558785
-0.0
tensor(22.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=2.72............. Loss: -0.05909990, mean(E): -21.78949147-0.00000000j, var(E): 0.14734921
-0.0
tensor(22.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=2.72............. Loss: -0.00677206, mean(E): -21.78903059-0.00000000j, var(E): 0.09078505
-0.0
tensor(22.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=2.73............. Loss: 0.12232499, mean(E): -21.80395539+0.00000000j, var(E): 0.10871725
-0.0
tensor(22.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=2.73............. Loss: -0.01179705, mean(E): -21.78050685+0.00000000j, var(E): 0.26704481
-0.0
tensor(22.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=2.73............. Loss: -0.10154243, mean(E): -21.76819712+0.00000000j, var(E): 0.10095444
-0.0
tensor(22.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=2.73............. Loss: 0.05420332, mean(E): -21.79802448-0.00000000j, var(E): 0.11292663
-0.0
tensor(22.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=2.73............. Loss: -0.06723574, mean(E): -21.78048871-0.00000000j, var(E): 0.08482602
-0.0
tensor(22.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=2.71............. Loss: -0.03049742, mean(E): -21.78177995-0.00000000j, var(E): 0.14410547
-0.0
tensor(22.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=2.72............. Loss: -0.16248649, mean(E): -21.75309106-0.00000000j, var(E): 0.20685084
-0.0
tensor(22.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=2.72............. Loss: -0.04335193, mean(E): -21.77745377-0.00000000j, var(E): 0.13317518
-0.0
tensor(22.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=2.72............. Loss: 0.17435160, mean(E): -21.81420195-0.00000000j, var(E): 0.21903809
-0.0
tensor(22.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=2.73............. Loss: 0.11324141, mean(E): -21.80343802-0.00000000j, var(E): 0.20642175
-0.0
tensor(22.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=2.73............. Loss: -0.06331889, mean(E): -21.78839629+0.00000000j, var(E): 0.15684083
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=2.73............. Loss: -0.13686273, mean(E): -21.78212128-0.00000000j, var(E): 0.13160530
-0.0
tensor(22.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=2.72............. Loss: -0.00841487, mean(E): -21.78732851+0.00000000j, var(E): 0.07750769
-0.0
tensor(22.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=2.71............. Loss: -0.14548399, mean(E): -21.77051143-0.00000000j, var(E): 0.14140327
-0.0
tensor(22.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=2.73............. Loss: 0.00162154, mean(E): -21.78798170+0.00000000j, var(E): 0.08505399
-0.0
tensor(22.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=2.72............. Loss: -0.07218740, mean(E): -21.77857368+0.00000000j, var(E): 0.13916989
-0.0
tensor(22.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=2.72............. Loss: -0.06942780, mean(E): -21.78086791-0.00000000j, var(E): 0.14386652
-0.0
tensor(22.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=2.73............. Loss: 0.00650409, mean(E): -21.78754235-0.00000000j, var(E): 0.23582553
-0.0
tensor(22.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=2.73............. Loss: -0.04721822, mean(E): -21.78439325-0.00000000j, var(E): 0.11320900
-0.0
tensor(22.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=2.73............. Loss: 0.13676982, mean(E): -21.80573070+0.00000000j, var(E): 0.11628308
-0.0
tensor(22.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=2.73............. Loss: -0.01189886, mean(E): -21.79141195+0.00000000j, var(E): 0.12155473
-0.0
tensor(22.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=2.72............. Loss: -0.08152402, mean(E): -21.77847744+0.00000000j, var(E): 0.15293989
-0.0
tensor(22.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=2.73............. Loss: 0.01761228, mean(E): -21.78469159+0.00000000j, var(E): 0.18861854
-0.0
tensor(22.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=2.72............. Loss: -0.19802434, mean(E): -21.76124187-0.00000000j, var(E): 0.20762957
-0.0
tensor(22.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=2.73............. Loss: -0.03660449, mean(E): -21.78448212+0.00000000j, var(E): 0.13623216
-0.0
tensor(22.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=2.72............. Loss: -0.05451631, mean(E): -21.78694962-0.00000000j, var(E): 0.10262707
-0.0
tensor(22.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=2.72............. Loss: 0.06636840, mean(E): -21.79910039-0.00000000j, var(E): 0.14321172
-0.0
tensor(22.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=2.73............. Loss: -0.03788548, mean(E): -21.77917353-0.00000000j, var(E): 0.17502614
-0.0
tensor(22.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=2.73............. Loss: -0.03073210, mean(E): -21.78147657+0.00000000j, var(E): 0.11094374
-0.0
tensor(22.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=2.73............. Loss: 0.07748328, mean(E): -21.80409781+0.00000000j, var(E): 0.13573511
-0.0
tensor(22.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=2.72............. Loss: -0.02965819, mean(E): -21.78488442+0.00000000j, var(E): 0.18471327
-0.0
tensor(22.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=2.71............. Loss: -0.15368517, mean(E): -21.76426147-0.00000000j, var(E): 0.17712704
-0.0
tensor(22.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=2.71............. Loss: -0.01325790, mean(E): -21.77829751+0.00000000j, var(E): 0.16139742
-0.0
tensor(22.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=2.72............. Loss: -0.02174974, mean(E): -21.78069828-0.00000000j, var(E): 0.12555406
-0.0
tensor(22.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=2.72............. Loss: 0.05444829, mean(E): -21.79438466+0.00000000j, var(E): 0.18914904
-0.0
tensor(22.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=2.73............. Loss: 0.09303987, mean(E): -21.79939928+0.00000000j, var(E): 0.19793867
-0.0
tensor(22.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=2.72............. Loss: -0.04701898, mean(E): -21.78694204+0.00000000j, var(E): 0.08276243
-0.0
tensor(22.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=2.73............. Loss: 0.03261754, mean(E): -21.79502072+0.00000000j, var(E): 0.08767120
-0.0
tensor(22.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=2.73............. Loss: -0.05533867, mean(E): -21.77763603+0.00000002j, var(E): 0.10415582
-0.0
tensor(22.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=2.73............. Loss: -0.04448682, mean(E): -21.78903434-0.00000074j, var(E): 0.11428821
-0.0
tensor(22.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=2.73............. Loss: -0.17882591, mean(E): -21.77405566-0.00001812j, var(E): 0.16548292
-0.0
tensor(22.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=2.73............. Loss: -0.02928206, mean(E): -21.78294064+0.00030758j, var(E): 0.10172547
-0.0
tensor(22.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=2.73............. Loss: 0.15555003, mean(E): -21.79297066+0.00002336j, var(E): 0.29225671
-0.0
tensor(22.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=2.73............. Loss: -0.03223191, mean(E): -21.77774393+0.00003820j, var(E): 0.11597906
-0.0
tensor(22.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=2.73............. Loss: -0.05958256, mean(E): -21.77910993-0.00005489j, var(E): 0.16456012
-0.0
tensor(22.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=2.73............. Loss: 0.06048786, mean(E): -21.79279353+0.00000110j, var(E): 0.14549700
-0.0
tensor(22.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=2.73............. Loss: -0.00148010, mean(E): -21.79301747+0.00011507j, var(E): 0.23755068
-0.0
tensor(22.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=2.73............. Loss: -0.10782362, mean(E): -21.77765757-0.00012691j, var(E): 0.22754306
-0.0
tensor(22.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=2.73............. Loss: -0.09084599, mean(E): -21.77307685+0.00008071j, var(E): 0.24134918
-0.0
tensor(22.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=2.73............. Loss: -0.09768655, mean(E): -21.75697716-0.00003026j, var(E): 0.24356167
-0.0
tensor(22.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=2.72............. Loss: -0.14276250, mean(E): -21.76527444-0.00004051j, var(E): 0.13353865
-0.0
tensor(22.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=2.73............. Loss: 0.04668425, mean(E): -21.79189595+0.00002426j, var(E): 0.07486203
-0.0
tensor(22.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=2.73............. Loss: 0.19554364, mean(E): -21.80535587-0.00007920j, var(E): 0.13876340
-0.0
tensor(22.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=2.73............. Loss: 0.10836229, mean(E): -21.79973598-0.00000953j, var(E): 0.32518311
-0.0
tensor(22.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=2.73............. Loss: 0.13168205, mean(E): -21.80269098+0.00001569j, var(E): 0.16039216
-0.0
tensor(22.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=2.73............. Loss: -0.10343522, mean(E): -21.76882548+0.00002184j, var(E): 0.13274123
-0.0
tensor(22.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=2.71............. Loss: -0.09513828, mean(E): -21.78115013-0.00006906j, var(E): 0.16894565
-0.0
tensor(22.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=2.71............. Loss: 0.00937145, mean(E): -21.79409953+0.00010612j, var(E): 0.14122353
-0.0
tensor(22.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=2.72............. Loss: -0.02494027, mean(E): -21.78345194+0.00000308j, var(E): 0.16768776
-0.0
tensor(22.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=2.72............. Loss: -0.17847285, mean(E): -21.76481227-0.00000473j, var(E): 0.19660745
-0.0
tensor(22.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=2.73............. Loss: -0.04663904, mean(E): -21.78684617+0.00004659j, var(E): 0.12563284
-0.0
tensor(22.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=2.73............. Loss: -0.19822970, mean(E): -21.76807332+0.00010460j, var(E): 0.21725038
-0.0
tensor(22.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=2.72............. Loss: 0.07103979, mean(E): -21.79503651+0.00003762j, var(E): 0.20967048
-0.0
tensor(22.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=2.73............. Loss: 0.17155952, mean(E): -21.80420857-0.00008715j, var(E): 0.19867530
-0.0
tensor(22.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=2.73............. Loss: -0.02495729, mean(E): -21.78283978-0.00006217j, var(E): 0.07775536
-0.0
tensor(22.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=2.73............. Loss: -0.01960524, mean(E): -21.78572460-0.00005484j, var(E): 0.09136661
-0.0
tensor(22.7713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=2.73............. Loss: -0.06423073, mean(E): -21.77565142-0.00004482j, var(E): 0.12586393
-0.0
tensor(22.7712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=2.73............. Loss: -0.08261145, mean(E): -21.77968428-0.00006993j, var(E): 0.11381193
-0.0
tensor(22.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=2.72............. Loss: 0.03475846, mean(E): -21.78930234+0.00003668j, var(E): 0.11188980
-0.0
tensor(22.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=2.73............. Loss: 0.16462556, mean(E): -21.81765347-0.00006879j, var(E): 0.16062387
-0.0
tensor(22.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=2.73............. Loss: -0.04646104, mean(E): -21.78814269+0.00019987j, var(E): 0.06632482
-0.0
tensor(22.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=2.73............. Loss: -0.06704356, mean(E): -21.77208345+0.00000392j, var(E): 0.08742211
-0.0
tensor(22.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=2.71............. Loss: 0.03027265, mean(E): -21.78891495+0.00006592j, var(E): 0.20707287
-0.0
tensor(22.7765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=2.73............. Loss: -0.04237258, mean(E): -21.78269808+0.00030949j, var(E): 0.11254562
-0.0
tensor(22.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=2.73............. Loss: 0.07799704, mean(E): -21.79544502+0.00013993j, var(E): 0.11476256
-0.0
tensor(22.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=2.73............. Loss: -0.03058936, mean(E): -21.77679998+0.00012815j, var(E): 0.07959460
-0.0
tensor(22.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=2.73............. Loss: -0.04397563, mean(E): -21.78251532-0.00002368j, var(E): 0.11587549
-0.0
tensor(22.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=2.73............. Loss: 0.14470195, mean(E): -21.81019432+0.00014185j, var(E): 0.21463680
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=2.72............. Loss: -0.04758377, mean(E): -21.78685667+0.00006797j, var(E): 0.13240557
-0.0
tensor(22.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=2.73............. Loss: 0.05030473, mean(E): -21.79801216-0.00017737j, var(E): 0.11359658
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=2.73............. Loss: -0.09098253, mean(E): -21.78089015-0.00003182j, var(E): 0.19063277
-0.0
tensor(22.7895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=2.72............. Loss: -0.11423825, mean(E): -21.77522153-0.00000144j, var(E): 0.13271280
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=2.72............. Loss: -0.05124023, mean(E): -21.78498538+0.00005906j, var(E): 0.07214443
-0.0
tensor(22.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=2.73............. Loss: 0.09602998, mean(E): -21.79866400-0.00001792j, var(E): 0.13612958
-0.0
tensor(22.7910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=2.71............. Loss: -0.04310348, mean(E): -21.78637457+0.00002749j, var(E): 0.06425798
-0.0
tensor(22.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=2.72............. Loss: -0.15741394, mean(E): -21.77341852-0.00001181j, var(E): 0.33257151
-0.0
tensor(22.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=2.73............. Loss: -0.08322530, mean(E): -21.78981639-0.00000002j, var(E): 0.09087761
-0.0
tensor(22.7988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=2.73............. Loss: -0.01177877, mean(E): -21.77927779-0.00000395j, var(E): 0.09935351
-0.0
tensor(22.7978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.7997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=2.72............. Loss: -0.20451436, mean(E): -21.76015249-0.00000286j, var(E): 0.18912291
-0.0
tensor(22.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=2.73............. Loss: 0.01764059, mean(E): -21.79124056+0.00001081j, var(E): 0.06650128
-0.0
tensor(22.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=2.73............. Loss: -0.02556488, mean(E): -21.78307973+0.00000308j, var(E): 0.16953885
-0.0
tensor(22.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=2.73............. Loss: 0.03998763, mean(E): -21.80030084-0.00000960j, var(E): 0.08863536
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=2.73............. Loss: 0.06783271, mean(E): -21.80303114-0.00000064j, var(E): 0.12597254
-0.0
tensor(22.8071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=2.73............. Loss: -0.09430277, mean(E): -21.78048147+0.00000872j, var(E): 0.13711459
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=2.71............. Loss: 0.06351829, mean(E): -21.79431942+0.00000264j, var(E): 0.08528816
-0.0
tensor(22.8070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=2.73............. Loss: 0.10587740, mean(E): -21.80292781-0.00000256j, var(E): 0.21401500
-0.0
tensor(22.8085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=2.73............. Loss: -0.02474262, mean(E): -21.77936782+0.00000467j, var(E): 0.05666355
-0.0
tensor(22.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=2.73............. Loss: 0.05287781, mean(E): -21.79392860+0.00000077j, var(E): 0.22468565
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=2.73............. Loss: 0.12163908, mean(E): -21.80106487+0.00000543j, var(E): 0.17541829
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=2.73............. Loss: 0.00530372, mean(E): -21.78750665-0.00000491j, var(E): 0.07755318
-0.0
tensor(22.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=2.73............. Loss: -0.06020985, mean(E): -21.77877467+0.00000066j, var(E): 0.16322284
-0.0
tensor(22.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=2.73............. Loss: -0.13973999, mean(E): -21.76872905+0.00000083j, var(E): 0.11757684
-0.0
tensor(22.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=2.72............. Loss: -0.08398201, mean(E): -21.78370214+0.00000083j, var(E): 0.10776870
-0.0
tensor(22.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=2.73............. Loss: -0.08373119, mean(E): -21.77532580-0.00000426j, var(E): 0.15699983
-0.0
tensor(22.8168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=2.73............. Loss: 0.19318138, mean(E): -21.80349027-0.00000069j, var(E): 0.24422853
-0.0
tensor(22.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=2.73............. Loss: 0.00420992, mean(E): -21.78957419-0.00000546j, var(E): 0.06236425
-0.0
tensor(22.8209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=2.73............. Loss: 0.04401780, mean(E): -21.78985174-0.00000092j, var(E): 0.21540294
-0.0
tensor(22.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=2.73............. Loss: 0.07015921, mean(E): -21.80149480+0.00000045j, var(E): 0.23776871
-0.0
tensor(22.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=2.72............. Loss: 0.06325054, mean(E): -21.80530210+0.00000094j, var(E): 0.29522023
-0.0
tensor(22.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=2.73............. Loss: 0.08377316, mean(E): -21.79460096+0.00000146j, var(E): 0.29906474
-0.0
tensor(22.8274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=2.72............. Loss: -0.06886154, mean(E): -21.77869906+0.00000058j, var(E): 0.12616398
-0.0
tensor(22.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=2.73............. Loss: -0.02317647, mean(E): -21.78527691+0.00000104j, var(E): 0.10621263
-0.0
tensor(22.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=2.72............. Loss: 0.06202070, mean(E): -21.79222674-0.00000067j, var(E): 0.15054639
-0.0
tensor(22.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=2.73............. Loss: 0.06726810, mean(E): -21.79803164-0.00000023j, var(E): 0.11477928
-0.0
tensor(22.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=2.73............. Loss: 0.17252132, mean(E): -21.80840142-0.00000050j, var(E): 0.16424011
-0.0
tensor(22.8401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=2.72............. Loss: -0.11311772, mean(E): -21.76435819-0.00000363j, var(E): 0.17215907
-0.0
tensor(22.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=2.73............. Loss: -0.14836855, mean(E): -21.75875106-0.00000020j, var(E): 0.17787017
-0.0
tensor(22.8434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=2.73............. Loss: 0.02818227, mean(E): -21.77450367-0.00000409j, var(E): 0.12604388
-0.0
tensor(22.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=2.73............. Loss: 0.00505335, mean(E): -21.79021634-0.00000496j, var(E): 0.14873597
-0.0
tensor(22.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=2.72............. Loss: 0.11358854, mean(E): -21.79317799-0.00000036j, var(E): 0.10117812
-0.0
tensor(22.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=2.72............. Loss: 0.05179009, mean(E): -21.79375557+0.00000775j, var(E): 0.17183489
-0.0
tensor(22.8398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=2.73............. Loss: -0.07686613, mean(E): -21.78361369-0.00003001j, var(E): 0.12428373
-0.0
tensor(22.8450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=2.73............. Loss: -0.15868264, mean(E): -21.76433657+0.00001036j, var(E): 0.15780027
-0.0
tensor(22.8494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=2.73............. Loss: 0.03926931, mean(E): -21.79065295+0.00003183j, var(E): 0.09832575
-0.0
tensor(22.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=2.73............. Loss: 0.03325667, mean(E): -21.80127991+0.00003128j, var(E): 0.12455043
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=2.72............. Loss: 0.09960237, mean(E): -21.81520156-0.00011625j, var(E): 0.19699402
-0.0
tensor(22.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=2.73............. Loss: -0.06469309, mean(E): -21.77724140-0.00003562j, var(E): 0.09565195
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=2.73............. Loss: -0.02746885, mean(E): -21.78250089-0.00009326j, var(E): 0.16372554
-0.0
tensor(22.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=2.72............. Loss: 0.01321766, mean(E): -21.79086185-0.00032123j, var(E): 0.15150078
-0.0
tensor(22.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=2.73............. Loss: 0.00746640, mean(E): -21.78455783+0.00013699j, var(E): 0.18091946
-0.0
tensor(22.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=2.73............. Loss: 0.13605837, mean(E): -21.80740589+0.00011395j, var(E): 0.12929708
-0.0
tensor(22.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=2.73............. Loss: 0.02920488, mean(E): -21.79146295+0.00024659j, var(E): 0.16462138
-0.0
tensor(22.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=2.73............. Loss: -0.00028336, mean(E): -21.78604234+0.00007626j, var(E): 0.09679027
-0.0
tensor(22.8557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=2.73............. Loss: -0.14867739, mean(E): -21.76310804-0.00003086j, var(E): 0.18543219
-0.0
tensor(22.8582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=2.71............. Loss: 0.06026574, mean(E): -21.78700246-0.00002917j, var(E): 0.12554927
-0.0
tensor(22.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=2.72............. Loss: 0.16260033, mean(E): -21.81178775-0.00023557j, var(E): 0.12796214
-0.0
tensor(22.8596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=2.73............. Loss: -0.06329973, mean(E): -21.77517720-0.00000359j, var(E): 0.07422563
-0.0
tensor(22.8614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=2.73............. Loss: -0.10879156, mean(E): -21.77195265-0.00004586j, var(E): 0.07652275
-0.0
tensor(22.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=2.73............. Loss: -0.04435066, mean(E): -21.78460990-0.00006365j, var(E): 0.13873822
-0.0
tensor(22.8669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=2.73............. Loss: -0.03706147, mean(E): -21.78834767+0.00005715j, var(E): 0.09375919
-0.0
tensor(22.8698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=2.73............. Loss: -0.01432191, mean(E): -21.78705662-0.00003782j, var(E): 0.10022994
-0.0
tensor(22.8719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=2.72............. Loss: -0.02826307, mean(E): -21.78876185+0.00002656j, var(E): 0.06609526
-0.0
tensor(22.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=2.73............. Loss: 0.04884448, mean(E): -21.80326628+0.00002805j, var(E): 0.09561322
-0.0
tensor(22.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=2.73............. Loss: -0.05338695, mean(E): -21.78062654-0.00008867j, var(E): 0.16916148
-0.0
tensor(22.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=2.73............. Loss: -0.02222946, mean(E): -21.78294900+0.00001957j, var(E): 0.09374211
-0.0
tensor(22.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=2.73............. Loss: -0.01572992, mean(E): -21.78698438-0.00001794j, var(E): 0.13557130
-0.0
tensor(22.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=2.72............. Loss: -0.12819374, mean(E): -21.77238833+0.00001536j, var(E): 0.12606182
-0.0
tensor(22.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=2.73............. Loss: -0.03366100, mean(E): -21.79450168+0.00001818j, var(E): 0.07510572
-0.0
tensor(22.8840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=2.73............. Loss: 0.18120116, mean(E): -21.80646197+0.00001519j, var(E): 0.33750471
-0.0
tensor(22.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=2.72............. Loss: -0.10799744, mean(E): -21.77677895-0.00002007j, var(E): 0.18230067
-0.0
tensor(22.8835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=2.73............. Loss: -0.01711876, mean(E): -21.78786570+0.00000391j, var(E): 0.07978500
-0.0
tensor(22.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=2.71............. Loss: 0.01400030, mean(E): -21.79046298+0.00001434j, var(E): 0.08442165
-0.0
tensor(22.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=2.73............. Loss: 0.07226933, mean(E): -21.78945056-0.00000411j, var(E): 0.19295970
-0.0
tensor(22.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=2.73............. Loss: 0.05947072, mean(E): -21.78500104-0.00000084j, var(E): 0.25810337
-0.0
tensor(22.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=2.72............. Loss: -0.03886066, mean(E): -21.78848772+0.00000811j, var(E): 0.12456726
-0.0
tensor(22.8921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=2.73............. Loss: 0.05724330, mean(E): -21.78458082-0.00000809j, var(E): 0.17984341
-0.0
tensor(22.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=2.73............. Loss: 0.06144870, mean(E): -21.79551582-0.00000523j, var(E): 0.16957411
-0.0
tensor(22.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=2.73............. Loss: -0.01491121, mean(E): -21.77758891-0.00001182j, var(E): 0.13401846
-0.0
tensor(22.8948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=2.73............. Loss: 0.06945122, mean(E): -21.78997443-0.00000624j, var(E): 0.16588144
-0.0
tensor(22.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=2.73............. Loss: 0.09121716, mean(E): -21.80571213+0.00000081j, var(E): 0.17249662
-0.0
tensor(22.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=2.72............. Loss: 0.09050621, mean(E): -21.79144259+0.00000000j, var(E): 0.14961067
-0.0
tensor(22.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=2.73............. Loss: 0.06434437, mean(E): -21.79228170-0.00000028j, var(E): 0.37250128
-0.0
tensor(22.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=2.73............. Loss: -0.06662465, mean(E): -21.77721769+0.00000347j, var(E): 0.13785044
-0.0
tensor(22.8959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.8998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=2.73............. Loss: -0.04328721, mean(E): -21.78161017-0.00000041j, var(E): 0.07198160
-0.0
tensor(22.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=2.73............. Loss: -0.04392137, mean(E): -21.78612948-0.00000020j, var(E): 0.12505175
-0.0
tensor(22.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=2.73............. Loss: -0.06081058, mean(E): -21.77396788+0.00000870j, var(E): 0.14369039
-0.0
tensor(22.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=2.73............. Loss: 0.01053918, mean(E): -21.79105295+0.00000291j, var(E): 0.08747669
-0.0
tensor(22.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=2.72............. Loss: -0.02885383, mean(E): -21.78861425+0.00000630j, var(E): 0.09033288
-0.0
tensor(22.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=2.72............. Loss: -0.15411642, mean(E): -21.76944149-0.00000500j, var(E): 0.10349068
-0.0
tensor(22.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=2.73............. Loss: 0.04796314, mean(E): -21.78895639+0.00000184j, var(E): 0.14199313
-0.0
tensor(22.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=2.72............. Loss: 0.06384624, mean(E): -21.80014282+0.00000014j, var(E): 0.15476264
-0.0
tensor(22.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=2.73............. Loss: 0.20783251, mean(E): -21.82081973+0.00000138j, var(E): 0.46607702
-0.0
tensor(22.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=2.73............. Loss: -0.16720183, mean(E): -21.76532376-0.00000196j, var(E): 0.17399333
-0.0
tensor(22.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=2.73............. Loss: 0.02802371, mean(E): -21.78726992-0.00000114j, var(E): 0.16286712
-0.0
tensor(22.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=2.73............. Loss: 0.02216225, mean(E): -21.78910404+0.00000170j, var(E): 0.14952574
-0.0
tensor(22.9118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=2.73............. Loss: 0.02902603, mean(E): -21.79323531+0.00000382j, var(E): 0.11087398
-0.0
tensor(22.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=2.73............. Loss: -0.00185487, mean(E): -21.78617997+0.00000251j, var(E): 0.10125176
-0.0
tensor(22.9178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=2.73............. Loss: -0.01610419, mean(E): -21.78385402-0.00000176j, var(E): 0.20241393
-0.0
tensor(22.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=2.73............. Loss: -0.02488934, mean(E): -21.78745478-0.00000017j, var(E): 0.21073634
-0.0
tensor(22.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=2.72............. Loss: 0.02850368, mean(E): -21.78960572+0.00000919j, var(E): 0.19528841
-0.0
tensor(22.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=2.73............. Loss: -0.07580814, mean(E): -21.78353627+0.00000914j, var(E): 0.10327317
-0.0
tensor(22.9208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=2.73............. Loss: -0.09410899, mean(E): -21.78542189+0.00000942j, var(E): 0.13769806
-0.0
tensor(22.9200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=2.73............. Loss: 0.13459329, mean(E): -21.80269082+0.00000211j, var(E): 0.17258407
-0.0
tensor(22.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=2.73............. Loss: 0.05230990, mean(E): -21.79086610+0.00000584j, var(E): 0.10752223
-0.0
tensor(22.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=2.73............. Loss: -0.08948083, mean(E): -21.77498153-0.00000655j, var(E): 0.10864441
-0.0
tensor(22.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=2.73............. Loss: -0.06594223, mean(E): -21.77558343-0.00000523j, var(E): 0.17131118
-0.0
tensor(22.9303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=2.71............. Loss: 0.06284910, mean(E): -21.79817607-0.00003106j, var(E): 0.17505084
-0.0
tensor(22.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=2.72............. Loss: -0.03118779, mean(E): -21.77622140+0.00002894j, var(E): 0.16891511
-0.0
tensor(22.9368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=2.72............. Loss: 0.06162951, mean(E): -21.78834746+0.00002271j, var(E): 0.09858998
-0.0
tensor(22.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=2.72............. Loss: 0.00218016, mean(E): -21.78016538+0.00002450j, var(E): 0.24731658
-0.0
tensor(22.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=2.73............. Loss: -0.03318397, mean(E): -21.78103542-0.00001244j, var(E): 0.15100263
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=2.73............. Loss: 0.09630507, mean(E): -21.79858129+0.00031837j, var(E): 0.16500102
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=2.73............. Loss: 0.08581208, mean(E): -21.80271966-0.00027406j, var(E): 0.19024527
-0.0
tensor(22.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=2.73............. Loss: 0.06007375, mean(E): -21.80447708-0.00048641j, var(E): 0.12442219
-0.0
tensor(22.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=2.73............. Loss: 0.08574718, mean(E): -21.80126872+0.00034380j, var(E): 0.10505774
-0.0
tensor(22.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=2.73............. Loss: -0.10501575, mean(E): -21.77440399-0.00010016j, var(E): 0.11205167
-0.0
tensor(22.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=2.73............. Loss: -0.00871989, mean(E): -21.79080883-0.00024616j, var(E): 0.12801838
-0.0
tensor(22.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=2.72............. Loss: 0.02618953, mean(E): -21.79301527+0.00020717j, var(E): 0.13706095
-0.0
tensor(22.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=2.73............. Loss: 0.01090773, mean(E): -21.78967602+0.00005949j, var(E): 0.14438664
-0.0
tensor(22.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=2.73............. Loss: 0.14388218, mean(E): -21.80204322-0.00013469j, var(E): 0.26779631
-0.0
tensor(22.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=2.73............. Loss: -0.11873157, mean(E): -21.77739324-0.00006280j, var(E): 0.12549884
-0.0
tensor(22.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=2.71............. Loss: -0.09343653, mean(E): -21.78119610+0.00005116j, var(E): 0.09387012
-0.0
tensor(22.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=2.72............. Loss: 0.03435726, mean(E): -21.78938999-0.00001394j, var(E): 0.15340024
-0.0
tensor(22.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=2.71............. Loss: 0.04811661, mean(E): -21.80985694+0.00006678j, var(E): 0.07722755
-0.0
tensor(22.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=2.73............. Loss: -0.01950167, mean(E): -21.79384858+0.00003380j, var(E): 0.15643649
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=2.73............. Loss: -0.05380725, mean(E): -21.78374612+0.00002484j, var(E): 0.17797924
-0.0
tensor(22.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=2.72............. Loss: -0.24211210, mean(E): -21.77149680+0.00001756j, var(E): 0.17423828
-0.0
tensor(22.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=2.73............. Loss: -0.01347441, mean(E): -21.78415676-0.00002077j, var(E): 0.18477764
-0.0
tensor(22.9567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=2.72............. Loss: 0.05476666, mean(E): -21.80043126-0.00001390j, var(E): 0.06657781
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=2.73............. Loss: 0.01393605, mean(E): -21.78906537-0.00000688j, var(E): 0.10473047
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=2.73............. Loss: -0.00315151, mean(E): -21.78855376+0.00001927j, var(E): 0.11904418
-0.0
tensor(22.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=2.72............. Loss: -0.14522079, mean(E): -21.77344489-0.00000491j, var(E): 0.08923320
-0.0
tensor(22.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=2.72............. Loss: -0.20526265, mean(E): -21.76509374-0.00000083j, var(E): 0.10998875
-0.0
tensor(22.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=2.72............. Loss: -0.01782328, mean(E): -21.77574847-0.00000232j, var(E): 0.08155326
-0.0
tensor(22.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=2.72............. Loss: -0.03077663, mean(E): -21.78835178+0.00000165j, var(E): 0.15034609
-0.0
tensor(22.9674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=2.71............. Loss: 0.02888501, mean(E): -21.78597757+0.00000049j, var(E): 0.12997717
-0.0
tensor(22.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=2.72............. Loss: 0.12418282, mean(E): -21.80415034+0.00000119j, var(E): 0.17237074
-0.0
tensor(22.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=2.72............. Loss: 0.01881020, mean(E): -21.79499780-0.00000099j, var(E): 0.21771526
-0.0
tensor(22.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=2.73............. Loss: -0.00428824, mean(E): -21.79332619-0.00000052j, var(E): 0.08283997
-0.0
tensor(22.9735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=2.72............. Loss: -0.00443432, mean(E): -21.79046909+0.00000082j, var(E): 0.10252179
-0.0
tensor(22.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=2.73............. Loss: -0.03510451, mean(E): -21.78486047-0.00000024j, var(E): 0.06632126
-0.0
tensor(22.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=2.73............. Loss: 0.08815136, mean(E): -21.79731334-0.00000010j, var(E): 0.12090591
-0.0
tensor(22.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=2.73............. Loss: -0.06597719, mean(E): -21.78005729-0.00000045j, var(E): 0.11132752
-0.0
tensor(22.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=2.73............. Loss: 0.00174558, mean(E): -21.78516047-0.00000029j, var(E): 0.09369715
-0.0
tensor(22.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=2.72............. Loss: -0.11266435, mean(E): -21.78165005-0.00000005j, var(E): 0.13327779
-0.0
tensor(22.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=2.73............. Loss: 0.22958260, mean(E): -21.81060543-0.00000020j, var(E): 0.28442106
-0.0
tensor(22.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=2.73............. Loss: -0.01753961, mean(E): -21.78192992-0.00000015j, var(E): 0.11496554
-0.0
tensor(22.9741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=2.73............. Loss: 0.02375153, mean(E): -21.78596674-0.00000021j, var(E): 0.21859490
-0.0
tensor(22.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=2.73............. Loss: -0.03139222, mean(E): -21.78740523+0.00000020j, var(E): 0.15346754
-0.0
tensor(22.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=2.72............. Loss: 0.06096700, mean(E): -21.78980161+0.00000000j, var(E): 0.12875783
-0.0
tensor(22.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=2.73............. Loss: -0.01142118, mean(E): -21.78605502-0.00000013j, var(E): 0.07603147
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=2.72............. Loss: 0.06345643, mean(E): -21.79461744+0.00000010j, var(E): 0.15652594
-0.0
tensor(22.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=2.73............. Loss: -0.06936691, mean(E): -21.78188367+0.00000001j, var(E): 0.09143092
-0.0
tensor(22.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=2.73............. Loss: 0.01133546, mean(E): -21.79366338-0.00000004j, var(E): 0.06057336
-0.0
tensor(22.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=2.72............. Loss: 0.06425252, mean(E): -21.78811722+0.00000004j, var(E): 0.16800743
-0.0
tensor(22.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=2.73............. Loss: 0.08417668, mean(E): -21.80733798-0.00000004j, var(E): 0.09647189
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=2.73............. Loss: -0.18793208, mean(E): -21.76934310-0.00000002j, var(E): 0.17791591
-0.0
tensor(22.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=2.72............. Loss: -0.14106422, mean(E): -21.76905337+0.00000000j, var(E): 0.08667495
-0.0
tensor(22.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=2.71............. Loss: 0.06614595, mean(E): -21.79767385+0.00000002j, var(E): 0.21073529
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=2.72............. Loss: -0.08909118, mean(E): -21.77121879+0.00000002j, var(E): 0.13613435
-0.0
tensor(22.9836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=2.72............. Loss: 0.02207140, mean(E): -21.78750318+0.00000001j, var(E): 0.27058794
-0.0
tensor(22.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=2.72............. Loss: 0.02939725, mean(E): -21.80183689-0.00000002j, var(E): 0.13204854
-0.0
tensor(22.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=2.73............. Loss: -0.10098932, mean(E): -21.78563501-0.00000001j, var(E): 0.12812779
-0.0
tensor(22.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=2.73............. Loss: -0.09981603, mean(E): -21.78072731+0.00000001j, var(E): 0.22786528
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=2.72............. Loss: -0.08831969, mean(E): -21.78877125+0.00000001j, var(E): 0.12608841
-0.0
tensor(22.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=2.72............. Loss: -0.04777651, mean(E): -21.78757541+0.00000000j, var(E): 0.07806307
-0.0
tensor(22.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=2.72............. Loss: 0.02969544, mean(E): -21.79251674-0.00000001j, var(E): 0.09141876
-0.0
tensor(22.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(22.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=2.71............. Loss: -0.05004621, mean(E): -21.77776340+0.00000000j, var(E): 0.11709547
-0.0
tensor(22.9996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=2.73............. Loss: 0.11885397, mean(E): -21.80609372+0.00000000j, var(E): 0.15551165
-0.0
tensor(23.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=2.72............. Loss: -0.01126052, mean(E): -21.79300817-0.00000000j, var(E): 0.10487774
-0.0
tensor(23.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=2.73............. Loss: 0.04592508, mean(E): -21.79230370-0.00000000j, var(E): 0.12544206
-0.0
tensor(23.0025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=2.72............. Loss: -0.17123424, mean(E): -21.77194465-0.00000000j, var(E): 0.15543199
-0.0
tensor(23.0045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=2.72............. Loss: 0.02523007, mean(E): -21.79158900+0.00000000j, var(E): 0.10566397
-0.0
tensor(23.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=2.73............. Loss: -0.05775965, mean(E): -21.77333562-0.00000001j, var(E): 0.17079296
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=2.73............. Loss: 0.17014506, mean(E): -21.80797513+0.00000000j, var(E): 0.12443860
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=2.73............. Loss: -0.00675948, mean(E): -21.78560618+0.00000001j, var(E): 0.09057767
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=2.72............. Loss: -0.07634660, mean(E): -21.78297663-0.00000001j, var(E): 0.13023174
-0.0
tensor(23.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=2.73............. Loss: 0.03433315, mean(E): -21.79627266-0.00000000j, var(E): 0.07731640
-0.0
tensor(23.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=2.73............. Loss: -0.03016651, mean(E): -21.78100034-0.00000001j, var(E): 0.11153220
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=2.73............. Loss: -0.09568323, mean(E): -21.77583982+0.00000002j, var(E): 0.07529136
-0.0
tensor(23.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=2.73............. Loss: 0.12181762, mean(E): -21.80840373-0.00000002j, var(E): 0.08647145
-0.0
tensor(23.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=2.73............. Loss: -0.07885700, mean(E): -21.78432906+0.00000000j, var(E): 0.11194918
-0.0
tensor(23.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=2.73............. Loss: 0.05048973, mean(E): -21.80125782+0.00000001j, var(E): 0.09899190
-0.0
tensor(23.0084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=2.73............. Loss: -0.03593273, mean(E): -21.78568578+0.00000004j, var(E): 0.07432634
-0.0
tensor(23.0103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=2.73............. Loss: 0.09789017, mean(E): -21.79512170+0.00000001j, var(E): 0.20682788
-0.0
tensor(23.0132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=2.71............. Loss: 0.02274079, mean(E): -21.79460228+0.00000002j, var(E): 0.16619501
-0.0
tensor(23.0138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=2.71............. Loss: -0.00739608, mean(E): -21.79024397+0.00000002j, var(E): 0.06074153
-0.0
tensor(23.0162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=2.73............. Loss: 0.02962936, mean(E): -21.78978666+0.00000002j, var(E): 0.09482809
-0.0
tensor(23.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=2.73............. Loss: -0.04310213, mean(E): -21.78213485+0.00000001j, var(E): 0.05748858
-0.0
tensor(23.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=2.73............. Loss: 0.00539792, mean(E): -21.79021903-0.00000001j, var(E): 0.19195876
-0.0
tensor(23.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=2.73............. Loss: 0.00458830, mean(E): -21.79658916-0.00000002j, var(E): 0.20767530
-0.0
tensor(23.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=2.72............. Loss: -0.06849249, mean(E): -21.77925409+0.00000000j, var(E): 0.06452824
-0.0
tensor(23.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=2.73............. Loss: 0.08356238, mean(E): -21.79457919-0.00000002j, var(E): 0.16392278
-0.0
tensor(23.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=2.73............. Loss: 0.01236661, mean(E): -21.78816419-0.00000001j, var(E): 0.06028370
-0.0
tensor(23.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=2.73............. Loss: -0.02455661, mean(E): -21.78525057-0.00000000j, var(E): 0.20214915
-0.0
tensor(23.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=2.73............. Loss: 0.00948653, mean(E): -21.79195036+0.00000004j, var(E): 0.07235536
-0.0
tensor(23.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=2.72............. Loss: -0.19367034, mean(E): -21.77139083-0.00000000j, var(E): 0.18037902
-0.0
tensor(23.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=2.73............. Loss: 0.00235557, mean(E): -21.79454055-0.00000006j, var(E): 0.17175038
-0.0
tensor(23.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=2.73............. Loss: -0.07858664, mean(E): -21.77283908-0.00000001j, var(E): 0.11332898
-0.0
tensor(23.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=2.73............. Loss: 0.13373946, mean(E): -21.79734483-0.00000033j, var(E): 0.16920015
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=2.73............. Loss: 0.00733829, mean(E): -21.79600515+0.00000003j, var(E): 0.12041317
-0.0
tensor(23.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=2.72............. Loss: 0.02389381, mean(E): -21.79441818+0.00000083j, var(E): 0.18433329
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=2.72............. Loss: -0.06281942, mean(E): -21.78159828+0.00001105j, var(E): 0.11761140
-0.0
tensor(23.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=2.73............. Loss: 0.00849916, mean(E): -21.78439083-0.00009792j, var(E): 0.17923765
-0.0
tensor(23.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=2.73............. Loss: -0.02318179, mean(E): -21.79317149+0.00032862j, var(E): 0.07658343
-0.0
tensor(23.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=2.73............. Loss: 0.03975984, mean(E): -21.79744930-0.00022888j, var(E): 0.07642077
-0.0
tensor(23.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=2.73............. Loss: -0.01983602, mean(E): -21.78224437-0.00001071j, var(E): 0.12219186
-0.0
tensor(23.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=2.73............. Loss: 0.00036816, mean(E): -21.78791970-0.00008825j, var(E): 0.10462835
-0.0
tensor(23.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=2.73............. Loss: 0.03052039, mean(E): -21.78946830+0.00002051j, var(E): 0.14547435
-0.0
tensor(23.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=2.73............. Loss: 0.08793402, mean(E): -21.80693329+0.00009640j, var(E): 0.15835636
-0.0
tensor(23.0495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=2.72............. Loss: -0.00679878, mean(E): -21.79213162-0.00021204j, var(E): 0.14647099
-0.0
tensor(23.0514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=2.72............. Loss: 0.17518369, mean(E): -21.81043610-0.00004522j, var(E): 0.23176682
-0.0
tensor(23.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=2.71............. Loss: -0.05909827, mean(E): -21.77921834+0.00003871j, var(E): 0.09050095
-0.0
tensor(23.0517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=2.73............. Loss: 0.10743628, mean(E): -21.79947867-0.00002224j, var(E): 0.12578752
-0.0
tensor(23.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=2.73............. Loss: -0.00794480, mean(E): -21.78424945-0.00006821j, var(E): 0.24942745
-0.0
tensor(23.0553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=2.73............. Loss: -0.04859707, mean(E): -21.77523081+0.00000368j, var(E): 0.07002707
-0.0
tensor(23.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=2.73............. Loss: -0.11052250, mean(E): -21.77713170+0.00004265j, var(E): 0.11216601
-0.0
tensor(23.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=2.73............. Loss: -0.03470329, mean(E): -21.79477105-0.00000577j, var(E): 0.07006058
-0.0
tensor(23.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=2.72............. Loss: -0.01396998, mean(E): -21.79050724-0.00001580j, var(E): 0.09374364
-0.0
tensor(23.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=2.73............. Loss: -0.04444014, mean(E): -21.78015276+0.00000411j, var(E): 0.13288563
-0.0
tensor(23.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=2.72............. Loss: -0.03175104, mean(E): -21.79266431+0.00000653j, var(E): 0.09331696
-0.0
tensor(23.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=2.72............. Loss: -0.06844282, mean(E): -21.78162941+0.00000401j, var(E): 0.06175380
-0.0
tensor(23.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=2.72............. Loss: -0.19528644, mean(E): -21.77314938+0.00000689j, var(E): 0.13482340
-0.0
tensor(23.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=2.73............. Loss: 0.10919599, mean(E): -21.80516928-0.00000063j, var(E): 0.13626528
-0.0
tensor(23.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=2.71............. Loss: -0.11779865, mean(E): -21.77727389+0.00000489j, var(E): 0.11327152
-0.0
tensor(23.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=2.72............. Loss: 0.02385984, mean(E): -21.78789709+0.00001247j, var(E): 0.13157131
-0.0
tensor(23.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=2.73............. Loss: 0.10500336, mean(E): -21.80329412+0.00000539j, var(E): 0.24527631
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=2.72............. Loss: -0.15358767, mean(E): -21.77850055-0.00000356j, var(E): 0.13271520
-0.0
tensor(23.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=2.73............. Loss: 0.23463020, mean(E): -21.81585251-0.00000105j, var(E): 0.32373970
-0.0
tensor(23.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=2.73............. Loss: -0.07113175, mean(E): -21.78154382-0.00001251j, var(E): 0.12304638
-0.0
tensor(23.0768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=2.72............. Loss: -0.07102118, mean(E): -21.79129023+0.00000746j, var(E): 0.09662715
-0.0
tensor(23.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=2.73............. Loss: -0.16502362, mean(E): -21.77475132+0.00000975j, var(E): 0.13775742
-0.0
tensor(23.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=2.72............. Loss: -0.15373387, mean(E): -21.76927017-0.00000297j, var(E): 0.10974844
-0.0
tensor(23.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=2.73............. Loss: 0.02643811, mean(E): -21.79415701-0.00000455j, var(E): 0.19571169
-0.0
tensor(23.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=2.73............. Loss: 0.00014026, mean(E): -21.77426932-0.00000762j, var(E): 0.12537446
-0.0
tensor(23.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=2.73............. Loss: -0.07469050, mean(E): -21.78898352+0.00001309j, var(E): 0.14505943
-0.0
tensor(23.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=2.71............. Loss: -0.01646277, mean(E): -21.79238257-0.00001020j, var(E): 0.16833323
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=2.73............. Loss: -0.00342318, mean(E): -21.78667842+0.00000480j, var(E): 0.13786198
-0.0
tensor(23.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=2.72............. Loss: -0.05385885, mean(E): -21.79121091-0.00001281j, var(E): 0.06574003
-0.0
tensor(23.0848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=2.73............. Loss: -0.10351717, mean(E): -21.78404214+0.00000619j, var(E): 0.11350477
-0.0
tensor(23.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=2.73............. Loss: 0.18336359, mean(E): -21.81095264+0.00000256j, var(E): 0.24529534
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=2.73............. Loss: 0.06322662, mean(E): -21.79056300+0.00000766j, var(E): 0.22991277
-0.0
tensor(23.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=2.73............. Loss: 0.01918030, mean(E): -21.79548178-0.00000221j, var(E): 0.19025549
-0.0
tensor(23.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=2.73............. Loss: -0.20006662, mean(E): -21.76597450-0.00000506j, var(E): 0.19846033
-0.0
tensor(23.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=2.73............. Loss: 0.01620919, mean(E): -21.79216223+0.00000228j, var(E): 0.13578982
-0.0
tensor(23.0886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=2.73............. Loss: 0.00153017, mean(E): -21.79457225-0.00001095j, var(E): 0.08716421
-0.0
tensor(23.0908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=2.73............. Loss: 0.11038807, mean(E): -21.81013089+0.00000610j, var(E): 0.16604298
-0.0
tensor(23.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=2.72............. Loss: -0.02550704, mean(E): -21.78853161-0.00000232j, var(E): 0.08247342
-0.0
tensor(23.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=2.73............. Loss: 0.08049622, mean(E): -21.80017220-0.00000660j, var(E): 0.11582447
-0.0
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=2.71............. Loss: 0.05273429, mean(E): -21.79529919-0.00000516j, var(E): 0.22056481
-0.0
tensor(23.1006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=2.73............. Loss: -0.15795956, mean(E): -21.77757188-0.00000302j, var(E): 0.10617988
-0.0
tensor(23.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=2.71............. Loss: -0.03390427, mean(E): -21.78651742-0.00001186j, var(E): 0.11220275
-0.0
tensor(23.0977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=2.73............. Loss: 0.04926110, mean(E): -21.79748577-0.00000802j, var(E): 0.12655171
-0.0
tensor(23.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=2.73............. Loss: 0.12097200, mean(E): -21.79990513-0.00002078j, var(E): 0.19302332
-0.0
tensor(23.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=2.73............. Loss: -0.05870980, mean(E): -21.78219663+0.00001178j, var(E): 0.09882368
-0.0
tensor(23.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=2.73............. Loss: 0.05819348, mean(E): -21.80012798+0.00000169j, var(E): 0.11371613
-0.0
tensor(23.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=2.71............. Loss: -0.10116425, mean(E): -21.78233760+0.00008277j, var(E): 0.13884808
-0.0
tensor(23.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=2.72............. Loss: -0.13757429, mean(E): -21.76315389+0.00006328j, var(E): 0.12642809
-0.0
tensor(23.1064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=2.73............. Loss: -0.02535387, mean(E): -21.77815906-0.00008669j, var(E): 0.06383570
-0.0
tensor(23.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=2.72............. Loss: -0.15088196, mean(E): -21.77074223-0.00001033j, var(E): 0.11688658
-0.0
tensor(23.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=2.73............. Loss: -0.03043523, mean(E): -21.78648964+0.00012155j, var(E): 0.09223295
-0.0
tensor(23.1110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=2.71............. Loss: -0.02774141, mean(E): -21.78722566+0.00000010j, var(E): 0.07721072
-0.0
tensor(23.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=2.72............. Loss: -0.10887137, mean(E): -21.77812102+0.00008168j, var(E): 0.20538658
-0.0
tensor(23.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=2.72............. Loss: -0.00222348, mean(E): -21.78624732+0.00009794j, var(E): 0.31728355
-0.0
tensor(23.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=2.73............. Loss: -0.02054869, mean(E): -21.79650427-0.00022145j, var(E): 0.10450788
-0.0
tensor(23.1142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=2.72............. Loss: -0.12966435, mean(E): -21.77923416-0.00000229j, var(E): 0.09155342
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=2.73............. Loss: 0.04673867, mean(E): -21.79668742-0.00002202j, var(E): 0.10830502
-0.0
tensor(23.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=2.73............. Loss: 0.02709466, mean(E): -21.79757762+0.00013179j, var(E): 0.13527705
-0.0
tensor(23.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=2.73............. Loss: -0.03345361, mean(E): -21.79307310-0.00005982j, var(E): 0.14118779
-0.0
tensor(23.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=2.73............. Loss: 0.07364768, mean(E): -21.79160206+0.00007319j, var(E): 0.35994218
-0.0
tensor(23.1213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=2.72............. Loss: -0.03013761, mean(E): -21.77505374-0.00005143j, var(E): 0.08283996
-0.0
tensor(23.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=2.72............. Loss: -0.05209953, mean(E): -21.78295385-0.00009207j, var(E): 0.07127860
-0.0
tensor(23.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=2.73............. Loss: -0.01455259, mean(E): -21.78788084+0.00003288j, var(E): 0.07939883
-0.0
tensor(23.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=2.72............. Loss: -0.04143895, mean(E): -21.78795243+0.00014238j, var(E): 0.11603628
-0.0
tensor(23.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=2.72............. Loss: 0.01838061, mean(E): -21.78620602-0.00007991j, var(E): 0.10779309
-0.0
tensor(23.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=2.73............. Loss: -0.13327532, mean(E): -21.78072806+0.00027254j, var(E): 0.19510480
-0.0
tensor(23.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=2.73............. Loss: -0.04588785, mean(E): -21.78763151+0.00006659j, var(E): 0.10973264
-0.0
tensor(23.1291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=2.72............. Loss: 0.01667641, mean(E): -21.79812572-0.00000450j, var(E): 0.14318264
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=2.73............. Loss: -0.08532096, mean(E): -21.78374717-0.00007772j, var(E): 0.10416302
-0.0
tensor(23.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=2.73............. Loss: -0.01121866, mean(E): -21.78789620+0.00012519j, var(E): 0.09565165
-0.0
tensor(23.1317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=2.73............. Loss: -0.01200369, mean(E): -21.79373155-0.00004534j, var(E): 0.11893802
-0.0
tensor(23.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=2.73............. Loss: -0.08648666, mean(E): -21.77403804+0.00002326j, var(E): 0.13970888
-0.0
tensor(23.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=2.72............. Loss: 0.01493191, mean(E): -21.79224749+0.00002322j, var(E): 0.09491343
-0.0
tensor(23.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=2.73............. Loss: -0.02043086, mean(E): -21.78244014-0.00001388j, var(E): 0.06768531
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=2.73............. Loss: -0.08231229, mean(E): -21.77802466-0.00004099j, var(E): 0.11718889
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=2.73............. Loss: -0.07150740, mean(E): -21.77854987+0.00008444j, var(E): 0.14401970
-0.0
tensor(23.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=2.73............. Loss: -0.06586387, mean(E): -21.77928275+0.00005213j, var(E): 0.09062702
-0.0
tensor(23.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=2.72............. Loss: -0.01432921, mean(E): -21.79132124+0.00001148j, var(E): 0.06189300
-0.0
tensor(23.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=2.71............. Loss: -0.09707559, mean(E): -21.77987903+0.00002764j, var(E): 0.07263642
-0.0
tensor(23.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=2.73............. Loss: -0.02070978, mean(E): -21.79159266+0.00001604j, var(E): 0.07689708
-0.0
tensor(23.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=2.72............. Loss: 0.14456975, mean(E): -21.81118208+0.00002705j, var(E): 0.23644142
-0.0
tensor(23.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=2.72............. Loss: 0.11210042, mean(E): -21.80297761-0.00004495j, var(E): 0.26887399
-0.0
tensor(23.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=2.72............. Loss: -0.03892423, mean(E): -21.79054458-0.00003338j, var(E): 0.08025565
-0.0
tensor(23.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=2.73............. Loss: -0.09640717, mean(E): -21.77650309-0.00003322j, var(E): 0.13242564
-0.0
tensor(23.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=2.73............. Loss: 0.02637940, mean(E): -21.79371079+0.00001023j, var(E): 0.13115844
-0.0
tensor(23.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=2.73............. Loss: -0.16294286, mean(E): -21.76961806-0.00001438j, var(E): 0.14678871
-0.0
tensor(23.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=2.73............. Loss: 0.11907740, mean(E): -21.80266625+0.00000842j, var(E): 0.14107837
-0.0
tensor(23.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=2.72............. Loss: -0.11555921, mean(E): -21.78139552-0.00001266j, var(E): 0.23924444
-0.0
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=2.73............. Loss: -0.02012136, mean(E): -21.78616377-0.00002562j, var(E): 0.08731181
-0.0
tensor(23.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=2.73............. Loss: -0.08723699, mean(E): -21.78430553-0.00000443j, var(E): 0.22666569
-0.0
tensor(23.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=2.73............. Loss: -0.18969587, mean(E): -21.76721878+0.00001764j, var(E): 0.16071468
-0.0
tensor(23.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=2.72............. Loss: 0.12711952, mean(E): -21.79892299-0.00000446j, var(E): 0.22416445
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=2.72............. Loss: -0.05504757, mean(E): -21.77820625+0.00000984j, var(E): 0.08288013
-0.0
tensor(23.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=2.71............. Loss: -0.02843698, mean(E): -21.78356253+0.00000161j, var(E): 0.07244914
-0.0
tensor(23.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=2.73............. Loss: 0.00578129, mean(E): -21.79644738+0.00000293j, var(E): 0.15362412
-0.0
tensor(23.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=2.73............. Loss: -0.06815374, mean(E): -21.77303895-0.00000963j, var(E): 0.07252021
-0.0
tensor(23.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=2.72............. Loss: 0.19424575, mean(E): -21.81181637+0.00000745j, var(E): 0.25693727
-0.0
tensor(23.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=2.72............. Loss: 0.06979206, mean(E): -21.79779558+0.00000099j, var(E): 0.12236480
-0.0
tensor(23.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=2.73............. Loss: 0.02925209, mean(E): -21.79745471+0.00001497j, var(E): 0.11356402
-0.0
tensor(23.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=2.73............. Loss: -0.15860372, mean(E): -21.76648062+0.00000040j, var(E): 0.10886910
-0.0
tensor(23.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=2.73............. Loss: 0.02328240, mean(E): -21.79311526-0.00003122j, var(E): 0.08554644
-0.0
tensor(23.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=2.72............. Loss: 0.06302060, mean(E): -21.80001872+0.00002581j, var(E): 0.10068007
-0.0
tensor(23.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=2.73............. Loss: -0.11520041, mean(E): -21.77873870+0.00000907j, var(E): 0.14085727
-0.0
tensor(23.1697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=2.71............. Loss: -0.06287414, mean(E): -21.77594008+0.00000724j, var(E): 0.09236479
-0.0
tensor(23.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=2.71............. Loss: 0.00856823, mean(E): -21.78932468+0.00001643j, var(E): 0.07487828
-0.0
tensor(23.1752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=2.72............. Loss: -0.07158274, mean(E): -21.77985698-0.00001670j, var(E): 0.11796620
-0.0
tensor(23.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=2.72............. Loss: -0.03581694, mean(E): -21.78601386-0.00003473j, var(E): 0.11827883
-0.0
tensor(23.1758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=2.72............. Loss: 0.05885949, mean(E): -21.79487034+0.00008361j, var(E): 0.14094121
-0.0
tensor(23.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=2.71............. Loss: 0.05179082, mean(E): -21.79340814+0.00012119j, var(E): 0.08274542
-0.0
tensor(23.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=2.71............. Loss: 0.06450791, mean(E): -21.80128495+0.00007129j, var(E): 0.17809420
-0.0
tensor(23.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=2.73............. Loss: -0.00693438, mean(E): -21.78791586-0.00002254j, var(E): 0.05113376
-0.0
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=2.71............. Loss: -0.10274811, mean(E): -21.78145155-0.00013282j, var(E): 0.13681067
-0.0
tensor(23.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=2.71............. Loss: 0.05686951, mean(E): -21.79992302+0.00017217j, var(E): 0.17638571
-0.0
tensor(23.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=2.73............. Loss: -0.03670859, mean(E): -21.78364200+0.00000947j, var(E): 0.10377728
-0.0
tensor(23.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=2.73............. Loss: -0.07272782, mean(E): -21.78779134+0.00024645j, var(E): 0.10726433
-0.0
tensor(23.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=2.73............. Loss: -0.09890705, mean(E): -21.78569532-0.00009877j, var(E): 0.20341010
-0.0
tensor(23.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=2.72............. Loss: -0.11761533, mean(E): -21.77030206+0.00007691j, var(E): 0.11513767
-0.0
tensor(23.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=2.72............. Loss: -0.10366937, mean(E): -21.78083369-0.00022001j, var(E): 0.11231821
-0.0
tensor(23.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=2.73............. Loss: 0.04010117, mean(E): -21.78921474+0.00004930j, var(E): 0.05254739
-0.0
tensor(23.1896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=2.72............. Loss: -0.10350163, mean(E): -21.76618741+0.00003434j, var(E): 0.06065295
-0.0
tensor(23.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=2.74............. Loss: 0.07347395, mean(E): -21.80074817-0.00000628j, var(E): 0.12405987
-0.0
tensor(23.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=2.73............. Loss: -0.04536034, mean(E): -21.78821109-0.00018571j, var(E): 0.17449491
-0.0
tensor(23.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=2.73............. Loss: -0.02431103, mean(E): -21.78940130-0.00004275j, var(E): 0.11707415
-0.0
tensor(23.1872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=2.73............. Loss: -0.04586516, mean(E): -21.79026193+0.00008750j, var(E): 0.13589373
-0.0
tensor(23.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=2.72............. Loss: -0.24430709, mean(E): -21.75840199+0.00001226j, var(E): 0.15091395
-0.0
tensor(23.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=2.73............. Loss: 0.02143408, mean(E): -21.79818085-0.00002917j, var(E): 0.05381102
-0.0
tensor(23.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=2.72............. Loss: 0.01960903, mean(E): -21.79651963+0.00002839j, var(E): 0.14751363
-0.0
tensor(23.1949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=2.73............. Loss: 0.14468607, mean(E): -21.80943803-0.00000037j, var(E): 0.11678009
-0.0
tensor(23.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=2.73............. Loss: -0.04411312, mean(E): -21.79171377+0.00006103j, var(E): 0.15748827
-0.0
tensor(23.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.1998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=2.72............. Loss: 0.09289720, mean(E): -21.79682718+0.00000694j, var(E): 0.14433105
-0.0
tensor(23.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=2.71............. Loss: 0.01571281, mean(E): -21.78789151+0.00000798j, var(E): 0.09548645
-0.0
tensor(23.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=2.71............. Loss: 0.06097398, mean(E): -21.80275811-0.00002926j, var(E): 0.12714237
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=2.71............. Loss: 0.01163881, mean(E): -21.79481875+0.00002120j, var(E): 0.09910004
-0.0
tensor(23.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=2.71............. Loss: -0.02992939, mean(E): -21.79138958+0.00002162j, var(E): 0.08385027
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=2.73............. Loss: -0.12984470, mean(E): -21.77258229+0.00001534j, var(E): 0.21313076
-0.0
tensor(23.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=2.73............. Loss: 0.00671911, mean(E): -21.79562862+0.00006839j, var(E): 0.10341273
-0.0
tensor(23.2017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=2.73............. Loss: 0.01654024, mean(E): -21.79364145+0.00000844j, var(E): 0.16418171
-0.0
tensor(23.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=2.73............. Loss: -0.02227240, mean(E): -21.79444673-0.00000053j, var(E): 0.09057091
-0.0
tensor(23.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=2.73............. Loss: -0.02769369, mean(E): -21.78962033+0.00000494j, var(E): 0.11692041
-0.0
tensor(23.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=2.73............. Loss: -0.03148769, mean(E): -21.78269173-0.00001910j, var(E): 0.13291858
-0.0
tensor(23.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=2.73............. Loss: 0.15178703, mean(E): -21.80398297-0.00002954j, var(E): 0.09257102
-0.0
tensor(23.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=2.73............. Loss: -0.07133135, mean(E): -21.78113139-0.00001367j, var(E): 0.09172733
-0.0
tensor(23.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=2.73............. Loss: 0.13067471, mean(E): -21.80646536-0.00004446j, var(E): 0.15204272
-0.0
tensor(23.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=2.73............. Loss: 0.13268485, mean(E): -21.80310520-0.00003246j, var(E): 0.15058512
-0.0
tensor(23.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=2.72............. Loss: -0.06507670, mean(E): -21.78157639+0.00003545j, var(E): 0.09601075
-0.0
tensor(23.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=2.73............. Loss: 0.02733306, mean(E): -21.79165285+0.00004589j, var(E): 0.12817679
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=2.73............. Loss: -0.02771956, mean(E): -21.78208247-0.00003786j, var(E): 0.12891390
-0.0
tensor(23.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=2.73............. Loss: -0.02900521, mean(E): -21.78684753+0.00002762j, var(E): 0.06504326
-0.0
tensor(23.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=2.72............. Loss: 0.00888913, mean(E): -21.78098145-0.00000146j, var(E): 0.16019865
-0.0
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=2.72............. Loss: 0.01492664, mean(E): -21.79278839-0.00001720j, var(E): 0.14556838
-0.0
tensor(23.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=2.73............. Loss: 0.08147858, mean(E): -21.80632428+0.00001465j, var(E): 0.09495129
-0.0
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=2.73............. Loss: 0.00758437, mean(E): -21.78513170+0.00001941j, var(E): 0.12282752
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=2.72............. Loss: 0.03036575, mean(E): -21.79491920-0.00001022j, var(E): 0.10264834
-0.0
tensor(23.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=2.73............. Loss: -0.00204344, mean(E): -21.77485873-0.00000069j, var(E): 0.07118180
-0.0
tensor(23.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=2.73............. Loss: -0.17668685, mean(E): -21.77512712+0.00000122j, var(E): 0.13262115
-0.0
tensor(23.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=2.71............. Loss: -0.17448330, mean(E): -21.76586420+0.00002797j, var(E): 0.20576497
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=2.71............. Loss: 0.01965017, mean(E): -21.78940798+0.00002819j, var(E): 0.15610070
-0.0
tensor(23.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=2.72............. Loss: 0.31105936, mean(E): -21.82995715+0.00009097j, var(E): 0.23727725
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=2.73............. Loss: -0.09224583, mean(E): -21.78392328+0.00020965j, var(E): 0.10586479
-0.0
tensor(23.2189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=2.72............. Loss: -0.01267201, mean(E): -21.78110896+0.00011151j, var(E): 0.05085678
-0.0
tensor(23.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=2.73............. Loss: -0.15616306, mean(E): -21.77658412+0.00005269j, var(E): 0.11759916
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=2.73............. Loss: 0.01847148, mean(E): -21.79588613+0.00015842j, var(E): 0.06256566
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=2.73............. Loss: 0.01025698, mean(E): -21.79460301-0.00005680j, var(E): 0.09102503
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=2.73............. Loss: 0.09722345, mean(E): -21.80039875-0.00005608j, var(E): 0.23437341
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=2.72............. Loss: -0.15014651, mean(E): -21.78040097+0.00001945j, var(E): 0.13788827
-0.0
tensor(23.2210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=2.73............. Loss: -0.04794337, mean(E): -21.78716508+0.00016985j, var(E): 0.07330298
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=2.73............. Loss: 0.03408747, mean(E): -21.79482932-0.00004609j, var(E): 0.12186394
-0.0
tensor(23.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=2.73............. Loss: -0.01754346, mean(E): -21.78594922+0.00000850j, var(E): 0.11932042
-0.0
tensor(23.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=2.73............. Loss: -0.01836461, mean(E): -21.78728631+0.00010483j, var(E): 0.06233437
-0.0
tensor(23.2265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=2.73............. Loss: -0.16159974, mean(E): -21.77355910+0.00014947j, var(E): 0.13222622
-0.0
tensor(23.2277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=2.73............. Loss: -0.03075301, mean(E): -21.78930372+0.00017121j, var(E): 0.08294304
-0.0
tensor(23.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=2.73............. Loss: -0.01295847, mean(E): -21.78965759-0.00013034j, var(E): 0.08683471
-0.0
tensor(23.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=2.73............. Loss: -0.00334290, mean(E): -21.78532963+0.00013280j, var(E): 0.11404137
-0.0
tensor(23.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=2.73............. Loss: 0.08941066, mean(E): -21.80577416-0.00004607j, var(E): 0.07829356
-0.0
tensor(23.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=2.73............. Loss: 0.09773220, mean(E): -21.80797680+0.00006460j, var(E): 0.07024157
-0.0
tensor(23.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=2.73............. Loss: 0.02034015, mean(E): -21.80339463-0.00011792j, var(E): 0.10792316
-0.0
tensor(23.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=2.73............. Loss: -0.09524609, mean(E): -21.77485286-0.00006877j, var(E): 0.18954223
-0.0
tensor(23.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=2.73............. Loss: -0.10844668, mean(E): -21.76917048+0.00001983j, var(E): 0.15115436
-0.0
tensor(23.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=2.73............. Loss: -0.11437874, mean(E): -21.78610694+0.00000160j, var(E): 0.07777934
-0.0
tensor(23.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=2.73............. Loss: -0.08107761, mean(E): -21.77608801+0.00004079j, var(E): 0.10095177
-0.0
tensor(23.2369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=2.72............. Loss: 0.10367346, mean(E): -21.79952546+0.00001722j, var(E): 0.13442784
-0.0
tensor(23.2397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=2.71............. Loss: -0.00162951, mean(E): -21.79003825+0.00001807j, var(E): 0.11716845
-0.0
tensor(23.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=2.72............. Loss: 0.02158150, mean(E): -21.79537898+0.00000279j, var(E): 0.15036466
-0.0
tensor(23.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=2.71............. Loss: 0.02993956, mean(E): -21.79305121+0.00000592j, var(E): 0.11049101
-0.0
tensor(23.2418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=2.71............. Loss: 0.12919768, mean(E): -21.81312069+0.00000601j, var(E): 0.12424731
-0.0
tensor(23.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=2.73............. Loss: -0.04073202, mean(E): -21.78655894-0.00000415j, var(E): 0.17468316
-0.0
tensor(23.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=2.73............. Loss: 0.02970426, mean(E): -21.78806499+0.00000252j, var(E): 0.11802394
-0.0
tensor(23.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=2.73............. Loss: 0.05219292, mean(E): -21.80454798-0.00000330j, var(E): 0.11738511
-0.0
tensor(23.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=2.73............. Loss: -0.03476242, mean(E): -21.78770026-0.00000009j, var(E): 0.12548597
-0.0
tensor(23.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=2.72............. Loss: -0.01819661, mean(E): -21.79145657+0.00000286j, var(E): 0.12036803
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=2.73............. Loss: -0.04455242, mean(E): -21.78242587+0.00000642j, var(E): 0.22401848
-0.0
tensor(23.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=2.73............. Loss: -0.05346581, mean(E): -21.78307059+0.00000042j, var(E): 0.06581995
-0.0
tensor(23.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=2.73............. Loss: 0.06018408, mean(E): -21.79876090-0.00000147j, var(E): 0.14966220
-0.0
tensor(23.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=2.73............. Loss: 0.04203991, mean(E): -21.79791333+0.00000196j, var(E): 0.09826414
-0.0
tensor(23.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=2.73............. Loss: -0.08825019, mean(E): -21.78101338-0.00000149j, var(E): 0.10191737
-0.0
tensor(23.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=2.73............. Loss: 0.00597560, mean(E): -21.79211327+0.00000202j, var(E): 0.10110475
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=2.73............. Loss: -0.06497846, mean(E): -21.78820156-0.00000028j, var(E): 0.12495439
-0.0
tensor(23.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=2.73............. Loss: -0.02606419, mean(E): -21.78641996+0.00000105j, var(E): 0.16051522
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=2.73............. Loss: -0.03236424, mean(E): -21.79640049+0.00000131j, var(E): 0.07949558
-0.0
tensor(23.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=2.72............. Loss: 0.11458432, mean(E): -21.79919166-0.00000076j, var(E): 0.31174571
-0.0
tensor(23.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=2.72............. Loss: 0.01613601, mean(E): -21.79776101+0.00000032j, var(E): 0.06969969
-0.0
tensor(23.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=2.72............. Loss: 0.02015229, mean(E): -21.80020630+0.00000015j, var(E): 0.08325868
-0.0
tensor(23.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=2.71............. Loss: -0.05368559, mean(E): -21.78854360-0.00000280j, var(E): 0.05509121
-0.0
tensor(23.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=2.73............. Loss: 0.10483854, mean(E): -21.80737096+0.00000043j, var(E): 0.10992671
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=2.73............. Loss: -0.01328423, mean(E): -21.79035863+0.00000198j, var(E): 0.09351173
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=2.73............. Loss: -0.01045334, mean(E): -21.79175569-0.00000011j, var(E): 0.10976576
-0.0
tensor(23.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=2.73............. Loss: -0.00441889, mean(E): -21.78754745+0.00000037j, var(E): 0.10316622
-0.0
tensor(23.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=2.73............. Loss: -0.21212153, mean(E): -21.76075100-0.00000105j, var(E): 0.19641204
-0.0
tensor(23.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=2.72............. Loss: -0.05720555, mean(E): -21.78293333-0.00000149j, var(E): 0.07790890
-0.0
tensor(23.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=2.72............. Loss: 0.06924225, mean(E): -21.79821561-0.00000136j, var(E): 0.08151483
-0.0
tensor(23.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=2.72............. Loss: -0.09101746, mean(E): -21.78144355-0.00000252j, var(E): 0.14901282
-0.0
tensor(23.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=2.71............. Loss: 0.06089292, mean(E): -21.79265419+0.00000050j, var(E): 0.15302701
-0.0
tensor(23.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=2.73............. Loss: -0.03233476, mean(E): -21.78806157+0.00000218j, var(E): 0.09717746
-0.0
tensor(23.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=2.73............. Loss: -0.02461771, mean(E): -21.78965546-0.00000093j, var(E): 0.11110278
-0.0
tensor(23.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=2.73............. Loss: -0.03449684, mean(E): -21.78724153-0.00000034j, var(E): 0.10050268
-0.0
tensor(23.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=2.73............. Loss: 0.02919758, mean(E): -21.79057456-0.00000375j, var(E): 0.05431796
-0.0
tensor(23.2715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=2.72............. Loss: -0.11260515, mean(E): -21.77290647+0.00000162j, var(E): 0.08131816
-0.0
tensor(23.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=2.72............. Loss: -0.02904648, mean(E): -21.78151209-0.00000289j, var(E): 0.10675260
-0.0
tensor(23.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=2.73............. Loss: -0.09095940, mean(E): -21.77633761+0.00000343j, var(E): 0.09159361
-0.0
tensor(23.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=2.73............. Loss: -0.08229346, mean(E): -21.77545939-0.00000851j, var(E): 0.18181553
-0.0
tensor(23.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=2.73............. Loss: 0.03514368, mean(E): -21.79993114+0.00002559j, var(E): 0.06513519
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=2.73............. Loss: 0.13289404, mean(E): -21.80746715-0.00002071j, var(E): 0.15673003
-0.0
tensor(23.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=2.73............. Loss: -0.09932731, mean(E): -21.77335404+0.00005425j, var(E): 0.08663744
-0.0
tensor(23.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=2.73............. Loss: -0.13349094, mean(E): -21.77577874+0.00011112j, var(E): 0.11301480
-0.0
tensor(23.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=2.73............. Loss: 0.02444725, mean(E): -21.79105634+0.00005690j, var(E): 0.10482622
-0.0
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=2.73............. Loss: -0.04083227, mean(E): -21.78781618+0.00002179j, var(E): 0.05236050
-0.0
tensor(23.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=2.72............. Loss: 0.09479403, mean(E): -21.79516409-0.00005225j, var(E): 0.22249428
-0.0
tensor(23.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=2.73............. Loss: -0.04809454, mean(E): -21.79093312+0.00011844j, var(E): 0.06806104
-0.0
tensor(23.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=2.73............. Loss: -0.22834099, mean(E): -21.76725182+0.00042507j, var(E): 0.14608755
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=2.73............. Loss: -0.05714273, mean(E): -21.78429656-0.00014278j, var(E): 0.20097490
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=2.73............. Loss: -0.06331775, mean(E): -21.78376026-0.00008049j, var(E): 0.07399106
-0.0
tensor(23.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=2.73............. Loss: -0.00015617, mean(E): -21.79343124+0.00026949j, var(E): 0.09253845
-0.0
tensor(23.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=2.73............. Loss: -0.18326648, mean(E): -21.77317858+0.00000500j, var(E): 0.12713290
-0.0
tensor(23.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=2.72............. Loss: -0.12881834, mean(E): -21.77296139+0.00008356j, var(E): 0.09068756
-0.0
tensor(23.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=2.73............. Loss: -0.04675514, mean(E): -21.78616376-0.00001337j, var(E): 0.10565759
-0.0
tensor(23.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=2.72............. Loss: 0.02082197, mean(E): -21.79214132-0.00004303j, var(E): 0.10841120
-0.0
tensor(23.2909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=2.72............. Loss: -0.01319045, mean(E): -21.78599259+0.00033833j, var(E): 0.08107621
-0.0
tensor(23.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=2.72............. Loss: -0.01222336, mean(E): -21.78376009+0.00002155j, var(E): 0.09076092
-0.0
tensor(23.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=2.73............. Loss: 0.05830972, mean(E): -21.79383954+0.00018585j, var(E): 0.08022000
-0.0
tensor(23.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=2.73............. Loss: 0.10664297, mean(E): -21.80782868-0.00001090j, var(E): 0.08201104
-0.0
tensor(23.2852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=2.73............. Loss: -0.09835420, mean(E): -21.78160751+0.00010390j, var(E): 0.13350263
-0.0
tensor(23.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=2.73............. Loss: 0.19485549, mean(E): -21.81020679-0.00001510j, var(E): 0.28263074
-0.0
tensor(23.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=2.73............. Loss: -0.05624704, mean(E): -21.78317992-0.00016170j, var(E): 0.07337368
-0.0
tensor(23.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=2.73............. Loss: 0.11988024, mean(E): -21.80387646+0.00001569j, var(E): 0.15423559
-0.0
tensor(23.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=2.73............. Loss: 0.02867207, mean(E): -21.79382404+0.00001225j, var(E): 0.05622537
-0.0
tensor(23.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=2.73............. Loss: -0.05266125, mean(E): -21.79448579-0.00011220j, var(E): 0.07907148
-0.0
tensor(23.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=2.73............. Loss: -0.08733797, mean(E): -21.77575824-0.00008061j, var(E): 0.19259298
-0.0
tensor(23.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=2.73............. Loss: -0.04327667, mean(E): -21.78700707+0.00000393j, var(E): 0.11162631
-0.0
tensor(23.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=2.73............. Loss: 0.02099579, mean(E): -21.80296165+0.00006083j, var(E): 0.06964434
-0.0
tensor(23.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=2.73............. Loss: 0.01550777, mean(E): -21.79410198-0.00005799j, var(E): 0.16286515
-0.0
tensor(23.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=2.73............. Loss: -0.09781967, mean(E): -21.77341890+0.00001623j, var(E): 0.08290306
-0.0
tensor(23.2981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=2.73............. Loss: 0.06440533, mean(E): -21.79806639-0.00001709j, var(E): 0.08064147
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=2.73............. Loss: 0.03664531, mean(E): -21.79599641-0.00002746j, var(E): 0.08926496
-0.0
tensor(23.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=2.73............. Loss: -0.00203923, mean(E): -21.78631930+0.00000304j, var(E): 0.07043481
-0.0
tensor(23.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=2.73............. Loss: 0.16091476, mean(E): -21.80933247+0.00000289j, var(E): 0.29178421
-0.0
tensor(23.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=2.73............. Loss: 0.15318160, mean(E): -21.80456334+0.00000230j, var(E): 0.12767865
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=2.73............. Loss: -0.04278643, mean(E): -21.78785686-0.00001792j, var(E): 0.15877442
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=2.72............. Loss: -0.09848694, mean(E): -21.77856792+0.00000138j, var(E): 0.08587628
-0.0
tensor(23.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=2.72............. Loss: 0.01977944, mean(E): -21.80048313+0.00000612j, var(E): 0.09392719
-0.0
tensor(23.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=2.72............. Loss: 0.04548193, mean(E): -21.79597654+0.00000037j, var(E): 0.16233304
-0.0
tensor(23.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=2.73............. Loss: 0.01896618, mean(E): -21.78877410-0.00000579j, var(E): 0.10606987
-0.0
tensor(23.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=2.72............. Loss: -0.07761522, mean(E): -21.76888931+0.00000444j, var(E): 0.18604512
-0.0
tensor(23.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=2.73............. Loss: 0.03407594, mean(E): -21.79579934+0.00000412j, var(E): 0.04737922
-0.0
tensor(23.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=2.73............. Loss: -0.11349694, mean(E): -21.77596488-0.00000819j, var(E): 0.12607581
-0.0
tensor(23.3134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=2.73............. Loss: -0.03572180, mean(E): -21.79695129+0.00000232j, var(E): 0.13020122
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=2.73............. Loss: -0.06095787, mean(E): -21.78775908+0.00000007j, var(E): 0.08974622
-0.0
tensor(23.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=2.73............. Loss: 0.08593923, mean(E): -21.81151799-0.00000157j, var(E): 0.16969304
-0.0
tensor(23.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=2.73............. Loss: -0.03718219, mean(E): -21.78536927-0.00000261j, var(E): 0.06766479
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=2.73............. Loss: 0.00615261, mean(E): -21.79410162+0.00000219j, var(E): 0.12155763
-0.0
tensor(23.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=2.72............. Loss: -0.15200216, mean(E): -21.77328540-0.00000184j, var(E): 0.06404226
-0.0
tensor(23.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=2.73............. Loss: 0.27831564, mean(E): -21.82318026+0.00000173j, var(E): 0.36612099
-0.0
tensor(23.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=2.73............. Loss: -0.06186066, mean(E): -21.78060077-0.00000021j, var(E): 0.05491687
-0.0
tensor(23.3203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=2.73............. Loss: 0.06253760, mean(E): -21.80439556-0.00000020j, var(E): 0.18915114
-0.0
tensor(23.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=2.73............. Loss: 0.04807140, mean(E): -21.79864456-0.00000059j, var(E): 0.15631193
-0.0
tensor(23.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=2.72............. Loss: -0.00997081, mean(E): -21.78585653+0.00000344j, var(E): 0.06842932
-0.0
tensor(23.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=2.73............. Loss: 0.09495665, mean(E): -21.80453315-0.00000061j, var(E): 0.12817404
-0.0
tensor(23.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=2.73............. Loss: -0.02552070, mean(E): -21.79365403+0.00000026j, var(E): 0.05730228
-0.0
tensor(23.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=2.73............. Loss: 0.15076306, mean(E): -21.80385856-0.00000046j, var(E): 0.17328457
-0.0
tensor(23.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=2.73............. Loss: -0.07032614, mean(E): -21.78540228+0.00000025j, var(E): 0.06745549
-0.0
tensor(23.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=2.73............. Loss: -0.00132069, mean(E): -21.79981124+0.00000003j, var(E): 0.06196104
-0.0
tensor(23.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=2.73............. Loss: 0.03367636, mean(E): -21.79329767-0.00000156j, var(E): 0.17202612
-0.0
tensor(23.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=2.73............. Loss: -0.01503745, mean(E): -21.78634068-0.00000109j, var(E): 0.08900904
-0.0
tensor(23.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=2.73............. Loss: -0.13661695, mean(E): -21.76872243-0.00000106j, var(E): 0.09122592
-0.0
tensor(23.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=2.73............. Loss: -0.06465464, mean(E): -21.78623042-0.00000083j, var(E): 0.08956793
-0.0
tensor(23.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=2.72............. Loss: -0.06635855, mean(E): -21.78742950-0.00000059j, var(E): 0.08003126
-0.0
tensor(23.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=2.72............. Loss: -0.05387469, mean(E): -21.78117718-0.00000013j, var(E): 0.19792452
-0.0
tensor(23.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=2.72............. Loss: 0.07458455, mean(E): -21.79442223-0.00000003j, var(E): 0.15765783
-0.0
tensor(23.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=2.72............. Loss: 0.01392083, mean(E): -21.79418062-0.00000065j, var(E): 0.08225994
-0.0
tensor(23.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=2.71............. Loss: -0.01214122, mean(E): -21.78998452-0.00000030j, var(E): 0.07014016
-0.0
tensor(23.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=2.73............. Loss: 0.12593333, mean(E): -21.80971132-0.00000046j, var(E): 0.10539174
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=2.73............. Loss: -0.08142814, mean(E): -21.77504052-0.00000063j, var(E): 0.11336756
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=2.73............. Loss: -0.04578897, mean(E): -21.78431572-0.00000070j, var(E): 0.06620439
-0.0
tensor(23.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=2.72............. Loss: -0.27286743, mean(E): -21.76631494-0.00000023j, var(E): 0.24189882
-0.0
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=2.73............. Loss: 0.11430218, mean(E): -21.80925366+0.00000091j, var(E): 0.14396836
-0.0
tensor(23.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=2.73............. Loss: 0.01272592, mean(E): -21.79239411-0.00000011j, var(E): 0.11483920
-0.0
tensor(23.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=2.73............. Loss: -0.02652103, mean(E): -21.78401288-0.00000076j, var(E): 0.11141296
-0.0
tensor(23.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=2.73............. Loss: -0.07249652, mean(E): -21.78960557-0.00000050j, var(E): 0.08525344
-0.0
tensor(23.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=2.73............. Loss: -0.02223391, mean(E): -21.78528581-0.00000128j, var(E): 0.06460834
-0.0
tensor(23.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=2.73............. Loss: -0.01321013, mean(E): -21.78468071+0.00000163j, var(E): 0.09086531
-0.0
tensor(23.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=2.73............. Loss: 0.08568215, mean(E): -21.80174492-0.00000043j, var(E): 0.07167060
-0.0
tensor(23.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=2.72............. Loss: 0.11433400, mean(E): -21.80732128-0.00000303j, var(E): 0.14165002
-0.0
tensor(23.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=2.73............. Loss: -0.00855266, mean(E): -21.79051941-0.00000269j, var(E): 0.07885277
-0.0
tensor(23.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=2.73............. Loss: 0.05849771, mean(E): -21.79722332+0.00000466j, var(E): 0.12405301
-0.0
tensor(23.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=2.72............. Loss: -0.04320354, mean(E): -21.78860327-0.00000423j, var(E): 0.16147365
-0.0
tensor(23.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=2.73............. Loss: -0.11100691, mean(E): -21.77080230-0.00000491j, var(E): 0.09947331
-0.0
tensor(23.3449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=2.73............. Loss: -0.05362162, mean(E): -21.77892598+0.00000401j, var(E): 0.08316557
-0.0
tensor(23.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=2.73............. Loss: -0.04514054, mean(E): -21.78458371+0.00001021j, var(E): 0.06590820
-0.0
tensor(23.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=2.72............. Loss: 0.00412924, mean(E): -21.79331309+0.00000885j, var(E): 0.05154968
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=2.73............. Loss: -0.03324372, mean(E): -21.78611426+0.00003040j, var(E): 0.05631176
-0.0
tensor(23.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=2.73............. Loss: 0.10135954, mean(E): -21.79320147+0.00005435j, var(E): 0.44080922
-0.0
tensor(23.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=2.71............. Loss: -0.02865844, mean(E): -21.79277758+0.00030578j, var(E): 0.08159221
-0.0
tensor(23.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=2.72............. Loss: 0.02169837, mean(E): -21.79396480-0.00016105j, var(E): 0.08576988
-0.0
tensor(23.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=2.72............. Loss: -0.01155665, mean(E): -21.78550500+0.00017740j, var(E): 0.11617094
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=2.72............. Loss: -0.11465002, mean(E): -21.77256576+0.00004570j, var(E): 0.11912203
-0.0
tensor(23.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=2.72............. Loss: 0.04458936, mean(E): -21.79230720+0.00018187j, var(E): 0.12872131
-0.0
tensor(23.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=2.73............. Loss: -0.08874551, mean(E): -21.77500799+0.00009810j, var(E): 0.09702367
-0.0
tensor(23.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=2.73............. Loss: 0.07093732, mean(E): -21.79806125-0.00027837j, var(E): 0.18793931
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=2.73............. Loss: 0.01184295, mean(E): -21.78814313-0.00012628j, var(E): 0.14091288
-0.0
tensor(23.3572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=2.73............. Loss: 0.11635048, mean(E): -21.80172664-0.00005835j, var(E): 0.15898210
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=2.73............. Loss: 0.04742823, mean(E): -21.80236527+0.00001728j, var(E): 0.09866144
-0.0
tensor(23.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=2.72............. Loss: -0.00138831, mean(E): -21.79781527-0.00000579j, var(E): 0.06276388
-0.0
tensor(23.3600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=2.72............. Loss: -0.05453636, mean(E): -21.78315342+0.00004678j, var(E): 0.09733864
-0.0
tensor(23.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=2.73............. Loss: 0.32047698, mean(E): -21.82145906+0.00000092j, var(E): 0.46835060
-0.0
tensor(23.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=2.73............. Loss: -0.08480663, mean(E): -21.78226075+0.00000944j, var(E): 0.08337714
-0.0
tensor(23.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=2.71............. Loss: 0.08139237, mean(E): -21.79887998+0.00002390j, var(E): 0.14188181
-0.0
tensor(23.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=2.73............. Loss: 0.01667336, mean(E): -21.80161801+0.00000797j, var(E): 0.08517305
-0.0
tensor(23.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=2.73............. Loss: -0.08469712, mean(E): -21.77822534-0.00000309j, var(E): 0.07455655
-0.0
tensor(23.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=2.73............. Loss: 0.01022950, mean(E): -21.78198926+0.00001214j, var(E): 0.11461723
-0.0
tensor(23.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=2.73............. Loss: -0.07536722, mean(E): -21.77650014+0.00000506j, var(E): 0.08460285
-0.0
tensor(23.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=2.73............. Loss: 0.01378953, mean(E): -21.79246283-0.00002003j, var(E): 0.12447863
-0.0
tensor(23.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=2.72............. Loss: -0.07097648, mean(E): -21.77811745-0.00002189j, var(E): 0.08186829
-0.0
tensor(23.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=2.73............. Loss: 0.00067344, mean(E): -21.79313178+0.00000802j, var(E): 0.09092776
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=2.72............. Loss: 0.12542434, mean(E): -21.80156619-0.00002003j, var(E): 0.28010498
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=2.73............. Loss: -0.00881364, mean(E): -21.78912466-0.00001583j, var(E): 0.04504609
-0.0
tensor(23.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=2.73............. Loss: 0.15123452, mean(E): -21.80647651+0.00001267j, var(E): 0.31995561
-0.0
tensor(23.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=2.73............. Loss: 0.03346596, mean(E): -21.79478459+0.00003245j, var(E): 0.08868617
-0.0
tensor(23.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=2.72............. Loss: -0.06848097, mean(E): -21.77906921+0.00000235j, var(E): 0.08866091
-0.0
tensor(23.3784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=2.73............. Loss: 0.02595996, mean(E): -21.79471081+0.00000640j, var(E): 0.21174328
-0.0
tensor(23.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=2.71............. Loss: -0.02143663, mean(E): -21.79702032+0.00001045j, var(E): 0.11756360
-0.0
tensor(23.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=2.73............. Loss: 0.07210812, mean(E): -21.79822399-0.00000342j, var(E): 0.10375606
-0.0
tensor(23.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=2.72............. Loss: -0.01960727, mean(E): -21.79214992+0.00000797j, var(E): 0.11412218
-0.0
tensor(23.3826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=2.73............. Loss: -0.01640522, mean(E): -21.78571365-0.00002705j, var(E): 0.03752033
-0.0
tensor(23.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=2.73............. Loss: 0.06220048, mean(E): -21.80228988-0.00005365j, var(E): 0.15500197
-0.0
tensor(23.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=2.72............. Loss: 0.03919235, mean(E): -21.79333050-0.00000861j, var(E): 0.07288809
-0.0
tensor(23.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=2.73............. Loss: 0.00418967, mean(E): -21.78795706+0.00000833j, var(E): 0.05439687
-0.0
tensor(23.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=2.73............. Loss: -0.05337497, mean(E): -21.78395525+0.00002975j, var(E): 0.07296504
-0.0
tensor(23.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=2.72............. Loss: 0.10167484, mean(E): -21.80052481-0.00002007j, var(E): 0.12693721
-0.0
tensor(23.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=2.73............. Loss: -0.16184912, mean(E): -21.76427563-0.00000119j, var(E): 0.10982429
-0.0
tensor(23.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=2.73............. Loss: 0.09175946, mean(E): -21.80314236-0.00000899j, var(E): 0.06764337
-0.0
tensor(23.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=2.73............. Loss: 0.02012473, mean(E): -21.78951545+0.00000079j, var(E): 0.10587045
-0.0
tensor(23.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=2.73............. Loss: -0.05628165, mean(E): -21.77748403-0.00001957j, var(E): 0.11982768
-0.0
tensor(23.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=2.72............. Loss: 0.11871304, mean(E): -21.80501726+0.00000413j, var(E): 0.20161546
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=2.73............. Loss: 0.07213214, mean(E): -21.79144641-0.00002823j, var(E): 0.16900386
-0.0
tensor(23.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=2.73............. Loss: -0.09382408, mean(E): -21.77934083+0.00001292j, var(E): 0.07700186
-0.0
tensor(23.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=2.72............. Loss: -0.08947540, mean(E): -21.78303105-0.00000773j, var(E): 0.08872361
-0.0
tensor(23.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=2.72............. Loss: 0.01073117, mean(E): -21.79654708+0.00001592j, var(E): 0.11117800
-0.0
tensor(23.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=2.73............. Loss: -0.01351410, mean(E): -21.79107082-0.00002275j, var(E): 0.05518871
-0.0
tensor(23.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=2.72............. Loss: -0.00971456, mean(E): -21.78517805-0.00002723j, var(E): 0.20866272
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=2.73............. Loss: -0.02601543, mean(E): -21.78044441-0.00001471j, var(E): 0.16197013
-0.0
tensor(23.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=2.73............. Loss: 0.08210908, mean(E): -21.80456724+0.00004086j, var(E): 0.13312074
-0.0
tensor(23.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=2.73............. Loss: 0.07090040, mean(E): -21.80257764+0.00000362j, var(E): 0.06624429
-0.0
tensor(23.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=2.73............. Loss: 0.01615628, mean(E): -21.79402433+0.00000220j, var(E): 0.23721621
-0.0
tensor(23.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=2.73............. Loss: -0.02943769, mean(E): -21.78097153+0.00002250j, var(E): 0.08375124
-0.0
tensor(23.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=2.73............. Loss: 0.11932718, mean(E): -21.80417632-0.00002542j, var(E): 0.16763537
-0.0
tensor(23.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=2.72............. Loss: 0.02649096, mean(E): -21.79222896+0.00002583j, var(E): 0.13822400
-0.0
tensor(23.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=2.73............. Loss: -0.10340814, mean(E): -21.78240979+0.00000372j, var(E): 0.12470827
-0.0
tensor(23.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=2.73............. Loss: 0.05977340, mean(E): -21.79603069+0.00006425j, var(E): 0.14443401
-0.0
tensor(23.4089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=2.73............. Loss: -0.04207630, mean(E): -21.78451571-0.00013577j, var(E): 0.18588376
-0.0
tensor(23.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=2.73............. Loss: -0.07706859, mean(E): -21.77910850-0.00000313j, var(E): 0.07860833
-0.0
tensor(23.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=2.72............. Loss: -0.17979113, mean(E): -21.77067609-0.00004043j, var(E): 0.11303321
-0.0
tensor(23.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=2.73............. Loss: 0.15340569, mean(E): -21.80578246-0.00002130j, var(E): 0.18824272
-0.0
tensor(23.4113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=2.73............. Loss: -0.15273891, mean(E): -21.77735836+0.00025618j, var(E): 0.12076767
-0.0
tensor(23.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=2.73............. Loss: 0.05682346, mean(E): -21.79790663+0.00002410j, var(E): 0.17557596
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=2.72............. Loss: 0.05318057, mean(E): -21.79852214+0.00005676j, var(E): 0.08636474
-0.0
tensor(23.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=2.72............. Loss: -0.11004307, mean(E): -21.78058489+0.00007660j, var(E): 0.10645394
-0.0
tensor(23.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=2.73............. Loss: 0.05600446, mean(E): -21.80148416+0.00017467j, var(E): 0.06157247
-0.0
tensor(23.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=2.73............. Loss: 0.01375980, mean(E): -21.79778870+0.00012007j, var(E): 0.10198447
-0.0
tensor(23.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=2.73............. Loss: -0.03398225, mean(E): -21.78566099+0.00002303j, var(E): 0.14986099
-0.0
tensor(23.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=2.73............. Loss: -0.07020663, mean(E): -21.77940360-0.00000841j, var(E): 0.08323144
-0.0
tensor(23.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=2.73............. Loss: -0.03090382, mean(E): -21.79008914+0.00006868j, var(E): 0.07039146
-0.0
tensor(23.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=2.74............. Loss: 0.20983680, mean(E): -21.80352162+0.00030413j, var(E): 0.49107724
-0.0
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=2.73............. Loss: 0.01733409, mean(E): -21.78221028+0.00006764j, var(E): 0.07701132
-0.0
tensor(23.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=2.74............. Loss: 0.01853581, mean(E): -21.78663050+0.00000915j, var(E): 0.11903229
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=2.73............. Loss: -0.01776743, mean(E): -21.79105200-0.00005748j, var(E): 0.05804891
-0.0
tensor(23.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=2.72............. Loss: -0.10491490, mean(E): -21.77744892-0.00000763j, var(E): 0.15866975
-0.0
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=2.73............. Loss: -0.12830689, mean(E): -21.78154506-0.00001923j, var(E): 0.09547493
-0.0
tensor(23.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=2.73............. Loss: 0.11563812, mean(E): -21.80882750-0.00001524j, var(E): 0.10237880
-0.0
tensor(23.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=2.73............. Loss: 0.11591510, mean(E): -21.81287542-0.00001140j, var(E): 0.11964237
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=2.73............. Loss: -0.10473350, mean(E): -21.78127643-0.00000932j, var(E): 0.08416408
-0.0
tensor(23.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=2.72............. Loss: 0.00827358, mean(E): -21.79147576-0.00000630j, var(E): 0.05001826
-0.0
tensor(23.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=2.73............. Loss: -0.06923835, mean(E): -21.78143666+0.00001411j, var(E): 0.11345312
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=2.72............. Loss: -0.02829248, mean(E): -21.78876061+0.00001578j, var(E): 0.11218973
-0.0
tensor(23.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=2.73............. Loss: -0.02458236, mean(E): -21.79463646+0.00001226j, var(E): 0.07309037
-0.0
tensor(23.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=2.73............. Loss: -0.03306213, mean(E): -21.78122100+0.00000426j, var(E): 0.09092277
-0.0
tensor(23.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=2.72............. Loss: 0.00228678, mean(E): -21.79306183+0.00001437j, var(E): 0.11762496
-0.0
tensor(23.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=2.73............. Loss: -0.02300009, mean(E): -21.78984197-0.00000651j, var(E): 0.05088702
-0.0
tensor(23.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=2.72............. Loss: 0.08145915, mean(E): -21.80794231+0.00000571j, var(E): 0.07402934
-0.0
tensor(23.4279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=2.71............. Loss: 0.00309026, mean(E): -21.79510058+0.00002289j, var(E): 0.04117581
-0.0
tensor(23.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=2.72............. Loss: -0.09066310, mean(E): -21.77616383+0.00000117j, var(E): 0.08708629
-0.0
tensor(23.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=2.73............. Loss: -0.11464360, mean(E): -21.77968115-0.00000803j, var(E): 0.07494402
-0.0
tensor(23.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=2.73............. Loss: -0.14015280, mean(E): -21.77549473-0.00000112j, var(E): 0.10580746
-0.0
tensor(23.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=2.73............. Loss: -0.01416621, mean(E): -21.78689533-0.00000242j, var(E): 0.05579949
-0.0
tensor(23.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=2.73............. Loss: -0.02460969, mean(E): -21.78895167-0.00000664j, var(E): 0.23870142
-0.0
tensor(23.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=2.72............. Loss: -0.10737765, mean(E): -21.77685354+0.00000836j, var(E): 0.12695466
-0.0
tensor(23.4408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=2.73............. Loss: -0.04662147, mean(E): -21.78594448-0.00000897j, var(E): 0.09106093
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=2.73............. Loss: -0.04755118, mean(E): -21.77986216-0.00000797j, var(E): 0.08010778
-0.0
tensor(23.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=2.72............. Loss: -0.01530318, mean(E): -21.78377544+0.00000731j, var(E): 0.06827201
-0.0
tensor(23.4457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=2.73............. Loss: 0.13589035, mean(E): -21.80858049-0.00000865j, var(E): 0.25477064
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=2.73............. Loss: -0.09919065, mean(E): -21.77668162-0.00000292j, var(E): 0.05366639
-0.0
tensor(23.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=2.73............. Loss: 0.03761273, mean(E): -21.79910932-0.00002330j, var(E): 0.08503665
-0.0
tensor(23.4478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=2.73............. Loss: 0.04263157, mean(E): -21.79320672+0.00000210j, var(E): 0.08316859
-0.0
tensor(23.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=2.73............. Loss: -0.07700363, mean(E): -21.78506004+0.00000722j, var(E): 0.08075643
-0.0
tensor(23.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=2.73............. Loss: -0.06375750, mean(E): -21.78366691-0.00000654j, var(E): 0.07787757
-0.0
tensor(23.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=2.73............. Loss: -0.04773172, mean(E): -21.78760698+0.00001779j, var(E): 0.06607352
-0.0
tensor(23.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=2.73............. Loss: -0.06211945, mean(E): -21.78540547-0.00000823j, var(E): 0.06329809
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=2.73............. Loss: 0.07924042, mean(E): -21.79661786-0.00000936j, var(E): 0.06287172
-0.0
tensor(23.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=2.73............. Loss: 0.05994803, mean(E): -21.79940860-0.00000174j, var(E): 0.14146174
-0.0
tensor(23.4502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=2.73............. Loss: -0.05231348, mean(E): -21.78628153-0.00000486j, var(E): 0.08794795
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=2.73............. Loss: 0.06449754, mean(E): -21.80033728-0.00000285j, var(E): 0.10772090
-0.0
tensor(23.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=2.73............. Loss: -0.19156394, mean(E): -21.76312432+0.00001500j, var(E): 0.16635158
-0.0
tensor(23.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=2.72............. Loss: 0.13113985, mean(E): -21.80542778+0.00000816j, var(E): 0.17396387
-0.0
tensor(23.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=2.73............. Loss: -0.03973484, mean(E): -21.79115447+0.00001178j, var(E): 0.11078336
-0.0
tensor(23.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=2.73............. Loss: 0.10772872, mean(E): -21.80810249+0.00000257j, var(E): 0.09357757
-0.0
tensor(23.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=2.73............. Loss: -0.09393969, mean(E): -21.77529349+0.00000247j, var(E): 0.09002421
-0.0
tensor(23.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=2.73............. Loss: 0.04532993, mean(E): -21.79100478-0.00000342j, var(E): 0.05303353
-0.0
tensor(23.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=2.73............. Loss: 0.07667016, mean(E): -21.80394879-0.00004817j, var(E): 0.15113817
-0.0
tensor(23.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=2.73............. Loss: -0.13625978, mean(E): -21.77625119-0.00001041j, var(E): 0.09158416
-0.0
tensor(23.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=2.73............. Loss: 0.03040285, mean(E): -21.79435912-0.00002777j, var(E): 0.08458199
-0.0
tensor(23.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=2.73............. Loss: -0.09386913, mean(E): -21.77848090-0.00001425j, var(E): 0.12055635
-0.0
tensor(23.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=2.73............. Loss: -0.00355184, mean(E): -21.79439140+0.00007354j, var(E): 0.05135961
-0.0
tensor(23.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=2.72............. Loss: -0.01036409, mean(E): -21.79016841+0.00004515j, var(E): 0.04042142
-0.0
tensor(23.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=2.73............. Loss: -0.03359463, mean(E): -21.78269847-0.00014246j, var(E): 0.39815421
-0.0
tensor(23.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=2.72............. Loss: 0.03748388, mean(E): -21.80267409-0.00005438j, var(E): 0.10222652
-0.0
tensor(23.4633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=2.73............. Loss: 0.00556438, mean(E): -21.79570365-0.00006823j, var(E): 0.07185543
-0.0
tensor(23.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=2.73............. Loss: -0.04550949, mean(E): -21.78580847-0.00010134j, var(E): 0.05915805
-0.0
tensor(23.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=2.73............. Loss: 0.06645263, mean(E): -21.79737545-0.00010992j, var(E): 0.07381396
-0.0
tensor(23.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=2.73............. Loss: 0.05239479, mean(E): -21.79069081+0.00001736j, var(E): 0.09811086
-0.0
tensor(23.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=2.73............. Loss: 0.09122641, mean(E): -21.80040605-0.00009459j, var(E): 0.07003542
-0.0
tensor(23.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=2.73............. Loss: -0.05034512, mean(E): -21.78898738+0.00009129j, var(E): 0.13486853
-0.0
tensor(23.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=2.73............. Loss: -0.10245044, mean(E): -21.77648393-0.00003622j, var(E): 0.06043244
-0.0
tensor(23.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=2.73............. Loss: -0.12680642, mean(E): -21.77875246+0.00010101j, var(E): 0.10334986
-0.0
tensor(23.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=2.72............. Loss: -0.07846631, mean(E): -21.77789008-0.00004063j, var(E): 0.14782005
-0.0
tensor(23.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=2.72............. Loss: 0.00642757, mean(E): -21.79354496+0.00004404j, var(E): 0.08087258
-0.0
tensor(23.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=2.72............. Loss: -0.03341565, mean(E): -21.78999097+0.00006842j, var(E): 0.08652696
-0.0
tensor(23.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=2.73............. Loss: 0.04974016, mean(E): -21.79375030-0.00002569j, var(E): 0.05876242
-0.0
tensor(23.4806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=2.72............. Loss: -0.06084025, mean(E): -21.78050200-0.00002206j, var(E): 0.06274550
-0.0
tensor(23.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=2.73............. Loss: 0.01050634, mean(E): -21.79394656-0.00001907j, var(E): 0.09855237
-0.0
tensor(23.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=2.73............. Loss: 0.34654228, mean(E): -21.82048370+0.00003474j, var(E): 0.27531646
-0.0
tensor(23.4824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=2.72............. Loss: -0.15201789, mean(E): -21.77052276+0.00003617j, var(E): 0.10597720
-0.0
tensor(23.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=2.73............. Loss: -0.00851763, mean(E): -21.79649857+0.00000459j, var(E): 0.05926352
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=2.73............. Loss: -0.01743522, mean(E): -21.78452669+0.00001841j, var(E): 0.10997916
-0.0
tensor(23.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=2.73............. Loss: 0.09569678, mean(E): -21.79919189+0.00000493j, var(E): 0.14239265
-0.0
tensor(23.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=2.72............. Loss: 0.01146006, mean(E): -21.78708189-0.00003142j, var(E): 0.09784442
-0.0
tensor(23.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=2.72............. Loss: -0.02565844, mean(E): -21.78308572-0.00002561j, var(E): 0.06813012
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=2.73............. Loss: 0.01803440, mean(E): -21.79685369+0.00000619j, var(E): 0.08577784
-0.0
tensor(23.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=2.72............. Loss: 0.02014522, mean(E): -21.78895559-0.00001636j, var(E): 0.14564234
-0.0
tensor(23.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=2.73............. Loss: -0.01110306, mean(E): -21.78981996+0.00000291j, var(E): 0.08730036
-0.0
tensor(23.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=2.73............. Loss: 0.04583159, mean(E): -21.79474682-0.00003905j, var(E): 0.07180560
-0.0
tensor(23.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=2.72............. Loss: 0.13084151, mean(E): -21.80616883+0.00002305j, var(E): 0.12809226
-0.0
tensor(23.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=2.71............. Loss: -0.04759109, mean(E): -21.78430443-0.00000149j, var(E): 0.10484140
-0.0
tensor(23.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=2.72............. Loss: -0.04603957, mean(E): -21.79052107+0.00001183j, var(E): 0.08628539
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=2.72............. Loss: -0.02027514, mean(E): -21.79502929+0.00000800j, var(E): 0.10854369
-0.0
tensor(23.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=2.73............. Loss: 0.14844293, mean(E): -21.81130231-0.00000057j, var(E): 0.11599345
-0.0
tensor(23.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=2.73............. Loss: 0.01244283, mean(E): -21.78991607-0.00000782j, var(E): 0.07456883
-0.0
tensor(23.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=2.72............. Loss: 0.03580689, mean(E): -21.79379638+0.00000398j, var(E): 0.05622607
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=2.72............. Loss: 0.01299389, mean(E): -21.79189797-0.00000706j, var(E): 0.06348947
-0.0
tensor(23.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=2.72............. Loss: -0.12559105, mean(E): -21.76742102-0.00000076j, var(E): 0.08183602
-0.0
tensor(23.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=2.73............. Loss: -0.13125172, mean(E): -21.77767651+0.00000393j, var(E): 0.09680494
-0.0
tensor(23.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=2.72............. Loss: -0.07916947, mean(E): -21.79093882-0.00000321j, var(E): 0.12759648
-0.0
tensor(23.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=2.71............. Loss: -0.01718974, mean(E): -21.78716209+0.00000072j, var(E): 0.04301785
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=2.72............. Loss: -0.08959968, mean(E): -21.78207421+0.00000212j, var(E): 0.13223319
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=2.71............. Loss: -0.06934117, mean(E): -21.78311441+0.00000718j, var(E): 0.07398284
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=2.72............. Loss: -0.12327198, mean(E): -21.76952346-0.00000034j, var(E): 0.09525306
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=2.73............. Loss: 0.03585252, mean(E): -21.80140226+0.00000384j, var(E): 0.11679575
-0.0
tensor(23.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=2.73............. Loss: -0.09909095, mean(E): -21.77229509-0.00000161j, var(E): 0.09820033
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=2.72............. Loss: -0.00629018, mean(E): -21.79521268+0.00000183j, var(E): 0.09719442
-0.0
tensor(23.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=2.73............. Loss: 0.02525330, mean(E): -21.79229919+0.00001471j, var(E): 0.09567032
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=2.72............. Loss: 0.02037212, mean(E): -21.79580083-0.00000205j, var(E): 0.11181844
-0.0
tensor(23.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=2.73............. Loss: -0.03357009, mean(E): -21.78935353+0.00000049j, var(E): 0.09868867
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=2.73............. Loss: -0.03671420, mean(E): -21.79203839-0.00004829j, var(E): 0.09065345
-0.0
tensor(23.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=2.72............. Loss: -0.06882149, mean(E): -21.77672354+0.00005113j, var(E): 0.16203647
-0.0
tensor(23.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=2.73............. Loss: 0.07347523, mean(E): -21.80695917+0.00019168j, var(E): 0.13427612
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=2.73............. Loss: -0.10476446, mean(E): -21.78351846-0.00008306j, var(E): 0.07025708
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=2.72............. Loss: -0.09870304, mean(E): -21.78121255-0.00000725j, var(E): 0.07694176
-0.0
tensor(23.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=2.72............. Loss: 0.16015136, mean(E): -21.81782524-0.00004702j, var(E): 0.13238463
-0.0
tensor(23.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=2.72............. Loss: -0.20359350, mean(E): -21.76376396-0.00011765j, var(E): 0.16428651
-0.0
tensor(23.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=2.73............. Loss: -0.09885812, mean(E): -21.78601308-0.00026827j, var(E): 0.12046351
-0.0
tensor(23.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=2.73............. Loss: -0.11318651, mean(E): -21.77755246-0.00022442j, var(E): 0.09067047
-0.0
tensor(23.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=2.73............. Loss: -0.08054236, mean(E): -21.77893415-0.00004202j, var(E): 0.06946215
-0.0
tensor(23.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=2.72............. Loss: -0.02851141, mean(E): -21.78980364-0.00025068j, var(E): 0.06119936
-0.0
tensor(23.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=2.72............. Loss: 0.00492071, mean(E): -21.79282160+0.00008738j, var(E): 0.06907366
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=2.71............. Loss: -0.15910528, mean(E): -21.77226692+0.00004268j, var(E): 0.11890603
-0.0
tensor(23.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=2.73............. Loss: 0.08903765, mean(E): -21.80000296+0.00016292j, var(E): 0.40543773
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=2.72............. Loss: 0.08744283, mean(E): -21.80762354+0.00002812j, var(E): 0.07356218
-0.0
tensor(23.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=2.73............. Loss: 0.18211636, mean(E): -21.81833407+0.00002629j, var(E): 0.31032139
-0.0
tensor(23.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=2.73............. Loss: -0.05235475, mean(E): -21.78767147+0.00003481j, var(E): 0.10765978
-0.0
tensor(23.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=2.72............. Loss: -0.05509180, mean(E): -21.77425368-0.00000760j, var(E): 0.11001200
-0.0
tensor(23.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=2.72............. Loss: -0.04572702, mean(E): -21.79276148+0.00003797j, var(E): 0.09505713
-0.0
tensor(23.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=2.71............. Loss: -0.04593208, mean(E): -21.77532327+0.00003159j, var(E): 0.12532659
-0.0
tensor(23.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=2.72............. Loss: -0.05459854, mean(E): -21.77767921+0.00001405j, var(E): 0.11291923
-0.0
tensor(23.5121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=2.73............. Loss: 0.04265260, mean(E): -21.80063380+0.00000506j, var(E): 0.11144919
-0.0
tensor(23.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=2.73............. Loss: 0.20046154, mean(E): -21.81654164+0.00000903j, var(E): 0.17139307
-0.0
tensor(23.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=2.72............. Loss: 0.03477417, mean(E): -21.79330084-0.00000727j, var(E): 0.12051672
-0.0
tensor(23.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=2.72............. Loss: 0.05451441, mean(E): -21.79847310+0.00001496j, var(E): 0.09340395
-0.0
tensor(23.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=2.73............. Loss: -0.05952975, mean(E): -21.77984345+0.00001205j, var(E): 0.06687101
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=2.73............. Loss: -0.07816227, mean(E): -21.78521438+0.00000805j, var(E): 0.11747366
-0.0
tensor(23.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=2.73............. Loss: -0.02333050, mean(E): -21.78957990-0.00001557j, var(E): 0.10033338
-0.0
tensor(23.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=2.73............. Loss: -0.07361098, mean(E): -21.79141384+0.00000661j, var(E): 0.12529259
-0.0
tensor(23.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=2.72............. Loss: -0.08983487, mean(E): -21.77684392+0.00000041j, var(E): 0.10738065
-0.0
tensor(23.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=2.73............. Loss: 0.06631696, mean(E): -21.80192061-0.00000141j, var(E): 0.09995085
-0.0
tensor(23.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=2.72............. Loss: -0.08813499, mean(E): -21.78208169-0.00000123j, var(E): 0.13619339
-0.0
tensor(23.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=2.71............. Loss: -0.07332317, mean(E): -21.78145347+0.00000011j, var(E): 0.09312326
-0.0
tensor(23.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=2.72............. Loss: -0.09127280, mean(E): -21.77575284-0.00000271j, var(E): 0.08097829
-0.0
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=2.71............. Loss: 0.04937663, mean(E): -21.80847619+0.00000161j, var(E): 0.15819100
-0.0
tensor(23.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=2.72............. Loss: -0.04943290, mean(E): -21.78485258+0.00000061j, var(E): 0.12496561
-0.0
tensor(23.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=2.72............. Loss: -0.12368651, mean(E): -21.78484501-0.00000123j, var(E): 0.11117466
-0.0
tensor(23.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=2.71............. Loss: -0.04975755, mean(E): -21.78897015+0.00000039j, var(E): 0.09682358
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=2.72............. Loss: 0.05866066, mean(E): -21.79747472-0.00000057j, var(E): 0.07607585
-0.0
tensor(23.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=2.73............. Loss: -0.03439862, mean(E): -21.78588062-0.00000253j, var(E): 0.37063872
-0.0
tensor(23.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=2.72............. Loss: 0.02772617, mean(E): -21.79815909+0.00000225j, var(E): 0.08106317
-0.0
tensor(23.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=2.73............. Loss: 0.00199708, mean(E): -21.78997515+0.00000211j, var(E): 0.04916571
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=2.71............. Loss: -0.06941144, mean(E): -21.78421362-0.00000057j, var(E): 0.10962051
-0.0
tensor(23.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=2.71............. Loss: 0.19648275, mean(E): -21.81412163-0.00000029j, var(E): 0.21037770
-0.0
tensor(23.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=2.73............. Loss: -0.01581139, mean(E): -21.79039320-0.00000053j, var(E): 0.12168213
-0.0
tensor(23.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=2.73............. Loss: -0.13987672, mean(E): -21.77266824-0.00000046j, var(E): 0.24862476
-0.0
tensor(23.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=2.73............. Loss: -0.09012553, mean(E): -21.78033010+0.00000040j, var(E): 0.10889741
-0.0
tensor(23.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=2.73............. Loss: 0.00781558, mean(E): -21.79390979-0.00000168j, var(E): 0.06738707
-0.0
tensor(23.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=2.72............. Loss: -0.05444368, mean(E): -21.79039494+0.00000040j, var(E): 0.09989481
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=2.72............. Loss: -0.03021788, mean(E): -21.78952165+0.00000040j, var(E): 0.15822989
-0.0
tensor(23.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=2.71............. Loss: 0.08332817, mean(E): -21.80067867+0.00000011j, var(E): 0.05788440
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=2.71............. Loss: -0.07461437, mean(E): -21.78361047-0.00000077j, var(E): 0.10559538
-0.0
tensor(23.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=2.73............. Loss: 0.14467060, mean(E): -21.80911798-0.00000021j, var(E): 0.11713776
-0.0
tensor(23.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=2.73............. Loss: 0.08266957, mean(E): -21.79953767-0.00000038j, var(E): 0.09014730
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=2.72............. Loss: -0.12128079, mean(E): -21.77976045-0.00000116j, var(E): 0.13281761
-0.0
tensor(23.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=2.72............. Loss: 0.00499729, mean(E): -21.79035831+0.00000068j, var(E): 0.11126430
-0.0
tensor(23.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=2.72............. Loss: -0.02347720, mean(E): -21.79224848+0.00000037j, var(E): 0.05125452
-0.0
tensor(23.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=2.73............. Loss: 0.04779910, mean(E): -21.79266838+0.00000110j, var(E): 0.09081380
-0.0
tensor(23.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=2.73............. Loss: 0.06662281, mean(E): -21.80038488-0.00000106j, var(E): 0.05967104
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=2.72............. Loss: 0.02388728, mean(E): -21.79490589+0.00000165j, var(E): 0.06780476
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=2.73............. Loss: 0.00773895, mean(E): -21.79526826-0.00000096j, var(E): 0.05170842
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=2.71............. Loss: -0.12002996, mean(E): -21.78142937-0.00000131j, var(E): 0.09956668
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=2.72............. Loss: -0.16517624, mean(E): -21.77697130+0.00000394j, var(E): 0.11347880
-0.0
tensor(23.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=2.73............. Loss: -0.05809512, mean(E): -21.78415474-0.00000135j, var(E): 0.04454731
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=2.71............. Loss: -0.00373511, mean(E): -21.79144135-0.00000740j, var(E): 0.06118971
-0.0
tensor(23.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=2.73............. Loss: 0.04606396, mean(E): -21.79998914-0.00003808j, var(E): 0.09466954
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=2.73............. Loss: -0.00247388, mean(E): -21.78999144-0.00004162j, var(E): 0.24132488
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=2.71............. Loss: -0.12691670, mean(E): -21.77938416+0.00002301j, var(E): 0.10751969
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=2.72............. Loss: -0.01171301, mean(E): -21.78946623+0.00006893j, var(E): 0.07144637
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=2.73............. Loss: -0.14034673, mean(E): -21.76924947+0.00000831j, var(E): 0.08767813
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=2.73............. Loss: 0.03445513, mean(E): -21.79298310-0.00013285j, var(E): 0.10692166
-0.0
tensor(23.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=2.73............. Loss: -0.04621207, mean(E): -21.79533512+0.00001009j, var(E): 0.09598170
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=2.73............. Loss: -0.01025593, mean(E): -21.79176333+0.00046945j, var(E): 0.05519516
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=2.71............. Loss: 0.08554688, mean(E): -21.80159649+0.00019641j, var(E): 0.11502283
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=2.71............. Loss: 0.01098571, mean(E): -21.79613232-0.00011079j, var(E): 0.07124801
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=2.71............. Loss: 0.10720395, mean(E): -21.80290707-0.00006426j, var(E): 0.38324568
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=2.73............. Loss: 0.12391155, mean(E): -21.80624753-0.00005911j, var(E): 0.13240631
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=2.73............. Loss: -0.15382100, mean(E): -21.77422887-0.00025745j, var(E): 0.08209220
-0.0
tensor(23.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=2.73............. Loss: -0.01350281, mean(E): -21.79057912+0.00008827j, var(E): 0.13065703
-0.0
tensor(23.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=2.72............. Loss: 0.04891291, mean(E): -21.79669079+0.00024696j, var(E): 0.05822893
-0.0
tensor(23.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=2.73............. Loss: -0.08287160, mean(E): -21.78454806-0.00018402j, var(E): 0.07663545
-0.0
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=2.71............. Loss: -0.00557822, mean(E): -21.78727213+0.00000243j, var(E): 0.05533379
-0.0
tensor(23.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=2.73............. Loss: -0.07885767, mean(E): -21.77751215-0.00015456j, var(E): 0.12458147
-0.0
tensor(23.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=2.73............. Loss: 0.05117040, mean(E): -21.79197818-0.00003442j, var(E): 0.08750562
-0.0
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=2.71............. Loss: -0.06795934, mean(E): -21.78867226-0.00001748j, var(E): 0.07056642
-0.0
tensor(23.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=2.72............. Loss: 0.03703489, mean(E): -21.79098487+0.00010198j, var(E): 0.11768750
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=2.71............. Loss: -0.02461223, mean(E): -21.78643908-0.00006155j, var(E): 0.15271884
-0.0
tensor(23.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=2.72............. Loss: -0.13208811, mean(E): -21.77107288+0.00002239j, var(E): 0.04919099
-0.0
tensor(23.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=2.73............. Loss: 0.05926514, mean(E): -21.80488679+0.00000513j, var(E): 0.09297223
-0.0
tensor(23.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=2.73............. Loss: -0.09237181, mean(E): -21.78159139+0.00003058j, var(E): 0.08881507
-0.0
tensor(23.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=2.72............. Loss: -0.03625302, mean(E): -21.78823258+0.00003285j, var(E): 0.05222035
-0.0
tensor(23.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=2.73............. Loss: 0.05567886, mean(E): -21.79002973-0.00001603j, var(E): 0.11870432
-0.0
tensor(23.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=2.71............. Loss: -0.03442672, mean(E): -21.78380924+0.00002477j, var(E): 0.07940732
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=2.72............. Loss: -0.07586113, mean(E): -21.78218075-0.00001965j, var(E): 0.06218334
-0.0
tensor(23.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=2.73............. Loss: -0.09103149, mean(E): -21.77602488+0.00000325j, var(E): 0.08315352
-0.0
tensor(23.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=2.72............. Loss: 0.03329204, mean(E): -21.79579336+0.00003103j, var(E): 0.13613092
-0.0
tensor(23.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=2.71............. Loss: 0.08557370, mean(E): -21.80633849+0.00000063j, var(E): 0.08952877
-0.0
tensor(23.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=2.72............. Loss: -0.01101382, mean(E): -21.79519495+0.00000351j, var(E): 0.10006393
-0.0
tensor(23.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=2.72............. Loss: 0.10801394, mean(E): -21.80344677-0.00000498j, var(E): 0.13947786
-0.0
tensor(23.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=2.72............. Loss: -0.02023732, mean(E): -21.79232683+0.00001461j, var(E): 0.05675278
-0.0
tensor(23.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=2.73............. Loss: 0.08661122, mean(E): -21.80849379+0.00000939j, var(E): 0.11382741
-0.0
tensor(23.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=2.71............. Loss: 0.02695136, mean(E): -21.80034423+0.00001899j, var(E): 0.08264269
-0.0
tensor(23.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=2.72............. Loss: 0.03583379, mean(E): -21.80209148+0.00000795j, var(E): 0.07618587
-0.0
tensor(23.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=2.73............. Loss: -0.04762647, mean(E): -21.79105547-0.00000237j, var(E): 0.14748066
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=2.73............. Loss: 0.08800923, mean(E): -21.79953763+0.00003001j, var(E): 0.16816163
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=2.72............. Loss: -0.01993204, mean(E): -21.79214924+0.00001795j, var(E): 0.10864811
-0.0
tensor(23.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=2.73............. Loss: -0.04723134, mean(E): -21.78833146-0.00004620j, var(E): 0.07938314
-0.0
tensor(23.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=2.72............. Loss: 0.12803423, mean(E): -21.81104860+0.00003654j, var(E): 0.09164347
-0.0
tensor(23.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=2.72............. Loss: 0.12838724, mean(E): -21.79849142+0.00000336j, var(E): 0.18102442
-0.0
tensor(23.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=2.73............. Loss: -0.09164759, mean(E): -21.77860042+0.00003840j, var(E): 0.08615634
-0.0
tensor(23.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=2.71............. Loss: -0.02000147, mean(E): -21.78583055+0.00002393j, var(E): 0.13676434
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=2.72............. Loss: 0.01319170, mean(E): -21.79794199-0.00000060j, var(E): 0.07399979
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=2.72............. Loss: -0.06567868, mean(E): -21.79285451-0.00001024j, var(E): 0.10940824
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=2.73............. Loss: -0.06557151, mean(E): -21.78509378-0.00001277j, var(E): 0.12458851
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=2.73............. Loss: -0.04210345, mean(E): -21.78935591-0.00000478j, var(E): 0.07618358
-0.0
tensor(23.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=2.73............. Loss: 0.00366685, mean(E): -21.79640015+0.00001649j, var(E): 0.09190991
-0.0
tensor(23.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=2.72............. Loss: -0.12128437, mean(E): -21.77695919+0.00001932j, var(E): 0.08677664
-0.0
tensor(23.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=2.72............. Loss: -0.01612304, mean(E): -21.79053272+0.00017080j, var(E): 0.11792232
-0.0
tensor(23.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=2.72............. Loss: -0.01962467, mean(E): -21.79744157-0.00005618j, var(E): 0.21080537
-0.0
tensor(23.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=2.72............. Loss: 0.06229249, mean(E): -21.79704132-0.00009558j, var(E): 0.12719009
-0.0
tensor(23.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=2.73............. Loss: -0.02218690, mean(E): -21.78788439-0.00004441j, var(E): 0.13984325
-0.0
tensor(23.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=2.73............. Loss: -0.14512650, mean(E): -21.77451595+0.00009087j, var(E): 0.10754845
-0.0
tensor(23.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=2.73............. Loss: -0.05281314, mean(E): -21.78239578+0.00034738j, var(E): 0.07220394
-0.0
tensor(23.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=2.73............. Loss: -0.01841526, mean(E): -21.78991298+0.00045900j, var(E): 0.03821599
-0.0
tensor(23.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=2.73............. Loss: -0.19004812, mean(E): -21.76877426+0.00017845j, var(E): 0.12153530
-0.0
tensor(23.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=2.73............. Loss: -0.00696724, mean(E): -21.79121350-0.00013073j, var(E): 0.05879733
-0.0
tensor(23.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=2.73............. Loss: 0.02951935, mean(E): -21.79613090+0.00004395j, var(E): 0.07654580
-0.0
tensor(23.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=2.73............. Loss: 0.00592712, mean(E): -21.79332310-0.00019315j, var(E): 0.05054061
-0.0
tensor(23.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=2.73............. Loss: -0.08696183, mean(E): -21.78466342+0.00012604j, var(E): 0.12772985
-0.0
tensor(23.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=2.72............. Loss: 0.05297220, mean(E): -21.79231409+0.00017389j, var(E): 0.06653966
-0.0
tensor(23.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=2.71............. Loss: 0.16360254, mean(E): -21.81356330-0.00001055j, var(E): 0.23674680
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=2.72............. Loss: -0.14352667, mean(E): -21.76845251-0.00001924j, var(E): 0.10611168
-0.0
tensor(23.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=2.73............. Loss: 0.01542335, mean(E): -21.79727456+0.00005901j, var(E): 0.08461239
-0.0
tensor(23.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=2.73............. Loss: 0.02392334, mean(E): -21.79566921+0.00006250j, var(E): 0.11032756
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=2.73............. Loss: -0.05924877, mean(E): -21.79301239-0.00001874j, var(E): 0.06832522
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=2.73............. Loss: 0.00993825, mean(E): -21.79246633-0.00004822j, var(E): 0.11658446
-0.0
tensor(23.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=2.73............. Loss: -0.11564670, mean(E): -21.77894763+0.00000700j, var(E): 0.12143490
-0.0
tensor(23.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=2.73............. Loss: -0.03358077, mean(E): -21.78655089+0.00004122j, var(E): 0.09492568
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=2.73............. Loss: -0.09445652, mean(E): -21.77894517+0.00000978j, var(E): 0.06215546
-0.0
tensor(23.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=2.73............. Loss: 0.07015317, mean(E): -21.79698296+0.00005502j, var(E): 0.07126604
-0.0
tensor(23.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=2.72............. Loss: 0.00686274, mean(E): -21.79337455+0.00004134j, var(E): 0.05433401
-0.0
tensor(23.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=2.73............. Loss: 0.05010220, mean(E): -21.79816577+0.00003712j, var(E): 0.06636328
-0.0
tensor(23.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=2.72............. Loss: -0.03606931, mean(E): -21.78899047-0.00000617j, var(E): 0.13776935
-0.0
tensor(23.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=2.72............. Loss: 0.08300976, mean(E): -21.79818739-0.00002553j, var(E): 0.07713599
-0.0
tensor(23.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=2.73............. Loss: -0.02568344, mean(E): -21.78439814+0.00000392j, var(E): 0.11172356
-0.0
tensor(23.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=2.72............. Loss: -0.06527409, mean(E): -21.78500063+0.00000867j, var(E): 0.10137161
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=2.73............. Loss: -0.00934125, mean(E): -21.79085107+0.00001215j, var(E): 0.05146796
-0.0
tensor(23.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=2.73............. Loss: -0.01998088, mean(E): -21.79044685-0.00000876j, var(E): 0.08208623
-0.0
tensor(23.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=2.73............. Loss: 0.02637120, mean(E): -21.79746258-0.00000197j, var(E): 0.06437424
-0.0
tensor(23.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=2.73............. Loss: 0.07951662, mean(E): -21.80110002-0.00000171j, var(E): 0.06698760
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=2.73............. Loss: -0.06757006, mean(E): -21.78609379-0.00000059j, var(E): 0.09312722
-0.0
tensor(23.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=2.73............. Loss: 0.02545092, mean(E): -21.79435359-0.00000059j, var(E): 0.08401535
-0.0
tensor(23.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=2.73............. Loss: 0.11791716, mean(E): -21.80795143+0.00000064j, var(E): 0.08528762
-0.0
tensor(23.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=2.73............. Loss: -0.00802929, mean(E): -21.79504072+0.00000060j, var(E): 0.04046732
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=2.72............. Loss: 0.11281999, mean(E): -21.81099040+0.00000160j, var(E): 0.07323513
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=2.73............. Loss: -0.04937202, mean(E): -21.79234517+0.00000020j, var(E): 0.09830338
-0.0
tensor(23.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=2.73............. Loss: 0.00670515, mean(E): -21.78583337-0.00000117j, var(E): 0.27598818
-0.0
tensor(23.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=2.72............. Loss: -0.08986933, mean(E): -21.77815135-0.00000090j, var(E): 0.10269964
-0.0
tensor(23.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=2.73............. Loss: -0.01682776, mean(E): -21.79357265-0.00000133j, var(E): 0.06214926
-0.0
tensor(23.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=2.73............. Loss: 0.06340637, mean(E): -21.80127224-0.00000094j, var(E): 0.18192619
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=2.73............. Loss: 0.01103913, mean(E): -21.79668958+0.00000107j, var(E): 0.10431648
-0.0
tensor(23.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=2.73............. Loss: -0.06018335, mean(E): -21.79206201+0.00000009j, var(E): 0.11042030
-0.0
tensor(23.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=2.73............. Loss: -0.03992833, mean(E): -21.78772004-0.00000013j, var(E): 0.07062638
-0.0
tensor(23.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=2.73............. Loss: 0.07829011, mean(E): -21.80551111+0.00000036j, var(E): 0.07790001
-0.0
tensor(23.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=2.73............. Loss: -0.10577342, mean(E): -21.77864349-0.00000008j, var(E): 0.07880249
-0.0
tensor(23.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=2.73............. Loss: 0.06608996, mean(E): -21.80076163+0.00000062j, var(E): 0.08548185
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=2.73............. Loss: -0.07874565, mean(E): -21.77930228-0.00000028j, var(E): 0.06545355
-0.0
tensor(23.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=2.72............. Loss: 0.08249218, mean(E): -21.80250971-0.00000001j, var(E): 0.13453844
-0.0
tensor(23.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=2.72............. Loss: -0.09126954, mean(E): -21.77955666-0.00000077j, var(E): 0.11102268
-0.0
tensor(23.6262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=2.72............. Loss: -0.08972366, mean(E): -21.77262189+0.00000018j, var(E): 0.04881912
-0.0
tensor(23.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=2.73............. Loss: -0.11969063, mean(E): -21.77545473+0.00000022j, var(E): 0.20878258
-0.0
tensor(23.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=2.73............. Loss: 0.02280555, mean(E): -21.79157174+0.00000003j, var(E): 0.16025753
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=2.73............. Loss: 0.05947595, mean(E): -21.80405047-0.00000005j, var(E): 0.04786474
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=2.73............. Loss: -0.16453203, mean(E): -21.77205333-0.00000014j, var(E): 0.13778046
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=2.72............. Loss: 0.02373612, mean(E): -21.80068087-0.00000037j, var(E): 0.11398642
-0.0
tensor(23.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=2.73............. Loss: 0.00659285, mean(E): -21.78035760-0.00000066j, var(E): 0.26435770
-0.0
tensor(23.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=2.73............. Loss: 0.05275350, mean(E): -21.80426238+0.00000050j, var(E): 0.13614998
-0.0
tensor(23.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=2.72............. Loss: -0.06163853, mean(E): -21.77830841-0.00000019j, var(E): 0.07439321
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=2.72............. Loss: -0.03815974, mean(E): -21.78788520+0.00000010j, var(E): 0.12291890
-0.0
tensor(23.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=2.72............. Loss: -0.09349769, mean(E): -21.78462928-0.00000014j, var(E): 0.11599999
-0.0
tensor(23.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=2.73............. Loss: 0.07534452, mean(E): -21.80253749-0.00000020j, var(E): 0.08880873
-0.0
tensor(23.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=2.73............. Loss: -0.10492103, mean(E): -21.78090000-0.00000029j, var(E): 0.05158778
-0.0
tensor(23.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=2.73............. Loss: 0.03759806, mean(E): -21.79996643-0.00000015j, var(E): 0.07000008
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=2.73............. Loss: -0.13146394, mean(E): -21.77398245+0.00000049j, var(E): 0.07624335
-0.0
tensor(23.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=2.73............. Loss: -0.06260109, mean(E): -21.78797905+0.00000317j, var(E): 0.08033474
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=2.72............. Loss: 0.05421887, mean(E): -21.79836333+0.00000217j, var(E): 0.11602144
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=2.73............. Loss: 0.14392579, mean(E): -21.80604095-0.00000190j, var(E): 0.16038196
-0.0
tensor(23.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=2.73............. Loss: 0.05628198, mean(E): -21.79692057-0.00000009j, var(E): 0.11460048
-0.0
tensor(23.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=2.72............. Loss: 0.01369796, mean(E): -21.78868191-0.00000018j, var(E): 0.04597100
-0.0
tensor(23.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=2.73............. Loss: -0.08324826, mean(E): -21.77767290-0.00000021j, var(E): 0.15003197
-0.0
tensor(23.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=2.73............. Loss: 0.01736507, mean(E): -21.79405990+0.00000017j, var(E): 0.34143607
-0.0
tensor(23.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=2.73............. Loss: 0.05709972, mean(E): -21.80264679+0.00000000j, var(E): 0.09022166
-0.0
tensor(23.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=2.72............. Loss: 0.03308687, mean(E): -21.79415406-0.00000163j, var(E): 0.11570111
-0.0
tensor(23.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=2.73............. Loss: 0.05616326, mean(E): -21.80275234-0.00000040j, var(E): 0.06958092
-0.0
tensor(23.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=2.73............. Loss: 0.14561927, mean(E): -21.81497298+0.00000497j, var(E): 0.08672070
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=2.73............. Loss: 0.07073745, mean(E): -21.80846909+0.00000238j, var(E): 0.08456762
-0.0
tensor(23.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=2.73............. Loss: 0.19002867, mean(E): -21.81359952-0.00000874j, var(E): 0.14070875
-0.0
tensor(23.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=2.72............. Loss: -0.05920088, mean(E): -21.78567871-0.00000292j, var(E): 0.07578224
-0.0
tensor(23.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=2.73............. Loss: -0.02610475, mean(E): -21.78862259-0.00000749j, var(E): 0.11562195
-0.0
tensor(23.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=2.73............. Loss: -0.04580555, mean(E): -21.77999011+0.00000562j, var(E): 0.04717384
-0.0
tensor(23.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=2.73............. Loss: 0.05363111, mean(E): -21.79053813-0.00005072j, var(E): 0.08767066
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=2.72............. Loss: -0.00693707, mean(E): -21.79297850+0.00002803j, var(E): 0.04160468
-0.0
tensor(23.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=2.73............. Loss: -0.11713602, mean(E): -21.77876050+0.00003377j, var(E): 0.16359485
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=2.73............. Loss: -0.12027660, mean(E): -21.77495015-0.00007794j, var(E): 0.11461318
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=2.73............. Loss: 0.17285112, mean(E): -21.80734482+0.00018288j, var(E): 0.20324162
-0.0
tensor(23.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=2.73............. Loss: -0.07353118, mean(E): -21.78652590-0.00005038j, var(E): 0.08217051
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=2.73............. Loss: -0.07291107, mean(E): -21.79041547-0.00017823j, var(E): 0.09415619
-0.0
tensor(23.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=2.73............. Loss: 0.09306873, mean(E): -21.79825939-0.00016211j, var(E): 0.06736232
-0.0
tensor(23.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=2.72............. Loss: -0.03586541, mean(E): -21.78871793+0.00021097j, var(E): 0.06206489
-0.0
tensor(23.6459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=2.73............. Loss: -0.00520675, mean(E): -21.79024561-0.00011309j, var(E): 0.12604282
-0.0
tensor(23.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=2.73............. Loss: -0.05534727, mean(E): -21.78153127+0.00003976j, var(E): 0.10990115
-0.0
tensor(23.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=2.72............. Loss: -0.03883028, mean(E): -21.78051204+0.00009241j, var(E): 0.13626318
-0.0
tensor(23.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=2.73............. Loss: 0.16427728, mean(E): -21.80064041+0.00005573j, var(E): 0.23102434
-0.0
tensor(23.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=2.73............. Loss: 0.04586442, mean(E): -21.80024540+0.00000955j, var(E): 0.08699037
-0.0
tensor(23.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=2.73............. Loss: -0.09412673, mean(E): -21.78052026-0.00006406j, var(E): 0.06026644
-0.0
tensor(23.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=2.72............. Loss: 0.03176009, mean(E): -21.80446271-0.00001837j, var(E): 0.07300695
-0.0
tensor(23.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=2.73............. Loss: 0.05727943, mean(E): -21.79910587+0.00003282j, var(E): 0.11753608
-0.0
tensor(23.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=2.73............. Loss: -0.11311695, mean(E): -21.77742978-0.00000500j, var(E): 0.12346620
-0.0
tensor(23.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=2.73............. Loss: -0.00657711, mean(E): -21.79150735+0.00001849j, var(E): 0.09543150
-0.0
tensor(23.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=2.73............. Loss: -0.08546568, mean(E): -21.77502499-0.00000507j, var(E): 0.07787848
-0.0
tensor(23.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=2.73............. Loss: 0.01377044, mean(E): -21.79602574-0.00001086j, var(E): 0.05857483
-0.0
tensor(23.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=2.73............. Loss: -0.20363159, mean(E): -21.76305834+0.00000788j, var(E): 0.12408555
-0.0
tensor(23.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=2.73............. Loss: -0.06758020, mean(E): -21.78971610+0.00001496j, var(E): 0.06649745
-0.0
tensor(23.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(23.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=2.73............. Loss: 0.22035820, mean(E): -21.79984299-0.00000204j, var(E): 0.46803747
