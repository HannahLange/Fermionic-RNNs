1.13.1+cu117
GPU is available
Namespace(Jp=0.0, Jz=1.0, U=1.0, t=3.0, density=0.9375, Nx=4, Ny=4, bounds=1, boundsx=0, boundsy=0, load_model=0, sym=0.0, antisym=0.0, hd=30)
4x4_qubits/periodic/Jp=0.0Jz=1.0t=3.0den=0.94/
Use RNN cell with weight sharing.
Model parameters: 
rnn.W1: 10800
rnn.b1: 30
rnn.W2: 10800
rnn.b2: 30
rnn.Wmerge: 1800
lin1.weight: 90
lin1.bias: 3
lin2.weight: 90
lin2.bias: 3
Total number of parameters in the network: 23646
0.0
tensor(8.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1/ 20000/ t/epoch=2.05............. Loss: 6.35621550, mean(E): -15.24121372-0.00200583j, var(E): 35.89272641
0.0
tensor(8.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.0970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10/ 20000/ t/epoch=0.31............. Loss: 3.91396523, mean(E): -15.13363613-0.00299106j, var(E): 16.41685740
0.0
tensor(8.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20/ 20000/ t/epoch=0.31............. Loss: 3.47523548, mean(E): -15.43594554-0.00485329j, var(E): 16.38341431
0.0
tensor(8.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 30/ 20000/ t/epoch=0.31............. Loss: 4.96159017, mean(E): -15.31548784-0.00275785j, var(E): 20.05741187
0.0
tensor(8.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.1968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 40/ 20000/ t/epoch=0.31............. Loss: 7.52680653, mean(E): -16.38451839-0.01446213j, var(E): 49.25665887
0.0
tensor(8.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.2918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 50/ 20000/ t/epoch=0.31............. Loss: 2.73305409, mean(E): -15.60921544-0.00845991j, var(E): 12.19737534
0.0
tensor(8.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 60/ 20000/ t/epoch=0.31............. Loss: 3.68336374, mean(E): -15.93275896+0.00950026j, var(E): 16.39245926
0.0
tensor(8.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 70/ 20000/ t/epoch=0.31............. Loss: 3.90179750, mean(E): -16.09080807-0.04033664j, var(E): 16.15225114
0.0
tensor(8.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 80/ 20000/ t/epoch=0.31............. Loss: 4.05829598, mean(E): -16.45422664-0.01633249j, var(E): 18.88530807
0.0
tensor(8.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 90/ 20000/ t/epoch=0.31............. Loss: 3.13101093, mean(E): -16.60356289-0.02620850j, var(E): 13.13487238
0.0
tensor(8.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 100/ 20000/ t/epoch=0.31............. Loss: 3.15708422, mean(E): -17.13420617-0.00198914j, var(E): 17.37560100
0.0
tensor(8.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 110/ 20000/ t/epoch=0.31............. Loss: 2.83762818, mean(E): -16.64329513+0.03835890j, var(E): 14.53581237
0.0
tensor(8.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 120/ 20000/ t/epoch=0.32............. Loss: 4.38121608, mean(E): -18.13203461-0.01154943j, var(E): 25.22300952
0.0
tensor(8.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.7974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 130/ 20000/ t/epoch=0.31............. Loss: 3.51138522, mean(E): -18.44310065-0.08005491j, var(E): 20.70355601
0.0
tensor(8.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 140/ 20000/ t/epoch=0.31............. Loss: 2.49699456, mean(E): -18.55402417+0.01727847j, var(E): 16.64064957
0.0
tensor(8.9182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(8.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 150/ 20000/ t/epoch=0.31............. Loss: 1.97535623, mean(E): -18.34597028+0.04095159j, var(E): 12.81285032
0.0
tensor(9.0118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 160/ 20000/ t/epoch=0.31............. Loss: 2.50074156, mean(E): -18.79224607+0.03871491j, var(E): 13.40945299
0.0
tensor(9.0948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 170/ 20000/ t/epoch=0.31............. Loss: 0.68876340, mean(E): -18.83472544+0.03069341j, var(E): 11.78708690
0.0
tensor(9.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 180/ 20000/ t/epoch=0.31............. Loss: 1.70732121, mean(E): -19.58915408-0.01329164j, var(E): 11.67797898
0.0
tensor(9.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 190/ 20000/ t/epoch=0.31............. Loss: 1.35416291, mean(E): -19.06376999+0.00237690j, var(E): 11.54767348
0.0
tensor(9.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 200/ 20000/ t/epoch=0.31............. Loss: 1.21671873, mean(E): -19.52712630+0.03485614j, var(E): 16.19421098
0.0
tensor(9.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 210/ 20000/ t/epoch=0.31............. Loss: 0.65774447, mean(E): -19.49023570+0.00802335j, var(E): 8.80770795
0.0
tensor(9.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 220/ 20000/ t/epoch=0.31............. Loss: 0.87001564, mean(E): -19.60033518-0.03672361j, var(E): 12.21373943
0.0
tensor(9.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 230/ 20000/ t/epoch=0.31............. Loss: 0.84038483, mean(E): -19.42275662+0.02797883j, var(E): 10.27212165
0.0
tensor(9.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 240/ 20000/ t/epoch=0.31............. Loss: 1.65032422, mean(E): -19.72093019-0.05453818j, var(E): 8.71790045
0.0
tensor(9.5053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 250/ 20000/ t/epoch=0.31............. Loss: 0.60079836, mean(E): -19.45282959-0.03200335j, var(E): 10.59833479
0.0
tensor(9.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 260/ 20000/ t/epoch=0.31............. Loss: 0.51010201, mean(E): -20.22241542+0.01653378j, var(E): 10.66326327
0.0
tensor(9.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.5961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 270/ 20000/ t/epoch=0.31............. Loss: 0.80479633, mean(E): -19.79445914+0.03018874j, var(E): 9.33103034
0.0
tensor(9.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 280/ 20000/ t/epoch=0.31............. Loss: 1.04851378, mean(E): -19.95834398-0.03096080j, var(E): 9.88377140
0.0
tensor(9.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 290/ 20000/ t/epoch=0.31............. Loss: 0.80662310, mean(E): -20.32637935-0.04977715j, var(E): 10.99462921
0.0
tensor(9.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 300/ 20000/ t/epoch=0.31............. Loss: 1.05607784, mean(E): -20.24233896-0.02712873j, var(E): 9.30416699
0.0
tensor(9.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 310/ 20000/ t/epoch=0.31............. Loss: 1.85674949, mean(E): -20.22934002+0.00578605j, var(E): 7.59335748
0.0
tensor(9.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 320/ 20000/ t/epoch=0.31............. Loss: 0.23465145, mean(E): -20.20647169+0.05105048j, var(E): 10.23025848
0.0
tensor(9.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 330/ 20000/ t/epoch=0.31............. Loss: 0.91625489, mean(E): -20.57455383-0.00759040j, var(E): 10.36456531
0.0
tensor(9.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 340/ 20000/ t/epoch=0.31............. Loss: -0.05645894, mean(E): -19.91839749-0.01049537j, var(E): 8.29947440
0.0
tensor(9.8205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 350/ 20000/ t/epoch=0.31............. Loss: 0.74469288, mean(E): -20.26467231+0.02072403j, var(E): 6.81846890
0.0
tensor(9.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 360/ 20000/ t/epoch=0.31............. Loss: -0.42273078, mean(E): -20.19504567-0.02003796j, var(E): 7.43109334
0.0
tensor(9.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 370/ 20000/ t/epoch=0.31............. Loss: 0.58855888, mean(E): -20.69783942+0.01454773j, var(E): 8.38293761
0.0
tensor(9.8932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.8986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 380/ 20000/ t/epoch=0.31............. Loss: 0.06605846, mean(E): -20.47255483+0.01559472j, var(E): 7.42245137
0.0
tensor(9.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 390/ 20000/ t/epoch=0.31............. Loss: -0.09287952, mean(E): -20.42263569-0.06791970j, var(E): 6.32385302
0.0
tensor(9.9423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 400/ 20000/ t/epoch=0.31............. Loss: 0.08732144, mean(E): -20.50673393+0.00939216j, var(E): 7.27966765
0.0
tensor(9.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 410/ 20000/ t/epoch=0.31............. Loss: 1.25837079, mean(E): -20.66123652+0.01461052j, var(E): 11.31881943
0.0
tensor(9.9978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(9.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 420/ 20000/ t/epoch=0.32............. Loss: 0.44812154, mean(E): -20.31583030+0.04797094j, var(E): 8.89696572
0.0
tensor(10.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 430/ 20000/ t/epoch=0.31............. Loss: 0.74823833, mean(E): -20.69316015-0.00931989j, var(E): 7.46184663
0.0
tensor(10.0416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 440/ 20000/ t/epoch=0.31............. Loss: 0.82990966, mean(E): -20.28849931+0.00922028j, var(E): 7.92698534
0.0
tensor(10.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 450/ 20000/ t/epoch=0.31............. Loss: -0.71346367, mean(E): -20.38142399+0.00384798j, var(E): 6.42983787
0.0
tensor(10.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 460/ 20000/ t/epoch=0.31............. Loss: 0.48805654, mean(E): -20.82334440-0.01615265j, var(E): 7.14988255
0.0
tensor(10.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 470/ 20000/ t/epoch=0.31............. Loss: 0.35905973, mean(E): -20.76763298-0.02412022j, var(E): 7.77954204
0.0
tensor(10.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 480/ 20000/ t/epoch=0.31............. Loss: -0.06732965, mean(E): -20.68763388+0.00357713j, var(E): 5.96694109
0.0
tensor(10.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 490/ 20000/ t/epoch=0.31............. Loss: 0.39948281, mean(E): -20.54377396+0.01892857j, var(E): 9.51614684
0.0
tensor(10.1480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 500/ 20000/ t/epoch=0.32............. Loss: -0.07861765, mean(E): -20.61493231-0.05183417j, var(E): 5.72243765
0.0
tensor(10.1686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 510/ 20000/ t/epoch=0.32............. Loss: -0.43420776, mean(E): -20.43659397-0.01683715j, var(E): 6.81984317
0.0
tensor(10.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 520/ 20000/ t/epoch=0.32............. Loss: -0.00510840, mean(E): -20.67783003-0.00101269j, var(E): 5.29386642
0.0
tensor(10.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 530/ 20000/ t/epoch=0.31............. Loss: 0.75696999, mean(E): -20.73182598-0.01264634j, var(E): 5.61606669
0.0
tensor(10.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 540/ 20000/ t/epoch=0.32............. Loss: -0.09986094, mean(E): -20.64131315+0.04523129j, var(E): 6.26636243
0.0
tensor(10.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 550/ 20000/ t/epoch=0.31............. Loss: -0.88797249, mean(E): -20.46905306+0.03199852j, var(E): 6.58417319
0.0
tensor(10.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 560/ 20000/ t/epoch=0.32............. Loss: -0.39213079, mean(E): -20.67460271-0.00539836j, var(E): 6.16127139
0.0
tensor(10.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 570/ 20000/ t/epoch=0.31............. Loss: 0.09818275, mean(E): -20.61630976+0.01190666j, var(E): 4.38647777
0.0
tensor(10.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 580/ 20000/ t/epoch=0.32............. Loss: -0.25881614, mean(E): -20.47658143+0.01717739j, var(E): 5.93489240
0.0
tensor(10.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 590/ 20000/ t/epoch=0.32............. Loss: 0.22577495, mean(E): -20.76739322+0.05026642j, var(E): 5.20439001
0.0
tensor(10.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 600/ 20000/ t/epoch=0.32............. Loss: -0.26519289, mean(E): -20.58669619+0.00760852j, var(E): 6.41043295
0.0
tensor(10.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 610/ 20000/ t/epoch=0.32............. Loss: -0.39709341, mean(E): -20.73798835+0.05038896j, var(E): 5.12243296
0.0
tensor(10.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 620/ 20000/ t/epoch=0.32............. Loss: -0.19135385, mean(E): -20.83203900+0.02468918j, var(E): 5.73812318
0.0
tensor(10.3591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 630/ 20000/ t/epoch=0.32............. Loss: 0.26132712, mean(E): -20.78625322+0.01025328j, var(E): 4.97829149
0.0
tensor(10.3719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 640/ 20000/ t/epoch=0.32............. Loss: 0.14422198, mean(E): -20.75685866+0.00237980j, var(E): 6.14950112
0.0
tensor(10.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 650/ 20000/ t/epoch=0.32............. Loss: -1.13912210, mean(E): -20.46867854+0.00766606j, var(E): 3.99003407
0.0
tensor(10.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 660/ 20000/ t/epoch=0.32............. Loss: -0.35712915, mean(E): -20.49639114-0.01111288j, var(E): 4.49438362
0.0
tensor(10.4086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 670/ 20000/ t/epoch=0.32............. Loss: 0.27442886, mean(E): -20.95705411-0.01601777j, var(E): 5.66074549
0.0
tensor(10.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 680/ 20000/ t/epoch=0.32............. Loss: 0.84078861, mean(E): -20.98195964-0.02344454j, var(E): 8.72629587
0.0
tensor(10.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 690/ 20000/ t/epoch=0.32............. Loss: -0.21656677, mean(E): -20.73027773-0.01308699j, var(E): 5.40449649
0.0
tensor(10.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 700/ 20000/ t/epoch=0.32............. Loss: 0.28902951, mean(E): -20.69708664-0.02379719j, var(E): 5.16645752
0.0
tensor(10.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 710/ 20000/ t/epoch=0.32............. Loss: 0.03993088, mean(E): -20.76923840-0.00209077j, var(E): 6.18624676
0.0
tensor(10.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 720/ 20000/ t/epoch=0.32............. Loss: 0.19403124, mean(E): -20.82319429+0.00481545j, var(E): 5.55648847
0.0
tensor(10.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 730/ 20000/ t/epoch=0.32............. Loss: -0.11574750, mean(E): -20.81715462-0.03394441j, var(E): 7.14253183
0.0
tensor(10.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 740/ 20000/ t/epoch=0.32............. Loss: -0.83831548, mean(E): -20.58305868-0.00480539j, var(E): 4.43007745
0.0
tensor(10.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 750/ 20000/ t/epoch=0.32............. Loss: -0.64545978, mean(E): -20.79043180-0.02518863j, var(E): 4.06248054
0.0
tensor(10.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 760/ 20000/ t/epoch=0.32............. Loss: 0.00160740, mean(E): -20.86316328+0.03805060j, var(E): 4.69560152
0.0
tensor(10.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 770/ 20000/ t/epoch=0.32............. Loss: 0.30391534, mean(E): -20.88064532+0.01981135j, var(E): 4.98835991
0.0
tensor(10.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 780/ 20000/ t/epoch=0.32............. Loss: -0.52124014, mean(E): -20.90672559-0.00853009j, var(E): 4.06666558
0.0
tensor(10.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 790/ 20000/ t/epoch=0.32............. Loss: 0.19053903, mean(E): -21.01344801-0.01539260j, var(E): 8.68808009
0.0
tensor(10.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 800/ 20000/ t/epoch=0.32............. Loss: 0.88264037, mean(E): -20.80829148+0.07495560j, var(E): 5.17757949
0.0
tensor(10.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 810/ 20000/ t/epoch=0.32............. Loss: 0.09184729, mean(E): -20.96254932+0.03351406j, var(E): 3.90590492
0.0
tensor(10.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 820/ 20000/ t/epoch=0.32............. Loss: -0.73424107, mean(E): -20.70627562+0.01162607j, var(E): 3.78368472
0.0
tensor(10.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 830/ 20000/ t/epoch=0.32............. Loss: -0.54514673, mean(E): -20.71193966+0.01029996j, var(E): 5.04402042
0.0
tensor(10.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 840/ 20000/ t/epoch=0.32............. Loss: 1.49946301, mean(E): -21.24574159+0.02348701j, var(E): 7.22710456
0.0
tensor(10.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 850/ 20000/ t/epoch=0.32............. Loss: -1.47587074, mean(E): -20.83671389+0.03980009j, var(E): 4.78606064
0.0
tensor(10.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 860/ 20000/ t/epoch=0.32............. Loss: 0.18643155, mean(E): -20.89177981+0.01153472j, var(E): 4.08671430
0.0
tensor(10.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 870/ 20000/ t/epoch=0.32............. Loss: -0.84402471, mean(E): -20.81316425+0.01678217j, var(E): 5.37476157
0.0
tensor(10.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 880/ 20000/ t/epoch=0.32............. Loss: -0.41502682, mean(E): -20.75553786-0.00342891j, var(E): 4.15426254
0.0
tensor(10.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 890/ 20000/ t/epoch=0.32............. Loss: 0.74394257, mean(E): -21.09724718-0.04304322j, var(E): 5.24976329
0.0
tensor(10.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 900/ 20000/ t/epoch=0.32............. Loss: -0.17134086, mean(E): -20.95846580-0.02381686j, var(E): 4.97705470
0.0
tensor(10.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 910/ 20000/ t/epoch=0.32............. Loss: 0.21188000, mean(E): -21.26165407-0.05022184j, var(E): 5.92627922
0.0
tensor(10.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 920/ 20000/ t/epoch=0.32............. Loss: -0.38760350, mean(E): -21.03949924+0.00793931j, var(E): 3.42821943
0.0
tensor(10.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 930/ 20000/ t/epoch=0.32............. Loss: -0.59280187, mean(E): -20.86659908+0.02175030j, var(E): 6.65309608
0.0
tensor(10.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 940/ 20000/ t/epoch=0.32............. Loss: 0.18768880, mean(E): -21.23456721+0.00279212j, var(E): 4.12884833
0.0
tensor(10.7918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.7985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 950/ 20000/ t/epoch=0.32............. Loss: 0.01616883, mean(E): -21.18568144+0.03057793j, var(E): 5.38734726
0.0
tensor(10.8062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 960/ 20000/ t/epoch=0.32............. Loss: 0.26313629, mean(E): -21.16379489+0.01558523j, var(E): 3.95608838
0.0
tensor(10.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 970/ 20000/ t/epoch=0.32............. Loss: 0.68979297, mean(E): -21.07273555+0.03638966j, var(E): 5.36585698
0.0
tensor(10.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 980/ 20000/ t/epoch=0.32............. Loss: -0.18223684, mean(E): -21.20758431-0.03528448j, var(E): 2.35531150
0.0
tensor(10.8407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 990/ 20000/ t/epoch=0.32............. Loss: -0.90697167, mean(E): -20.99239705+0.00748070j, var(E): 3.34304205
0.0
tensor(10.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
0.0
tensor(10.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1000/ 20000/ t/epoch=0.32............. Loss: 0.56945188, mean(E): -21.29826614+0.01858040j, var(E): 3.52862425
-0.0
tensor(10.8647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1010/ 20000/ t/epoch=0.32............. Loss: -0.07407330, mean(E): -20.94083782+0.01669466j, var(E): 3.73752523
-0.0
tensor(10.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1020/ 20000/ t/epoch=0.32............. Loss: -0.28856258, mean(E): -21.04399138-0.00662946j, var(E): 3.72243973
-0.0
tensor(10.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1030/ 20000/ t/epoch=0.32............. Loss: 0.00733706, mean(E): -21.19326615+0.00746549j, var(E): 3.63232722
-0.0
tensor(10.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1040/ 20000/ t/epoch=0.32............. Loss: 0.42524707, mean(E): -21.32420624+0.00464664j, var(E): 4.44812308
-0.0
tensor(10.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1050/ 20000/ t/epoch=0.32............. Loss: 0.10333864, mean(E): -20.99771068+0.01176949j, var(E): 5.01401889
-0.0
tensor(10.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1060/ 20000/ t/epoch=0.32............. Loss: 0.09031947, mean(E): -21.20982711+0.02632225j, var(E): 4.03429942
-0.0
tensor(10.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1070/ 20000/ t/epoch=0.32............. Loss: -0.82689792, mean(E): -20.86296640-0.02922636j, var(E): 2.16702349
-0.0
tensor(10.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1080/ 20000/ t/epoch=0.32............. Loss: 0.37268876, mean(E): -21.23403181+0.00281034j, var(E): 5.05488491
-0.0
tensor(10.9649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1090/ 20000/ t/epoch=0.32............. Loss: -1.05176906, mean(E): -20.99430269+0.01065977j, var(E): 2.74313597
-0.0
tensor(10.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1100/ 20000/ t/epoch=0.32............. Loss: -0.25731211, mean(E): -21.01410659-0.01416416j, var(E): 3.27752350
-0.0
tensor(10.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1110/ 20000/ t/epoch=0.32............. Loss: -1.03172888, mean(E): -20.85129828+0.01206237j, var(E): 3.08629422
-0.0
tensor(10.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(10.9990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1120/ 20000/ t/epoch=0.32............. Loss: 0.78261741, mean(E): -21.32134168-0.05919597j, var(E): 3.76068489
-0.0
tensor(11.0061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1130/ 20000/ t/epoch=0.32............. Loss: -0.03121149, mean(E): -21.10839305-0.00914195j, var(E): 5.98812710
-0.0
tensor(11.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1140/ 20000/ t/epoch=0.32............. Loss: -0.80660045, mean(E): -21.02165893-0.02413141j, var(E): 2.69542585
-0.0
tensor(11.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1150/ 20000/ t/epoch=0.32............. Loss: -0.93713926, mean(E): -20.96665468+0.00382160j, var(E): 2.65318698
-0.0
tensor(11.0325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1160/ 20000/ t/epoch=0.32............. Loss: 1.08349805, mean(E): -21.20566887+0.01985859j, var(E): 4.02197032
-0.0
tensor(11.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1170/ 20000/ t/epoch=0.32............. Loss: -0.18568771, mean(E): -21.17308751+0.01890328j, var(E): 2.44843092
-0.0
tensor(11.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1180/ 20000/ t/epoch=0.32............. Loss: 0.72085470, mean(E): -21.26593568+0.00064226j, var(E): 4.84758168
-0.0
tensor(11.0706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1190/ 20000/ t/epoch=0.32............. Loss: 0.18765348, mean(E): -21.42909324-0.01164335j, var(E): 3.69882945
-0.0
tensor(11.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1200/ 20000/ t/epoch=0.32............. Loss: -0.56843922, mean(E): -20.91295460+0.00911315j, var(E): 2.54088888
-0.0
tensor(11.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.0988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1210/ 20000/ t/epoch=0.32............. Loss: -0.08122353, mean(E): -21.25799874+0.00737510j, var(E): 3.86794715
-0.0
tensor(11.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1220/ 20000/ t/epoch=0.32............. Loss: 0.23211784, mean(E): -21.12140341-0.02812063j, var(E): 3.55217393
-0.0
tensor(11.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1230/ 20000/ t/epoch=0.32............. Loss: 0.61191630, mean(E): -21.35123801-0.00654466j, var(E): 3.91140103
-0.0
tensor(11.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1240/ 20000/ t/epoch=0.32............. Loss: 0.13597789, mean(E): -21.25398158-0.07712501j, var(E): 3.99651887
-0.0
tensor(11.1279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1250/ 20000/ t/epoch=0.32............. Loss: -0.14579893, mean(E): -21.10771154+0.00095402j, var(E): 2.52978340
-0.0
tensor(11.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1260/ 20000/ t/epoch=0.32............. Loss: 0.24414828, mean(E): -21.32173087-0.04318747j, var(E): 3.49645851
-0.0
tensor(11.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1270/ 20000/ t/epoch=0.32............. Loss: -0.15066056, mean(E): -21.16711190-0.02435170j, var(E): 4.17293074
-0.0
tensor(11.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1280/ 20000/ t/epoch=0.32............. Loss: 0.82393136, mean(E): -21.34565654+0.03408781j, var(E): 4.69115758
-0.0
tensor(11.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1290/ 20000/ t/epoch=0.32............. Loss: 0.01478870, mean(E): -21.11216606+0.03812582j, var(E): 3.09364992
-0.0
tensor(11.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1300/ 20000/ t/epoch=0.32............. Loss: -0.30808445, mean(E): -21.12434124+0.01403437j, var(E): 3.58949585
-0.0
tensor(11.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1310/ 20000/ t/epoch=0.32............. Loss: -0.07329237, mean(E): -21.14739692+0.00186300j, var(E): 2.15712909
-0.0
tensor(11.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1320/ 20000/ t/epoch=0.32............. Loss: 0.64060160, mean(E): -21.28827367-0.01721894j, var(E): 3.67177731
-0.0
tensor(11.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.1995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1330/ 20000/ t/epoch=0.32............. Loss: -0.21507946, mean(E): -21.26430156-0.01393343j, var(E): 2.81622414
-0.0
tensor(11.2036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1340/ 20000/ t/epoch=0.32............. Loss: 0.72253458, mean(E): -21.47614596-0.03052964j, var(E): 3.07758896
-0.0
tensor(11.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1350/ 20000/ t/epoch=0.32............. Loss: 0.32756620, mean(E): -21.19796042+0.00675799j, var(E): 4.31553532
-0.0
tensor(11.2169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1360/ 20000/ t/epoch=0.32............. Loss: -0.22656733, mean(E): -21.20803370-0.01010638j, var(E): 3.08836939
-0.0
tensor(11.2304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1370/ 20000/ t/epoch=0.32............. Loss: -0.59666401, mean(E): -21.23601180-0.00530072j, var(E): 3.33681210
-0.0
tensor(11.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1380/ 20000/ t/epoch=0.32............. Loss: 0.47198576, mean(E): -21.32734231+0.00574503j, var(E): 5.83924677
-0.0
tensor(11.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1390/ 20000/ t/epoch=0.32............. Loss: -0.60109101, mean(E): -21.06076217+0.00708204j, var(E): 3.42145884
-0.0
tensor(11.2718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1400/ 20000/ t/epoch=0.32............. Loss: 0.30788335, mean(E): -21.32034969-0.00352450j, var(E): 3.89273092
-0.0
tensor(11.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1410/ 20000/ t/epoch=0.32............. Loss: -0.39408463, mean(E): -21.21179553+0.02064595j, var(E): 3.83738183
-0.0
tensor(11.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1420/ 20000/ t/epoch=0.32............. Loss: -0.76670453, mean(E): -20.98665950+0.02367927j, var(E): 2.77423099
-0.0
tensor(11.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1430/ 20000/ t/epoch=0.32............. Loss: -0.28843977, mean(E): -21.33724062+0.00379102j, var(E): 2.70480419
-0.0
tensor(11.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1440/ 20000/ t/epoch=0.32............. Loss: 0.41131570, mean(E): -21.49542813-0.00314961j, var(E): 3.37635506
-0.0
tensor(11.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1450/ 20000/ t/epoch=0.32............. Loss: 0.00467959, mean(E): -21.30414668-0.02011525j, var(E): 2.89867399
-0.0
tensor(11.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1460/ 20000/ t/epoch=0.32............. Loss: -0.51606820, mean(E): -21.13304248-0.03085859j, var(E): 2.43676993
-0.0
tensor(11.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1470/ 20000/ t/epoch=0.32............. Loss: 0.84565571, mean(E): -21.36075017+0.00247338j, var(E): 3.94477733
-0.0
tensor(11.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1480/ 20000/ t/epoch=0.32............. Loss: -0.36120432, mean(E): -21.21388275+0.00390037j, var(E): 2.05953722
-0.0
tensor(11.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1490/ 20000/ t/epoch=0.32............. Loss: -0.68314794, mean(E): -21.20704216-0.00171264j, var(E): 2.50444537
-0.0
tensor(11.3427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1500/ 20000/ t/epoch=0.32............. Loss: 0.19152712, mean(E): -21.37654936-0.03068142j, var(E): 2.23975812
-0.0
tensor(11.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1510/ 20000/ t/epoch=0.32............. Loss: 0.26953875, mean(E): -21.33318555-0.01380034j, var(E): 2.63594602
-0.0
tensor(11.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1520/ 20000/ t/epoch=0.32............. Loss: -0.42410512, mean(E): -21.17543831-0.01355239j, var(E): 2.94243973
-0.0
tensor(11.3689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1530/ 20000/ t/epoch=0.32............. Loss: 0.16197147, mean(E): -21.25582815-0.01125859j, var(E): 3.47598833
-0.0
tensor(11.3773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1540/ 20000/ t/epoch=0.32............. Loss: -0.03262517, mean(E): -21.33553336-0.00853407j, var(E): 2.30321701
-0.0
tensor(11.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1550/ 20000/ t/epoch=0.32............. Loss: 0.41887310, mean(E): -21.37381739-0.00239936j, var(E): 5.43223635
-0.0
tensor(11.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1560/ 20000/ t/epoch=0.32............. Loss: -0.45823185, mean(E): -21.01710259-0.00810649j, var(E): 2.36404414
-0.0
tensor(11.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1570/ 20000/ t/epoch=0.32............. Loss: 0.13789564, mean(E): -21.36308183+0.04639451j, var(E): 2.46922800
-0.0
tensor(11.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1580/ 20000/ t/epoch=0.32............. Loss: 0.41646097, mean(E): -21.48112489-0.00976999j, var(E): 2.33224713
-0.0
tensor(11.4107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1590/ 20000/ t/epoch=0.32............. Loss: -0.10514729, mean(E): -21.38450409-0.02277185j, var(E): 2.58478290
-0.0
tensor(11.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1600/ 20000/ t/epoch=0.32............. Loss: 0.12496669, mean(E): -21.43759298-0.01715741j, var(E): 2.36601262
-0.0
tensor(11.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1610/ 20000/ t/epoch=0.32............. Loss: 0.53642040, mean(E): -21.40688063-0.01460241j, var(E): 2.17791795
-0.0
tensor(11.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1620/ 20000/ t/epoch=0.32............. Loss: 0.95734959, mean(E): -21.48050129+0.02183608j, var(E): 4.44515698
-0.0
tensor(11.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1630/ 20000/ t/epoch=0.32............. Loss: -0.08954698, mean(E): -21.31213040+0.01781358j, var(E): 1.87017552
-0.0
tensor(11.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1640/ 20000/ t/epoch=0.32............. Loss: -0.24623873, mean(E): -21.30518867+0.01242300j, var(E): 2.39017838
-0.0
tensor(11.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1650/ 20000/ t/epoch=0.32............. Loss: -0.80533609, mean(E): -21.17883096-0.02643246j, var(E): 2.71519661
-0.0
tensor(11.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1660/ 20000/ t/epoch=0.32............. Loss: -0.33661496, mean(E): -21.38719143-0.00752042j, var(E): 2.88233484
-0.0
tensor(11.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1670/ 20000/ t/epoch=0.32............. Loss: -0.08954889, mean(E): -21.47141333-0.02719933j, var(E): 3.32356888
-0.0
tensor(11.4819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1680/ 20000/ t/epoch=0.32............. Loss: 0.19475912, mean(E): -21.23480724+0.02363618j, var(E): 2.71956283
-0.0
tensor(11.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1690/ 20000/ t/epoch=0.32............. Loss: 0.17371430, mean(E): -21.46708002-0.04071864j, var(E): 2.97618284
-0.0
tensor(11.5013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1700/ 20000/ t/epoch=0.32............. Loss: -0.84721884, mean(E): -21.11245666-0.01064586j, var(E): 2.71205802
-0.0
tensor(11.5077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1710/ 20000/ t/epoch=0.32............. Loss: -0.41290551, mean(E): -21.27074583+0.01838782j, var(E): 2.39614975
-0.0
tensor(11.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1720/ 20000/ t/epoch=0.32............. Loss: 0.13173956, mean(E): -21.40432390+0.01908119j, var(E): 2.10467825
-0.0
tensor(11.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1730/ 20000/ t/epoch=0.32............. Loss: 0.22376236, mean(E): -21.31001466-0.02184660j, var(E): 4.03877838
-0.0
tensor(11.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1740/ 20000/ t/epoch=0.32............. Loss: -1.08110078, mean(E): -21.05551853-0.02236709j, var(E): 1.88676723
-0.0
tensor(11.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1750/ 20000/ t/epoch=0.32............. Loss: 0.04857539, mean(E): -21.45467488-0.03871617j, var(E): 2.86450888
-0.0
tensor(11.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1760/ 20000/ t/epoch=0.32............. Loss: 0.24160780, mean(E): -21.51553350+0.01977979j, var(E): 1.67108382
-0.0
tensor(11.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1770/ 20000/ t/epoch=0.32............. Loss: -0.26372130, mean(E): -21.37622804+0.01923838j, var(E): 1.86156352
-0.0
tensor(11.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1780/ 20000/ t/epoch=0.32............. Loss: -0.44519526, mean(E): -21.29737378-0.01338885j, var(E): 2.05576354
-0.0
tensor(11.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1790/ 20000/ t/epoch=0.32............. Loss: -0.20240180, mean(E): -21.37924809-0.00582406j, var(E): 2.36301826
-0.0
tensor(11.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1800/ 20000/ t/epoch=0.32............. Loss: 0.58169035, mean(E): -21.46559459+0.01776568j, var(E): 3.34590595
-0.0
tensor(11.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1810/ 20000/ t/epoch=0.32............. Loss: -0.29647677, mean(E): -21.38434175+0.00165056j, var(E): 2.20808528
-0.0
tensor(11.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1820/ 20000/ t/epoch=0.32............. Loss: -0.04065550, mean(E): -21.33413884+0.00067519j, var(E): 1.72087922
-0.0
tensor(11.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1830/ 20000/ t/epoch=0.32............. Loss: 0.03394883, mean(E): -21.33976854+0.00078326j, var(E): 1.67792252
-0.0
tensor(11.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1840/ 20000/ t/epoch=0.32............. Loss: -0.86580085, mean(E): -21.10956301+0.01402513j, var(E): 3.07310458
-0.0
tensor(11.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1850/ 20000/ t/epoch=0.32............. Loss: 1.54465323, mean(E): -21.63005801+0.00595213j, var(E): 4.23491877
-0.0
tensor(11.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1860/ 20000/ t/epoch=0.32............. Loss: -0.34705824, mean(E): -21.29845644-0.01476105j, var(E): 2.89044668
-0.0
tensor(11.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1870/ 20000/ t/epoch=0.32............. Loss: 0.17502022, mean(E): -21.41807690-0.00606274j, var(E): 2.17550162
-0.0
tensor(11.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1880/ 20000/ t/epoch=0.32............. Loss: 0.50498408, mean(E): -21.55989104-0.00145326j, var(E): 4.11363443
-0.0
tensor(11.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1890/ 20000/ t/epoch=0.32............. Loss: -0.91312005, mean(E): -21.19415832+0.04892418j, var(E): 3.33451074
-0.0
tensor(11.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1900/ 20000/ t/epoch=0.32............. Loss: 0.96112058, mean(E): -21.50247680+0.02987381j, var(E): 4.38267898
-0.0
tensor(11.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1910/ 20000/ t/epoch=0.32............. Loss: 0.21427937, mean(E): -21.38090515-0.02572360j, var(E): 1.97135746
-0.0
tensor(11.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1920/ 20000/ t/epoch=0.32............. Loss: 1.06997301, mean(E): -21.50432849+0.00313951j, var(E): 4.52712938
-0.0
tensor(11.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1930/ 20000/ t/epoch=0.32............. Loss: -0.69539004, mean(E): -21.25269404-0.03579844j, var(E): 2.39962505
-0.0
tensor(11.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1940/ 20000/ t/epoch=0.32............. Loss: -0.05341515, mean(E): -21.42336724-0.00967331j, var(E): 1.36910977
-0.0
tensor(11.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1950/ 20000/ t/epoch=0.32............. Loss: -0.82150178, mean(E): -21.36661873-0.00788431j, var(E): 1.70764349
-0.0
tensor(11.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1960/ 20000/ t/epoch=0.32............. Loss: 0.17181827, mean(E): -21.47696596+0.01094444j, var(E): 1.87234803
-0.0
tensor(11.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1970/ 20000/ t/epoch=0.32............. Loss: -0.82774628, mean(E): -21.27123142+0.00623466j, var(E): 1.89069587
-0.0
tensor(11.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1980/ 20000/ t/epoch=0.32............. Loss: 0.13420434, mean(E): -21.47974290+0.00026663j, var(E): 3.30784193
-0.0
tensor(11.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 1990/ 20000/ t/epoch=0.32............. Loss: -0.27488866, mean(E): -21.40146484+0.00429042j, var(E): 2.97635798
-0.0
tensor(11.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2000/ 20000/ t/epoch=0.32............. Loss: -0.67884592, mean(E): -21.23210097+0.00929345j, var(E): 2.62778701
-0.0
tensor(11.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2010/ 20000/ t/epoch=0.32............. Loss: -0.62330490, mean(E): -21.41075191+0.02362628j, var(E): 1.99612144
-0.0
tensor(11.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2020/ 20000/ t/epoch=0.32............. Loss: -0.13149149, mean(E): -21.35298539+0.00947457j, var(E): 2.21039527
-0.0
tensor(11.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2030/ 20000/ t/epoch=0.32............. Loss: -0.20301230, mean(E): -21.42096207+0.00235547j, var(E): 1.36469149
-0.0
tensor(11.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2040/ 20000/ t/epoch=0.32............. Loss: -0.14795716, mean(E): -21.48654459+0.01180593j, var(E): 2.04551576
-0.0
tensor(11.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2050/ 20000/ t/epoch=0.32............. Loss: 0.12591011, mean(E): -21.49868582+0.02090537j, var(E): 2.13135097
-0.0
tensor(11.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2060/ 20000/ t/epoch=0.32............. Loss: -0.51776169, mean(E): -21.35094110+0.03601846j, var(E): 1.78409308
-0.0
tensor(11.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2070/ 20000/ t/epoch=0.32............. Loss: -0.18394604, mean(E): -21.36360445-0.00423773j, var(E): 1.72105018
-0.0
tensor(11.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2080/ 20000/ t/epoch=0.32............. Loss: -0.02200842, mean(E): -21.50543409+0.02194387j, var(E): 1.65100403
-0.0
tensor(11.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2090/ 20000/ t/epoch=0.32............. Loss: 0.37080484, mean(E): -21.43215153+0.01598372j, var(E): 2.46613463
-0.0
tensor(11.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2100/ 20000/ t/epoch=0.32............. Loss: 0.20996769, mean(E): -21.52515544+0.02054203j, var(E): 1.78099520
-0.0
tensor(11.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2110/ 20000/ t/epoch=0.32............. Loss: -0.40849901, mean(E): -21.28973862+0.00825194j, var(E): 1.90724145
-0.0
tensor(11.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2120/ 20000/ t/epoch=0.32............. Loss: -0.06908919, mean(E): -21.43245872+0.01589047j, var(E): 2.22201441
-0.0
tensor(11.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2130/ 20000/ t/epoch=0.32............. Loss: 0.48185470, mean(E): -21.55719609+0.01964473j, var(E): 1.82466383
-0.0
tensor(11.7742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2140/ 20000/ t/epoch=0.32............. Loss: -1.32538597, mean(E): -21.24013852+0.00564600j, var(E): 2.57968031
-0.0
tensor(11.7762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2150/ 20000/ t/epoch=0.32............. Loss: 0.09884816, mean(E): -21.36815765-0.00896666j, var(E): 2.68036401
-0.0
tensor(11.7829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2160/ 20000/ t/epoch=0.32............. Loss: -0.35173496, mean(E): -21.41806652+0.03418929j, var(E): 1.50016229
-0.0
tensor(11.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2170/ 20000/ t/epoch=0.32............. Loss: -0.46300955, mean(E): -21.41121823+0.02302243j, var(E): 1.70145380
-0.0
tensor(11.7894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2180/ 20000/ t/epoch=0.32............. Loss: -0.33341470, mean(E): -21.33799699-0.01051841j, var(E): 1.11652677
-0.0
tensor(11.7902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2190/ 20000/ t/epoch=0.32............. Loss: 0.09567669, mean(E): -21.44243259-0.02919731j, var(E): 1.80430531
-0.0
tensor(11.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2200/ 20000/ t/epoch=0.32............. Loss: 0.98412062, mean(E): -21.56491481+0.01219520j, var(E): 2.81630028
-0.0
tensor(11.8035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2210/ 20000/ t/epoch=0.32............. Loss: 0.34117410, mean(E): -21.62261286-0.00385291j, var(E): 2.55435366
-0.0
tensor(11.8089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2220/ 20000/ t/epoch=0.32............. Loss: 0.33740732, mean(E): -21.56042090-0.00485152j, var(E): 1.95800220
-0.0
tensor(11.8107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2230/ 20000/ t/epoch=0.32............. Loss: 0.15502490, mean(E): -21.45733704-0.04203512j, var(E): 1.92000623
-0.0
tensor(11.8118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2240/ 20000/ t/epoch=0.32............. Loss: -0.31408005, mean(E): -21.37610815+0.00643338j, var(E): 2.00026102
-0.0
tensor(11.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2250/ 20000/ t/epoch=0.32............. Loss: 0.58514720, mean(E): -21.60659005+0.01097454j, var(E): 2.92621428
-0.0
tensor(11.8191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2260/ 20000/ t/epoch=0.32............. Loss: 0.09837663, mean(E): -21.45151368-0.02892081j, var(E): 2.35283558
-0.0
tensor(11.8253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2270/ 20000/ t/epoch=0.32............. Loss: 0.73402325, mean(E): -21.57940606+0.03477358j, var(E): 1.99936497
-0.0
tensor(11.8315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2280/ 20000/ t/epoch=0.32............. Loss: 0.04291052, mean(E): -21.40835437-0.00572989j, var(E): 1.61382801
-0.0
tensor(11.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2290/ 20000/ t/epoch=0.32............. Loss: -0.39892133, mean(E): -21.35641524-0.03432698j, var(E): 2.09503878
-0.0
tensor(11.8447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2300/ 20000/ t/epoch=0.32............. Loss: -0.19792663, mean(E): -21.41817969-0.02442264j, var(E): 1.64155211
-0.0
tensor(11.8467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2310/ 20000/ t/epoch=0.32............. Loss: 0.47123385, mean(E): -21.53320065+0.02493409j, var(E): 2.33149334
-0.0
tensor(11.8515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2320/ 20000/ t/epoch=0.32............. Loss: -0.47843477, mean(E): -21.27515445+0.02187406j, var(E): 1.98522056
-0.0
tensor(11.8585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2330/ 20000/ t/epoch=0.32............. Loss: 0.14448293, mean(E): -21.45138955+0.01449617j, var(E): 1.78104186
-0.0
tensor(11.8637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2340/ 20000/ t/epoch=0.32............. Loss: 0.32514443, mean(E): -21.57185544+0.00044054j, var(E): 1.32941540
-0.0
tensor(11.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2350/ 20000/ t/epoch=0.32............. Loss: -0.61204895, mean(E): -21.30830976-0.01388615j, var(E): 1.22779569
-0.0
tensor(11.8704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2360/ 20000/ t/epoch=0.32............. Loss: -0.22879362, mean(E): -21.45528048-0.01068286j, var(E): 2.01982767
-0.0
tensor(11.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2370/ 20000/ t/epoch=0.32............. Loss: -0.16288258, mean(E): -21.41558024-0.01209529j, var(E): 1.56589193
-0.0
tensor(11.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2380/ 20000/ t/epoch=0.32............. Loss: -0.03125672, mean(E): -21.48794696-0.00137326j, var(E): 1.54785482
-0.0
tensor(11.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2390/ 20000/ t/epoch=0.32............. Loss: 0.06379704, mean(E): -21.46628171+0.00218644j, var(E): 1.56630441
-0.0
tensor(11.8848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2400/ 20000/ t/epoch=0.32............. Loss: -0.40190027, mean(E): -21.40499503+0.01680841j, var(E): 1.44957693
-0.0
tensor(11.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2410/ 20000/ t/epoch=0.32............. Loss: -0.69827169, mean(E): -21.32571967-0.00838554j, var(E): 2.03283568
-0.0
tensor(11.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.8989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2420/ 20000/ t/epoch=0.32............. Loss: -0.13469163, mean(E): -21.41665478-0.01026501j, var(E): 1.56454307
-0.0
tensor(11.9000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2430/ 20000/ t/epoch=0.32............. Loss: -0.40872495, mean(E): -21.42444184-0.00109355j, var(E): 2.25154297
-0.0
tensor(11.9045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2440/ 20000/ t/epoch=0.32............. Loss: -0.61286273, mean(E): -21.27962358-0.00415818j, var(E): 2.16497646
-0.0
tensor(11.9129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2450/ 20000/ t/epoch=0.32............. Loss: 0.51041868, mean(E): -21.53025929+0.02981032j, var(E): 2.00746215
-0.0
tensor(11.9206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2460/ 20000/ t/epoch=0.32............. Loss: 0.29004341, mean(E): -21.58560793+0.00612873j, var(E): 2.32743375
-0.0
tensor(11.9232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2470/ 20000/ t/epoch=0.32............. Loss: -0.30935097, mean(E): -21.39644873-0.02732940j, var(E): 2.81062938
-0.0
tensor(11.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2480/ 20000/ t/epoch=0.32............. Loss: 0.63499053, mean(E): -21.48211012-0.02792882j, var(E): 1.95323586
-0.0
tensor(11.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2490/ 20000/ t/epoch=0.32............. Loss: -0.62384196, mean(E): -21.40231679+0.03461167j, var(E): 2.11322728
-0.0
tensor(11.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2500/ 20000/ t/epoch=0.32............. Loss: -0.38410945, mean(E): -21.27045670-0.00219021j, var(E): 1.72289736
-0.0
tensor(11.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2510/ 20000/ t/epoch=0.32............. Loss: 0.12409150, mean(E): -21.55167306+0.03904912j, var(E): 1.22331229
-0.0
tensor(11.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2520/ 20000/ t/epoch=0.32............. Loss: -0.30695557, mean(E): -21.52743566+0.00716613j, var(E): 1.67904946
-0.0
tensor(11.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2530/ 20000/ t/epoch=0.32............. Loss: -0.38346295, mean(E): -21.49380879-0.00679698j, var(E): 1.60426896
-0.0
tensor(11.9580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2540/ 20000/ t/epoch=0.32............. Loss: 0.10572485, mean(E): -21.38310851+0.00945252j, var(E): 1.78327477
-0.0
tensor(11.9634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2550/ 20000/ t/epoch=0.32............. Loss: -0.55769180, mean(E): -21.35334133-0.00772879j, var(E): 1.71388834
-0.0
tensor(11.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2560/ 20000/ t/epoch=0.32............. Loss: 0.82480230, mean(E): -21.49375499-0.03067529j, var(E): 4.69103598
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2570/ 20000/ t/epoch=0.32............. Loss: 0.68689935, mean(E): -21.46433156-0.00822007j, var(E): 2.44061897
-0.0
tensor(11.9754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2580/ 20000/ t/epoch=0.32............. Loss: -0.50802922, mean(E): -21.36079197+0.00104699j, var(E): 1.73059812
-0.0
tensor(11.9777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2590/ 20000/ t/epoch=0.32............. Loss: -0.10570639, mean(E): -21.45892381+0.00649999j, var(E): 1.87286242
-0.0
tensor(11.9824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2600/ 20000/ t/epoch=0.32............. Loss: 0.15077653, mean(E): -21.53613488-0.00582838j, var(E): 2.14321918
-0.0
tensor(11.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2610/ 20000/ t/epoch=0.32............. Loss: -1.04725344, mean(E): -21.24464411-0.00946095j, var(E): 2.37140514
-0.0
tensor(11.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2620/ 20000/ t/epoch=0.32............. Loss: -0.65894261, mean(E): -21.43285589-0.00388650j, var(E): 1.91826762
-0.0
tensor(11.9859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2630/ 20000/ t/epoch=0.32............. Loss: 0.45375086, mean(E): -21.54211357-0.01061532j, var(E): 3.07719981
-0.0
tensor(11.9870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2640/ 20000/ t/epoch=0.32............. Loss: -0.59592538, mean(E): -21.32461581-0.01354639j, var(E): 2.67119574
-0.0
tensor(11.9910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2650/ 20000/ t/epoch=0.32............. Loss: -1.27204256, mean(E): -21.18044540-0.01511172j, var(E): 1.74486272
-0.0
tensor(11.9952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2660/ 20000/ t/epoch=0.32............. Loss: -0.41068718, mean(E): -21.41830114-0.00365686j, var(E): 2.14320759
-0.0
tensor(11.9995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(11.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2670/ 20000/ t/epoch=0.32............. Loss: -0.46444157, mean(E): -21.34320993+0.00296261j, var(E): 1.61692568
-0.0
tensor(12.0039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2680/ 20000/ t/epoch=0.32............. Loss: -0.47650764, mean(E): -21.31750202-0.02241515j, var(E): 2.02738927
-0.0
tensor(12.0078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2690/ 20000/ t/epoch=0.32............. Loss: 0.16530539, mean(E): -21.50186566+0.00226003j, var(E): 2.07785186
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2700/ 20000/ t/epoch=0.32............. Loss: 0.11969004, mean(E): -21.48799503+0.02158414j, var(E): 2.12995946
-0.0
tensor(12.0110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2710/ 20000/ t/epoch=0.32............. Loss: -0.61986838, mean(E): -21.33567043-0.00673823j, var(E): 1.38550558
-0.0
tensor(12.0160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2720/ 20000/ t/epoch=0.32............. Loss: 0.10861459, mean(E): -21.46611133+0.00414364j, var(E): 1.27566327
-0.0
tensor(12.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2730/ 20000/ t/epoch=0.32............. Loss: 0.04859316, mean(E): -21.53886407-0.00497440j, var(E): 1.41049326
-0.0
tensor(12.0284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2740/ 20000/ t/epoch=0.32............. Loss: 0.17047022, mean(E): -21.41460687-0.01364816j, var(E): 2.16222948
-0.0
tensor(12.0322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2750/ 20000/ t/epoch=0.32............. Loss: -0.19547797, mean(E): -21.49640743-0.00509549j, var(E): 1.63910751
-0.0
tensor(12.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2760/ 20000/ t/epoch=0.32............. Loss: 0.59716473, mean(E): -21.58403210+0.00706538j, var(E): 3.10765294
-0.0
tensor(12.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2770/ 20000/ t/epoch=0.32............. Loss: 0.74328795, mean(E): -21.55221843-0.00580580j, var(E): 2.80716187
-0.0
tensor(12.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2780/ 20000/ t/epoch=0.32............. Loss: 0.07093405, mean(E): -21.48253856+0.00206689j, var(E): 1.41005676
-0.0
tensor(12.0374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2790/ 20000/ t/epoch=0.32............. Loss: 0.28693350, mean(E): -21.49536397-0.01261956j, var(E): 1.24053726
-0.0
tensor(12.0391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2800/ 20000/ t/epoch=0.32............. Loss: -0.01604305, mean(E): -21.39745235+0.02665938j, var(E): 1.39480873
-0.0
tensor(12.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2810/ 20000/ t/epoch=0.32............. Loss: -0.48161738, mean(E): -21.38248173+0.00616744j, var(E): 1.90109442
-0.0
tensor(12.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2820/ 20000/ t/epoch=0.32............. Loss: 0.51133050, mean(E): -21.48849693-0.00482795j, var(E): 2.80809497
-0.0
tensor(12.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2830/ 20000/ t/epoch=0.32............. Loss: -0.50689846, mean(E): -21.41683664-0.00679101j, var(E): 1.73487187
-0.0
tensor(12.0647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2840/ 20000/ t/epoch=0.32............. Loss: 0.27169110, mean(E): -21.46856115+0.00226542j, var(E): 2.18071030
-0.0
tensor(12.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2850/ 20000/ t/epoch=0.32............. Loss: -0.37005204, mean(E): -21.32930298+0.00386699j, var(E): 2.60626577
-0.0
tensor(12.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2860/ 20000/ t/epoch=0.32............. Loss: 0.01014762, mean(E): -21.44478345-0.03243349j, var(E): 1.82984369
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2870/ 20000/ t/epoch=0.32............. Loss: 0.28441322, mean(E): -21.62438178+0.00464676j, var(E): 1.19055912
-0.0
tensor(12.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2880/ 20000/ t/epoch=0.32............. Loss: -0.39431987, mean(E): -21.56545610-0.00439330j, var(E): 1.35479093
-0.0
tensor(12.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2890/ 20000/ t/epoch=0.32............. Loss: 0.12126760, mean(E): -21.53076845+0.00861557j, var(E): 1.07420486
-0.0
tensor(12.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2900/ 20000/ t/epoch=0.32............. Loss: -0.07093661, mean(E): -21.41993862-0.01383168j, var(E): 1.65804107
-0.0
tensor(12.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2910/ 20000/ t/epoch=0.32............. Loss: -0.68222615, mean(E): -21.29373761-0.01891066j, var(E): 2.45438008
-0.0
tensor(12.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2920/ 20000/ t/epoch=0.32............. Loss: -0.81020493, mean(E): -21.41021062+0.00106097j, var(E): 1.37305424
-0.0
tensor(12.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2930/ 20000/ t/epoch=0.32............. Loss: -0.04250868, mean(E): -21.47305294+0.02819953j, var(E): 1.15755236
-0.0
tensor(12.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2940/ 20000/ t/epoch=0.32............. Loss: -0.58709435, mean(E): -21.42838421-0.00633922j, var(E): 3.06386328
-0.0
tensor(12.0904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2950/ 20000/ t/epoch=0.32............. Loss: 0.19112150, mean(E): -21.54534136+0.00960923j, var(E): 1.89328357
-0.0
tensor(12.0946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2960/ 20000/ t/epoch=0.32............. Loss: -0.22796598, mean(E): -21.40823375-0.00153761j, var(E): 1.12231340
-0.0
tensor(12.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2970/ 20000/ t/epoch=0.32............. Loss: -0.14111118, mean(E): -21.60662081+0.01227097j, var(E): 1.34732154
-0.0
tensor(12.0978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2980/ 20000/ t/epoch=0.32............. Loss: -0.26442449, mean(E): -21.43494731+0.00737738j, var(E): 1.76600705
-0.0
tensor(12.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 2990/ 20000/ t/epoch=0.32............. Loss: -0.21995150, mean(E): -21.48908387+0.00600867j, var(E): 1.77132435
-0.0
tensor(12.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3000/ 20000/ t/epoch=0.32............. Loss: -0.22400185, mean(E): -21.36216225+0.00821958j, var(E): 1.79276319
-0.0
tensor(12.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3010/ 20000/ t/epoch=0.32............. Loss: 0.75664447, mean(E): -21.59106390-0.00820155j, var(E): 2.58574401
-0.0
tensor(12.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3020/ 20000/ t/epoch=0.32............. Loss: 0.11031056, mean(E): -21.58822039-0.00054088j, var(E): 1.39738318
-0.0
tensor(12.1154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3030/ 20000/ t/epoch=0.32............. Loss: 0.02730994, mean(E): -21.44133601+0.03054430j, var(E): 1.35632625
-0.0
tensor(12.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3040/ 20000/ t/epoch=0.32............. Loss: 0.30780318, mean(E): -21.57465149+0.00056446j, var(E): 1.96620154
-0.0
tensor(12.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3050/ 20000/ t/epoch=0.32............. Loss: -0.12927549, mean(E): -21.44940232-0.03137392j, var(E): 1.65620615
-0.0
tensor(12.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3060/ 20000/ t/epoch=0.32............. Loss: -1.08309632, mean(E): -21.34856757-0.00002119j, var(E): 1.90308226
-0.0
tensor(12.1184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3070/ 20000/ t/epoch=0.32............. Loss: -0.09855570, mean(E): -21.49124781-0.00234741j, var(E): 1.55576010
-0.0
tensor(12.1226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3080/ 20000/ t/epoch=0.32............. Loss: -0.24826792, mean(E): -21.43760443+0.00871342j, var(E): 2.32600545
-0.0
tensor(12.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3090/ 20000/ t/epoch=0.32............. Loss: -0.00700163, mean(E): -21.39364213+0.00738606j, var(E): 1.80292201
-0.0
tensor(12.1253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3100/ 20000/ t/epoch=0.32............. Loss: -0.55708582, mean(E): -21.45811670-0.01203362j, var(E): 1.19849514
-0.0
tensor(12.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3110/ 20000/ t/epoch=0.32............. Loss: 0.15655066, mean(E): -21.56561679-0.01643411j, var(E): 2.20927050
-0.0
tensor(12.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3120/ 20000/ t/epoch=0.32............. Loss: -0.38473129, mean(E): -21.39715991-0.00755294j, var(E): 1.42481735
-0.0
tensor(12.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3130/ 20000/ t/epoch=0.32............. Loss: -0.15533829, mean(E): -21.58628323+0.00719731j, var(E): 1.99103903
-0.0
tensor(12.1460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3140/ 20000/ t/epoch=0.32............. Loss: -0.26375454, mean(E): -21.44861131+0.01146380j, var(E): 1.09303863
-0.0
tensor(12.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3150/ 20000/ t/epoch=0.32............. Loss: 0.41937647, mean(E): -21.57038742-0.00188220j, var(E): 1.24713893
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3160/ 20000/ t/epoch=0.32............. Loss: 0.26801867, mean(E): -21.51514973+0.00755574j, var(E): 3.02924219
-0.0
tensor(12.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3170/ 20000/ t/epoch=0.32............. Loss: 0.07361899, mean(E): -21.59070640+0.00842452j, var(E): 2.06492118
-0.0
tensor(12.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3180/ 20000/ t/epoch=0.32............. Loss: -0.26273134, mean(E): -21.44381446+0.01453324j, var(E): 1.53054715
-0.0
tensor(12.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3190/ 20000/ t/epoch=0.32............. Loss: -0.28976732, mean(E): -21.44218790-0.00712558j, var(E): 1.44785242
-0.0
tensor(12.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3200/ 20000/ t/epoch=0.32............. Loss: 0.46465913, mean(E): -21.54497766+0.01039294j, var(E): 1.75495677
-0.0
tensor(12.1770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3210/ 20000/ t/epoch=0.32............. Loss: 0.87563441, mean(E): -21.68905115+0.00627504j, var(E): 3.67137279
-0.0
tensor(12.1795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3220/ 20000/ t/epoch=0.32............. Loss: -0.11094415, mean(E): -21.51700808+0.00275988j, var(E): 1.45490546
-0.0
tensor(12.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3230/ 20000/ t/epoch=0.32............. Loss: 0.05884366, mean(E): -21.56581472-0.00511714j, var(E): 1.60078009
-0.0
tensor(12.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3240/ 20000/ t/epoch=0.32............. Loss: 0.96477831, mean(E): -21.59561071+0.00041720j, var(E): 2.66685528
-0.0
tensor(12.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3250/ 20000/ t/epoch=0.32............. Loss: 0.22442793, mean(E): -21.44897679-0.01079753j, var(E): 2.33699560
-0.0
tensor(12.1895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3260/ 20000/ t/epoch=0.32............. Loss: 0.26900478, mean(E): -21.63328327+0.02298114j, var(E): 1.36880342
-0.0
tensor(12.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3270/ 20000/ t/epoch=0.32............. Loss: -0.76443968, mean(E): -21.38464101+0.02582292j, var(E): 1.97155091
-0.0
tensor(12.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3280/ 20000/ t/epoch=0.32............. Loss: -0.81821589, mean(E): -21.36404771+0.00320793j, var(E): 1.08432247
-0.0
tensor(12.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3290/ 20000/ t/epoch=0.32............. Loss: 0.61799906, mean(E): -21.62772709+0.00929370j, var(E): 1.52286395
-0.0
tensor(12.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3300/ 20000/ t/epoch=0.32............. Loss: -0.45647469, mean(E): -21.42320939+0.01070791j, var(E): 1.78551741
-0.0
tensor(12.2052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3310/ 20000/ t/epoch=0.32............. Loss: 0.18340019, mean(E): -21.52783166-0.02411939j, var(E): 1.35812621
-0.0
tensor(12.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3320/ 20000/ t/epoch=0.32............. Loss: -0.58123183, mean(E): -21.46288540+0.00482726j, var(E): 2.03410191
-0.0
tensor(12.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3330/ 20000/ t/epoch=0.32............. Loss: -0.32698222, mean(E): -21.38451990-0.01683213j, var(E): 1.08442354
-0.0
tensor(12.2116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3340/ 20000/ t/epoch=0.32............. Loss: -0.44472821, mean(E): -21.37610357-0.02467204j, var(E): 1.50696894
-0.0
tensor(12.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3350/ 20000/ t/epoch=0.32............. Loss: 0.33561630, mean(E): -21.61984381+0.00099791j, var(E): 1.56073034
-0.0
tensor(12.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3360/ 20000/ t/epoch=0.32............. Loss: -0.44031593, mean(E): -21.36088486-0.01581330j, var(E): 1.90190785
-0.0
tensor(12.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3370/ 20000/ t/epoch=0.32............. Loss: -0.34468281, mean(E): -21.45043182-0.01570522j, var(E): 1.42356041
-0.0
tensor(12.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3380/ 20000/ t/epoch=0.32............. Loss: -0.72609666, mean(E): -21.35992812+0.00155277j, var(E): 1.42474760
-0.0
tensor(12.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3390/ 20000/ t/epoch=0.32............. Loss: -0.26191897, mean(E): -21.41356024+0.00803778j, var(E): 1.89871651
-0.0
tensor(12.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3400/ 20000/ t/epoch=0.32............. Loss: 0.17613628, mean(E): -21.47283648-0.01468057j, var(E): 3.13814972
-0.0
tensor(12.2429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3410/ 20000/ t/epoch=0.32............. Loss: -0.23735534, mean(E): -21.53420656-0.00296596j, var(E): 1.89048891
-0.0
tensor(12.2435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3420/ 20000/ t/epoch=0.32............. Loss: -0.17935612, mean(E): -21.46571117-0.02722010j, var(E): 0.87321268
-0.0
tensor(12.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3430/ 20000/ t/epoch=0.32............. Loss: -0.01033816, mean(E): -21.55525248-0.00693826j, var(E): 1.65912888
-0.0
tensor(12.2506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3440/ 20000/ t/epoch=0.32............. Loss: -0.71024635, mean(E): -21.35820915+0.01809443j, var(E): 2.33114588
-0.0
tensor(12.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3450/ 20000/ t/epoch=0.32............. Loss: 0.08857406, mean(E): -21.55362387+0.01788900j, var(E): 1.59916660
-0.0
tensor(12.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3460/ 20000/ t/epoch=0.32............. Loss: -0.07364517, mean(E): -21.46751541-0.00542070j, var(E): 1.31281280
-0.0
tensor(12.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3470/ 20000/ t/epoch=0.32............. Loss: 0.61672493, mean(E): -21.67030125-0.00551911j, var(E): 2.31524114
-0.0
tensor(12.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3480/ 20000/ t/epoch=0.32............. Loss: 0.34016581, mean(E): -21.58361043-0.00814691j, var(E): 1.73291122
-0.0
tensor(12.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3490/ 20000/ t/epoch=0.32............. Loss: -0.05078366, mean(E): -21.48424705+0.00867753j, var(E): 2.24737766
-0.0
tensor(12.2578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3500/ 20000/ t/epoch=0.32............. Loss: -0.15229116, mean(E): -21.58813179-0.00349398j, var(E): 1.39095961
-0.0
tensor(12.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3510/ 20000/ t/epoch=0.32............. Loss: 0.60572739, mean(E): -21.57356816-0.00288697j, var(E): 1.89679323
-0.0
tensor(12.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3520/ 20000/ t/epoch=0.32............. Loss: -0.50567881, mean(E): -21.41530832+0.00178980j, var(E): 1.30644813
-0.0
tensor(12.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3530/ 20000/ t/epoch=0.32............. Loss: 0.20401112, mean(E): -21.56707429+0.00469035j, var(E): 1.36785329
-0.0
tensor(12.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3540/ 20000/ t/epoch=0.32............. Loss: -0.82803211, mean(E): -21.36344215+0.01171169j, var(E): 1.75483923
-0.0
tensor(12.2766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3550/ 20000/ t/epoch=0.32............. Loss: -0.22943225, mean(E): -21.35127121-0.00446444j, var(E): 2.02007387
-0.0
tensor(12.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3560/ 20000/ t/epoch=0.32............. Loss: 0.17657616, mean(E): -21.57820523+0.02541454j, var(E): 1.60060462
-0.0
tensor(12.2880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3570/ 20000/ t/epoch=0.32............. Loss: -0.35716596, mean(E): -21.53408208-0.00179291j, var(E): 1.69832388
-0.0
tensor(12.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3580/ 20000/ t/epoch=0.32............. Loss: -0.54666805, mean(E): -21.38455398-0.00896331j, var(E): 0.97999158
-0.0
tensor(12.2964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3590/ 20000/ t/epoch=0.32............. Loss: 0.37986099, mean(E): -21.65867254-0.03240146j, var(E): 1.12932956
-0.0
tensor(12.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3600/ 20000/ t/epoch=0.32............. Loss: -0.79331753, mean(E): -21.37647045+0.00556641j, var(E): 1.56892330
-0.0
tensor(12.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3610/ 20000/ t/epoch=0.32............. Loss: 0.69382667, mean(E): -21.68651263-0.01762756j, var(E): 1.40794318
-0.0
tensor(12.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3620/ 20000/ t/epoch=0.32............. Loss: 0.12615205, mean(E): -21.54343822+0.00626936j, var(E): 1.99158341
-0.0
tensor(12.3078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3630/ 20000/ t/epoch=0.32............. Loss: -0.16506901, mean(E): -21.61144558+0.00522998j, var(E): 1.51512171
-0.0
tensor(12.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3640/ 20000/ t/epoch=0.32............. Loss: 0.48104620, mean(E): -21.64700840-0.00523931j, var(E): 2.58640948
-0.0
tensor(12.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3650/ 20000/ t/epoch=0.32............. Loss: 0.10600588, mean(E): -21.51000535-0.00500661j, var(E): 1.55649498
-0.0
tensor(12.3196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3660/ 20000/ t/epoch=0.32............. Loss: 0.47014667, mean(E): -21.57564913+0.01150131j, var(E): 1.49651046
-0.0
tensor(12.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3670/ 20000/ t/epoch=0.32............. Loss: 0.41056834, mean(E): -21.63110948-0.02241268j, var(E): 2.12272438
-0.0
tensor(12.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3680/ 20000/ t/epoch=0.32............. Loss: -0.69993873, mean(E): -21.39827999+0.00191700j, var(E): 1.21566767
-0.0
tensor(12.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3690/ 20000/ t/epoch=0.32............. Loss: -0.56393436, mean(E): -21.45055819-0.02586547j, var(E): 1.99119987
-0.0
tensor(12.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3700/ 20000/ t/epoch=0.32............. Loss: 0.07927420, mean(E): -21.58447059-0.00248120j, var(E): 1.13071619
-0.0
tensor(12.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3710/ 20000/ t/epoch=0.32............. Loss: -0.76501662, mean(E): -21.35775623+0.00067847j, var(E): 1.51147214
-0.0
tensor(12.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3720/ 20000/ t/epoch=0.32............. Loss: -0.10311927, mean(E): -21.53554499-0.03462429j, var(E): 1.51576340
-0.0
tensor(12.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3730/ 20000/ t/epoch=0.32............. Loss: -0.46962601, mean(E): -21.45797556+0.01543689j, var(E): 1.24191084
-0.0
tensor(12.3546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3740/ 20000/ t/epoch=0.32............. Loss: 0.00080637, mean(E): -21.48573320-0.02166447j, var(E): 1.91015130
-0.0
tensor(12.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3750/ 20000/ t/epoch=0.32............. Loss: 0.57881502, mean(E): -21.64499551+0.00740716j, var(E): 1.90451153
-0.0
tensor(12.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3760/ 20000/ t/epoch=0.32............. Loss: -0.63636926, mean(E): -21.42545793+0.02510740j, var(E): 1.97798398
-0.0
tensor(12.3676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3770/ 20000/ t/epoch=0.32............. Loss: 0.50219314, mean(E): -21.60253654-0.00342391j, var(E): 1.24970618
-0.0
tensor(12.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3780/ 20000/ t/epoch=0.32............. Loss: -0.07310489, mean(E): -21.52034382-0.01104566j, var(E): 1.44590747
-0.0
tensor(12.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3790/ 20000/ t/epoch=0.32............. Loss: 0.19563317, mean(E): -21.60654332+0.00717918j, var(E): 1.44714689
-0.0
tensor(12.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3800/ 20000/ t/epoch=0.32............. Loss: 0.22097305, mean(E): -21.55792243-0.00168343j, var(E): 1.01078857
-0.0
tensor(12.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3810/ 20000/ t/epoch=0.32............. Loss: -0.20871797, mean(E): -21.47367595-0.01096943j, var(E): 1.70837828
-0.0
tensor(12.3882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3820/ 20000/ t/epoch=0.32............. Loss: -0.13987333, mean(E): -21.44358832+0.01879467j, var(E): 0.86823905
-0.0
tensor(12.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3830/ 20000/ t/epoch=0.32............. Loss: 0.17228034, mean(E): -21.57087483-0.02199684j, var(E): 2.57407341
-0.0
tensor(12.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3840/ 20000/ t/epoch=0.32............. Loss: -0.79010694, mean(E): -21.36930821-0.01182865j, var(E): 1.11167423
-0.0
tensor(12.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3850/ 20000/ t/epoch=0.32............. Loss: -0.24231133, mean(E): -21.50629179-0.00107860j, var(E): 1.54364722
-0.0
tensor(12.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3860/ 20000/ t/epoch=0.32............. Loss: 0.11440841, mean(E): -21.48501291-0.00971148j, var(E): 1.15075033
-0.0
tensor(12.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3870/ 20000/ t/epoch=0.32............. Loss: -0.56521939, mean(E): -21.44089660+0.00878196j, var(E): 1.30709842
-0.0
tensor(12.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3880/ 20000/ t/epoch=0.32............. Loss: 1.01455216, mean(E): -21.60857498+0.01085838j, var(E): 2.00116478
-0.0
tensor(12.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3890/ 20000/ t/epoch=0.32............. Loss: -0.11002203, mean(E): -21.58064254-0.01159660j, var(E): 1.10709634
-0.0
tensor(12.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3900/ 20000/ t/epoch=0.32............. Loss: 0.52783381, mean(E): -21.56838300-0.00330659j, var(E): 2.03045357
-0.0
tensor(12.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3910/ 20000/ t/epoch=0.32............. Loss: 0.25961219, mean(E): -21.47330593-0.00990395j, var(E): 2.99045922
-0.0
tensor(12.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3920/ 20000/ t/epoch=0.32............. Loss: 0.22118011, mean(E): -21.60815944-0.02007675j, var(E): 1.52313019
-0.0
tensor(12.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3930/ 20000/ t/epoch=0.32............. Loss: -0.20264737, mean(E): -21.47954723+0.00219202j, var(E): 1.76381474
-0.0
tensor(12.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3940/ 20000/ t/epoch=0.32............. Loss: -0.37574724, mean(E): -21.50835626+0.01101695j, var(E): 1.25264685
-0.0
tensor(12.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3950/ 20000/ t/epoch=0.32............. Loss: 1.36220590, mean(E): -21.78798835+0.00505379j, var(E): 4.16715374
-0.0
tensor(12.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3960/ 20000/ t/epoch=0.32............. Loss: -0.14980378, mean(E): -21.47220458+0.00916715j, var(E): 1.69467116
-0.0
tensor(12.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3970/ 20000/ t/epoch=0.32............. Loss: -0.66254675, mean(E): -21.49588416-0.00865238j, var(E): 1.20535560
-0.0
tensor(12.4388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3980/ 20000/ t/epoch=0.32............. Loss: 0.06419996, mean(E): -21.59189515+0.00522276j, var(E): 0.63702357
-0.0
tensor(12.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 3990/ 20000/ t/epoch=0.32............. Loss: -0.21956251, mean(E): -21.45281064+0.00410816j, var(E): 1.50178757
-0.0
tensor(12.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4000/ 20000/ t/epoch=0.32............. Loss: 0.11624923, mean(E): -21.56074695+0.00282475j, var(E): 2.07006521
-0.0
tensor(12.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4010/ 20000/ t/epoch=0.32............. Loss: -0.20227673, mean(E): -21.53601364+0.00336061j, var(E): 1.44077432
-0.0
tensor(12.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4020/ 20000/ t/epoch=0.32............. Loss: -0.39845977, mean(E): -21.54705410-0.02112700j, var(E): 1.27086453
-0.0
tensor(12.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4030/ 20000/ t/epoch=0.32............. Loss: -0.78897471, mean(E): -21.45443650-0.01855555j, var(E): 1.79350795
-0.0
tensor(12.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4040/ 20000/ t/epoch=0.32............. Loss: 0.25748218, mean(E): -21.56650764+0.00900019j, var(E): 2.49835046
-0.0
tensor(12.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4050/ 20000/ t/epoch=0.32............. Loss: -0.10846903, mean(E): -21.54009405+0.00861896j, var(E): 1.11437168
-0.0
tensor(12.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4060/ 20000/ t/epoch=0.32............. Loss: -0.27995488, mean(E): -21.52972660+0.00135686j, var(E): 1.30504862
-0.0
tensor(12.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4070/ 20000/ t/epoch=0.32............. Loss: -0.40486084, mean(E): -21.44406569+0.00350902j, var(E): 0.94302403
-0.0
tensor(12.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4080/ 20000/ t/epoch=0.32............. Loss: -0.17081224, mean(E): -21.53946366+0.00817908j, var(E): 1.59334057
-0.0
tensor(12.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4090/ 20000/ t/epoch=0.32............. Loss: -0.03497823, mean(E): -21.45415767+0.01059257j, var(E): 1.26479667
-0.0
tensor(12.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4100/ 20000/ t/epoch=0.32............. Loss: -0.70730403, mean(E): -21.37142630-0.00072804j, var(E): 1.33627651
-0.0
tensor(12.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4110/ 20000/ t/epoch=0.32............. Loss: 0.12383857, mean(E): -21.50777989-0.03046892j, var(E): 1.16747329
-0.0
tensor(12.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4120/ 20000/ t/epoch=0.32............. Loss: 0.28166580, mean(E): -21.49204783+0.00338696j, var(E): 1.29034745
-0.0
tensor(12.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4130/ 20000/ t/epoch=0.32............. Loss: -0.61381501, mean(E): -21.43180934+0.00397098j, var(E): 1.24909078
-0.0
tensor(12.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4140/ 20000/ t/epoch=0.32............. Loss: 0.05274321, mean(E): -21.56173647-0.00184145j, var(E): 1.08495559
-0.0
tensor(12.5022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4150/ 20000/ t/epoch=0.32............. Loss: -0.42305411, mean(E): -21.49973171+0.00759057j, var(E): 1.63239009
-0.0
tensor(12.5034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4160/ 20000/ t/epoch=0.32............. Loss: -0.47980086, mean(E): -21.44025178-0.00585180j, var(E): 1.26703547
-0.0
tensor(12.5099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4170/ 20000/ t/epoch=0.32............. Loss: 0.22854768, mean(E): -21.63149644+0.00642347j, var(E): 0.87496510
-0.0
tensor(12.5159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4180/ 20000/ t/epoch=0.32............. Loss: -0.21196191, mean(E): -21.50660904+0.02135502j, var(E): 1.50103755
-0.0
tensor(12.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4190/ 20000/ t/epoch=0.32............. Loss: -0.15219508, mean(E): -21.54516366-0.00506841j, var(E): 1.12719805
-0.0
tensor(12.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4200/ 20000/ t/epoch=0.32............. Loss: -0.68687800, mean(E): -21.43562324+0.00134410j, var(E): 1.40850296
-0.0
tensor(12.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4210/ 20000/ t/epoch=0.32............. Loss: -0.29149557, mean(E): -21.44103479-0.01610847j, var(E): 1.83036457
-0.0
tensor(12.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4220/ 20000/ t/epoch=0.32............. Loss: -0.35431708, mean(E): -21.54402615-0.01743094j, var(E): 1.62022678
-0.0
tensor(12.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4230/ 20000/ t/epoch=0.32............. Loss: -0.14207003, mean(E): -21.54360402-0.00344824j, var(E): 2.37072293
-0.0
tensor(12.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4240/ 20000/ t/epoch=0.32............. Loss: 0.66591892, mean(E): -21.61597246-0.00805580j, var(E): 1.32106581
-0.0
tensor(12.5410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4250/ 20000/ t/epoch=0.32............. Loss: -0.06255840, mean(E): -21.54419536+0.01272235j, var(E): 1.16782426
-0.0
tensor(12.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4260/ 20000/ t/epoch=0.32............. Loss: -0.66499180, mean(E): -21.44352810+0.00493118j, var(E): 1.23072726
-0.0
tensor(12.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4270/ 20000/ t/epoch=0.32............. Loss: 0.21000403, mean(E): -21.65133268-0.00068506j, var(E): 1.34887590
-0.0
tensor(12.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4280/ 20000/ t/epoch=0.32............. Loss: -0.51762475, mean(E): -21.41491330+0.01091977j, var(E): 1.10915395
-0.0
tensor(12.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4290/ 20000/ t/epoch=0.32............. Loss: 1.18881564, mean(E): -21.73756532+0.01139478j, var(E): 1.65173464
-0.0
tensor(12.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4300/ 20000/ t/epoch=0.32............. Loss: -0.18852985, mean(E): -21.45912744+0.00255545j, var(E): 0.74451712
-0.0
tensor(12.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4310/ 20000/ t/epoch=0.32............. Loss: -0.09563416, mean(E): -21.47666224+0.00976174j, var(E): 0.68511405
-0.0
tensor(12.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4320/ 20000/ t/epoch=0.32............. Loss: 0.21403235, mean(E): -21.53620261-0.00357163j, var(E): 1.08807019
-0.0
tensor(12.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4330/ 20000/ t/epoch=0.32............. Loss: -0.03052729, mean(E): -21.51025290+0.01439277j, var(E): 1.05724677
-0.0
tensor(12.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4340/ 20000/ t/epoch=0.32............. Loss: 1.40307547, mean(E): -21.73979075-0.01103245j, var(E): 4.12886222
-0.0
tensor(12.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4350/ 20000/ t/epoch=0.32............. Loss: 0.37638858, mean(E): -21.71130383-0.01423284j, var(E): 1.41081165
-0.0
tensor(12.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4360/ 20000/ t/epoch=0.32............. Loss: -0.14871542, mean(E): -21.51399545+0.01023997j, var(E): 1.62009000
-0.0
tensor(12.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4370/ 20000/ t/epoch=0.32............. Loss: -0.73831537, mean(E): -21.46613949+0.01722554j, var(E): 1.13225297
-0.0
tensor(12.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4380/ 20000/ t/epoch=0.32............. Loss: 0.56370319, mean(E): -21.66083256-0.01733508j, var(E): 1.17099905
-0.0
tensor(12.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4390/ 20000/ t/epoch=0.32............. Loss: -0.12597459, mean(E): -21.61056426-0.00428663j, var(E): 2.12422696
-0.0
tensor(12.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4400/ 20000/ t/epoch=0.32............. Loss: 0.11747068, mean(E): -21.60436211-0.00468746j, var(E): 0.83684348
-0.0
tensor(12.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4410/ 20000/ t/epoch=0.32............. Loss: -0.01787182, mean(E): -21.55689567-0.01222513j, var(E): 1.61338057
-0.0
tensor(12.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4420/ 20000/ t/epoch=0.32............. Loss: 0.08282230, mean(E): -21.59184833+0.01653446j, var(E): 1.21825077
-0.0
tensor(12.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4430/ 20000/ t/epoch=0.32............. Loss: 0.29946004, mean(E): -21.62654277-0.01008504j, var(E): 1.05432817
-0.0
tensor(12.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4440/ 20000/ t/epoch=0.32............. Loss: -0.12805033, mean(E): -21.50286903-0.00911886j, var(E): 0.89808033
-0.0
tensor(12.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4450/ 20000/ t/epoch=0.32............. Loss: 0.24427677, mean(E): -21.65002495-0.01238909j, var(E): 1.07986844
-0.0
tensor(12.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4460/ 20000/ t/epoch=0.32............. Loss: -0.22914901, mean(E): -21.61417912-0.01377132j, var(E): 1.28954068
-0.0
tensor(12.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4470/ 20000/ t/epoch=0.32............. Loss: -0.64066273, mean(E): -21.43568497+0.00239781j, var(E): 1.32273393
-0.0
tensor(12.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4480/ 20000/ t/epoch=0.32............. Loss: 0.56766419, mean(E): -21.57478444+0.01243558j, var(E): 1.62209187
-0.0
tensor(12.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4490/ 20000/ t/epoch=0.32............. Loss: -0.40090425, mean(E): -21.50216993-0.00204456j, var(E): 1.27335860
-0.0
tensor(12.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4500/ 20000/ t/epoch=0.32............. Loss: -0.51792654, mean(E): -21.53662586+0.02027539j, var(E): 1.78790063
-0.0
tensor(12.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4510/ 20000/ t/epoch=0.32............. Loss: 0.12469998, mean(E): -21.59458277-0.00852679j, var(E): 0.99008779
-0.0
tensor(12.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4520/ 20000/ t/epoch=0.32............. Loss: 0.41029569, mean(E): -21.68371207-0.01187288j, var(E): 1.67225225
-0.0
tensor(12.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4530/ 20000/ t/epoch=0.32............. Loss: -0.51227960, mean(E): -21.46952876-0.00196570j, var(E): 1.30058784
-0.0
tensor(12.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4540/ 20000/ t/epoch=0.32............. Loss: -0.63764199, mean(E): -21.37854373+0.01189439j, var(E): 1.80009051
-0.0
tensor(12.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4550/ 20000/ t/epoch=0.32............. Loss: 0.69765090, mean(E): -21.59823769-0.02833657j, var(E): 1.95442170
-0.0
tensor(12.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4560/ 20000/ t/epoch=0.32............. Loss: 0.54785136, mean(E): -21.66605790-0.01588475j, var(E): 1.44321687
-0.0
tensor(12.6466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4570/ 20000/ t/epoch=0.32............. Loss: 0.75620002, mean(E): -21.65366411-0.00042759j, var(E): 2.76918276
-0.0
tensor(12.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4580/ 20000/ t/epoch=0.32............. Loss: -0.18944701, mean(E): -21.47978669+0.00831358j, var(E): 0.70428481
-0.0
tensor(12.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4590/ 20000/ t/epoch=0.32............. Loss: 0.06694390, mean(E): -21.62769958-0.00605776j, var(E): 2.06906397
-0.0
tensor(12.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4600/ 20000/ t/epoch=0.32............. Loss: 0.30566927, mean(E): -21.69449511-0.01571234j, var(E): 1.19055534
-0.0
tensor(12.6578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4610/ 20000/ t/epoch=0.32............. Loss: -0.58455432, mean(E): -21.58302376+0.01053147j, var(E): 1.09126364
-0.0
tensor(12.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4620/ 20000/ t/epoch=0.32............. Loss: 0.24786602, mean(E): -21.70327584-0.01241646j, var(E): 1.80148148
-0.0
tensor(12.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4630/ 20000/ t/epoch=0.32............. Loss: 0.01366318, mean(E): -21.62337292-0.00622692j, var(E): 1.32705713
-0.0
tensor(12.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4640/ 20000/ t/epoch=0.32............. Loss: -0.28408019, mean(E): -21.45215040+0.00266928j, var(E): 1.80193713
-0.0
tensor(12.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4650/ 20000/ t/epoch=0.32............. Loss: 0.47484701, mean(E): -21.63080244-0.00827010j, var(E): 0.96256821
-0.0
tensor(12.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4660/ 20000/ t/epoch=0.32............. Loss: 0.39779164, mean(E): -21.63586115-0.00203000j, var(E): 1.07206064
-0.0
tensor(12.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4670/ 20000/ t/epoch=0.32............. Loss: 0.29683990, mean(E): -21.67026794+0.00522272j, var(E): 1.08066508
-0.0
tensor(12.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4680/ 20000/ t/epoch=0.32............. Loss: 0.07565417, mean(E): -21.57911803-0.00896840j, var(E): 1.27241815
-0.0
tensor(12.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4690/ 20000/ t/epoch=0.32............. Loss: -0.25685640, mean(E): -21.50353783-0.00899793j, var(E): 1.36579054
-0.0
tensor(12.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4700/ 20000/ t/epoch=0.32............. Loss: 0.13437879, mean(E): -21.54456191+0.00938157j, var(E): 1.87430019
-0.0
tensor(12.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4710/ 20000/ t/epoch=0.32............. Loss: 0.59356947, mean(E): -21.67912773-0.00763474j, var(E): 1.44536984
-0.0
tensor(12.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4720/ 20000/ t/epoch=0.32............. Loss: -0.52610207, mean(E): -21.57404678+0.00352990j, var(E): 1.00513377
-0.0
tensor(12.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4730/ 20000/ t/epoch=0.32............. Loss: 0.52314454, mean(E): -21.67447335+0.01239308j, var(E): 0.84309865
-0.0
tensor(12.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4740/ 20000/ t/epoch=0.32............. Loss: 0.26640424, mean(E): -21.61237789-0.00523983j, var(E): 1.34934908
-0.0
tensor(12.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4750/ 20000/ t/epoch=0.32............. Loss: 0.18358294, mean(E): -21.60825250+0.00682707j, var(E): 1.21259058
-0.0
tensor(12.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4760/ 20000/ t/epoch=0.32............. Loss: 0.21119228, mean(E): -21.64465087+0.00434589j, var(E): 1.34872282
-0.0
tensor(12.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4770/ 20000/ t/epoch=0.32............. Loss: 0.24088806, mean(E): -21.69770064+0.01222212j, var(E): 0.95063184
-0.0
tensor(12.7011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4780/ 20000/ t/epoch=0.32............. Loss: 0.03870511, mean(E): -21.62985520+0.00454101j, var(E): 1.62061188
-0.0
tensor(12.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4790/ 20000/ t/epoch=0.32............. Loss: -0.02288869, mean(E): -21.58546712-0.00710543j, var(E): 1.09385414
-0.0
tensor(12.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4800/ 20000/ t/epoch=0.32............. Loss: -0.12128101, mean(E): -21.62588176-0.00316838j, var(E): 2.35477218
-0.0
tensor(12.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4810/ 20000/ t/epoch=0.32............. Loss: -0.84442076, mean(E): -21.43641106+0.00259127j, var(E): 1.98239787
-0.0
tensor(12.7077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4820/ 20000/ t/epoch=0.32............. Loss: -0.95753580, mean(E): -21.40766812-0.00227810j, var(E): 1.31297264
-0.0
tensor(12.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4830/ 20000/ t/epoch=0.32............. Loss: 0.93784508, mean(E): -21.68884307+0.00073057j, var(E): 2.07773397
-0.0
tensor(12.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4840/ 20000/ t/epoch=0.32............. Loss: -0.01325890, mean(E): -21.59801540-0.00449955j, var(E): 1.46599663
-0.0
tensor(12.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4850/ 20000/ t/epoch=0.32............. Loss: -0.81163584, mean(E): -21.50777161-0.01553288j, var(E): 1.08263996
-0.0
tensor(12.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4860/ 20000/ t/epoch=0.32............. Loss: -0.17964397, mean(E): -21.55271339-0.02118190j, var(E): 1.20306028
-0.0
tensor(12.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4870/ 20000/ t/epoch=0.32............. Loss: 0.13165389, mean(E): -21.58487654-0.00789142j, var(E): 1.55427206
-0.0
tensor(12.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4880/ 20000/ t/epoch=0.32............. Loss: 0.52791644, mean(E): -21.60311207-0.00872967j, var(E): 1.00055731
-0.0
tensor(12.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4890/ 20000/ t/epoch=0.32............. Loss: 0.29873187, mean(E): -21.62528811-0.01050901j, var(E): 0.59519381
-0.0
tensor(12.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4900/ 20000/ t/epoch=0.32............. Loss: 0.43828532, mean(E): -21.58309787-0.01150201j, var(E): 2.17054583
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4910/ 20000/ t/epoch=0.32............. Loss: 0.19107067, mean(E): -21.59681115+0.01463940j, var(E): 3.55458472
-0.0
tensor(12.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4920/ 20000/ t/epoch=0.32............. Loss: -0.24638779, mean(E): -21.55619950-0.01736097j, var(E): 1.14974380
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4930/ 20000/ t/epoch=0.32............. Loss: 0.45276235, mean(E): -21.69833289-0.00263227j, var(E): 0.60310782
-0.0
tensor(12.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4940/ 20000/ t/epoch=0.32............. Loss: -0.07742719, mean(E): -21.64465584-0.00754503j, var(E): 1.11972616
-0.0
tensor(12.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4950/ 20000/ t/epoch=0.32............. Loss: 0.04752945, mean(E): -21.58125265-0.00166002j, var(E): 1.17693600
-0.0
tensor(12.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4960/ 20000/ t/epoch=0.32............. Loss: 0.17106127, mean(E): -21.66276418+0.00426450j, var(E): 1.53093507
-0.0
tensor(12.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4970/ 20000/ t/epoch=0.32............. Loss: 0.10956557, mean(E): -21.64804978-0.01412307j, var(E): 2.51667034
-0.0
tensor(12.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4980/ 20000/ t/epoch=0.32............. Loss: 0.09429221, mean(E): -21.67152882-0.01343019j, var(E): 2.46663428
-0.0
tensor(12.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 4990/ 20000/ t/epoch=0.32............. Loss: -0.23338502, mean(E): -21.53973681-0.00024250j, var(E): 0.90890187
-0.0
tensor(12.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5000/ 20000/ t/epoch=0.32............. Loss: -0.33221447, mean(E): -21.59207089+0.00441906j, var(E): 0.95621263
-0.0
tensor(12.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5010/ 20000/ t/epoch=0.32............. Loss: -0.40434328, mean(E): -21.55226842-0.00268820j, var(E): 1.07595906
-0.0
tensor(12.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5020/ 20000/ t/epoch=0.32............. Loss: -0.57323319, mean(E): -21.52319557+0.01566826j, var(E): 1.75160928
-0.0
tensor(12.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5030/ 20000/ t/epoch=0.32............. Loss: -0.17238270, mean(E): -21.53729128-0.00470445j, var(E): 1.02210898
-0.0
tensor(12.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5040/ 20000/ t/epoch=0.32............. Loss: -0.25926293, mean(E): -21.50285299+0.00444360j, var(E): 0.93405643
-0.0
tensor(12.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5050/ 20000/ t/epoch=0.32............. Loss: 0.02693586, mean(E): -21.60975697+0.00461842j, var(E): 1.19621004
-0.0
tensor(12.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5060/ 20000/ t/epoch=0.32............. Loss: 0.15581561, mean(E): -21.54331557-0.00667241j, var(E): 2.02204703
-0.0
tensor(12.7701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5070/ 20000/ t/epoch=0.32............. Loss: 0.49270477, mean(E): -21.64729908+0.00113970j, var(E): 1.26381897
-0.0
tensor(12.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5080/ 20000/ t/epoch=0.32............. Loss: -0.19301389, mean(E): -21.54758755-0.00091035j, var(E): 1.31388204
-0.0
tensor(12.7761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5090/ 20000/ t/epoch=0.33............. Loss: 0.13903376, mean(E): -21.66181714-0.00804648j, var(E): 1.21210782
-0.0
tensor(12.7806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5100/ 20000/ t/epoch=0.32............. Loss: -0.28009634, mean(E): -21.51686398-0.00945636j, var(E): 0.84305017
-0.0
tensor(12.7836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5110/ 20000/ t/epoch=0.32............. Loss: -0.26664322, mean(E): -21.53102101+0.00159372j, var(E): 0.91349941
-0.0
tensor(12.7857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5120/ 20000/ t/epoch=0.32............. Loss: 0.00686708, mean(E): -21.57232970-0.00040141j, var(E): 0.77448189
-0.0
tensor(12.7896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5130/ 20000/ t/epoch=0.32............. Loss: -0.00025529, mean(E): -21.59518443-0.01355708j, var(E): 0.63997727
-0.0
tensor(12.7933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5140/ 20000/ t/epoch=0.32............. Loss: 0.82897826, mean(E): -21.63867630-0.00730357j, var(E): 1.38283909
-0.0
tensor(12.7966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5150/ 20000/ t/epoch=0.32............. Loss: -0.10614284, mean(E): -21.59449296+0.00334642j, var(E): 1.04536925
-0.0
tensor(12.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5160/ 20000/ t/epoch=0.32............. Loss: -0.01816982, mean(E): -21.60173685+0.00731730j, var(E): 0.97874542
-0.0
tensor(12.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5170/ 20000/ t/epoch=0.32............. Loss: -0.43279848, mean(E): -21.50537041+0.01493567j, var(E): 0.97812820
-0.0
tensor(12.8001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5180/ 20000/ t/epoch=0.32............. Loss: 0.30418868, mean(E): -21.67703339-0.00027990j, var(E): 1.00391182
-0.0
tensor(12.8013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5190/ 20000/ t/epoch=0.32............. Loss: 0.04921239, mean(E): -21.56877796-0.00277019j, var(E): 1.60690512
-0.0
tensor(12.7981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5200/ 20000/ t/epoch=0.32............. Loss: 0.69048004, mean(E): -21.74974684-0.00376572j, var(E): 1.92695734
-0.0
tensor(12.7993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.7999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5210/ 20000/ t/epoch=0.32............. Loss: -0.71999852, mean(E): -21.44813950+0.00386812j, var(E): 1.10299219
-0.0
tensor(12.8003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5220/ 20000/ t/epoch=0.33............. Loss: 0.02751345, mean(E): -21.58676135+0.00589901j, var(E): 0.70974393
-0.0
tensor(12.8045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5230/ 20000/ t/epoch=0.32............. Loss: -0.13599005, mean(E): -21.52207162+0.00183073j, var(E): 0.83471018
-0.0
tensor(12.8091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5240/ 20000/ t/epoch=0.32............. Loss: 0.11773357, mean(E): -21.65138410-0.00745302j, var(E): 1.37882525
-0.0
tensor(12.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5250/ 20000/ t/epoch=0.32............. Loss: -0.16971966, mean(E): -21.56321038+0.00335345j, var(E): 0.86059102
-0.0
tensor(12.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5260/ 20000/ t/epoch=0.32............. Loss: -0.13160037, mean(E): -21.63846256-0.00006365j, var(E): 1.12175645
-0.0
tensor(12.8151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5270/ 20000/ t/epoch=0.32............. Loss: -0.15562618, mean(E): -21.49909406-0.00750312j, var(E): 1.16782665
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5280/ 20000/ t/epoch=0.32............. Loss: -0.48820121, mean(E): -21.50121217+0.00324160j, var(E): 1.43668137
-0.0
tensor(12.8144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5290/ 20000/ t/epoch=0.33............. Loss: -0.44571328, mean(E): -21.51089999-0.01472925j, var(E): 0.96682654
-0.0
tensor(12.8178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5300/ 20000/ t/epoch=0.32............. Loss: -0.38806145, mean(E): -21.55027470+0.00598538j, var(E): 0.87507809
-0.0
tensor(12.8212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5310/ 20000/ t/epoch=0.32............. Loss: -0.29675838, mean(E): -21.56757208-0.00386363j, var(E): 0.79096563
-0.0
tensor(12.8232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5320/ 20000/ t/epoch=0.33............. Loss: 0.06145534, mean(E): -21.63782308+0.00284262j, var(E): 1.42631973
-0.0
tensor(12.8254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5330/ 20000/ t/epoch=0.33............. Loss: 0.79372242, mean(E): -21.72316603-0.00938364j, var(E): 1.53461845
-0.0
tensor(12.8283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5340/ 20000/ t/epoch=0.32............. Loss: -0.19596932, mean(E): -21.57038370-0.01280679j, var(E): 0.84011278
-0.0
tensor(12.8294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5350/ 20000/ t/epoch=0.32............. Loss: 0.44186219, mean(E): -21.71191951+0.01137942j, var(E): 1.01445735
-0.0
tensor(12.8317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5360/ 20000/ t/epoch=0.33............. Loss: 0.31866244, mean(E): -21.60631106+0.00377064j, var(E): 1.57015088
-0.0
tensor(12.8337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5370/ 20000/ t/epoch=0.32............. Loss: -0.06466112, mean(E): -21.60465209+0.01614433j, var(E): 1.75626577
-0.0
tensor(12.8357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5380/ 20000/ t/epoch=0.32............. Loss: 0.39910440, mean(E): -21.62183464+0.00002353j, var(E): 0.85122919
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5390/ 20000/ t/epoch=0.32............. Loss: 0.68528536, mean(E): -21.69599688+0.00451311j, var(E): 1.65509372
-0.0
tensor(12.8390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5400/ 20000/ t/epoch=0.32............. Loss: -0.32160778, mean(E): -21.57467926-0.00293930j, var(E): 0.81367581
-0.0
tensor(12.8433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5410/ 20000/ t/epoch=0.32............. Loss: -0.14807648, mean(E): -21.57433751+0.00782885j, var(E): 1.62688251
-0.0
tensor(12.8486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5420/ 20000/ t/epoch=0.32............. Loss: 0.11499654, mean(E): -21.67661117-0.02126447j, var(E): 1.30484804
-0.0
tensor(12.8514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5430/ 20000/ t/epoch=0.32............. Loss: -0.22533238, mean(E): -21.55075498-0.00346036j, var(E): 1.02882549
-0.0
tensor(12.8529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5440/ 20000/ t/epoch=0.32............. Loss: 0.04985586, mean(E): -21.57336614-0.01068896j, var(E): 0.78612388
-0.0
tensor(12.8542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5450/ 20000/ t/epoch=0.32............. Loss: -0.09736756, mean(E): -21.60998829-0.00819596j, var(E): 1.42377636
-0.0
tensor(12.8567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5460/ 20000/ t/epoch=0.32............. Loss: 0.23323389, mean(E): -21.64123991+0.00042823j, var(E): 1.11051143
-0.0
tensor(12.8609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5470/ 20000/ t/epoch=0.32............. Loss: 0.19377594, mean(E): -21.66160602+0.00694219j, var(E): 0.86675475
-0.0
tensor(12.8651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5480/ 20000/ t/epoch=0.33............. Loss: 0.55138991, mean(E): -21.74600417-0.00666922j, var(E): 0.94719804
-0.0
tensor(12.8667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5490/ 20000/ t/epoch=0.32............. Loss: -0.49765737, mean(E): -21.53309544-0.00168202j, var(E): 0.90892376
-0.0
tensor(12.8705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5500/ 20000/ t/epoch=0.32............. Loss: -0.22505563, mean(E): -21.57686920-0.00447293j, var(E): 1.55866228
-0.0
tensor(12.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5510/ 20000/ t/epoch=0.32............. Loss: -0.53638097, mean(E): -21.55023441-0.00379441j, var(E): 1.30627412
-0.0
tensor(12.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5520/ 20000/ t/epoch=0.32............. Loss: -0.56764949, mean(E): -21.54574827+0.01349420j, var(E): 1.27665253
-0.0
tensor(12.8732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5530/ 20000/ t/epoch=0.32............. Loss: 0.20062361, mean(E): -21.62475143-0.00741515j, var(E): 0.86737302
-0.0
tensor(12.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5540/ 20000/ t/epoch=0.32............. Loss: -0.45515488, mean(E): -21.53555438+0.00028356j, var(E): 1.51144017
-0.0
tensor(12.8749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5550/ 20000/ t/epoch=0.32............. Loss: 0.05303522, mean(E): -21.61276935+0.00490025j, var(E): 0.79011143
-0.0
tensor(12.8762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5560/ 20000/ t/epoch=0.32............. Loss: 0.57593436, mean(E): -21.60413302-0.01460461j, var(E): 2.80716034
-0.0
tensor(12.8774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5570/ 20000/ t/epoch=0.33............. Loss: -0.10066723, mean(E): -21.52800821-0.00578715j, var(E): 0.98930934
-0.0
tensor(12.8777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5580/ 20000/ t/epoch=0.32............. Loss: -0.15837271, mean(E): -21.48813963+0.01021664j, var(E): 1.27354452
-0.0
tensor(12.8813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5590/ 20000/ t/epoch=0.32............. Loss: 0.05498491, mean(E): -21.58749770-0.01366623j, var(E): 1.32853382
-0.0
tensor(12.8828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5600/ 20000/ t/epoch=0.32............. Loss: 0.45513720, mean(E): -21.64112829-0.00343272j, var(E): 1.92111587
-0.0
tensor(12.8842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5610/ 20000/ t/epoch=0.32............. Loss: 0.05280508, mean(E): -21.53301296+0.01268625j, var(E): 0.69410389
-0.0
tensor(12.8864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5620/ 20000/ t/epoch=0.33............. Loss: 0.57577120, mean(E): -21.69641523-0.00374353j, var(E): 1.78817239
-0.0
tensor(12.8874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5630/ 20000/ t/epoch=0.32............. Loss: 0.28129243, mean(E): -21.59274122-0.00114755j, var(E): 2.10476469
-0.0
tensor(12.8895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5640/ 20000/ t/epoch=0.32............. Loss: 0.00072797, mean(E): -21.61126151+0.00023613j, var(E): 0.82157579
-0.0
tensor(12.8916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5650/ 20000/ t/epoch=0.32............. Loss: -0.41597430, mean(E): -21.51075219-0.00457302j, var(E): 1.14034006
-0.0
tensor(12.8955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.8999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5660/ 20000/ t/epoch=0.32............. Loss: -0.39515368, mean(E): -21.52570262+0.01437567j, var(E): 0.94914897
-0.0
tensor(12.9014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5670/ 20000/ t/epoch=0.32............. Loss: 0.09298430, mean(E): -21.62817662+0.01150198j, var(E): 0.81325398
-0.0
tensor(12.9055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5680/ 20000/ t/epoch=0.32............. Loss: -0.46125282, mean(E): -21.47802257-0.00294849j, var(E): 0.76819670
-0.0
tensor(12.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5690/ 20000/ t/epoch=0.33............. Loss: 0.22373720, mean(E): -21.64150668+0.00597619j, var(E): 1.72429579
-0.0
tensor(12.9093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5700/ 20000/ t/epoch=0.32............. Loss: 0.37261270, mean(E): -21.72685689+0.00389534j, var(E): 1.19054019
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5710/ 20000/ t/epoch=0.32............. Loss: -0.45373575, mean(E): -21.46951276-0.00095871j, var(E): 1.64763672
-0.0
tensor(12.9069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5720/ 20000/ t/epoch=0.32............. Loss: 0.21706047, mean(E): -21.61160696+0.00306253j, var(E): 2.44000123
-0.0
tensor(12.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5730/ 20000/ t/epoch=0.32............. Loss: 0.24759176, mean(E): -21.63104331+0.00420861j, var(E): 0.59938922
-0.0
tensor(12.9088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5740/ 20000/ t/epoch=0.32............. Loss: 0.26783876, mean(E): -21.65460893+0.01024952j, var(E): 1.11234091
-0.0
tensor(12.9110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5750/ 20000/ t/epoch=0.32............. Loss: 0.02057277, mean(E): -21.59182222+0.01602703j, var(E): 0.92869105
-0.0
tensor(12.9142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5760/ 20000/ t/epoch=0.32............. Loss: 0.08276004, mean(E): -21.67412173-0.01470469j, var(E): 1.14159815
-0.0
tensor(12.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5770/ 20000/ t/epoch=0.32............. Loss: 0.34421155, mean(E): -21.70293478-0.00131920j, var(E): 0.89236170
-0.0
tensor(12.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5780/ 20000/ t/epoch=0.32............. Loss: 0.02497289, mean(E): -21.54295265+0.00445724j, var(E): 0.80995414
-0.0
tensor(12.9183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5790/ 20000/ t/epoch=0.33............. Loss: 0.02106104, mean(E): -21.58339793-0.01057547j, var(E): 0.86492775
-0.0
tensor(12.9209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5800/ 20000/ t/epoch=0.32............. Loss: -0.65045576, mean(E): -21.46623529-0.00700775j, var(E): 1.06118774
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5810/ 20000/ t/epoch=0.32............. Loss: 0.24219617, mean(E): -21.75463478-0.00095225j, var(E): 1.10330378
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5820/ 20000/ t/epoch=0.32............. Loss: -0.21948051, mean(E): -21.57685782+0.00086648j, var(E): 0.93034868
-0.0
tensor(12.9228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5830/ 20000/ t/epoch=0.32............. Loss: 0.19593347, mean(E): -21.65769014+0.00375557j, var(E): 1.00428988
-0.0
tensor(12.9239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5840/ 20000/ t/epoch=0.32............. Loss: -0.20999687, mean(E): -21.56936418+0.00017128j, var(E): 1.18017958
-0.0
tensor(12.9253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5850/ 20000/ t/epoch=0.32............. Loss: 0.25208764, mean(E): -21.66313895+0.00063476j, var(E): 1.22120296
-0.0
tensor(12.9287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5860/ 20000/ t/epoch=0.32............. Loss: 0.10428455, mean(E): -21.62828827-0.00796326j, var(E): 2.00144894
-0.0
tensor(12.9296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5870/ 20000/ t/epoch=0.32............. Loss: -0.04209565, mean(E): -21.57388200+0.01715894j, var(E): 1.06424619
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5880/ 20000/ t/epoch=0.32............. Loss: -0.36080049, mean(E): -21.54882385-0.00313413j, var(E): 1.56846751
-0.0
tensor(12.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5890/ 20000/ t/epoch=0.32............. Loss: -0.02670754, mean(E): -21.60822148+0.01197555j, var(E): 0.84194895
-0.0
tensor(12.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5900/ 20000/ t/epoch=0.32............. Loss: 0.38749879, mean(E): -21.62490154+0.00020620j, var(E): 1.45807479
-0.0
tensor(12.9325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5910/ 20000/ t/epoch=0.32............. Loss: 0.51805552, mean(E): -21.67455287+0.00619816j, var(E): 1.33222143
-0.0
tensor(12.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5920/ 20000/ t/epoch=0.32............. Loss: -0.25882136, mean(E): -21.52877184-0.00588695j, var(E): 0.93441877
-0.0
tensor(12.9338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5930/ 20000/ t/epoch=0.32............. Loss: -0.07819187, mean(E): -21.60765098+0.00770446j, var(E): 0.67810853
-0.0
tensor(12.9366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5940/ 20000/ t/epoch=0.32............. Loss: -0.44670001, mean(E): -21.53546056-0.00096030j, var(E): 1.29564758
-0.0
tensor(12.9394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5950/ 20000/ t/epoch=0.32............. Loss: -0.18222242, mean(E): -21.55693719+0.00170344j, var(E): 1.21562792
-0.0
tensor(12.9414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5960/ 20000/ t/epoch=0.32............. Loss: -0.61592575, mean(E): -21.54526632-0.00986354j, var(E): 1.13750297
-0.0
tensor(12.9433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5970/ 20000/ t/epoch=0.32............. Loss: 0.72584428, mean(E): -21.74052378-0.00228031j, var(E): 2.60353737
-0.0
tensor(12.9459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5980/ 20000/ t/epoch=0.32............. Loss: -0.08840091, mean(E): -21.60303049-0.00559332j, var(E): 0.66122083
-0.0
tensor(12.9474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 5990/ 20000/ t/epoch=0.32............. Loss: -0.45198857, mean(E): -21.56563742+0.00156257j, var(E): 0.92116413
-0.0
tensor(12.9479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6000/ 20000/ t/epoch=0.32............. Loss: 0.00904199, mean(E): -21.64638026+0.00546903j, var(E): 0.61413873
-0.0
tensor(12.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6010/ 20000/ t/epoch=0.32............. Loss: -0.60978046, mean(E): -21.55818904-0.01069501j, var(E): 1.86135827
-0.0
tensor(12.9493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6020/ 20000/ t/epoch=0.32............. Loss: -0.38281955, mean(E): -21.56526574-0.00967460j, var(E): 2.25083110
-0.0
tensor(12.9505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6030/ 20000/ t/epoch=0.32............. Loss: -0.91373384, mean(E): -21.47878168-0.00199474j, var(E): 1.30505859
-0.0
tensor(12.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6040/ 20000/ t/epoch=0.32............. Loss: 0.38005352, mean(E): -21.64012728+0.00686044j, var(E): 1.72935011
-0.0
tensor(12.9544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6050/ 20000/ t/epoch=0.32............. Loss: 0.15745500, mean(E): -21.60406522-0.00559283j, var(E): 1.21597052
-0.0
tensor(12.9565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6060/ 20000/ t/epoch=0.32............. Loss: -0.65811622, mean(E): -21.42258059-0.01892456j, var(E): 1.05166021
-0.0
tensor(12.9582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6070/ 20000/ t/epoch=0.32............. Loss: 0.21938613, mean(E): -21.65995260+0.00979137j, var(E): 0.80590663
-0.0
tensor(12.9599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6080/ 20000/ t/epoch=0.32............. Loss: -0.23888320, mean(E): -21.55688418-0.00604154j, var(E): 1.38490633
-0.0
tensor(12.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6090/ 20000/ t/epoch=0.32............. Loss: -0.09366864, mean(E): -21.61388689+0.01279293j, var(E): 1.10420507
-0.0
tensor(12.9625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6100/ 20000/ t/epoch=0.32............. Loss: 0.12144745, mean(E): -21.68076860+0.00111266j, var(E): 0.95069294
-0.0
tensor(12.9641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6110/ 20000/ t/epoch=0.32............. Loss: 0.02437211, mean(E): -21.61012236+0.00431456j, var(E): 1.13856705
-0.0
tensor(12.9655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6120/ 20000/ t/epoch=0.32............. Loss: -0.61697050, mean(E): -21.45590308-0.00571566j, var(E): 1.29940786
-0.0
tensor(12.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6130/ 20000/ t/epoch=0.32............. Loss: -0.62454126, mean(E): -21.51734088+0.00292028j, var(E): 0.74618211
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6140/ 20000/ t/epoch=0.32............. Loss: -0.03043795, mean(E): -21.63733690-0.00969746j, var(E): 1.29561193
-0.0
tensor(12.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6150/ 20000/ t/epoch=0.32............. Loss: 0.02222298, mean(E): -21.60191520-0.00669906j, var(E): 1.31170797
-0.0
tensor(12.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6160/ 20000/ t/epoch=0.32............. Loss: 0.45787856, mean(E): -21.74606609-0.00264682j, var(E): 2.22220016
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6170/ 20000/ t/epoch=0.32............. Loss: -0.26925367, mean(E): -21.53336159+0.00198298j, var(E): 1.01373096
-0.0
tensor(12.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6180/ 20000/ t/epoch=0.32............. Loss: 0.25109860, mean(E): -21.65090072+0.00757170j, var(E): 1.07633956
-0.0
tensor(12.9683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6190/ 20000/ t/epoch=0.32............. Loss: -0.21899316, mean(E): -21.47289426+0.01386459j, var(E): 0.95606858
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6200/ 20000/ t/epoch=0.33............. Loss: -0.60053611, mean(E): -21.51636864-0.00512567j, var(E): 1.07036177
-0.0
tensor(12.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6210/ 20000/ t/epoch=0.32............. Loss: -0.25865268, mean(E): -21.58176720+0.00037698j, var(E): 0.91942504
-0.0
tensor(12.9698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6220/ 20000/ t/epoch=0.32............. Loss: -0.33498052, mean(E): -21.49566435-0.00154854j, var(E): 0.61490669
-0.0
tensor(12.9710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6230/ 20000/ t/epoch=0.32............. Loss: -0.91870525, mean(E): -21.43427651-0.01409597j, var(E): 1.48934786
-0.0
tensor(12.9729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6240/ 20000/ t/epoch=0.32............. Loss: 0.17383890, mean(E): -21.62838956+0.00261854j, var(E): 0.61077908
-0.0
tensor(12.9756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6250/ 20000/ t/epoch=0.32............. Loss: -0.46509648, mean(E): -21.53562273+0.00123560j, var(E): 1.04293317
-0.0
tensor(12.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6260/ 20000/ t/epoch=0.32............. Loss: -0.07311224, mean(E): -21.60609811-0.00004641j, var(E): 0.94218367
-0.0
tensor(12.9784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6270/ 20000/ t/epoch=0.32............. Loss: 0.18561455, mean(E): -21.67603699+0.01318639j, var(E): 1.23695381
-0.0
tensor(12.9800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6280/ 20000/ t/epoch=0.32............. Loss: 0.04619759, mean(E): -21.65675207+0.01401538j, var(E): 1.81029853
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6290/ 20000/ t/epoch=0.32............. Loss: 0.26713456, mean(E): -21.55045095+0.00202424j, var(E): 1.55958284
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6300/ 20000/ t/epoch=0.32............. Loss: -0.42384182, mean(E): -21.59101693+0.00221139j, var(E): 1.29828967
-0.0
tensor(12.9817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6310/ 20000/ t/epoch=0.32............. Loss: -0.75238833, mean(E): -21.45945028+0.00538762j, var(E): 1.15570459
-0.0
tensor(12.9833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6320/ 20000/ t/epoch=0.32............. Loss: 0.11471473, mean(E): -21.61122927+0.01415171j, var(E): 2.46428873
-0.0
tensor(12.9874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6330/ 20000/ t/epoch=0.32............. Loss: 0.52611419, mean(E): -21.75080581+0.00773927j, var(E): 0.80635883
-0.0
tensor(12.9909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6340/ 20000/ t/epoch=0.32............. Loss: -0.19439702, mean(E): -21.55975833-0.00978483j, var(E): 1.39114659
-0.0
tensor(12.9916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6350/ 20000/ t/epoch=0.32............. Loss: -0.18188874, mean(E): -21.61569577-0.01026185j, var(E): 1.26037968
-0.0
tensor(12.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6360/ 20000/ t/epoch=0.32............. Loss: -0.56095808, mean(E): -21.51061737+0.00236658j, var(E): 0.94714454
-0.0
tensor(12.9927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6370/ 20000/ t/epoch=0.32............. Loss: -0.35978768, mean(E): -21.48813710+0.01235017j, var(E): 0.58039380
-0.0
tensor(12.9948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6380/ 20000/ t/epoch=0.32............. Loss: 0.19657251, mean(E): -21.59784651+0.00764679j, var(E): 1.67208405
-0.0
tensor(12.9972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(12.9997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6390/ 20000/ t/epoch=0.32............. Loss: -0.21911273, mean(E): -21.56963745-0.00481667j, var(E): 0.82336656
-0.0
tensor(12.9999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6400/ 20000/ t/epoch=0.32............. Loss: 0.16583764, mean(E): -21.61304414-0.00195068j, var(E): 1.86593501
-0.0
tensor(13.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6410/ 20000/ t/epoch=0.33............. Loss: -0.56440546, mean(E): -21.55498078+0.00654327j, var(E): 0.93810338
-0.0
tensor(13.0010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6420/ 20000/ t/epoch=0.32............. Loss: -0.04116926, mean(E): -21.63506380+0.00898572j, var(E): 1.19778198
-0.0
tensor(13.0021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6430/ 20000/ t/epoch=0.32............. Loss: -0.09537844, mean(E): -21.64717939-0.00820243j, var(E): 1.27567529
-0.0
tensor(13.0048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6440/ 20000/ t/epoch=0.32............. Loss: 0.14371162, mean(E): -21.64826877-0.00010427j, var(E): 0.93155730
-0.0
tensor(13.0067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6450/ 20000/ t/epoch=0.32............. Loss: 0.05950675, mean(E): -21.64465574+0.00097132j, var(E): 0.76406107
-0.0
tensor(13.0087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6460/ 20000/ t/epoch=0.32............. Loss: -0.53262449, mean(E): -21.56863133-0.00031929j, var(E): 1.10038801
-0.0
tensor(13.0120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6470/ 20000/ t/epoch=0.33............. Loss: -0.48389522, mean(E): -21.48929699+0.00043950j, var(E): 0.85508502
-0.0
tensor(13.0143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6480/ 20000/ t/epoch=0.32............. Loss: -0.80062848, mean(E): -21.45500527+0.00559782j, var(E): 1.53984818
-0.0
tensor(13.0163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6490/ 20000/ t/epoch=0.32............. Loss: -0.21587722, mean(E): -21.54290548-0.00897058j, var(E): 2.64197378
-0.0
tensor(13.0178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6500/ 20000/ t/epoch=0.32............. Loss: -0.68347683, mean(E): -21.48184834-0.00301439j, var(E): 1.12951491
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6510/ 20000/ t/epoch=0.32............. Loss: 0.82767521, mean(E): -21.75887075-0.00288179j, var(E): 1.61920865
-0.0
tensor(13.0197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6520/ 20000/ t/epoch=0.32............. Loss: -0.23748380, mean(E): -21.55080168-0.00723053j, var(E): 1.16532635
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6530/ 20000/ t/epoch=0.33............. Loss: -0.41150498, mean(E): -21.56126499-0.00405570j, var(E): 0.77513445
-0.0
tensor(13.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6540/ 20000/ t/epoch=0.32............. Loss: -0.16592917, mean(E): -21.60651571-0.00589777j, var(E): 0.65297380
-0.0
tensor(13.0216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6550/ 20000/ t/epoch=0.32............. Loss: -0.00220629, mean(E): -21.64315343-0.00476047j, var(E): 1.36855414
-0.0
tensor(13.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6560/ 20000/ t/epoch=0.32............. Loss: 0.78146429, mean(E): -21.70075626-0.00440877j, var(E): 2.55586051
-0.0
tensor(13.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6570/ 20000/ t/epoch=0.32............. Loss: -0.08403014, mean(E): -21.60110780+0.00061798j, var(E): 0.92166333
-0.0
tensor(13.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6580/ 20000/ t/epoch=0.32............. Loss: -0.66383666, mean(E): -21.48444191-0.01122010j, var(E): 1.18414018
-0.0
tensor(13.0234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6590/ 20000/ t/epoch=0.32............. Loss: -0.92613436, mean(E): -21.51084046+0.00013572j, var(E): 1.23290838
-0.0
tensor(13.0248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6600/ 20000/ t/epoch=0.32............. Loss: -0.19379260, mean(E): -21.55335024+0.00476092j, var(E): 1.55975369
-0.0
tensor(13.0273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6610/ 20000/ t/epoch=0.32............. Loss: -0.81203031, mean(E): -21.50538141-0.00093984j, var(E): 1.39406297
-0.0
tensor(13.0290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6620/ 20000/ t/epoch=0.32............. Loss: 0.01331990, mean(E): -21.59183407-0.01157695j, var(E): 0.51473812
-0.0
tensor(13.0323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6630/ 20000/ t/epoch=0.32............. Loss: 0.38130380, mean(E): -21.65474550-0.01352870j, var(E): 1.76559810
-0.0
tensor(13.0348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6640/ 20000/ t/epoch=0.32............. Loss: -0.31904023, mean(E): -21.59231039+0.01322580j, var(E): 0.65994703
-0.0
tensor(13.0371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6650/ 20000/ t/epoch=0.32............. Loss: -0.23295515, mean(E): -21.60158156-0.00232872j, var(E): 0.50111791
-0.0
tensor(13.0402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6660/ 20000/ t/epoch=0.32............. Loss: -0.09634710, mean(E): -21.62894052+0.00396491j, var(E): 0.88742332
-0.0
tensor(13.0438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6670/ 20000/ t/epoch=0.32............. Loss: 0.00965961, mean(E): -21.61765337-0.00460026j, var(E): 1.45503498
-0.0
tensor(13.0472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6680/ 20000/ t/epoch=0.32............. Loss: -0.31447709, mean(E): -21.61512551-0.01481962j, var(E): 0.91748786
-0.0
tensor(13.0488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6690/ 20000/ t/epoch=0.32............. Loss: -0.09677513, mean(E): -21.60978010-0.00295523j, var(E): 1.00187840
-0.0
tensor(13.0505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6700/ 20000/ t/epoch=0.32............. Loss: -0.64149050, mean(E): -21.50585576-0.01370098j, var(E): 0.71865271
-0.0
tensor(13.0526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6710/ 20000/ t/epoch=0.32............. Loss: -0.23256317, mean(E): -21.59192877+0.00870822j, var(E): 0.62984200
-0.0
tensor(13.0549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6720/ 20000/ t/epoch=0.32............. Loss: -0.81344756, mean(E): -21.49794385-0.01059411j, var(E): 1.05859373
-0.0
tensor(13.0563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6730/ 20000/ t/epoch=0.32............. Loss: 0.24232528, mean(E): -21.68835483+0.00321410j, var(E): 0.79496692
-0.0
tensor(13.0581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6740/ 20000/ t/epoch=0.33............. Loss: -0.54938355, mean(E): -21.52846924+0.00637375j, var(E): 0.66752184
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6750/ 20000/ t/epoch=0.32............. Loss: -0.49436230, mean(E): -21.59415478+0.00512514j, var(E): 0.86659923
-0.0
tensor(13.0593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6760/ 20000/ t/epoch=0.32............. Loss: 0.70826029, mean(E): -21.73376372-0.00323998j, var(E): 1.69917680
-0.0
tensor(13.0600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6770/ 20000/ t/epoch=0.32............. Loss: 0.20090987, mean(E): -21.64219016-0.00779548j, var(E): 0.75980129
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6780/ 20000/ t/epoch=0.32............. Loss: 0.37041495, mean(E): -21.67963605+0.00097381j, var(E): 1.68676739
-0.0
tensor(13.0605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6790/ 20000/ t/epoch=0.32............. Loss: -0.37762330, mean(E): -21.55338212+0.00067149j, var(E): 0.69764957
-0.0
tensor(13.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6800/ 20000/ t/epoch=0.32............. Loss: 0.10007677, mean(E): -21.69574575+0.00625531j, var(E): 1.13700588
-0.0
tensor(13.0625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6810/ 20000/ t/epoch=0.32............. Loss: 0.26470402, mean(E): -21.59921591+0.00411037j, var(E): 1.55044444
-0.0
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6820/ 20000/ t/epoch=0.32............. Loss: -0.60148821, mean(E): -21.46368491+0.00386466j, var(E): 0.72223544
-0.0
tensor(13.0646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6830/ 20000/ t/epoch=0.33............. Loss: 0.44383476, mean(E): -21.65104960-0.00143223j, var(E): 1.52479665
-0.0
tensor(13.0674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6840/ 20000/ t/epoch=0.32............. Loss: -0.42667191, mean(E): -21.52488902-0.00589173j, var(E): 1.20883085
-0.0
tensor(13.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6850/ 20000/ t/epoch=0.32............. Loss: -0.71498616, mean(E): -21.46553885-0.00441047j, var(E): 0.92204738
-0.0
tensor(13.0712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6860/ 20000/ t/epoch=0.32............. Loss: 0.19199735, mean(E): -21.70286168+0.00378054j, var(E): 1.32743480
-0.0
tensor(13.0727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6870/ 20000/ t/epoch=0.32............. Loss: -0.19710355, mean(E): -21.57120417-0.01050802j, var(E): 1.06462916
-0.0
tensor(13.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6880/ 20000/ t/epoch=0.32............. Loss: 0.16287105, mean(E): -21.67648268+0.00736286j, var(E): 0.58030156
-0.0
tensor(13.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6890/ 20000/ t/epoch=0.32............. Loss: 0.20234990, mean(E): -21.66895182-0.00429061j, var(E): 0.58204702
-0.0
tensor(13.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6900/ 20000/ t/epoch=0.32............. Loss: 0.18624892, mean(E): -21.63977693-0.00144882j, var(E): 2.00493183
-0.0
tensor(13.0758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6910/ 20000/ t/epoch=0.32............. Loss: -0.13480240, mean(E): -21.55779107-0.00218939j, var(E): 1.81325997
-0.0
tensor(13.0769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6920/ 20000/ t/epoch=0.32............. Loss: -0.64053259, mean(E): -21.48944773+0.00454196j, var(E): 0.95560452
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6930/ 20000/ t/epoch=0.32............. Loss: -0.23962438, mean(E): -21.61293749-0.00479996j, var(E): 0.81959691
-0.0
tensor(13.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6940/ 20000/ t/epoch=0.32............. Loss: 0.47808707, mean(E): -21.66538927+0.01313036j, var(E): 1.47437363
-0.0
tensor(13.0781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6950/ 20000/ t/epoch=0.32............. Loss: 0.79339748, mean(E): -21.70684951+0.00008190j, var(E): 1.17970027
-0.0
tensor(13.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6960/ 20000/ t/epoch=0.32............. Loss: 0.16590799, mean(E): -21.67652710+0.00408777j, var(E): 1.44840358
-0.0
tensor(13.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6970/ 20000/ t/epoch=0.33............. Loss: -0.38316305, mean(E): -21.53928596+0.00180258j, var(E): 0.58622503
-0.0
tensor(13.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6980/ 20000/ t/epoch=0.32............. Loss: -0.71850146, mean(E): -21.49403886-0.00106989j, var(E): 1.25106756
-0.0
tensor(13.0854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 6990/ 20000/ t/epoch=0.32............. Loss: 0.18481441, mean(E): -21.66890265-0.00299336j, var(E): 1.05588619
-0.0
tensor(13.0863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7000/ 20000/ t/epoch=0.32............. Loss: 0.16702085, mean(E): -21.67826597-0.00762066j, var(E): 0.56561064
-0.0
tensor(13.0877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7010/ 20000/ t/epoch=0.32............. Loss: -0.02759586, mean(E): -21.53723368+0.00579254j, var(E): 1.87690585
-0.0
tensor(13.0900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7020/ 20000/ t/epoch=0.32............. Loss: 0.15518684, mean(E): -21.62281629+0.00177390j, var(E): 1.73200472
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7030/ 20000/ t/epoch=0.32............. Loss: 0.06655197, mean(E): -21.61166031-0.00060664j, var(E): 1.01592399
-0.0
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7040/ 20000/ t/epoch=0.32............. Loss: 0.14370480, mean(E): -21.65716389-0.00520907j, var(E): 0.67031623
-0.0
tensor(13.0915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7050/ 20000/ t/epoch=0.32............. Loss: -0.26738972, mean(E): -21.60529015+0.00494623j, var(E): 1.23386269
-0.0
tensor(13.0930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7060/ 20000/ t/epoch=0.32............. Loss: 0.27081067, mean(E): -21.72680806+0.00315703j, var(E): 1.43486984
-0.0
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7070/ 20000/ t/epoch=0.32............. Loss: 0.46831301, mean(E): -21.65918495+0.00005303j, var(E): 1.98136504
-0.0
tensor(13.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7080/ 20000/ t/epoch=0.32............. Loss: -0.13301112, mean(E): -21.58149161+0.00024994j, var(E): 0.76242843
-0.0
tensor(13.0958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7090/ 20000/ t/epoch=0.32............. Loss: -0.52532318, mean(E): -21.52535298+0.00862839j, var(E): 0.86667690
-0.0
tensor(13.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7100/ 20000/ t/epoch=0.32............. Loss: 0.90508673, mean(E): -21.73857794+0.00393488j, var(E): 1.92770676
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7110/ 20000/ t/epoch=0.32............. Loss: 0.39494403, mean(E): -21.71940346-0.00384060j, var(E): 2.23015127
-0.0
tensor(13.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7120/ 20000/ t/epoch=0.32............. Loss: -0.88093023, mean(E): -21.43542119-0.00080111j, var(E): 1.15474708
-0.0
tensor(13.0997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.0999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7130/ 20000/ t/epoch=0.32............. Loss: 0.33325772, mean(E): -21.69936510+0.00659873j, var(E): 0.79905879
-0.0
tensor(13.1014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7140/ 20000/ t/epoch=0.32............. Loss: 0.45509403, mean(E): -21.72637947-0.00113821j, var(E): 0.82241060
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7150/ 20000/ t/epoch=0.32............. Loss: 0.00337552, mean(E): -21.63409083+0.01414170j, var(E): 1.00892880
-0.0
tensor(13.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7160/ 20000/ t/epoch=0.32............. Loss: 0.57094810, mean(E): -21.64166554-0.00617322j, var(E): 1.52612373
-0.0
tensor(13.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7170/ 20000/ t/epoch=0.32............. Loss: 1.08067902, mean(E): -21.79082458-0.00685070j, var(E): 2.12487132
-0.0
tensor(13.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7180/ 20000/ t/epoch=0.32............. Loss: -0.23716113, mean(E): -21.60599661-0.00375901j, var(E): 0.65603577
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7190/ 20000/ t/epoch=0.32............. Loss: -0.19293116, mean(E): -21.53284838+0.00417798j, var(E): 0.86501556
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7200/ 20000/ t/epoch=0.32............. Loss: -0.42203073, mean(E): -21.57490452+0.00719068j, var(E): 0.76601017
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7210/ 20000/ t/epoch=0.32............. Loss: -0.28604544, mean(E): -21.59191053-0.01555451j, var(E): 0.76445013
-0.0
tensor(13.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7220/ 20000/ t/epoch=0.32............. Loss: 0.73967828, mean(E): -21.62243365-0.01485421j, var(E): 1.49881993
-0.0
tensor(13.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7230/ 20000/ t/epoch=0.32............. Loss: -0.43831527, mean(E): -21.57989485-0.00705748j, var(E): 1.63482120
-0.0
tensor(13.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7240/ 20000/ t/epoch=0.32............. Loss: 0.01795290, mean(E): -21.61330616-0.00513503j, var(E): 1.22020517
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7250/ 20000/ t/epoch=0.32............. Loss: 0.56142150, mean(E): -21.70481887-0.00379769j, var(E): 1.67197639
-0.0
tensor(13.1020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7260/ 20000/ t/epoch=0.32............. Loss: 0.52928818, mean(E): -21.76052023-0.00290622j, var(E): 1.57463287
-0.0
tensor(13.1032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7270/ 20000/ t/epoch=0.32............. Loss: 0.08650225, mean(E): -21.61510400-0.00500046j, var(E): 1.36428475
-0.0
tensor(13.1045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7280/ 20000/ t/epoch=0.32............. Loss: 0.39466334, mean(E): -21.75271580-0.00143732j, var(E): 1.48142241
-0.0
tensor(13.1070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7290/ 20000/ t/epoch=0.33............. Loss: 0.27476777, mean(E): -21.67999682-0.00236218j, var(E): 0.75403555
-0.0
tensor(13.1084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7300/ 20000/ t/epoch=0.32............. Loss: 0.21235458, mean(E): -21.64791635+0.00107246j, var(E): 1.17200689
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7310/ 20000/ t/epoch=0.32............. Loss: 0.34603016, mean(E): -21.68120746-0.00198071j, var(E): 1.61185533
-0.0
tensor(13.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7320/ 20000/ t/epoch=0.32............. Loss: -0.29161921, mean(E): -21.67046922-0.00077624j, var(E): 1.19713801
-0.0
tensor(13.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7330/ 20000/ t/epoch=0.32............. Loss: -0.18705157, mean(E): -21.60892933+0.00227661j, var(E): 1.33719545
-0.0
tensor(13.1095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7340/ 20000/ t/epoch=0.32............. Loss: -0.25109833, mean(E): -21.55084701+0.00168284j, var(E): 1.98361983
-0.0
tensor(13.1116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7350/ 20000/ t/epoch=0.32............. Loss: 0.16327536, mean(E): -21.71882682-0.00728181j, var(E): 1.52264603
-0.0
tensor(13.1135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7360/ 20000/ t/epoch=0.32............. Loss: -0.41027302, mean(E): -21.55289917+0.00448860j, var(E): 0.89111494
-0.0
tensor(13.1158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7370/ 20000/ t/epoch=0.32............. Loss: 0.09005889, mean(E): -21.65603653+0.00230835j, var(E): 0.90132270
-0.0
tensor(13.1174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7380/ 20000/ t/epoch=0.32............. Loss: -0.45209898, mean(E): -21.55431697+0.00249726j, var(E): 0.70248767
-0.0
tensor(13.1185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7390/ 20000/ t/epoch=0.32............. Loss: 0.31639814, mean(E): -21.65661427+0.00132244j, var(E): 1.59539765
-0.0
tensor(13.1194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7400/ 20000/ t/epoch=0.32............. Loss: -0.18179925, mean(E): -21.66792263-0.00168031j, var(E): 1.02413916
-0.0
tensor(13.1208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7410/ 20000/ t/epoch=0.32............. Loss: -0.49083788, mean(E): -21.52963516-0.00243580j, var(E): 1.28785576
-0.0
tensor(13.1225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7420/ 20000/ t/epoch=0.32............. Loss: -0.08161518, mean(E): -21.63722982+0.00188815j, var(E): 1.30614421
-0.0
tensor(13.1237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7430/ 20000/ t/epoch=0.32............. Loss: 0.28688305, mean(E): -21.65220518-0.00372873j, var(E): 0.80212815
-0.0
tensor(13.1241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7440/ 20000/ t/epoch=0.32............. Loss: -0.19295693, mean(E): -21.58972136-0.00850829j, var(E): 1.09100048
-0.0
tensor(13.1250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7450/ 20000/ t/epoch=0.32............. Loss: -0.19345025, mean(E): -21.56588085-0.00247986j, var(E): 0.79169279
-0.0
tensor(13.1272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7460/ 20000/ t/epoch=0.32............. Loss: -0.34530930, mean(E): -21.57199973-0.00803844j, var(E): 0.89100475
-0.0
tensor(13.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7470/ 20000/ t/epoch=0.32............. Loss: 0.36883974, mean(E): -21.67142328+0.00629757j, var(E): 1.03681545
-0.0
tensor(13.1299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7480/ 20000/ t/epoch=0.32............. Loss: -0.47407323, mean(E): -21.51157865-0.00191698j, var(E): 1.32705950
-0.0
tensor(13.1313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7490/ 20000/ t/epoch=0.32............. Loss: -0.09570223, mean(E): -21.59071288+0.00716224j, var(E): 1.01124196
-0.0
tensor(13.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7500/ 20000/ t/epoch=0.33............. Loss: -0.24782301, mean(E): -21.56676138-0.01061919j, var(E): 1.09746902
-0.0
tensor(13.1337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7510/ 20000/ t/epoch=0.32............. Loss: 0.33049833, mean(E): -21.65851138+0.00452500j, var(E): 1.43732046
-0.0
tensor(13.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7520/ 20000/ t/epoch=0.32............. Loss: 0.01721747, mean(E): -21.62361167+0.00749905j, var(E): 0.52758868
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7530/ 20000/ t/epoch=0.32............. Loss: -0.53602071, mean(E): -21.56875484+0.00550362j, var(E): 1.82915613
-0.0
tensor(13.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7540/ 20000/ t/epoch=0.32............. Loss: -0.54685420, mean(E): -21.58450488-0.01016532j, var(E): 0.92611589
-0.0
tensor(13.1350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7550/ 20000/ t/epoch=0.32............. Loss: 0.96825284, mean(E): -21.78285973-0.00903652j, var(E): 1.91402577
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7560/ 20000/ t/epoch=0.32............. Loss: -0.08833254, mean(E): -21.58946509-0.00308767j, var(E): 0.91706021
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7570/ 20000/ t/epoch=0.32............. Loss: 0.09829911, mean(E): -21.63112624+0.00179299j, var(E): 1.36844312
-0.0
tensor(13.1352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7580/ 20000/ t/epoch=0.32............. Loss: -0.55297155, mean(E): -21.51256005-0.00101961j, var(E): 1.02654090
-0.0
tensor(13.1364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7590/ 20000/ t/epoch=0.32............. Loss: 0.30581693, mean(E): -21.71121036-0.00264929j, var(E): 1.12013707
-0.0
tensor(13.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7600/ 20000/ t/epoch=0.33............. Loss: 0.36004366, mean(E): -21.68937210+0.00234265j, var(E): 0.99509924
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7610/ 20000/ t/epoch=0.32............. Loss: -0.72041334, mean(E): -21.47608807-0.01402788j, var(E): 1.15573200
-0.0
tensor(13.1372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7620/ 20000/ t/epoch=0.32............. Loss: -0.38940087, mean(E): -21.57200333+0.00578614j, var(E): 0.77362283
-0.0
tensor(13.1391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7630/ 20000/ t/epoch=0.32............. Loss: 0.26026251, mean(E): -21.60750177+0.00793555j, var(E): 1.10655929
-0.0
tensor(13.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7640/ 20000/ t/epoch=0.32............. Loss: -0.52624005, mean(E): -21.57291220-0.00106435j, var(E): 0.69589646
-0.0
tensor(13.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7650/ 20000/ t/epoch=0.32............. Loss: 0.84097554, mean(E): -21.75984241-0.00157704j, var(E): 2.36424926
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7660/ 20000/ t/epoch=0.32............. Loss: -0.04803599, mean(E): -21.62269215+0.00713724j, var(E): 1.72690618
-0.0
tensor(13.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7670/ 20000/ t/epoch=0.32............. Loss: -0.52120779, mean(E): -21.54508284-0.01106746j, var(E): 0.83510596
-0.0
tensor(13.1413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7680/ 20000/ t/epoch=0.32............. Loss: -0.68268569, mean(E): -21.55760868+0.00212460j, var(E): 1.41106506
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7690/ 20000/ t/epoch=0.32............. Loss: -0.09077990, mean(E): -21.60025095+0.00129454j, var(E): 0.83284895
-0.0
tensor(13.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7700/ 20000/ t/epoch=0.32............. Loss: 0.43807182, mean(E): -21.68330426+0.00643821j, var(E): 1.53000142
-0.0
tensor(13.1423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7710/ 20000/ t/epoch=0.33............. Loss: 0.59593473, mean(E): -21.70067850+0.00194875j, var(E): 1.27135911
-0.0
tensor(13.1438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7720/ 20000/ t/epoch=0.32............. Loss: -0.44740234, mean(E): -21.56036651-0.00055962j, var(E): 1.18300895
-0.0
tensor(13.1451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7730/ 20000/ t/epoch=0.32............. Loss: -0.60754123, mean(E): -21.52900391+0.00579019j, var(E): 0.68338304
-0.0
tensor(13.1464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7740/ 20000/ t/epoch=0.33............. Loss: -0.21204207, mean(E): -21.62359805-0.00456108j, var(E): 0.81197013
-0.0
tensor(13.1470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7750/ 20000/ t/epoch=0.32............. Loss: -0.20952705, mean(E): -21.57218053+0.00750566j, var(E): 1.05302749
-0.0
tensor(13.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7760/ 20000/ t/epoch=0.32............. Loss: 0.17794269, mean(E): -21.62062604+0.01297863j, var(E): 1.29047687
-0.0
tensor(13.1484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7770/ 20000/ t/epoch=0.32............. Loss: -0.48545679, mean(E): -21.58510133+0.00319279j, var(E): 1.04328034
-0.0
tensor(13.1498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7780/ 20000/ t/epoch=0.32............. Loss: 0.26509414, mean(E): -21.64647138-0.00217478j, var(E): 1.14105706
-0.0
tensor(13.1522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7790/ 20000/ t/epoch=0.32............. Loss: -0.27167774, mean(E): -21.64934061-0.00543129j, var(E): 1.03245779
-0.0
tensor(13.1536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7800/ 20000/ t/epoch=0.32............. Loss: -0.16985827, mean(E): -21.60109209-0.00193662j, var(E): 0.99217244
-0.0
tensor(13.1545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7810/ 20000/ t/epoch=0.32............. Loss: 0.40605606, mean(E): -21.70708276+0.00169367j, var(E): 1.08965376
-0.0
tensor(13.1560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7820/ 20000/ t/epoch=0.32............. Loss: -0.31440850, mean(E): -21.51713022+0.00429154j, var(E): 0.96848673
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7830/ 20000/ t/epoch=0.32............. Loss: -0.47450962, mean(E): -21.52253583-0.00237255j, var(E): 0.50044752
-0.0
tensor(13.1574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7840/ 20000/ t/epoch=0.32............. Loss: -0.02423608, mean(E): -21.62574039-0.00322032j, var(E): 1.08053979
-0.0
tensor(13.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7850/ 20000/ t/epoch=0.32............. Loss: 0.37827649, mean(E): -21.69251321-0.00789087j, var(E): 1.63008568
-0.0
tensor(13.1591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7860/ 20000/ t/epoch=0.32............. Loss: -0.11726514, mean(E): -21.62815579-0.00023733j, var(E): 0.71211495
-0.0
tensor(13.1604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7870/ 20000/ t/epoch=0.32............. Loss: -0.00769259, mean(E): -21.58568698-0.00090876j, var(E): 1.46098019
-0.0
tensor(13.1628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7880/ 20000/ t/epoch=0.32............. Loss: 0.11657689, mean(E): -21.62797725-0.00004657j, var(E): 1.85231668
-0.0
tensor(13.1634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7890/ 20000/ t/epoch=0.32............. Loss: 0.53918494, mean(E): -21.73275545-0.00613817j, var(E): 0.90066207
-0.0
tensor(13.1649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7900/ 20000/ t/epoch=0.33............. Loss: 0.26663570, mean(E): -21.67914776-0.01164777j, var(E): 0.92865506
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7910/ 20000/ t/epoch=0.32............. Loss: -0.55639042, mean(E): -21.53798244-0.00519452j, var(E): 1.50260667
-0.0
tensor(13.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7920/ 20000/ t/epoch=0.32............. Loss: 0.69264335, mean(E): -21.75505050-0.00212248j, var(E): 1.63541486
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7930/ 20000/ t/epoch=0.32............. Loss: -0.95030565, mean(E): -21.52674447-0.00246500j, var(E): 1.58944799
-0.0
tensor(13.1665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7940/ 20000/ t/epoch=0.32............. Loss: 0.37194449, mean(E): -21.66996945+0.00828634j, var(E): 1.85045982
-0.0
tensor(13.1683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7950/ 20000/ t/epoch=0.32............. Loss: -0.36801441, mean(E): -21.55431510+0.01419731j, var(E): 1.12548271
-0.0
tensor(13.1706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7960/ 20000/ t/epoch=0.32............. Loss: -0.46634124, mean(E): -21.57125382-0.00194381j, var(E): 0.59565815
-0.0
tensor(13.1719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7970/ 20000/ t/epoch=0.32............. Loss: -0.38186588, mean(E): -21.57509093-0.00250560j, var(E): 0.78646547
-0.0
tensor(13.1734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7980/ 20000/ t/epoch=0.32............. Loss: -0.42520907, mean(E): -21.58570012+0.00999512j, var(E): 0.88940089
-0.0
tensor(13.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 7990/ 20000/ t/epoch=0.32............. Loss: -0.11232258, mean(E): -21.58975828+0.00730636j, var(E): 0.37755178
-0.0
tensor(13.1763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8000/ 20000/ t/epoch=0.32............. Loss: -0.39620289, mean(E): -21.54860759+0.00142682j, var(E): 3.01875378
-0.0
tensor(13.1780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8010/ 20000/ t/epoch=0.32............. Loss: -0.26143939, mean(E): -21.65807199+0.00936579j, var(E): 0.50748351
-0.0
tensor(13.1793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8020/ 20000/ t/epoch=0.32............. Loss: 0.97129173, mean(E): -21.82192754-0.00465249j, var(E): 1.69893576
-0.0
tensor(13.1804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8030/ 20000/ t/epoch=0.32............. Loss: -0.44049949, mean(E): -21.53003857-0.00986080j, var(E): 0.79144246
-0.0
tensor(13.1822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8040/ 20000/ t/epoch=0.32............. Loss: 0.10257423, mean(E): -21.66451203+0.00221026j, var(E): 1.19410260
-0.0
tensor(13.1848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8050/ 20000/ t/epoch=0.32............. Loss: -0.34166287, mean(E): -21.58075636-0.00276381j, var(E): 0.41775040
-0.0
tensor(13.1858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8060/ 20000/ t/epoch=0.32............. Loss: -0.31454538, mean(E): -21.58646935+0.00517952j, var(E): 1.02584963
-0.0
tensor(13.1873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8070/ 20000/ t/epoch=0.32............. Loss: 0.74564028, mean(E): -21.76481646+0.00026034j, var(E): 1.45698595
-0.0
tensor(13.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8080/ 20000/ t/epoch=0.32............. Loss: -0.44059725, mean(E): -21.51116285+0.00305569j, var(E): 0.72020171
-0.0
tensor(13.1876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8090/ 20000/ t/epoch=0.32............. Loss: 0.16753525, mean(E): -21.71578256-0.00169034j, var(E): 1.23123545
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8100/ 20000/ t/epoch=0.32............. Loss: -0.22100734, mean(E): -21.67678476-0.00394067j, var(E): 1.21958203
-0.0
tensor(13.1893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8110/ 20000/ t/epoch=0.32............. Loss: -0.16403597, mean(E): -21.56276434-0.00294294j, var(E): 0.95700765
-0.0
tensor(13.1902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8120/ 20000/ t/epoch=0.32............. Loss: 0.21806240, mean(E): -21.67440525-0.00238494j, var(E): 0.76495965
-0.0
tensor(13.1915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8130/ 20000/ t/epoch=0.32............. Loss: -0.25706922, mean(E): -21.61625393+0.00612023j, var(E): 0.85061540
-0.0
tensor(13.1928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8140/ 20000/ t/epoch=0.32............. Loss: -0.12484162, mean(E): -21.58612343-0.00362663j, var(E): 1.24580258
-0.0
tensor(13.1938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8150/ 20000/ t/epoch=0.32............. Loss: -0.60998166, mean(E): -21.54514043-0.00275403j, var(E): 0.95395363
-0.0
tensor(13.1955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8160/ 20000/ t/epoch=0.32............. Loss: -0.38781150, mean(E): -21.55642665-0.00360935j, var(E): 0.74512406
-0.0
tensor(13.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8170/ 20000/ t/epoch=0.32............. Loss: 0.82460519, mean(E): -21.75916815+0.00395607j, var(E): 1.06888134
-0.0
tensor(13.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8180/ 20000/ t/epoch=0.33............. Loss: -0.40696629, mean(E): -21.57071654-0.01014424j, var(E): 1.31626717
-0.0
tensor(13.1985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8190/ 20000/ t/epoch=0.32............. Loss: -0.07312283, mean(E): -21.61006202-0.00914956j, var(E): 1.04539259
-0.0
tensor(13.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8200/ 20000/ t/epoch=0.32............. Loss: 0.66473058, mean(E): -21.69833840-0.00824730j, var(E): 1.12792112
-0.0
tensor(13.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.1999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8210/ 20000/ t/epoch=0.32............. Loss: -0.40978878, mean(E): -21.60263277-0.00354008j, var(E): 1.07522094
-0.0
tensor(13.2000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8220/ 20000/ t/epoch=0.32............. Loss: 0.23219016, mean(E): -21.65520387+0.00142936j, var(E): 1.01867366
-0.0
tensor(13.2010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8230/ 20000/ t/epoch=0.32............. Loss: 0.12220684, mean(E): -21.63345446-0.00415253j, var(E): 0.79301293
-0.0
tensor(13.2026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8240/ 20000/ t/epoch=0.32............. Loss: 0.16885206, mean(E): -21.71062102+0.00320473j, var(E): 0.52614036
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8250/ 20000/ t/epoch=0.32............. Loss: -0.28276578, mean(E): -21.60574346-0.00074014j, var(E): 0.50064709
-0.0
tensor(13.2039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8260/ 20000/ t/epoch=0.32............. Loss: -0.32150777, mean(E): -21.62243674+0.00670397j, var(E): 0.68726274
-0.0
tensor(13.2053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8270/ 20000/ t/epoch=0.32............. Loss: -0.49391263, mean(E): -21.59596481-0.00313181j, var(E): 0.57007431
-0.0
tensor(13.2065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8280/ 20000/ t/epoch=0.32............. Loss: -0.16934392, mean(E): -21.60477105+0.00365658j, var(E): 0.84219892
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8290/ 20000/ t/epoch=0.32............. Loss: 0.54241666, mean(E): -21.68167992-0.00353642j, var(E): 2.18627094
-0.0
tensor(13.2067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8300/ 20000/ t/epoch=0.32............. Loss: -0.35615188, mean(E): -21.58520488+0.00557508j, var(E): 0.78435851
-0.0
tensor(13.2079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8310/ 20000/ t/epoch=0.33............. Loss: 0.86296833, mean(E): -21.78095309-0.00661560j, var(E): 1.81812137
-0.0
tensor(13.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8320/ 20000/ t/epoch=0.32............. Loss: 0.36494379, mean(E): -21.72659951+0.00768287j, var(E): 0.78542723
-0.0
tensor(13.2096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8330/ 20000/ t/epoch=0.32............. Loss: -0.09953345, mean(E): -21.52117208+0.00105387j, var(E): 1.57540481
-0.0
tensor(13.2107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8340/ 20000/ t/epoch=0.32............. Loss: 0.29266301, mean(E): -21.69320549-0.00315925j, var(E): 1.29743969
-0.0
tensor(13.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8350/ 20000/ t/epoch=0.32............. Loss: 0.51229739, mean(E): -21.70169061-0.00193644j, var(E): 0.93462249
-0.0
tensor(13.2132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8360/ 20000/ t/epoch=0.32............. Loss: 0.21049192, mean(E): -21.64934632+0.00568199j, var(E): 1.08972533
-0.0
tensor(13.2148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8370/ 20000/ t/epoch=0.32............. Loss: 0.27738880, mean(E): -21.68317257+0.00588186j, var(E): 0.90646170
-0.0
tensor(13.2163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8380/ 20000/ t/epoch=0.32............. Loss: 0.37047344, mean(E): -21.65153909-0.00226861j, var(E): 1.70463211
-0.0
tensor(13.2177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8390/ 20000/ t/epoch=0.33............. Loss: 0.03817445, mean(E): -21.66997570+0.00577876j, var(E): 1.44346386
-0.0
tensor(13.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8400/ 20000/ t/epoch=0.32............. Loss: -0.14359325, mean(E): -21.61865236-0.00661120j, var(E): 0.90755023
-0.0
tensor(13.2204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8410/ 20000/ t/epoch=0.32............. Loss: 0.56995983, mean(E): -21.73595747+0.00105065j, var(E): 0.59261142
-0.0
tensor(13.2217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8420/ 20000/ t/epoch=0.32............. Loss: -0.17093047, mean(E): -21.56163829-0.00185147j, var(E): 1.63401127
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8430/ 20000/ t/epoch=0.32............. Loss: 0.10151999, mean(E): -21.62255953+0.00335816j, var(E): 1.29457897
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8440/ 20000/ t/epoch=0.32............. Loss: -0.04922266, mean(E): -21.66145337-0.00052864j, var(E): 1.10412043
-0.0
tensor(13.2235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8450/ 20000/ t/epoch=0.32............. Loss: -0.48866066, mean(E): -21.60564584+0.00112416j, var(E): 0.86635330
-0.0
tensor(13.2250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8460/ 20000/ t/epoch=0.32............. Loss: -0.26477902, mean(E): -21.62300003+0.00412175j, var(E): 0.62991080
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8470/ 20000/ t/epoch=0.32............. Loss: -0.37858823, mean(E): -21.59069869-0.00030653j, var(E): 1.15825310
-0.0
tensor(13.2258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8480/ 20000/ t/epoch=0.32............. Loss: -0.74041544, mean(E): -21.49435730-0.00178760j, var(E): 1.16360958
-0.0
tensor(13.2264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8490/ 20000/ t/epoch=0.32............. Loss: -0.78753039, mean(E): -21.49554889-0.00622948j, var(E): 0.91488834
-0.0
tensor(13.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8500/ 20000/ t/epoch=0.32............. Loss: 0.13745271, mean(E): -21.59996112-0.00269719j, var(E): 1.02685313
-0.0
tensor(13.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8510/ 20000/ t/epoch=0.33............. Loss: -0.47760483, mean(E): -21.51106095+0.00385880j, var(E): 1.64069299
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8520/ 20000/ t/epoch=0.32............. Loss: 0.29932493, mean(E): -21.69860511-0.01459470j, var(E): 1.87496553
-0.0
tensor(13.2291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8530/ 20000/ t/epoch=0.32............. Loss: -0.50272489, mean(E): -21.59388025-0.00627462j, var(E): 1.02376557
-0.0
tensor(13.2306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8540/ 20000/ t/epoch=0.32............. Loss: -0.57621105, mean(E): -21.55978425+0.00709786j, var(E): 1.86053543
-0.0
tensor(13.2322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8550/ 20000/ t/epoch=0.32............. Loss: -0.25826443, mean(E): -21.62926457-0.00322168j, var(E): 1.02976065
-0.0
tensor(13.2338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8560/ 20000/ t/epoch=0.32............. Loss: -0.10577321, mean(E): -21.63561258+0.00291778j, var(E): 0.78700967
-0.0
tensor(13.2352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8570/ 20000/ t/epoch=0.32............. Loss: 0.14881951, mean(E): -21.70733110-0.00124017j, var(E): 0.78005719
-0.0
tensor(13.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8580/ 20000/ t/epoch=0.32............. Loss: 0.42059082, mean(E): -21.70009154-0.00160912j, var(E): 0.93656919
-0.0
tensor(13.2363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8590/ 20000/ t/epoch=0.32............. Loss: 0.44533989, mean(E): -21.66361077-0.00844037j, var(E): 0.74792616
-0.0
tensor(13.2369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8600/ 20000/ t/epoch=0.32............. Loss: -0.00307112, mean(E): -21.65134207+0.00278706j, var(E): 0.76093102
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8610/ 20000/ t/epoch=0.32............. Loss: -0.08786068, mean(E): -21.58934780+0.00066958j, var(E): 0.48963214
-0.0
tensor(13.2393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8620/ 20000/ t/epoch=0.32............. Loss: 0.17790322, mean(E): -21.69025942-0.00758124j, var(E): 1.58492918
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8630/ 20000/ t/epoch=0.32............. Loss: -0.27256575, mean(E): -21.56408083+0.00834749j, var(E): 1.08828422
-0.0
tensor(13.2402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8640/ 20000/ t/epoch=0.32............. Loss: -0.49201308, mean(E): -21.52984446-0.00319614j, var(E): 0.69919226
-0.0
tensor(13.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8650/ 20000/ t/epoch=0.32............. Loss: -0.08542522, mean(E): -21.60345794-0.00401431j, var(E): 0.90194549
-0.0
tensor(13.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8660/ 20000/ t/epoch=0.32............. Loss: -0.63235770, mean(E): -21.57524440-0.00367944j, var(E): 0.96339398
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8670/ 20000/ t/epoch=0.32............. Loss: 0.03459212, mean(E): -21.66575918+0.00682443j, var(E): 0.59277217
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8680/ 20000/ t/epoch=0.32............. Loss: -0.23862078, mean(E): -21.58916435-0.00006929j, var(E): 0.86690717
-0.0
tensor(13.2412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8690/ 20000/ t/epoch=0.32............. Loss: 0.18919011, mean(E): -21.68540532-0.00003210j, var(E): 0.86023754
-0.0
tensor(13.2439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8700/ 20000/ t/epoch=0.32............. Loss: 0.53112987, mean(E): -21.73803261+0.00038500j, var(E): 1.52942725
-0.0
tensor(13.2461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8710/ 20000/ t/epoch=0.32............. Loss: -0.15819699, mean(E): -21.64968995+0.00117654j, var(E): 1.09678703
-0.0
tensor(13.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8720/ 20000/ t/epoch=0.32............. Loss: -0.20146421, mean(E): -21.56174312-0.00134898j, var(E): 0.59259279
-0.0
tensor(13.2471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8730/ 20000/ t/epoch=0.32............. Loss: 0.02235628, mean(E): -21.60558140-0.00482915j, var(E): 0.69203186
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8740/ 20000/ t/epoch=0.32............. Loss: 0.27261356, mean(E): -21.72892421+0.00771086j, var(E): 0.66279016
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8750/ 20000/ t/epoch=0.32............. Loss: 0.05119803, mean(E): -21.62933243-0.00447279j, var(E): 0.48408306
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8760/ 20000/ t/epoch=0.32............. Loss: -0.31126199, mean(E): -21.60076497+0.00430786j, var(E): 0.64509753
-0.0
tensor(13.2477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8770/ 20000/ t/epoch=0.32............. Loss: -0.63632458, mean(E): -21.60246926+0.00641753j, var(E): 1.17301294
-0.0
tensor(13.2485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8780/ 20000/ t/epoch=0.32............. Loss: -0.22939388, mean(E): -21.59798259+0.00581514j, var(E): 2.32909801
-0.0
tensor(13.2499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8790/ 20000/ t/epoch=0.32............. Loss: -0.15771586, mean(E): -21.62061077-0.00147236j, var(E): 0.64034269
-0.0
tensor(13.2519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8800/ 20000/ t/epoch=0.33............. Loss: -0.20694882, mean(E): -21.67271757+0.00401573j, var(E): 0.73795746
-0.0
tensor(13.2536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8810/ 20000/ t/epoch=0.32............. Loss: 0.39581836, mean(E): -21.73621625-0.00246824j, var(E): 1.20827110
-0.0
tensor(13.2556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8820/ 20000/ t/epoch=0.32............. Loss: 0.02553987, mean(E): -21.70340684+0.00008662j, var(E): 0.77627508
-0.0
tensor(13.2571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8830/ 20000/ t/epoch=0.32............. Loss: -0.09326445, mean(E): -21.66879798-0.00342139j, var(E): 0.61654273
-0.0
tensor(13.2585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8840/ 20000/ t/epoch=0.32............. Loss: -0.03150720, mean(E): -21.63083517-0.00700407j, var(E): 0.63287187
-0.0
tensor(13.2598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8850/ 20000/ t/epoch=0.32............. Loss: 1.78963650, mean(E): -21.74256523-0.00250787j, var(E): 9.08870445
-0.0
tensor(13.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8860/ 20000/ t/epoch=0.32............. Loss: -0.00698045, mean(E): -21.61308249+0.00195891j, var(E): 0.99439423
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8870/ 20000/ t/epoch=0.32............. Loss: 0.69285055, mean(E): -21.77765361-0.00280498j, var(E): 0.87182103
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8880/ 20000/ t/epoch=0.32............. Loss: -0.06798837, mean(E): -21.60929283-0.00360574j, var(E): 0.94312555
-0.0
tensor(13.2606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8890/ 20000/ t/epoch=0.32............. Loss: 1.02571942, mean(E): -21.74243234-0.00671538j, var(E): 1.71580031
-0.0
tensor(13.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8900/ 20000/ t/epoch=0.32............. Loss: -0.92242724, mean(E): -21.45837738+0.00405164j, var(E): 1.13883606
-0.0
tensor(13.2630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8910/ 20000/ t/epoch=0.32............. Loss: -0.20160709, mean(E): -21.60570233-0.00664441j, var(E): 1.26806476
-0.0
tensor(13.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8920/ 20000/ t/epoch=0.32............. Loss: -0.49953978, mean(E): -21.53369605+0.00805330j, var(E): 0.77700163
-0.0
tensor(13.2656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8930/ 20000/ t/epoch=0.32............. Loss: 0.44965209, mean(E): -21.69751730-0.00257785j, var(E): 1.69956505
-0.0
tensor(13.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8940/ 20000/ t/epoch=0.32............. Loss: 0.02493139, mean(E): -21.68512158+0.00249341j, var(E): 1.25901916
-0.0
tensor(13.2666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8950/ 20000/ t/epoch=0.33............. Loss: -0.09001147, mean(E): -21.68803323-0.00204630j, var(E): 0.85919768
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8960/ 20000/ t/epoch=0.32............. Loss: -0.36972710, mean(E): -21.62433534-0.00431105j, var(E): 0.63959064
-0.0
tensor(13.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8970/ 20000/ t/epoch=0.32............. Loss: 0.53468745, mean(E): -21.64071155-0.00069402j, var(E): 2.84042363
-0.0
tensor(13.2683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8980/ 20000/ t/epoch=0.32............. Loss: -0.69687975, mean(E): -21.54033657-0.00055003j, var(E): 1.44277542
-0.0
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 8990/ 20000/ t/epoch=0.32............. Loss: 0.26002103, mean(E): -21.68739733+0.00381227j, var(E): 1.53054308
-0.0
tensor(13.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9000/ 20000/ t/epoch=0.32............. Loss: 0.20429134, mean(E): -21.69168359+0.00421832j, var(E): 1.33989979
-0.0
tensor(13.2709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9010/ 20000/ t/epoch=0.32............. Loss: 0.11545595, mean(E): -21.65324086-0.00716404j, var(E): 0.60129039
-0.0
tensor(13.2722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9020/ 20000/ t/epoch=0.32............. Loss: -0.26656815, mean(E): -21.64064202+0.00277080j, var(E): 0.65815137
-0.0
tensor(13.2729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9030/ 20000/ t/epoch=0.32............. Loss: 0.17086568, mean(E): -21.65715306+0.00244235j, var(E): 0.80577910
-0.0
tensor(13.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9040/ 20000/ t/epoch=0.32............. Loss: -0.17700211, mean(E): -21.58386030+0.00502661j, var(E): 0.64979316
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9050/ 20000/ t/epoch=0.32............. Loss: 0.24617293, mean(E): -21.70865544-0.00500492j, var(E): 1.17013499
-0.0
tensor(13.2743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9060/ 20000/ t/epoch=0.33............. Loss: 0.28440809, mean(E): -21.67833919+0.00043819j, var(E): 0.72740399
-0.0
tensor(13.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9070/ 20000/ t/epoch=0.32............. Loss: 1.00918419, mean(E): -21.77722725+0.00260668j, var(E): 1.28815771
-0.0
tensor(13.2758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9080/ 20000/ t/epoch=0.32............. Loss: -0.27442135, mean(E): -21.57139481-0.00718554j, var(E): 0.73763536
-0.0
tensor(13.2759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9090/ 20000/ t/epoch=0.32............. Loss: 0.44376403, mean(E): -21.69007945-0.00102793j, var(E): 1.39073112
-0.0
tensor(13.2777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9100/ 20000/ t/epoch=0.32............. Loss: -0.41892706, mean(E): -21.56219040-0.00455984j, var(E): 0.76182280
-0.0
tensor(13.2805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9110/ 20000/ t/epoch=0.32............. Loss: -0.17580346, mean(E): -21.64673035-0.00236343j, var(E): 0.89549339
-0.0
tensor(13.2833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9120/ 20000/ t/epoch=0.32............. Loss: -0.12051484, mean(E): -21.62688421+0.00182025j, var(E): 0.76996767
-0.0
tensor(13.2851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9130/ 20000/ t/epoch=0.32............. Loss: 0.35560775, mean(E): -21.67684607+0.00074994j, var(E): 1.56835322
-0.0
tensor(13.2872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9140/ 20000/ t/epoch=0.32............. Loss: 0.41656133, mean(E): -21.69137223-0.00731393j, var(E): 2.22484037
-0.0
tensor(13.2892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9150/ 20000/ t/epoch=0.33............. Loss: -0.19026076, mean(E): -21.57653735-0.00007644j, var(E): 0.81341833
-0.0
tensor(13.2906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9160/ 20000/ t/epoch=0.32............. Loss: -0.16808422, mean(E): -21.61962037+0.00025151j, var(E): 1.71487763
-0.0
tensor(13.2922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9170/ 20000/ t/epoch=0.32............. Loss: -0.45732570, mean(E): -21.55903512-0.00165670j, var(E): 0.55634690
-0.0
tensor(13.2936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9180/ 20000/ t/epoch=0.32............. Loss: -0.45343870, mean(E): -21.51932633-0.00367978j, var(E): 0.68234053
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9190/ 20000/ t/epoch=0.32............. Loss: -0.24364917, mean(E): -21.60660588-0.00330446j, var(E): 1.70531146
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9200/ 20000/ t/epoch=0.33............. Loss: 0.30162216, mean(E): -21.71579683+0.00069428j, var(E): 0.57283749
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9210/ 20000/ t/epoch=0.32............. Loss: -0.46493089, mean(E): -21.56750015-0.00103806j, var(E): 1.15732510
-0.0
tensor(13.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9220/ 20000/ t/epoch=0.32............. Loss: 0.21045344, mean(E): -21.70541117-0.00287440j, var(E): 0.46053761
-0.0
tensor(13.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9230/ 20000/ t/epoch=0.32............. Loss: 0.20066075, mean(E): -21.64694457+0.00217457j, var(E): 1.43238936
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9240/ 20000/ t/epoch=0.32............. Loss: -0.46673153, mean(E): -21.61007584-0.00598136j, var(E): 0.99330679
-0.0
tensor(13.2959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9250/ 20000/ t/epoch=0.32............. Loss: -0.11966547, mean(E): -21.62098777+0.00256102j, var(E): 1.64335143
-0.0
tensor(13.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9260/ 20000/ t/epoch=0.32............. Loss: -0.10258143, mean(E): -21.62750339+0.00358613j, var(E): 1.33556922
-0.0
tensor(13.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9270/ 20000/ t/epoch=0.32............. Loss: -0.13198679, mean(E): -21.65554443+0.00307453j, var(E): 0.89274104
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9280/ 20000/ t/epoch=0.32............. Loss: -0.25705385, mean(E): -21.59910375+0.00412618j, var(E): 0.77206512
-0.0
tensor(13.2970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9290/ 20000/ t/epoch=0.32............. Loss: -0.01084594, mean(E): -21.69041583-0.00104839j, var(E): 0.68129363
-0.0
tensor(13.2984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.2998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9300/ 20000/ t/epoch=0.32............. Loss: -0.57882606, mean(E): -21.55209032-0.00055945j, var(E): 1.04319950
-0.0
tensor(13.2999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9310/ 20000/ t/epoch=0.32............. Loss: -0.11388001, mean(E): -21.63746693+0.00728909j, var(E): 0.81628304
-0.0
tensor(13.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9320/ 20000/ t/epoch=0.32............. Loss: -0.11936479, mean(E): -21.62931221-0.00198651j, var(E): 0.85652134
-0.0
tensor(13.3016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9330/ 20000/ t/epoch=0.32............. Loss: -0.11905855, mean(E): -21.63524895-0.00417091j, var(E): 0.72093530
-0.0
tensor(13.3028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9340/ 20000/ t/epoch=0.32............. Loss: 0.77334455, mean(E): -21.78957979-0.00045961j, var(E): 1.42429317
-0.0
tensor(13.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9350/ 20000/ t/epoch=0.32............. Loss: -0.18974689, mean(E): -21.59410354+0.00009809j, var(E): 1.30239944
-0.0
tensor(13.3041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9360/ 20000/ t/epoch=0.32............. Loss: -0.42856331, mean(E): -21.55169687-0.00160899j, var(E): 0.53884198
-0.0
tensor(13.3044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9370/ 20000/ t/epoch=0.32............. Loss: -0.23024561, mean(E): -21.66779621+0.00156653j, var(E): 0.92481803
-0.0
tensor(13.3060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9380/ 20000/ t/epoch=0.32............. Loss: -0.29427111, mean(E): -21.62501568-0.00206114j, var(E): 0.74822684
-0.0
tensor(13.3075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9390/ 20000/ t/epoch=0.33............. Loss: 0.59176741, mean(E): -21.72550085+0.00045641j, var(E): 1.47585393
-0.0
tensor(13.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9400/ 20000/ t/epoch=0.32............. Loss: -0.24688837, mean(E): -21.61270679-0.00616838j, var(E): 0.78879697
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9410/ 20000/ t/epoch=0.32............. Loss: 0.18819141, mean(E): -21.63398466-0.00384975j, var(E): 1.28057846
-0.0
tensor(13.3100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9420/ 20000/ t/epoch=0.32............. Loss: -0.46310271, mean(E): -21.54635437+0.00564905j, var(E): 1.52111958
-0.0
tensor(13.3113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9430/ 20000/ t/epoch=0.32............. Loss: -0.51379554, mean(E): -21.53226433+0.00208835j, var(E): 1.02591507
-0.0
tensor(13.3120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9440/ 20000/ t/epoch=0.32............. Loss: 1.41116939, mean(E): -21.77129497+0.00336516j, var(E): 3.97767244
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9450/ 20000/ t/epoch=0.32............. Loss: 0.64070188, mean(E): -21.74499060+0.00197268j, var(E): 1.74052435
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9460/ 20000/ t/epoch=0.32............. Loss: -0.25834876, mean(E): -21.60577173-0.00255481j, var(E): 1.13390163
-0.0
tensor(13.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9470/ 20000/ t/epoch=0.32............. Loss: -0.40961241, mean(E): -21.47519155-0.00118458j, var(E): 1.37123893
-0.0
tensor(13.3133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9480/ 20000/ t/epoch=0.32............. Loss: 0.11655052, mean(E): -21.69689306+0.00403873j, var(E): 1.32394359
-0.0
tensor(13.3149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9490/ 20000/ t/epoch=0.32............. Loss: -0.27611097, mean(E): -21.58088903+0.00026741j, var(E): 0.57337363
-0.0
tensor(13.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9500/ 20000/ t/epoch=0.32............. Loss: -0.26276348, mean(E): -21.57065122-0.00581698j, var(E): 0.68786413
-0.0
tensor(13.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9510/ 20000/ t/epoch=0.32............. Loss: 0.05677685, mean(E): -21.64780844-0.00023524j, var(E): 1.15153767
-0.0
tensor(13.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9520/ 20000/ t/epoch=0.32............. Loss: 0.60048311, mean(E): -21.74216200+0.00298895j, var(E): 1.54309495
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9530/ 20000/ t/epoch=0.32............. Loss: -0.31238264, mean(E): -21.63530803-0.00067705j, var(E): 0.71631827
-0.0
tensor(13.3170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9540/ 20000/ t/epoch=0.32............. Loss: -0.31463117, mean(E): -21.59457961-0.00355568j, var(E): 0.97578344
-0.0
tensor(13.3177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9550/ 20000/ t/epoch=0.32............. Loss: -0.49844599, mean(E): -21.58022351+0.00129611j, var(E): 0.83920629
-0.0
tensor(13.3195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9560/ 20000/ t/epoch=0.32............. Loss: -0.76066171, mean(E): -21.49078628-0.00079087j, var(E): 0.82897874
-0.0
tensor(13.3212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9570/ 20000/ t/epoch=0.32............. Loss: -0.17783087, mean(E): -21.60718301-0.00023809j, var(E): 0.94453519
-0.0
tensor(13.3221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9580/ 20000/ t/epoch=0.32............. Loss: 0.17242185, mean(E): -21.66890335-0.00385357j, var(E): 0.56715573
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9590/ 20000/ t/epoch=0.32............. Loss: 0.11179685, mean(E): -21.68657371-0.00219733j, var(E): 1.56947341
-0.0
tensor(13.3232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9600/ 20000/ t/epoch=0.32............. Loss: -0.22288612, mean(E): -21.64477911-0.00035384j, var(E): 0.87181658
-0.0
tensor(13.3242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9610/ 20000/ t/epoch=0.32............. Loss: 0.07569573, mean(E): -21.62268934+0.00262112j, var(E): 0.85906253
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9620/ 20000/ t/epoch=0.32............. Loss: -0.12236429, mean(E): -21.61182963+0.00174855j, var(E): 0.74788412
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9630/ 20000/ t/epoch=0.32............. Loss: 0.30567903, mean(E): -21.70213487-0.00403450j, var(E): 0.91731945
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9640/ 20000/ t/epoch=0.33............. Loss: -0.47812174, mean(E): -21.55552210+0.00195000j, var(E): 0.75320054
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9650/ 20000/ t/epoch=0.32............. Loss: -0.01851126, mean(E): -21.64014353+0.00312012j, var(E): 1.04542102
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9660/ 20000/ t/epoch=0.32............. Loss: -0.09286934, mean(E): -21.60145002+0.00120346j, var(E): 0.53866784
-0.0
tensor(13.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9670/ 20000/ t/epoch=0.33............. Loss: 0.36227409, mean(E): -21.70228125+0.00240000j, var(E): 0.73487759
-0.0
tensor(13.3267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9680/ 20000/ t/epoch=0.32............. Loss: -0.63918185, mean(E): -21.61380893+0.00048614j, var(E): 1.82381424
-0.0
tensor(13.3280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9690/ 20000/ t/epoch=0.32............. Loss: -0.18591855, mean(E): -21.63083936-0.00440559j, var(E): 1.87374370
-0.0
tensor(13.3298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9700/ 20000/ t/epoch=0.32............. Loss: 0.04247798, mean(E): -21.69839927+0.00780566j, var(E): 1.19248715
-0.0
tensor(13.3307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9710/ 20000/ t/epoch=0.32............. Loss: 0.28882846, mean(E): -21.69441764-0.00110859j, var(E): 0.74271508
-0.0
tensor(13.3318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9720/ 20000/ t/epoch=0.32............. Loss: -0.23254136, mean(E): -21.60475741-0.00004504j, var(E): 0.93794002
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9730/ 20000/ t/epoch=0.32............. Loss: -0.63990338, mean(E): -21.52796355-0.00185222j, var(E): 0.76057381
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9740/ 20000/ t/epoch=0.32............. Loss: -0.04234765, mean(E): -21.61642901+0.00025775j, var(E): 0.68469368
-0.0
tensor(13.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9750/ 20000/ t/epoch=0.32............. Loss: -0.41785765, mean(E): -21.56327665-0.00589209j, var(E): 0.81941858
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9760/ 20000/ t/epoch=0.32............. Loss: -0.81497577, mean(E): -21.49511802-0.00426818j, var(E): 1.52336180
-0.0
tensor(13.3323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9770/ 20000/ t/epoch=0.33............. Loss: 0.33388480, mean(E): -21.74094756-0.00184897j, var(E): 0.82910494
-0.0
tensor(13.3333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9780/ 20000/ t/epoch=0.32............. Loss: -0.36039362, mean(E): -21.60332644+0.00155276j, var(E): 0.93092351
-0.0
tensor(13.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9790/ 20000/ t/epoch=0.32............. Loss: -0.24864629, mean(E): -21.58678036-0.00202647j, var(E): 0.98799745
-0.0
tensor(13.3348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9800/ 20000/ t/epoch=0.33............. Loss: 0.48674309, mean(E): -21.64631881+0.00131886j, var(E): 1.38375635
-0.0
tensor(13.3364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9810/ 20000/ t/epoch=0.32............. Loss: 0.58761447, mean(E): -21.77172521-0.00335329j, var(E): 1.14885894
-0.0
tensor(13.3376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9820/ 20000/ t/epoch=0.32............. Loss: -0.25744195, mean(E): -21.60266669-0.00023260j, var(E): 1.02872124
-0.0
tensor(13.3391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9830/ 20000/ t/epoch=0.32............. Loss: 0.25205574, mean(E): -21.65834741+0.00188630j, var(E): 0.92613975
-0.0
tensor(13.3408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9840/ 20000/ t/epoch=0.33............. Loss: -0.02029741, mean(E): -21.68009740+0.00576226j, var(E): 1.23481632
-0.0
tensor(13.3412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9850/ 20000/ t/epoch=0.33............. Loss: -0.36047077, mean(E): -21.53621316+0.00023921j, var(E): 0.62249778
-0.0
tensor(13.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9860/ 20000/ t/epoch=0.32............. Loss: -0.57190850, mean(E): -21.55932713+0.00042926j, var(E): 0.41004282
-0.0
tensor(13.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9870/ 20000/ t/epoch=0.32............. Loss: 0.47476218, mean(E): -21.74122171+0.00158012j, var(E): 1.01188328
-0.0
tensor(13.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9880/ 20000/ t/epoch=0.33............. Loss: -0.18677030, mean(E): -21.61287151-0.00417226j, var(E): 0.64334668
-0.0
tensor(13.3444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9890/ 20000/ t/epoch=0.32............. Loss: 0.49837817, mean(E): -21.70126074-0.00136284j, var(E): 1.12946283
-0.0
tensor(13.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9900/ 20000/ t/epoch=0.32............. Loss: -0.35233348, mean(E): -21.63906807+0.00145662j, var(E): 0.59604680
-0.0
tensor(13.3464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9910/ 20000/ t/epoch=0.32............. Loss: -0.33320065, mean(E): -21.62220135+0.00035500j, var(E): 1.08969015
-0.0
tensor(13.3468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9920/ 20000/ t/epoch=0.32............. Loss: -0.43841586, mean(E): -21.55808180+0.00077868j, var(E): 0.96583706
-0.0
tensor(13.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9930/ 20000/ t/epoch=0.32............. Loss: -1.15121164, mean(E): -21.52020043+0.00435111j, var(E): 2.48003998
-0.0
tensor(13.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9940/ 20000/ t/epoch=0.32............. Loss: -0.09139698, mean(E): -21.68737631+0.00466272j, var(E): 1.07135205
-0.0
tensor(13.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9950/ 20000/ t/epoch=0.32............. Loss: -0.03011622, mean(E): -21.64773099+0.00019099j, var(E): 1.45654239
-0.0
tensor(13.3486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9960/ 20000/ t/epoch=0.33............. Loss: 0.07512108, mean(E): -21.71034084+0.00091737j, var(E): 0.79076189
-0.0
tensor(13.3502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9970/ 20000/ t/epoch=0.32............. Loss: -0.59601168, mean(E): -21.53199777+0.00208011j, var(E): 1.39765645
-0.0
tensor(13.3513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9980/ 20000/ t/epoch=0.32............. Loss: -0.59651713, mean(E): -21.53712534+0.00524469j, var(E): 1.69984736
-0.0
tensor(13.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 9990/ 20000/ t/epoch=0.32............. Loss: 0.04506451, mean(E): -21.69604052-0.00203009j, var(E): 0.84272553
-0.0
tensor(13.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10000/ 20000/ t/epoch=0.32............. Loss: -0.12432568, mean(E): -21.54804413-0.00082717j, var(E): 1.10225718
-0.0
tensor(13.3544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10010/ 20000/ t/epoch=0.32............. Loss: -0.73486936, mean(E): -21.56132068+0.00615463j, var(E): 0.98135889
-0.0
tensor(13.3557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10020/ 20000/ t/epoch=0.32............. Loss: -0.02640526, mean(E): -21.64576812+0.00588883j, var(E): 0.39255103
-0.0
tensor(13.3568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10030/ 20000/ t/epoch=0.32............. Loss: 0.17291462, mean(E): -21.70591384+0.00352352j, var(E): 0.51495253
-0.0
tensor(13.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10040/ 20000/ t/epoch=0.32............. Loss: -0.87244347, mean(E): -21.44489852+0.00568423j, var(E): 0.98709407
-0.0
tensor(13.3579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10050/ 20000/ t/epoch=0.32............. Loss: -0.07146593, mean(E): -21.66509196-0.00111792j, var(E): 0.79681700
-0.0
tensor(13.3593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10060/ 20000/ t/epoch=0.32............. Loss: -0.31074085, mean(E): -21.63796855-0.00030808j, var(E): 1.01636283
-0.0
tensor(13.3609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10070/ 20000/ t/epoch=0.32............. Loss: -0.62760514, mean(E): -21.55306429-0.00117057j, var(E): 0.50295187
-0.0
tensor(13.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10080/ 20000/ t/epoch=0.32............. Loss: -0.56180949, mean(E): -21.56687718-0.00158354j, var(E): 0.97867520
-0.0
tensor(13.3628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10090/ 20000/ t/epoch=0.32............. Loss: 0.24785835, mean(E): -21.66438242-0.00167118j, var(E): 0.71271248
-0.0
tensor(13.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10100/ 20000/ t/epoch=0.32............. Loss: 0.23990973, mean(E): -21.71333358+0.00094771j, var(E): 0.86068485
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10110/ 20000/ t/epoch=0.32............. Loss: -0.67629742, mean(E): -21.52715446+0.00006288j, var(E): 0.82041237
-0.0
tensor(13.3641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10120/ 20000/ t/epoch=0.32............. Loss: 0.05921389, mean(E): -21.64091652+0.00398682j, var(E): 1.30760578
-0.0
tensor(13.3661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10130/ 20000/ t/epoch=0.32............. Loss: -0.35722617, mean(E): -21.56118361+0.00113475j, var(E): 0.78688519
-0.0
tensor(13.3666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10140/ 20000/ t/epoch=0.32............. Loss: 0.00517224, mean(E): -21.69663620-0.00094130j, var(E): 1.16015189
-0.0
tensor(13.3683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10150/ 20000/ t/epoch=0.32............. Loss: 0.10042946, mean(E): -21.66176243+0.00017346j, var(E): 0.51794577
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10160/ 20000/ t/epoch=0.32............. Loss: -0.29635087, mean(E): -21.64726591+0.00306576j, var(E): 1.07916905
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10170/ 20000/ t/epoch=0.33............. Loss: 0.05954691, mean(E): -21.68690418-0.00559014j, var(E): 0.64782389
-0.0
tensor(13.3703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10180/ 20000/ t/epoch=0.32............. Loss: -0.04317418, mean(E): -21.66289036-0.00580273j, var(E): 1.58114579
-0.0
tensor(13.3717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10190/ 20000/ t/epoch=0.33............. Loss: 0.14386933, mean(E): -21.67734970-0.00111792j, var(E): 0.44607931
-0.0
tensor(13.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10200/ 20000/ t/epoch=0.32............. Loss: -0.75136978, mean(E): -21.51038608+0.00132821j, var(E): 0.80351006
-0.0
tensor(13.3740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10210/ 20000/ t/epoch=0.33............. Loss: -0.37573289, mean(E): -21.57678092+0.00301055j, var(E): 0.60957409
-0.0
tensor(13.3752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10220/ 20000/ t/epoch=0.33............. Loss: -0.19561020, mean(E): -21.59324203+0.00115474j, var(E): 1.52023885
-0.0
tensor(13.3763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10230/ 20000/ t/epoch=0.33............. Loss: -0.36190822, mean(E): -21.58749767+0.00055495j, var(E): 0.31279483
-0.0
tensor(13.3783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10240/ 20000/ t/epoch=0.32............. Loss: -0.18533154, mean(E): -21.63330143+0.00217295j, var(E): 0.65409647
-0.0
tensor(13.3797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10250/ 20000/ t/epoch=0.32............. Loss: -0.68144342, mean(E): -21.51788712-0.00093538j, var(E): 1.78301281
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10260/ 20000/ t/epoch=0.33............. Loss: -0.38306497, mean(E): -21.57541621+0.00385323j, var(E): 0.83840007
-0.0
tensor(13.3806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10270/ 20000/ t/epoch=0.32............. Loss: 0.76564162, mean(E): -21.81269913-0.00120979j, var(E): 0.74036120
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10280/ 20000/ t/epoch=0.32............. Loss: 0.18175208, mean(E): -21.64561680-0.00193619j, var(E): 1.78541074
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10290/ 20000/ t/epoch=0.32............. Loss: -0.54696841, mean(E): -21.59188081+0.00306420j, var(E): 1.02588798
-0.0
tensor(13.3822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10300/ 20000/ t/epoch=0.32............. Loss: 0.09949910, mean(E): -21.64030259-0.00575667j, var(E): 1.27213100
-0.0
tensor(13.3835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10310/ 20000/ t/epoch=0.32............. Loss: -0.18064857, mean(E): -21.59821465-0.00143875j, var(E): 0.43641644
-0.0
tensor(13.3849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10320/ 20000/ t/epoch=0.32............. Loss: -0.01453427, mean(E): -21.69159846+0.00248883j, var(E): 1.51683659
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10330/ 20000/ t/epoch=0.32............. Loss: 0.21213019, mean(E): -21.73042564-0.00061281j, var(E): 0.94285228
-0.0
tensor(13.3855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10340/ 20000/ t/epoch=0.32............. Loss: -0.31948639, mean(E): -21.59615302-0.00194066j, var(E): 0.83663704
-0.0
tensor(13.3863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10350/ 20000/ t/epoch=0.32............. Loss: -0.48882135, mean(E): -21.53264038+0.00548296j, var(E): 0.62575869
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10360/ 20000/ t/epoch=0.32............. Loss: 0.17513590, mean(E): -21.69823885+0.00077755j, var(E): 0.63234939
-0.0
tensor(13.3869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10370/ 20000/ t/epoch=0.32............. Loss: 0.21544521, mean(E): -21.67043424-0.00368891j, var(E): 1.01430255
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10380/ 20000/ t/epoch=0.32............. Loss: -0.23351914, mean(E): -21.65780463+0.00016962j, var(E): 0.86522796
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10390/ 20000/ t/epoch=0.32............. Loss: -0.08134857, mean(E): -21.57859884-0.00291249j, var(E): 0.84409070
-0.0
tensor(13.3886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10400/ 20000/ t/epoch=0.33............. Loss: -0.38976807, mean(E): -21.56922413-0.00145954j, var(E): 0.73079709
-0.0
tensor(13.3901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10410/ 20000/ t/epoch=0.33............. Loss: -0.23006229, mean(E): -21.62933345-0.00110983j, var(E): 0.45565056
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10420/ 20000/ t/epoch=0.32............. Loss: -0.17337979, mean(E): -21.67204113+0.00014195j, var(E): 0.72368242
-0.0
tensor(13.3908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10430/ 20000/ t/epoch=0.33............. Loss: 0.06382560, mean(E): -21.63212014+0.00088448j, var(E): 0.45882873
-0.0
tensor(13.3918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10440/ 20000/ t/epoch=0.32............. Loss: 0.34940136, mean(E): -21.72386283+0.00098850j, var(E): 1.46084495
-0.0
tensor(13.3928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10450/ 20000/ t/epoch=0.32............. Loss: 0.06827100, mean(E): -21.65378710-0.00172859j, var(E): 0.87474366
-0.0
tensor(13.3940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10460/ 20000/ t/epoch=0.33............. Loss: -0.51549363, mean(E): -21.52301245-0.00539552j, var(E): 1.44024014
-0.0
tensor(13.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10470/ 20000/ t/epoch=0.32............. Loss: -0.04853606, mean(E): -21.63042889-0.00110883j, var(E): 1.09798811
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10480/ 20000/ t/epoch=0.32............. Loss: 0.37100336, mean(E): -21.64364862+0.00007939j, var(E): 1.29654730
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10490/ 20000/ t/epoch=0.32............. Loss: -0.57499463, mean(E): -21.54972639-0.00006640j, var(E): 0.97265704
-0.0
tensor(13.3959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10500/ 20000/ t/epoch=0.32............. Loss: -0.07928173, mean(E): -21.61461060+0.00608406j, var(E): 0.88784616
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10510/ 20000/ t/epoch=0.32............. Loss: -0.19081584, mean(E): -21.62926882+0.00207784j, var(E): 1.53333940
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10520/ 20000/ t/epoch=0.32............. Loss: -0.44191769, mean(E): -21.62477436-0.00127203j, var(E): 1.92728321
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10530/ 20000/ t/epoch=0.32............. Loss: -0.38494003, mean(E): -21.60506125-0.00029372j, var(E): 0.74423782
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10540/ 20000/ t/epoch=0.32............. Loss: -0.04473376, mean(E): -21.62164292-0.00210990j, var(E): 0.88351385
-0.0
tensor(13.3967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10550/ 20000/ t/epoch=0.32............. Loss: -0.24195878, mean(E): -21.60255806-0.00241475j, var(E): 1.22353027
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10560/ 20000/ t/epoch=0.33............. Loss: -0.41453425, mean(E): -21.57044444+0.00139221j, var(E): 1.04350119
-0.0
tensor(13.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10570/ 20000/ t/epoch=0.32............. Loss: 0.87001799, mean(E): -21.66356546+0.00411143j, var(E): 2.37184511
-0.0
tensor(13.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10580/ 20000/ t/epoch=0.32............. Loss: 0.04566918, mean(E): -21.68489428-0.00338195j, var(E): 0.82811253
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10590/ 20000/ t/epoch=0.32............. Loss: -0.05609175, mean(E): -21.63046212+0.00543114j, var(E): 0.79805148
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10600/ 20000/ t/epoch=0.32............. Loss: -0.52581082, mean(E): -21.53888687+0.00206824j, var(E): 0.75825316
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.3999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10610/ 20000/ t/epoch=0.32............. Loss: -0.14667782, mean(E): -21.62208889-0.00152341j, var(E): 1.23204616
-0.0
tensor(13.4004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10620/ 20000/ t/epoch=0.32............. Loss: 0.09230927, mean(E): -21.66949422-0.00175930j, var(E): 0.47052710
-0.0
tensor(13.4016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10630/ 20000/ t/epoch=0.32............. Loss: 0.18608081, mean(E): -21.66084908-0.00065371j, var(E): 1.64245124
-0.0
tensor(13.4026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10640/ 20000/ t/epoch=0.33............. Loss: -0.79005098, mean(E): -21.51683778-0.00254061j, var(E): 1.14768574
-0.0
tensor(13.4036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10650/ 20000/ t/epoch=0.32............. Loss: 0.13397978, mean(E): -21.64499287-0.00038711j, var(E): 0.80205884
-0.0
tensor(13.4052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10660/ 20000/ t/epoch=0.32............. Loss: 0.23374177, mean(E): -21.69571882-0.00008810j, var(E): 0.67419969
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10670/ 20000/ t/epoch=0.32............. Loss: -0.18375248, mean(E): -21.62184681+0.00037618j, var(E): 1.35255397
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10680/ 20000/ t/epoch=0.32............. Loss: 0.58203682, mean(E): -21.71992285-0.00202001j, var(E): 1.07323047
-0.0
tensor(13.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10690/ 20000/ t/epoch=0.32............. Loss: 0.50718298, mean(E): -21.75715067+0.00029778j, var(E): 1.17683095
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10700/ 20000/ t/epoch=0.32............. Loss: 0.18072216, mean(E): -21.66079471-0.00226263j, var(E): 1.76258457
-0.0
tensor(13.4068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10710/ 20000/ t/epoch=0.32............. Loss: -0.00080207, mean(E): -21.62334623-0.00192255j, var(E): 0.49080545
-0.0
tensor(13.4071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10720/ 20000/ t/epoch=0.32............. Loss: 0.44966867, mean(E): -21.75013719-0.00202066j, var(E): 0.81976815
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10730/ 20000/ t/epoch=0.32............. Loss: 0.08560137, mean(E): -21.69290353-0.00075263j, var(E): 0.85836943
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10740/ 20000/ t/epoch=0.32............. Loss: 0.13576464, mean(E): -21.66040387-0.00113708j, var(E): 0.61762023
-0.0
tensor(13.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10750/ 20000/ t/epoch=0.33............. Loss: -1.26708214, mean(E): -21.46003741+0.00017288j, var(E): 1.32105586
-0.0
tensor(13.4096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10760/ 20000/ t/epoch=0.32............. Loss: -0.08633627, mean(E): -21.62482151-0.00133276j, var(E): 0.90903097
-0.0
tensor(13.4114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10770/ 20000/ t/epoch=0.32............. Loss: 0.48329591, mean(E): -21.76341324-0.00123983j, var(E): 0.79850246
-0.0
tensor(13.4134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10780/ 20000/ t/epoch=0.32............. Loss: 0.41944836, mean(E): -21.78187734-0.00006384j, var(E): 0.85969398
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10790/ 20000/ t/epoch=0.32............. Loss: 0.66141981, mean(E): -21.74175734+0.00052852j, var(E): 2.01126742
-0.0
tensor(13.4147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10800/ 20000/ t/epoch=0.32............. Loss: 0.17529361, mean(E): -21.62475779-0.00053834j, var(E): 0.62894471
-0.0
tensor(13.4156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10810/ 20000/ t/epoch=0.32............. Loss: 0.09163184, mean(E): -21.63474322-0.00044484j, var(E): 1.42462294
-0.0
tensor(13.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10820/ 20000/ t/epoch=0.32............. Loss: -0.08162793, mean(E): -21.63642930+0.00186698j, var(E): 1.05864851
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10830/ 20000/ t/epoch=0.32............. Loss: -0.45237964, mean(E): -21.56535419+0.00155772j, var(E): 0.60369017
-0.0
tensor(13.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10840/ 20000/ t/epoch=0.32............. Loss: 0.24191279, mean(E): -21.63670980+0.00133926j, var(E): 1.08889526
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10850/ 20000/ t/epoch=0.32............. Loss: -0.36051843, mean(E): -21.57625623-0.00144441j, var(E): 0.38871189
-0.0
tensor(13.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10860/ 20000/ t/epoch=0.32............. Loss: -0.64159446, mean(E): -21.54644632+0.00035581j, var(E): 1.21494212
-0.0
tensor(13.4168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10870/ 20000/ t/epoch=0.32............. Loss: -0.22727731, mean(E): -21.61828410-0.00024567j, var(E): 0.91597106
-0.0
tensor(13.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10880/ 20000/ t/epoch=0.33............. Loss: 0.26768781, mean(E): -21.72279275+0.00027068j, var(E): 0.61493147
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10890/ 20000/ t/epoch=0.32............. Loss: -0.54308634, mean(E): -21.51306839-0.00330224j, var(E): 0.84592183
-0.0
tensor(13.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10900/ 20000/ t/epoch=0.32............. Loss: -0.09939182, mean(E): -21.64826958+0.00138295j, var(E): 0.72525225
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10910/ 20000/ t/epoch=0.32............. Loss: 0.27035513, mean(E): -21.64933626+0.00327002j, var(E): 0.68562487
-0.0
tensor(13.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10920/ 20000/ t/epoch=0.32............. Loss: -0.05518815, mean(E): -21.60389553+0.00139652j, var(E): 1.16603358
-0.0
tensor(13.4185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10930/ 20000/ t/epoch=0.33............. Loss: -0.09548922, mean(E): -21.66735449-0.00100085j, var(E): 0.69032450
-0.0
tensor(13.4190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10940/ 20000/ t/epoch=0.33............. Loss: 0.83599581, mean(E): -21.83744101-0.00144070j, var(E): 2.16562153
-0.0
tensor(13.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10950/ 20000/ t/epoch=0.32............. Loss: 0.17381722, mean(E): -21.68808815+0.00044070j, var(E): 0.31514516
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10960/ 20000/ t/epoch=0.32............. Loss: 0.30131363, mean(E): -21.70334999+0.00056158j, var(E): 0.83677498
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10970/ 20000/ t/epoch=0.33............. Loss: -0.12258374, mean(E): -21.65313539-0.00272390j, var(E): 1.33719449
-0.0
tensor(13.4198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10980/ 20000/ t/epoch=0.32............. Loss: -0.26497261, mean(E): -21.58137807+0.00299105j, var(E): 0.60349820
-0.0
tensor(13.4205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 10990/ 20000/ t/epoch=0.33............. Loss: -0.66578196, mean(E): -21.49593000+0.00060302j, var(E): 0.83306996
-0.0
tensor(13.4217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11000/ 20000/ t/epoch=0.33............. Loss: -0.91128287, mean(E): -21.56059750-0.00066175j, var(E): 1.28228986
-0.0
tensor(13.4230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11010/ 20000/ t/epoch=0.32............. Loss: -0.27413892, mean(E): -21.59554386+0.00250561j, var(E): 0.91310194
-0.0
tensor(13.4250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11020/ 20000/ t/epoch=0.32............. Loss: -0.24386260, mean(E): -21.66207428+0.00364562j, var(E): 0.75229512
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11030/ 20000/ t/epoch=0.33............. Loss: 0.20088267, mean(E): -21.72435364+0.00100259j, var(E): 0.85095829
-0.0
tensor(13.4258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4271, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11040/ 20000/ t/epoch=0.33............. Loss: -0.29241749, mean(E): -21.63561560+0.00095464j, var(E): 1.06822128
-0.0
tensor(13.4278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11050/ 20000/ t/epoch=0.33............. Loss: 0.29784742, mean(E): -21.69265306+0.00026215j, var(E): 0.74099219
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11060/ 20000/ t/epoch=0.33............. Loss: -0.05557818, mean(E): -21.66767259-0.00109044j, var(E): 0.92063911
-0.0
tensor(13.4286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11070/ 20000/ t/epoch=0.32............. Loss: -0.18534923, mean(E): -21.63889365-0.00045764j, var(E): 0.70075033
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11080/ 20000/ t/epoch=0.33............. Loss: -0.12127852, mean(E): -21.64217818-0.00144068j, var(E): 1.00013626
-0.0
tensor(13.4298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11090/ 20000/ t/epoch=0.33............. Loss: 0.10517236, mean(E): -21.72648383+0.00051375j, var(E): 1.36771053
-0.0
tensor(13.4303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11100/ 20000/ t/epoch=0.33............. Loss: 0.28580009, mean(E): -21.72450535-0.00184153j, var(E): 1.48264868
-0.0
tensor(13.4314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11110/ 20000/ t/epoch=0.33............. Loss: -0.39833185, mean(E): -21.52861891-0.00032980j, var(E): 1.28637460
-0.0
tensor(13.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11120/ 20000/ t/epoch=0.33............. Loss: -0.10769508, mean(E): -21.62143311-0.00077605j, var(E): 0.76900817
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11130/ 20000/ t/epoch=0.33............. Loss: 0.06637149, mean(E): -21.70086205-0.00083570j, var(E): 0.66516458
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11140/ 20000/ t/epoch=0.33............. Loss: -0.61327024, mean(E): -21.47816576+0.00114285j, var(E): 1.29768915
-0.0
tensor(13.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11150/ 20000/ t/epoch=0.33............. Loss: -0.41174972, mean(E): -21.58327011+0.00028358j, var(E): 0.69538330
-0.0
tensor(13.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11160/ 20000/ t/epoch=0.33............. Loss: 0.17061266, mean(E): -21.66826149+0.00133634j, var(E): 2.53553870
-0.0
tensor(13.4345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11170/ 20000/ t/epoch=0.33............. Loss: 0.19221215, mean(E): -21.68669020+0.00184689j, var(E): 0.55592327
-0.0
tensor(13.4354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11180/ 20000/ t/epoch=0.32............. Loss: -0.15560184, mean(E): -21.64983837+0.00338602j, var(E): 0.52044482
-0.0
tensor(13.4357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11190/ 20000/ t/epoch=0.32............. Loss: -0.14181415, mean(E): -21.67083224+0.00260691j, var(E): 0.49884187
-0.0
tensor(13.4365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11200/ 20000/ t/epoch=0.33............. Loss: 0.00364069, mean(E): -21.65309175+0.00041482j, var(E): 0.50937983
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11210/ 20000/ t/epoch=0.32............. Loss: -0.12523139, mean(E): -21.61961419-0.00089531j, var(E): 0.60173207
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11220/ 20000/ t/epoch=0.32............. Loss: -0.61197434, mean(E): -21.54427018-0.00093555j, var(E): 1.00056699
-0.0
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11230/ 20000/ t/epoch=0.32............. Loss: 0.20161352, mean(E): -21.65448037-0.00119187j, var(E): 0.63329530
-0.0
tensor(13.4377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11240/ 20000/ t/epoch=0.33............. Loss: -0.04236658, mean(E): -21.63935579+0.00093182j, var(E): 0.45262407
-0.0
tensor(13.4387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11250/ 20000/ t/epoch=0.32............. Loss: -0.11019665, mean(E): -21.63069388+0.00074181j, var(E): 0.62890762
-0.0
tensor(13.4398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11260/ 20000/ t/epoch=0.32............. Loss: -0.16221779, mean(E): -21.66052395-0.00058070j, var(E): 0.60156391
-0.0
tensor(13.4403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11270/ 20000/ t/epoch=0.32............. Loss: -0.25629089, mean(E): -21.64433366+0.00008403j, var(E): 1.20771788
-0.0
tensor(13.4414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11280/ 20000/ t/epoch=0.32............. Loss: -0.14699619, mean(E): -21.62132983-0.00000243j, var(E): 0.39972213
-0.0
tensor(13.4422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11290/ 20000/ t/epoch=0.32............. Loss: -0.87831728, mean(E): -21.55557540+0.00103037j, var(E): 1.05773137
-0.0
tensor(13.4427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11300/ 20000/ t/epoch=0.33............. Loss: -0.18795648, mean(E): -21.59283944-0.00042932j, var(E): 1.29257500
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11310/ 20000/ t/epoch=0.32............. Loss: 0.39671248, mean(E): -21.69184557-0.00007061j, var(E): 0.68829283
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11320/ 20000/ t/epoch=0.32............. Loss: 0.17191376, mean(E): -21.74197535+0.00177080j, var(E): 0.81029852
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11330/ 20000/ t/epoch=0.32............. Loss: -0.31077467, mean(E): -21.62532458-0.00211784j, var(E): 0.42875634
-0.0
tensor(13.4442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11340/ 20000/ t/epoch=0.33............. Loss: 0.63643133, mean(E): -21.72598014-0.00215258j, var(E): 1.22761803
-0.0
tensor(13.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11350/ 20000/ t/epoch=0.32............. Loss: -0.22932971, mean(E): -21.64095528+0.00165251j, var(E): 1.65552231
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11360/ 20000/ t/epoch=0.32............. Loss: -0.33050228, mean(E): -21.59580795-0.00277586j, var(E): 1.42016697
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11370/ 20000/ t/epoch=0.32............. Loss: -0.16062535, mean(E): -21.59676269+0.00082144j, var(E): 1.54137065
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11380/ 20000/ t/epoch=0.32............. Loss: -0.68201273, mean(E): -21.54466750+0.00181891j, var(E): 0.74390324
-0.0
tensor(13.4463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11390/ 20000/ t/epoch=0.32............. Loss: -0.16268663, mean(E): -21.65320200+0.00061637j, var(E): 0.82373663
-0.0
tensor(13.4479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11400/ 20000/ t/epoch=0.32............. Loss: -0.28544228, mean(E): -21.59545413+0.00007400j, var(E): 0.71218185
-0.0
tensor(13.4496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11410/ 20000/ t/epoch=0.33............. Loss: 1.19355905, mean(E): -21.81831889-0.00093468j, var(E): 1.44702173
-0.0
tensor(13.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11420/ 20000/ t/epoch=0.32............. Loss: -0.09457144, mean(E): -21.61193278+0.00036551j, var(E): 0.50984503
-0.0
tensor(13.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11430/ 20000/ t/epoch=0.32............. Loss: 0.43685128, mean(E): -21.73373796+0.00361384j, var(E): 1.27326288
-0.0
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11440/ 20000/ t/epoch=0.33............. Loss: -0.44215476, mean(E): -21.57503583+0.00082850j, var(E): 0.88371494
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11450/ 20000/ t/epoch=0.32............. Loss: -0.89177502, mean(E): -21.52155621-0.00190325j, var(E): 0.93466660
-0.0
tensor(13.4519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11460/ 20000/ t/epoch=0.32............. Loss: -0.32580634, mean(E): -21.58412359-0.00195047j, var(E): 0.84524963
-0.0
tensor(13.4530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11470/ 20000/ t/epoch=0.33............. Loss: -0.38184380, mean(E): -21.57387164-0.00173595j, var(E): 0.60978476
-0.0
tensor(13.4537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11480/ 20000/ t/epoch=0.32............. Loss: 0.32712596, mean(E): -21.69281490+0.00285704j, var(E): 1.33582861
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11490/ 20000/ t/epoch=0.32............. Loss: -0.19062777, mean(E): -21.60823419-0.00097952j, var(E): 0.82685058
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11500/ 20000/ t/epoch=0.32............. Loss: 0.06384606, mean(E): -21.68086631-0.00048858j, var(E): 0.41879727
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11510/ 20000/ t/epoch=0.33............. Loss: -0.39850979, mean(E): -21.54806003+0.00271825j, var(E): 0.70324671
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11520/ 20000/ t/epoch=0.32............. Loss: -0.26168556, mean(E): -21.64250008+0.00035491j, var(E): 0.96134879
-0.0
tensor(13.4551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11530/ 20000/ t/epoch=0.32............. Loss: 0.17069864, mean(E): -21.64195131-0.00043997j, var(E): 0.89028154
-0.0
tensor(13.4554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11540/ 20000/ t/epoch=0.32............. Loss: -0.01043415, mean(E): -21.62928827-0.00085218j, var(E): 0.52604786
-0.0
tensor(13.4564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11550/ 20000/ t/epoch=0.32............. Loss: 0.47623685, mean(E): -21.74505673-0.00059251j, var(E): 0.67444721
-0.0
tensor(13.4570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11560/ 20000/ t/epoch=0.32............. Loss: -0.04041144, mean(E): -21.64075742-0.00047449j, var(E): 1.31666699
-0.0
tensor(13.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11570/ 20000/ t/epoch=0.33............. Loss: -0.48745188, mean(E): -21.57025098-0.00034896j, var(E): 1.52899572
-0.0
tensor(13.4586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11580/ 20000/ t/epoch=0.32............. Loss: -0.21417511, mean(E): -21.62741262+0.00212273j, var(E): 0.62725860
-0.0
tensor(13.4594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11590/ 20000/ t/epoch=0.32............. Loss: 0.38432827, mean(E): -21.74711734-0.00041928j, var(E): 0.72467851
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11600/ 20000/ t/epoch=0.32............. Loss: -0.94483625, mean(E): -21.49814773-0.00008172j, var(E): 1.27245712
-0.0
tensor(13.4605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11610/ 20000/ t/epoch=0.33............. Loss: -0.30278852, mean(E): -21.60456094+0.00064200j, var(E): 0.99750794
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11620/ 20000/ t/epoch=0.33............. Loss: -0.14058128, mean(E): -21.51618172-0.00045123j, var(E): 1.00940180
-0.0
tensor(13.4611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11630/ 20000/ t/epoch=0.32............. Loss: -0.20081743, mean(E): -21.61054888-0.00067945j, var(E): 0.90489740
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11640/ 20000/ t/epoch=0.32............. Loss: -0.21405745, mean(E): -21.63885811-0.00053449j, var(E): 0.97029558
-0.0
tensor(13.4617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11650/ 20000/ t/epoch=0.32............. Loss: -0.06487345, mean(E): -21.64986444-0.00130268j, var(E): 1.19306900
-0.0
tensor(13.4626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11660/ 20000/ t/epoch=0.32............. Loss: 0.10320253, mean(E): -21.66347586-0.00142336j, var(E): 0.87316472
-0.0
tensor(13.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11670/ 20000/ t/epoch=0.32............. Loss: -0.15903537, mean(E): -21.60474094-0.00171502j, var(E): 0.77093316
-0.0
tensor(13.4658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11680/ 20000/ t/epoch=0.32............. Loss: -0.23562974, mean(E): -21.66715911+0.00097563j, var(E): 1.84660719
-0.0
tensor(13.4670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11690/ 20000/ t/epoch=0.32............. Loss: 0.01462475, mean(E): -21.74204300-0.00187001j, var(E): 1.84216453
-0.0
tensor(13.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11700/ 20000/ t/epoch=0.32............. Loss: -0.14113209, mean(E): -21.65563285-0.00228241j, var(E): 0.42630417
-0.0
tensor(13.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11710/ 20000/ t/epoch=0.32............. Loss: -0.43350190, mean(E): -21.58365048+0.00177401j, var(E): 1.18624497
-0.0
tensor(13.4685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11720/ 20000/ t/epoch=0.32............. Loss: -0.08098646, mean(E): -21.65281909+0.00031326j, var(E): 1.01226966
-0.0
tensor(13.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11730/ 20000/ t/epoch=0.33............. Loss: -0.29386928, mean(E): -21.60802697+0.00152554j, var(E): 0.76276975
-0.0
tensor(13.4693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11740/ 20000/ t/epoch=0.32............. Loss: 0.16168367, mean(E): -21.67422768-0.00066481j, var(E): 0.80270567
-0.0
tensor(13.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11750/ 20000/ t/epoch=0.32............. Loss: -0.13143100, mean(E): -21.59458545+0.00008017j, var(E): 0.80647843
-0.0
tensor(13.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11760/ 20000/ t/epoch=0.32............. Loss: -0.14443721, mean(E): -21.65278910+0.00015203j, var(E): 0.80874865
-0.0
tensor(13.4712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11770/ 20000/ t/epoch=0.32............. Loss: 0.72566747, mean(E): -21.71771165-0.00106232j, var(E): 2.34658010
-0.0
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11780/ 20000/ t/epoch=0.32............. Loss: 0.14918942, mean(E): -21.68349343+0.00047531j, var(E): 0.53295524
-0.0
tensor(13.4729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11790/ 20000/ t/epoch=0.32............. Loss: -0.50269959, mean(E): -21.54670700+0.00060872j, var(E): 0.73902626
-0.0
tensor(13.4734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11800/ 20000/ t/epoch=0.32............. Loss: 0.43978370, mean(E): -21.69882927+0.00077665j, var(E): 0.87239345
-0.0
tensor(13.4745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11810/ 20000/ t/epoch=0.32............. Loss: -0.13620093, mean(E): -21.66465916+0.00001724j, var(E): 0.58074178
-0.0
tensor(13.4758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11820/ 20000/ t/epoch=0.32............. Loss: -0.10538397, mean(E): -21.62904051+0.00059072j, var(E): 0.47125390
-0.0
tensor(13.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11830/ 20000/ t/epoch=0.32............. Loss: 0.62906230, mean(E): -21.81970138+0.00038632j, var(E): 0.62389898
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11840/ 20000/ t/epoch=0.32............. Loss: 0.15877645, mean(E): -21.66422946+0.00080778j, var(E): 1.43841938
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11850/ 20000/ t/epoch=0.33............. Loss: -0.16966671, mean(E): -21.61320133-0.00041917j, var(E): 1.18118191
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11860/ 20000/ t/epoch=0.32............. Loss: -0.68443592, mean(E): -21.53453051+0.00075603j, var(E): 0.76542299
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11870/ 20000/ t/epoch=0.32............. Loss: 0.90433107, mean(E): -21.83956643+0.00195015j, var(E): 1.45691422
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11880/ 20000/ t/epoch=0.32............. Loss: 0.52156287, mean(E): -21.75609525-0.00054737j, var(E): 1.60731903
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11890/ 20000/ t/epoch=0.33............. Loss: -0.20257024, mean(E): -21.65566368-0.00049070j, var(E): 0.51869580
-0.0
tensor(13.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11900/ 20000/ t/epoch=0.32............. Loss: -0.40154745, mean(E): -21.58797069-0.00012436j, var(E): 0.97475476
-0.0
tensor(13.4781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11910/ 20000/ t/epoch=0.32............. Loss: -0.17723318, mean(E): -21.63121198+0.00149440j, var(E): 0.77850325
-0.0
tensor(13.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11920/ 20000/ t/epoch=0.32............. Loss: -0.56827553, mean(E): -21.57720731-0.00039479j, var(E): 1.20368264
-0.0
tensor(13.4796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11930/ 20000/ t/epoch=0.33............. Loss: -0.45736340, mean(E): -21.52846202-0.00165227j, var(E): 1.01905206
-0.0
tensor(13.4809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11940/ 20000/ t/epoch=0.33............. Loss: -0.58646100, mean(E): -21.54641057-0.00036676j, var(E): 0.68118291
-0.0
tensor(13.4830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11950/ 20000/ t/epoch=0.33............. Loss: -0.36918575, mean(E): -21.65393101-0.00088104j, var(E): 1.93551538
-0.0
tensor(13.4843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11960/ 20000/ t/epoch=0.32............. Loss: -0.58495726, mean(E): -21.55244690-0.00007220j, var(E): 1.19723061
-0.0
tensor(13.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11970/ 20000/ t/epoch=0.33............. Loss: -1.23041678, mean(E): -21.48780895-0.00034519j, var(E): 1.58840070
-0.0
tensor(13.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11980/ 20000/ t/epoch=0.32............. Loss: 0.23398372, mean(E): -21.69038919+0.00141812j, var(E): 1.10221340
-0.0
tensor(13.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 11990/ 20000/ t/epoch=0.32............. Loss: -0.20641893, mean(E): -21.62043307-0.00104576j, var(E): 1.17590354
-0.0
tensor(13.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12000/ 20000/ t/epoch=0.32............. Loss: -0.18274559, mean(E): -21.63439867-0.00024495j, var(E): 0.71143921
-0.0
tensor(13.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12010/ 20000/ t/epoch=0.32............. Loss: 0.72150975, mean(E): -21.75822820+0.00017679j, var(E): 1.29932645
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12020/ 20000/ t/epoch=0.32............. Loss: -0.29869692, mean(E): -21.62537495-0.00123227j, var(E): 0.77388221
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12030/ 20000/ t/epoch=0.32............. Loss: -0.42804163, mean(E): -21.56077299-0.00009336j, var(E): 0.68104324
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12040/ 20000/ t/epoch=0.32............. Loss: 0.41466097, mean(E): -21.68706045+0.00209030j, var(E): 0.80447420
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12050/ 20000/ t/epoch=0.33............. Loss: 0.52981950, mean(E): -21.77564545-0.00060866j, var(E): 0.82884403
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12060/ 20000/ t/epoch=0.32............. Loss: 0.32847043, mean(E): -21.70987801+0.00008187j, var(E): 1.14030380
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12070/ 20000/ t/epoch=0.32............. Loss: 0.26133883, mean(E): -21.69667999-0.00041734j, var(E): 0.80681760
-0.0
tensor(13.4893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12080/ 20000/ t/epoch=0.32............. Loss: -0.07979621, mean(E): -21.62607246+0.00150906j, var(E): 0.48621279
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12090/ 20000/ t/epoch=0.32............. Loss: -0.46385534, mean(E): -21.59116581-0.00059796j, var(E): 0.89801408
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12100/ 20000/ t/epoch=0.32............. Loss: -0.10876791, mean(E): -21.67304534-0.00026283j, var(E): 0.83507375
-0.0
tensor(13.4904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12110/ 20000/ t/epoch=0.32............. Loss: -0.10900657, mean(E): -21.64399480-0.00055960j, var(E): 0.60385699
-0.0
tensor(13.4910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12120/ 20000/ t/epoch=0.32............. Loss: -0.18655972, mean(E): -21.64607746+0.00129351j, var(E): 0.48515171
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12130/ 20000/ t/epoch=0.32............. Loss: -0.46674631, mean(E): -21.51693139-0.00049955j, var(E): 1.80344107
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12140/ 20000/ t/epoch=0.32............. Loss: -0.32215390, mean(E): -21.62158462-0.00012992j, var(E): 0.81102789
-0.0
tensor(13.4924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12150/ 20000/ t/epoch=0.32............. Loss: 0.20387214, mean(E): -21.65360534-0.00087498j, var(E): 0.67316606
-0.0
tensor(13.4936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12160/ 20000/ t/epoch=0.32............. Loss: 0.25751397, mean(E): -21.71109997-0.00024532j, var(E): 1.34460869
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12170/ 20000/ t/epoch=0.32............. Loss: -0.03126160, mean(E): -21.64327719+0.00030062j, var(E): 0.99062449
-0.0
tensor(13.4944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12180/ 20000/ t/epoch=0.32............. Loss: -0.25532243, mean(E): -21.61024767-0.00040974j, var(E): 0.61284042
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12190/ 20000/ t/epoch=0.33............. Loss: -0.25399268, mean(E): -21.61122855+0.00059825j, var(E): 1.22541365
-0.0
tensor(13.4951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12200/ 20000/ t/epoch=0.32............. Loss: 0.11035276, mean(E): -21.67930934-0.00022273j, var(E): 0.79908977
-0.0
tensor(13.4960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12210/ 20000/ t/epoch=0.32............. Loss: -0.05958426, mean(E): -21.68809619+0.00007597j, var(E): 1.10428844
-0.0
tensor(13.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12220/ 20000/ t/epoch=0.32............. Loss: 0.23215427, mean(E): -21.67824070-0.00133208j, var(E): 2.37984722
-0.0
tensor(13.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12230/ 20000/ t/epoch=0.33............. Loss: -0.19238815, mean(E): -21.58229871-0.00013994j, var(E): 0.40276203
-0.0
tensor(13.4979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12240/ 20000/ t/epoch=0.33............. Loss: 0.10697680, mean(E): -21.68665828-0.00110402j, var(E): 0.85565727
-0.0
tensor(13.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12250/ 20000/ t/epoch=0.32............. Loss: -0.60659904, mean(E): -21.54309822-0.00001954j, var(E): 0.75951905
-0.0
tensor(13.4989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12260/ 20000/ t/epoch=0.32............. Loss: -0.19392654, mean(E): -21.66873683+0.00100804j, var(E): 0.39340023
-0.0
tensor(13.4993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12270/ 20000/ t/epoch=0.32............. Loss: -0.57568717, mean(E): -21.57327324-0.00016983j, var(E): 0.87724786
-0.0
tensor(13.4996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12280/ 20000/ t/epoch=0.32............. Loss: -0.64139804, mean(E): -21.52449750-0.00152969j, var(E): 1.05533732
-0.0
tensor(13.4999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12290/ 20000/ t/epoch=0.32............. Loss: -0.11014515, mean(E): -21.66003914+0.00094905j, var(E): 0.82686313
-0.0
tensor(13.5008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12300/ 20000/ t/epoch=0.32............. Loss: -0.32442199, mean(E): -21.61321085-0.00017021j, var(E): 0.93194505
-0.0
tensor(13.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12310/ 20000/ t/epoch=0.32............. Loss: -0.02050566, mean(E): -21.66639710-0.00012352j, var(E): 0.57387843
-0.0
tensor(13.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12320/ 20000/ t/epoch=0.32............. Loss: -0.63204026, mean(E): -21.55793099-0.00013529j, var(E): 0.76526217
-0.0
tensor(13.5028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12330/ 20000/ t/epoch=0.33............. Loss: -0.54273635, mean(E): -21.55426293-0.00041903j, var(E): 1.02743112
-0.0
tensor(13.5039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12340/ 20000/ t/epoch=0.32............. Loss: -0.25884835, mean(E): -21.64090381+0.00051209j, var(E): 0.68982945
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12350/ 20000/ t/epoch=0.32............. Loss: -0.06190616, mean(E): -21.65509744-0.00068538j, var(E): 0.78654085
-0.0
tensor(13.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12360/ 20000/ t/epoch=0.32............. Loss: -0.15603682, mean(E): -21.66471474+0.00025312j, var(E): 0.65103036
-0.0
tensor(13.5044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12370/ 20000/ t/epoch=0.33............. Loss: -0.30427193, mean(E): -21.61374793-0.00027638j, var(E): 0.70689500
-0.0
tensor(13.5054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12380/ 20000/ t/epoch=0.32............. Loss: -0.61421992, mean(E): -21.56903104-0.00024067j, var(E): 0.94066405
-0.0
tensor(13.5068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12390/ 20000/ t/epoch=0.32............. Loss: -0.02808689, mean(E): -21.72243627+0.00025821j, var(E): 1.17974857
-0.0
tensor(13.5082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12400/ 20000/ t/epoch=0.32............. Loss: 0.16068950, mean(E): -21.66501248-0.00034459j, var(E): 0.78459569
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12410/ 20000/ t/epoch=0.32............. Loss: -0.22540678, mean(E): -21.62940298-0.00045915j, var(E): 0.64497633
-0.0
tensor(13.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12420/ 20000/ t/epoch=0.32............. Loss: -0.75449032, mean(E): -21.54135142+0.00040327j, var(E): 0.94263908
-0.0
tensor(13.5097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12430/ 20000/ t/epoch=0.32............. Loss: -0.06457591, mean(E): -21.62134262-0.00011895j, var(E): 0.65399900
-0.0
tensor(13.5105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12440/ 20000/ t/epoch=0.33............. Loss: -0.51304199, mean(E): -21.59359211-0.00062337j, var(E): 0.99280419
-0.0
tensor(13.5110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12450/ 20000/ t/epoch=0.32............. Loss: -0.09644400, mean(E): -21.64182806+0.00008633j, var(E): 0.73033151
-0.0
tensor(13.5123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12460/ 20000/ t/epoch=0.32............. Loss: 0.60024134, mean(E): -21.75887371-0.00023095j, var(E): 1.22325137
-0.0
tensor(13.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12470/ 20000/ t/epoch=0.32............. Loss: -0.53328483, mean(E): -21.53023701+0.00033393j, var(E): 1.45325566
-0.0
tensor(13.5130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12480/ 20000/ t/epoch=0.33............. Loss: -0.07492158, mean(E): -21.61282342-0.00021625j, var(E): 2.43253887
-0.0
tensor(13.5142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12490/ 20000/ t/epoch=0.32............. Loss: -0.38374289, mean(E): -21.56696269+0.00070123j, var(E): 1.00313786
-0.0
tensor(13.5143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12500/ 20000/ t/epoch=0.32............. Loss: 0.14753821, mean(E): -21.63359340+0.00022077j, var(E): 1.48475769
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12510/ 20000/ t/epoch=0.32............. Loss: 0.23144184, mean(E): -21.70868598-0.00070798j, var(E): 1.10131149
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12520/ 20000/ t/epoch=0.32............. Loss: -0.22490307, mean(E): -21.66520416-0.00028844j, var(E): 0.78206597
-0.0
tensor(13.5150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12530/ 20000/ t/epoch=0.32............. Loss: -0.39118750, mean(E): -21.58258884-0.00023523j, var(E): 1.06242926
-0.0
tensor(13.5158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12540/ 20000/ t/epoch=0.32............. Loss: 0.09217364, mean(E): -21.69169405+0.00013128j, var(E): 0.76766678
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12550/ 20000/ t/epoch=0.32............. Loss: -0.25572025, mean(E): -21.62301499+0.00037096j, var(E): 0.69586483
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12560/ 20000/ t/epoch=0.32............. Loss: 1.42874540, mean(E): -21.81238595-0.00003859j, var(E): 8.25617165
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12570/ 20000/ t/epoch=0.32............. Loss: -0.08742248, mean(E): -21.64609105-0.00020394j, var(E): 0.69853744
-0.0
tensor(13.5162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12580/ 20000/ t/epoch=0.32............. Loss: -0.12282425, mean(E): -21.61219168-0.00009026j, var(E): 0.43516194
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12590/ 20000/ t/epoch=0.32............. Loss: 0.46769913, mean(E): -21.76978854-0.00006350j, var(E): 0.67390222
-0.0
tensor(13.5173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12600/ 20000/ t/epoch=0.32............. Loss: 0.45508936, mean(E): -21.73692986+0.00015658j, var(E): 0.59327573
-0.0
tensor(13.5182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12610/ 20000/ t/epoch=0.32............. Loss: -0.76460795, mean(E): -21.53850853-0.00001402j, var(E): 1.09705892
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12620/ 20000/ t/epoch=0.32............. Loss: -0.22141467, mean(E): -21.64392411-0.00036104j, var(E): 1.11772867
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12630/ 20000/ t/epoch=0.32............. Loss: -0.42017305, mean(E): -21.59407734-0.00035535j, var(E): 0.54987492
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12640/ 20000/ t/epoch=0.32............. Loss: 0.08395440, mean(E): -21.69180377+0.00009901j, var(E): 1.16029785
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12650/ 20000/ t/epoch=0.32............. Loss: 0.34302175, mean(E): -21.70799487-0.00018069j, var(E): 1.25061189
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12660/ 20000/ t/epoch=0.33............. Loss: 0.62309994, mean(E): -21.72954459-0.00010265j, var(E): 0.93234847
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12670/ 20000/ t/epoch=0.32............. Loss: 0.15793543, mean(E): -21.70425642+0.00019302j, var(E): 1.16445078
-0.0
tensor(13.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12680/ 20000/ t/epoch=0.33............. Loss: -0.28612798, mean(E): -21.60689973-0.00043989j, var(E): 0.89622908
-0.0
tensor(13.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12690/ 20000/ t/epoch=0.32............. Loss: 0.20962974, mean(E): -21.76314530-0.00010843j, var(E): 0.74722013
-0.0
tensor(13.5190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12700/ 20000/ t/epoch=0.32............. Loss: -0.27612508, mean(E): -21.63041794+0.00012004j, var(E): 0.63686081
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12710/ 20000/ t/epoch=0.33............. Loss: 0.38270091, mean(E): -21.71232633-0.00000446j, var(E): 1.15703189
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12720/ 20000/ t/epoch=0.32............. Loss: -0.11139287, mean(E): -21.62994174-0.00001166j, var(E): 1.27121546
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12730/ 20000/ t/epoch=0.32............. Loss: -0.19141691, mean(E): -21.65196583+0.00021952j, var(E): 0.60564101
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12740/ 20000/ t/epoch=0.33............. Loss: 0.12297543, mean(E): -21.67806356+0.00024017j, var(E): 0.53362504
-0.0
tensor(13.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12750/ 20000/ t/epoch=0.33............. Loss: 0.25095101, mean(E): -21.69855449+0.00017820j, var(E): 1.00172064
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12760/ 20000/ t/epoch=0.33............. Loss: -0.28527139, mean(E): -21.63460765+0.00024540j, var(E): 0.47837830
-0.0
tensor(13.5210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12770/ 20000/ t/epoch=0.32............. Loss: -0.15067210, mean(E): -21.62506222-0.00032477j, var(E): 0.46136554
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12780/ 20000/ t/epoch=0.32............. Loss: -0.19468428, mean(E): -21.64412809-0.00044344j, var(E): 0.47782982
-0.0
tensor(13.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12790/ 20000/ t/epoch=0.32............. Loss: -1.33209838, mean(E): -21.41266020-0.00042065j, var(E): 1.11199521
-0.0
tensor(13.5214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12800/ 20000/ t/epoch=0.33............. Loss: 0.49913029, mean(E): -21.74761160-0.00008935j, var(E): 1.12271324
-0.0
tensor(13.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12810/ 20000/ t/epoch=0.33............. Loss: -0.19964127, mean(E): -21.63729016-0.00007138j, var(E): 0.52450570
-0.0
tensor(13.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12820/ 20000/ t/epoch=0.32............. Loss: 1.43071068, mean(E): -21.86283313+0.00048091j, var(E): 4.21220300
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12830/ 20000/ t/epoch=0.33............. Loss: -0.39722899, mean(E): -21.58687351-0.00010193j, var(E): 0.86099347
-0.0
tensor(13.5236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12840/ 20000/ t/epoch=0.32............. Loss: -0.02938801, mean(E): -21.69007017-0.00023401j, var(E): 1.52668191
-0.0
tensor(13.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12850/ 20000/ t/epoch=0.33............. Loss: -0.21383531, mean(E): -21.66076009+0.00055307j, var(E): 0.74434682
-0.0
tensor(13.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12860/ 20000/ t/epoch=0.32............. Loss: 0.28227256, mean(E): -21.69271380-0.00010069j, var(E): 0.60345002
-0.0
tensor(13.5253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12870/ 20000/ t/epoch=0.32............. Loss: -0.35540912, mean(E): -21.56279878-0.00000736j, var(E): 1.05624585
-0.0
tensor(13.5258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12880/ 20000/ t/epoch=0.32............. Loss: 0.14616965, mean(E): -21.66663172-0.00010025j, var(E): 0.68211837
-0.0
tensor(13.5265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12890/ 20000/ t/epoch=0.32............. Loss: -0.23562011, mean(E): -21.61683585-0.00048639j, var(E): 0.58937094
-0.0
tensor(13.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12900/ 20000/ t/epoch=0.32............. Loss: 0.30690252, mean(E): -21.69535633+0.00014724j, var(E): 0.67011187
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12910/ 20000/ t/epoch=0.32............. Loss: 0.39177523, mean(E): -21.72675587+0.00017904j, var(E): 1.45308376
-0.0
tensor(13.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12920/ 20000/ t/epoch=0.32............. Loss: -0.53024930, mean(E): -21.59306731+0.00005620j, var(E): 0.91317642
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12930/ 20000/ t/epoch=0.33............. Loss: -0.28187106, mean(E): -21.62815003+0.00009553j, var(E): 0.71945477
-0.0
tensor(13.5285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12940/ 20000/ t/epoch=0.32............. Loss: -0.36975731, mean(E): -21.58982834+0.00016900j, var(E): 0.83756517
-0.0
tensor(13.5293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12950/ 20000/ t/epoch=0.32............. Loss: -0.41434748, mean(E): -21.63483237-0.00012444j, var(E): 0.75084849
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12960/ 20000/ t/epoch=0.32............. Loss: 0.20206097, mean(E): -21.64575227+0.00016002j, var(E): 1.17476013
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12970/ 20000/ t/epoch=0.32............. Loss: 0.02917906, mean(E): -21.68039824-0.00019595j, var(E): 0.63833780
-0.0
tensor(13.5296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12980/ 20000/ t/epoch=0.32............. Loss: -0.21951258, mean(E): -21.61183678-0.00006364j, var(E): 0.51673316
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 12990/ 20000/ t/epoch=0.32............. Loss: -0.52831934, mean(E): -21.55527305+0.00011218j, var(E): 0.87957705
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13000/ 20000/ t/epoch=0.32............. Loss: 0.27489755, mean(E): -21.68902545+0.00008732j, var(E): 0.49971114
-0.0
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13010/ 20000/ t/epoch=0.32............. Loss: 0.48726701, mean(E): -21.73850372+0.00024819j, var(E): 1.01198012
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13020/ 20000/ t/epoch=0.32............. Loss: -0.56440544, mean(E): -21.52473196+0.00000408j, var(E): 0.99765336
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13030/ 20000/ t/epoch=0.32............. Loss: 0.72946220, mean(E): -21.77464675+0.00015715j, var(E): 1.83685060
-0.0
tensor(13.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13040/ 20000/ t/epoch=0.32............. Loss: -0.70848286, mean(E): -21.52814911-0.00011606j, var(E): 1.32070396
-0.0
tensor(13.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13050/ 20000/ t/epoch=0.32............. Loss: -0.41379970, mean(E): -21.59775646-0.00011094j, var(E): 0.55709333
-0.0
tensor(13.5299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13060/ 20000/ t/epoch=0.33............. Loss: -0.42075024, mean(E): -21.52848455-0.00000555j, var(E): 1.38425520
-0.0
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13070/ 20000/ t/epoch=0.32............. Loss: 0.46767560, mean(E): -21.71708925-0.00007811j, var(E): 1.75414897
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13080/ 20000/ t/epoch=0.32............. Loss: 0.47833665, mean(E): -21.74366198+0.00002235j, var(E): 1.45894105
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13090/ 20000/ t/epoch=0.32............. Loss: -0.88168073, mean(E): -21.55608529-0.00023877j, var(E): 1.48913547
-0.0
tensor(13.5305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13100/ 20000/ t/epoch=0.32............. Loss: -0.60608273, mean(E): -21.56774654+0.00002369j, var(E): 1.18007833
-0.0
tensor(13.5315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13110/ 20000/ t/epoch=0.32............. Loss: -0.03231047, mean(E): -21.68964790-0.00013522j, var(E): 0.72075747
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13120/ 20000/ t/epoch=0.32............. Loss: -0.15119027, mean(E): -21.67005249+0.00008871j, var(E): 0.62481592
-0.0
tensor(13.5325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13130/ 20000/ t/epoch=0.33............. Loss: 0.43248610, mean(E): -21.72419236+0.00024860j, var(E): 1.81724742
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13140/ 20000/ t/epoch=0.33............. Loss: 0.01152749, mean(E): -21.69869899-0.00001790j, var(E): 0.45716329
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13150/ 20000/ t/epoch=0.33............. Loss: -0.43546978, mean(E): -21.54501172+0.00008901j, var(E): 1.42845129
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13160/ 20000/ t/epoch=0.32............. Loss: -0.78155061, mean(E): -21.55025287+0.00011414j, var(E): 0.98842406
-0.0
tensor(13.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13170/ 20000/ t/epoch=0.33............. Loss: -0.41214915, mean(E): -21.58558817+0.00003605j, var(E): 0.52649246
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13180/ 20000/ t/epoch=0.33............. Loss: 0.18246853, mean(E): -21.72700570+0.00006127j, var(E): 0.83345824
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13190/ 20000/ t/epoch=0.32............. Loss: 0.19389570, mean(E): -21.71559288-0.00019429j, var(E): 0.61608347
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13200/ 20000/ t/epoch=0.32............. Loss: 0.42224779, mean(E): -21.73400896+0.00004295j, var(E): 1.11018419
-0.0
tensor(13.5349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13210/ 20000/ t/epoch=0.32............. Loss: -0.02672097, mean(E): -21.66732185-0.00010774j, var(E): 1.39618015
-0.0
tensor(13.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13220/ 20000/ t/epoch=0.32............. Loss: -0.24062874, mean(E): -21.59570495+0.00019045j, var(E): 0.53368154
-0.0
tensor(13.5361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13230/ 20000/ t/epoch=0.33............. Loss: -0.04834172, mean(E): -21.64216331+0.00004941j, var(E): 1.34331917
-0.0
tensor(13.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13240/ 20000/ t/epoch=0.32............. Loss: 0.39858049, mean(E): -21.69545123-0.00002312j, var(E): 0.92055701
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13250/ 20000/ t/epoch=0.33............. Loss: -0.16565800, mean(E): -21.64028744-0.00004627j, var(E): 0.72251958
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13260/ 20000/ t/epoch=0.33............. Loss: 0.35208137, mean(E): -21.72450148+0.00011798j, var(E): 0.69425434
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13270/ 20000/ t/epoch=0.33............. Loss: -0.93165087, mean(E): -21.51182146+0.00003830j, var(E): 1.29821483
-0.0
tensor(13.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13280/ 20000/ t/epoch=0.32............. Loss: -0.19324506, mean(E): -21.64844457+0.00002787j, var(E): 1.32954153
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13290/ 20000/ t/epoch=0.33............. Loss: 0.04617731, mean(E): -21.65964096-0.00015385j, var(E): 0.67673050
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13300/ 20000/ t/epoch=0.33............. Loss: -0.30192094, mean(E): -21.63764663+0.00008279j, var(E): 0.99429824
-0.0
tensor(13.5373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13310/ 20000/ t/epoch=0.33............. Loss: 0.13441428, mean(E): -21.64602631+0.00000388j, var(E): 1.47830378
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13320/ 20000/ t/epoch=0.32............. Loss: 0.36152394, mean(E): -21.74213393+0.00020307j, var(E): 0.52896456
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13330/ 20000/ t/epoch=0.32............. Loss: 0.27767636, mean(E): -21.70130323-0.00011585j, var(E): 1.55801189
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13340/ 20000/ t/epoch=0.32............. Loss: -0.45644600, mean(E): -21.60524499-0.00000482j, var(E): 0.82701100
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13350/ 20000/ t/epoch=0.32............. Loss: -0.35563929, mean(E): -21.58947231-0.00005400j, var(E): 0.66279360
-0.0
tensor(13.5374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13360/ 20000/ t/epoch=0.32............. Loss: -0.10405137, mean(E): -21.62563377+0.00013154j, var(E): 0.56934512
-0.0
tensor(13.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13370/ 20000/ t/epoch=0.33............. Loss: -0.28701994, mean(E): -21.55996860-0.00001725j, var(E): 0.31817509
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13380/ 20000/ t/epoch=0.33............. Loss: 0.55349411, mean(E): -21.71658494-0.00000393j, var(E): 1.76629829
-0.0
tensor(13.5388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13390/ 20000/ t/epoch=0.32............. Loss: -0.04792011, mean(E): -21.62683527-0.00003079j, var(E): 0.75742835
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13400/ 20000/ t/epoch=0.32............. Loss: -0.39210582, mean(E): -21.63502155-0.00001391j, var(E): 0.82548648
-0.0
tensor(13.5385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13410/ 20000/ t/epoch=0.32............. Loss: 0.07817972, mean(E): -21.63154083-0.00001758j, var(E): 1.03030226
-0.0
tensor(13.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13420/ 20000/ t/epoch=0.33............. Loss: -0.74039600, mean(E): -21.52800108+0.00005070j, var(E): 1.44140919
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13430/ 20000/ t/epoch=0.33............. Loss: -0.53509750, mean(E): -21.52705222-0.00002801j, var(E): 0.91734916
-0.0
tensor(13.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13440/ 20000/ t/epoch=0.32............. Loss: -0.14482235, mean(E): -21.67048740-0.00001877j, var(E): 1.57116901
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13450/ 20000/ t/epoch=0.32............. Loss: -0.53856560, mean(E): -21.57781621+0.00001998j, var(E): 0.84328999
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13460/ 20000/ t/epoch=0.33............. Loss: 0.49226060, mean(E): -21.77136667+0.00001113j, var(E): 0.53439383
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13470/ 20000/ t/epoch=0.33............. Loss: 0.09011950, mean(E): -21.63908732-0.00007003j, var(E): 0.75663360
-0.0
tensor(13.5409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13480/ 20000/ t/epoch=0.32............. Loss: 0.05128325, mean(E): -21.67259023+0.00005957j, var(E): 0.70581180
-0.0
tensor(13.5415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13490/ 20000/ t/epoch=0.32............. Loss: -0.74714777, mean(E): -21.49145749-0.00003593j, var(E): 1.36702742
-0.0
tensor(13.5425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13500/ 20000/ t/epoch=0.32............. Loss: 0.15089669, mean(E): -21.70025825-0.00001763j, var(E): 1.15333848
-0.0
tensor(13.5434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13510/ 20000/ t/epoch=0.32............. Loss: -0.49227657, mean(E): -21.58331104+0.00002634j, var(E): 0.90782811
-0.0
tensor(13.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13520/ 20000/ t/epoch=0.32............. Loss: -0.01810554, mean(E): -21.69987525-0.00002061j, var(E): 0.64512983
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13530/ 20000/ t/epoch=0.33............. Loss: 0.02525273, mean(E): -21.65454521-0.00002523j, var(E): 0.40840408
-0.0
tensor(13.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13540/ 20000/ t/epoch=0.33............. Loss: -0.31974589, mean(E): -21.57169267-0.00002905j, var(E): 0.72008640
-0.0
tensor(13.5456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13550/ 20000/ t/epoch=0.32............. Loss: 0.47750969, mean(E): -21.68910820-0.00002582j, var(E): 1.27279429
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13560/ 20000/ t/epoch=0.32............. Loss: -0.14591099, mean(E): -21.68199700-0.00001623j, var(E): 0.79545887
-0.0
tensor(13.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13570/ 20000/ t/epoch=0.32............. Loss: 0.05412804, mean(E): -21.69591399-0.00000308j, var(E): 1.11162428
-0.0
tensor(13.5469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13580/ 20000/ t/epoch=0.32............. Loss: 0.59309630, mean(E): -21.73960628-0.00001889j, var(E): 1.60858646
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13590/ 20000/ t/epoch=0.32............. Loss: 1.10104889, mean(E): -21.82307605+0.00000489j, var(E): 3.28771061
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13600/ 20000/ t/epoch=0.33............. Loss: -0.18708854, mean(E): -21.62736234-0.00001260j, var(E): 1.01086061
-0.0
tensor(13.5475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13610/ 20000/ t/epoch=0.32............. Loss: 0.24474744, mean(E): -21.74283928-0.00000369j, var(E): 0.57966033
-0.0
tensor(13.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13620/ 20000/ t/epoch=0.32............. Loss: 0.21688294, mean(E): -21.73082115+0.00001561j, var(E): 0.69964758
-0.0
tensor(13.5489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13630/ 20000/ t/epoch=0.32............. Loss: -0.25195454, mean(E): -21.63111903-0.00000910j, var(E): 0.85666091
-0.0
tensor(13.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13640/ 20000/ t/epoch=0.32............. Loss: -0.02938355, mean(E): -21.67306474+0.00003752j, var(E): 0.34304484
-0.0
tensor(13.5496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13650/ 20000/ t/epoch=0.32............. Loss: 0.40800811, mean(E): -21.71722031-0.00000189j, var(E): 0.83955824
-0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13660/ 20000/ t/epoch=0.32............. Loss: 0.82351558, mean(E): -21.73781440-0.00000469j, var(E): 2.24682232
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13670/ 20000/ t/epoch=0.32............. Loss: 0.23041959, mean(E): -21.67889231-0.00002439j, var(E): 1.84925616
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13680/ 20000/ t/epoch=0.32............. Loss: -0.58688553, mean(E): -21.54043811-0.00001194j, var(E): 0.58658009
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13690/ 20000/ t/epoch=0.32............. Loss: -0.38249827, mean(E): -21.63380828+0.00000245j, var(E): 0.77343936
-0.0
tensor(13.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13700/ 20000/ t/epoch=0.32............. Loss: -0.42026429, mean(E): -21.56235720+0.00004007j, var(E): 0.51646854
-0.0
tensor(13.5525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13710/ 20000/ t/epoch=0.32............. Loss: -0.17884261, mean(E): -21.57217331-0.00001085j, var(E): 0.84988992
-0.0
tensor(13.5537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13720/ 20000/ t/epoch=0.32............. Loss: 0.36740764, mean(E): -21.72801197+0.00001290j, var(E): 1.61033655
-0.0
tensor(13.5546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13730/ 20000/ t/epoch=0.32............. Loss: -0.17721870, mean(E): -21.65208282-0.00000285j, var(E): 1.38652634
-0.0
tensor(13.5559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13740/ 20000/ t/epoch=0.33............. Loss: 0.33035147, mean(E): -21.69106295+0.00002103j, var(E): 1.70725780
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13750/ 20000/ t/epoch=0.32............. Loss: -0.04946447, mean(E): -21.63914750+0.00000426j, var(E): 0.46980675
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13760/ 20000/ t/epoch=0.32............. Loss: -0.43997709, mean(E): -21.63049600-0.00000570j, var(E): 1.48976938
-0.0
tensor(13.5577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13770/ 20000/ t/epoch=0.32............. Loss: -0.28675150, mean(E): -21.58847904+0.00000722j, var(E): 0.63965536
-0.0
tensor(13.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13780/ 20000/ t/epoch=0.32............. Loss: 0.43414180, mean(E): -21.72852405+0.00001164j, var(E): 2.21399570
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13790/ 20000/ t/epoch=0.32............. Loss: -0.26285299, mean(E): -21.66495193-0.00000257j, var(E): 0.53915428
-0.0
tensor(13.5596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13800/ 20000/ t/epoch=0.32............. Loss: 0.18340178, mean(E): -21.69830303+0.00000401j, var(E): 0.42522101
-0.0
tensor(13.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13810/ 20000/ t/epoch=0.32............. Loss: -0.22626517, mean(E): -21.66064660-0.00001971j, var(E): 0.99232283
-0.0
tensor(13.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13820/ 20000/ t/epoch=0.32............. Loss: 0.16840657, mean(E): -21.71756673+0.00000428j, var(E): 0.75709852
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13830/ 20000/ t/epoch=0.32............. Loss: -0.41530688, mean(E): -21.60110824-0.00000192j, var(E): 0.62372534
-0.0
tensor(13.5599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13840/ 20000/ t/epoch=0.33............. Loss: -0.00521180, mean(E): -21.67062583+0.00002523j, var(E): 0.87381967
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13850/ 20000/ t/epoch=0.32............. Loss: -0.18563142, mean(E): -21.60700828-0.00000629j, var(E): 1.13462575
-0.0
tensor(13.5606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13860/ 20000/ t/epoch=0.32............. Loss: -0.40628933, mean(E): -21.61473124+0.00001150j, var(E): 0.43629197
-0.0
tensor(13.5614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13870/ 20000/ t/epoch=0.33............. Loss: -0.11669117, mean(E): -21.62868975+0.00000528j, var(E): 0.35803927
-0.0
tensor(13.5625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13880/ 20000/ t/epoch=0.32............. Loss: -0.39421861, mean(E): -21.62989683+0.00000797j, var(E): 0.54925789
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13890/ 20000/ t/epoch=0.32............. Loss: -0.29679878, mean(E): -21.63651500-0.00001798j, var(E): 1.07179957
-0.0
tensor(13.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13900/ 20000/ t/epoch=0.32............. Loss: -0.18576180, mean(E): -21.57685850+0.00000736j, var(E): 0.67222213
-0.0
tensor(13.5638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13910/ 20000/ t/epoch=0.33............. Loss: -0.70215965, mean(E): -21.54451824-0.00000374j, var(E): 0.58278397
-0.0
tensor(13.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13920/ 20000/ t/epoch=0.32............. Loss: -0.95087167, mean(E): -21.47664880+0.00000094j, var(E): 0.62439964
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13930/ 20000/ t/epoch=0.32............. Loss: -0.33668286, mean(E): -21.55861109+0.00000114j, var(E): 0.98285988
-0.0
tensor(13.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13940/ 20000/ t/epoch=0.32............. Loss: 0.87887725, mean(E): -21.78989234+0.00000512j, var(E): 1.84552445
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13950/ 20000/ t/epoch=0.33............. Loss: -0.09625851, mean(E): -21.71856837-0.00000528j, var(E): 0.90434849
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13960/ 20000/ t/epoch=0.32............. Loss: -0.32636561, mean(E): -21.63023743-0.00000117j, var(E): 0.71425770
-0.0
tensor(13.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13970/ 20000/ t/epoch=0.33............. Loss: -0.03471846, mean(E): -21.64247561+0.00000231j, var(E): 0.77848673
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13980/ 20000/ t/epoch=0.32............. Loss: -0.94368809, mean(E): -21.54354881-0.00000297j, var(E): 0.88973246
-0.0
tensor(13.5660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 13990/ 20000/ t/epoch=0.33............. Loss: -0.47347987, mean(E): -21.60781287+0.00000201j, var(E): 1.58248036
-0.0
tensor(13.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14000/ 20000/ t/epoch=0.32............. Loss: -0.25414127, mean(E): -21.60075053-0.00000030j, var(E): 0.74597065
-0.0
tensor(13.5679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14010/ 20000/ t/epoch=0.33............. Loss: 0.18361653, mean(E): -21.68915301-0.00000355j, var(E): 1.47398618
-0.0
tensor(13.5686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14020/ 20000/ t/epoch=0.32............. Loss: -0.06828850, mean(E): -21.66262584-0.00000299j, var(E): 0.80876113
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14030/ 20000/ t/epoch=0.33............. Loss: 1.15235633, mean(E): -21.80685428-0.00000201j, var(E): 1.41143209
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14040/ 20000/ t/epoch=0.33............. Loss: -0.66102731, mean(E): -21.51233371+0.00000046j, var(E): 1.14677057
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14050/ 20000/ t/epoch=0.33............. Loss: 0.34835490, mean(E): -21.73196621+0.00000178j, var(E): 1.16713650
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14060/ 20000/ t/epoch=0.32............. Loss: 0.17718725, mean(E): -21.69342696-0.00000320j, var(E): 0.74941508
-0.0
tensor(13.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5698, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14070/ 20000/ t/epoch=0.33............. Loss: -0.06787453, mean(E): -21.65578842+0.00000169j, var(E): 0.33915647
-0.0
tensor(13.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14080/ 20000/ t/epoch=0.33............. Loss: 0.02323427, mean(E): -21.68031500+0.00000036j, var(E): 0.63480941
-0.0
tensor(13.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14090/ 20000/ t/epoch=0.32............. Loss: -0.13483900, mean(E): -21.65425468-0.00000051j, var(E): 0.68542677
-0.0
tensor(13.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14100/ 20000/ t/epoch=0.32............. Loss: 0.30991499, mean(E): -21.79873569+0.00000213j, var(E): 0.40103683
-0.0
tensor(13.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14110/ 20000/ t/epoch=0.33............. Loss: -0.63856157, mean(E): -21.61182463+0.00000088j, var(E): 0.86814075
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14120/ 20000/ t/epoch=0.33............. Loss: 0.39215965, mean(E): -21.72803120+0.00000363j, var(E): 0.51315628
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14130/ 20000/ t/epoch=0.33............. Loss: -0.63319427, mean(E): -21.56473948-0.00000140j, var(E): 1.23579265
-0.0
tensor(13.5714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14140/ 20000/ t/epoch=0.33............. Loss: -0.22275786, mean(E): -21.63523790+0.00000249j, var(E): 0.67050418
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14150/ 20000/ t/epoch=0.33............. Loss: 0.00161995, mean(E): -21.64336679-0.00000090j, var(E): 0.74327873
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14160/ 20000/ t/epoch=0.32............. Loss: -0.45587676, mean(E): -21.58528948+0.00000149j, var(E): 0.61303963
-0.0
tensor(13.5720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14170/ 20000/ t/epoch=0.32............. Loss: -0.24760467, mean(E): -21.60310295-0.00000049j, var(E): 0.82230393
-0.0
tensor(13.5729, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5731, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14180/ 20000/ t/epoch=0.33............. Loss: 0.10250641, mean(E): -21.67967255+0.00000181j, var(E): 0.79798717
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14190/ 20000/ t/epoch=0.33............. Loss: -0.12139222, mean(E): -21.66538867-0.00000331j, var(E): 0.60395788
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14200/ 20000/ t/epoch=0.33............. Loss: 0.37393421, mean(E): -21.73732200+0.00000173j, var(E): 0.81593535
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14210/ 20000/ t/epoch=0.32............. Loss: -0.46374821, mean(E): -21.54061712+0.00000060j, var(E): 0.84171156
-0.0
tensor(13.5738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14220/ 20000/ t/epoch=0.32............. Loss: -0.30957926, mean(E): -21.66969276-0.00000031j, var(E): 0.85070970
-0.0
tensor(13.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14230/ 20000/ t/epoch=0.33............. Loss: 0.05808945, mean(E): -21.65016850+0.00000017j, var(E): 1.77539062
-0.0
tensor(13.5753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5757, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14240/ 20000/ t/epoch=0.32............. Loss: -0.48472448, mean(E): -21.60431961-0.00000474j, var(E): 0.56049224
-0.0
tensor(13.5760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14250/ 20000/ t/epoch=0.32............. Loss: -0.39531641, mean(E): -21.57503840+0.00000248j, var(E): 0.49283761
-0.0
tensor(13.5764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14260/ 20000/ t/epoch=0.33............. Loss: -0.05203443, mean(E): -21.62994440+0.00000439j, var(E): 1.17782331
-0.0
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14270/ 20000/ t/epoch=0.33............. Loss: 0.13738866, mean(E): -21.61028704-0.00000346j, var(E): 0.94330066
-0.0
tensor(13.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14280/ 20000/ t/epoch=0.33............. Loss: -0.33646430, mean(E): -21.67928836-0.00000173j, var(E): 0.98619808
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14290/ 20000/ t/epoch=0.32............. Loss: -0.02354847, mean(E): -21.65400404-0.00000020j, var(E): 1.58783399
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14300/ 20000/ t/epoch=0.32............. Loss: -0.00709796, mean(E): -21.66252964-0.00000127j, var(E): 0.47866689
-0.0
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14310/ 20000/ t/epoch=0.32............. Loss: 0.07652555, mean(E): -21.67757712-0.00000020j, var(E): 0.80063506
-0.0
tensor(13.5781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14320/ 20000/ t/epoch=0.32............. Loss: -0.06108938, mean(E): -21.64230557-0.00000182j, var(E): 1.35552872
-0.0
tensor(13.5785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14330/ 20000/ t/epoch=0.33............. Loss: -0.63778814, mean(E): -21.50884549+0.00000349j, var(E): 0.53140270
-0.0
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14340/ 20000/ t/epoch=0.32............. Loss: 0.73976417, mean(E): -21.85778023+0.00000187j, var(E): 1.15889491
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14350/ 20000/ t/epoch=0.33............. Loss: -0.21041582, mean(E): -21.61314597-0.00000134j, var(E): 1.27293008
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14360/ 20000/ t/epoch=0.32............. Loss: -0.78527854, mean(E): -21.55330517-0.00000293j, var(E): 1.03086049
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14370/ 20000/ t/epoch=0.32............. Loss: 0.94937338, mean(E): -21.80712132+0.00000040j, var(E): 1.69340926
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14380/ 20000/ t/epoch=0.33............. Loss: -0.12053586, mean(E): -21.64203567-0.00000008j, var(E): 0.80913925
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14390/ 20000/ t/epoch=0.32............. Loss: -0.03375488, mean(E): -21.67917779+0.00000164j, var(E): 0.95068379
-0.0
tensor(13.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14400/ 20000/ t/epoch=0.32............. Loss: -0.38981985, mean(E): -21.62831034+0.00000574j, var(E): 0.78496857
-0.0
tensor(13.5790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14410/ 20000/ t/epoch=0.33............. Loss: 0.25800247, mean(E): -21.72721014-0.00000021j, var(E): 0.96358888
-0.0
tensor(13.5795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14420/ 20000/ t/epoch=0.32............. Loss: -0.43197106, mean(E): -21.58927282+0.00000035j, var(E): 1.20055474
-0.0
tensor(13.5802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14430/ 20000/ t/epoch=0.33............. Loss: -0.05102833, mean(E): -21.66387746+0.00000989j, var(E): 1.02038443
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14440/ 20000/ t/epoch=0.32............. Loss: -0.23823141, mean(E): -21.65642104+0.00000591j, var(E): 1.04572919
-0.0
tensor(13.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14450/ 20000/ t/epoch=0.33............. Loss: -0.58344829, mean(E): -21.53590585-0.00000942j, var(E): 0.74048260
-0.0
tensor(13.5810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14460/ 20000/ t/epoch=0.32............. Loss: -0.38643170, mean(E): -21.56424209-0.00001017j, var(E): 1.00100798
-0.0
tensor(13.5823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14470/ 20000/ t/epoch=0.33............. Loss: -0.37134683, mean(E): -21.61315962+0.00001883j, var(E): 1.38395346
-0.0
tensor(13.5835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14480/ 20000/ t/epoch=0.32............. Loss: 0.63280582, mean(E): -21.72254545+0.00002991j, var(E): 1.70043016
-0.0
tensor(13.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14490/ 20000/ t/epoch=0.33............. Loss: -0.12028696, mean(E): -21.70623565-0.00000140j, var(E): 0.65955602
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14500/ 20000/ t/epoch=0.33............. Loss: -0.17100586, mean(E): -21.66567235+0.00001280j, var(E): 0.82650951
-0.0
tensor(13.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14510/ 20000/ t/epoch=0.32............. Loss: 0.54135782, mean(E): -21.77683930+0.00001613j, var(E): 1.09439865
-0.0
tensor(13.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5850, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14520/ 20000/ t/epoch=0.33............. Loss: 0.17008783, mean(E): -21.68125248+0.00002089j, var(E): 1.02650755
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5854, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14530/ 20000/ t/epoch=0.32............. Loss: -0.54244942, mean(E): -21.64966247-0.00007141j, var(E): 1.00416766
-0.0
tensor(13.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14540/ 20000/ t/epoch=0.33............. Loss: -0.19581398, mean(E): -21.65862760+0.00003776j, var(E): 0.61454700
-0.0
tensor(13.5870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14550/ 20000/ t/epoch=0.33............. Loss: -0.16012188, mean(E): -21.69167820-0.00003134j, var(E): 0.75137670
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14560/ 20000/ t/epoch=0.33............. Loss: 0.38939966, mean(E): -21.77678348+0.00001504j, var(E): 1.07392718
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14570/ 20000/ t/epoch=0.32............. Loss: -0.68386708, mean(E): -21.49371583-0.00000174j, var(E): 1.19764052
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14580/ 20000/ t/epoch=0.32............. Loss: 0.03307018, mean(E): -21.71195313+0.00011798j, var(E): 0.62383714
-0.0
tensor(13.5880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14590/ 20000/ t/epoch=0.32............. Loss: -0.81047324, mean(E): -21.55242660+0.00005770j, var(E): 0.91914233
-0.0
tensor(13.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14600/ 20000/ t/epoch=0.33............. Loss: -0.60104727, mean(E): -21.55590690+0.00000040j, var(E): 1.02042518
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14610/ 20000/ t/epoch=0.33............. Loss: -0.05439966, mean(E): -21.60401292+0.00003542j, var(E): 0.98780540
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14620/ 20000/ t/epoch=0.33............. Loss: 0.23939328, mean(E): -21.67294106-0.00005220j, var(E): 0.86401411
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14630/ 20000/ t/epoch=0.33............. Loss: -0.41216068, mean(E): -21.57893875-0.00004460j, var(E): 0.63993513
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14640/ 20000/ t/epoch=0.33............. Loss: -0.09522901, mean(E): -21.61302973+0.00001169j, var(E): 0.43631028
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14650/ 20000/ t/epoch=0.32............. Loss: -0.21738635, mean(E): -21.65058335-0.00001421j, var(E): 0.61359130
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14660/ 20000/ t/epoch=0.32............. Loss: 0.02734014, mean(E): -21.67087219+0.00001904j, var(E): 0.97610297
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14670/ 20000/ t/epoch=0.33............. Loss: 0.04322011, mean(E): -21.67625586-0.00006985j, var(E): 0.57995068
-0.0
tensor(13.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14680/ 20000/ t/epoch=0.33............. Loss: -0.48155678, mean(E): -21.56447063-0.00001334j, var(E): 0.61355151
-0.0
tensor(13.5902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14690/ 20000/ t/epoch=0.32............. Loss: -0.30564883, mean(E): -21.62950826-0.00000380j, var(E): 0.67366545
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14700/ 20000/ t/epoch=0.33............. Loss: -0.01939295, mean(E): -21.65188942+0.00003709j, var(E): 1.40393691
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14710/ 20000/ t/epoch=0.33............. Loss: 0.00164104, mean(E): -21.67339949-0.00004174j, var(E): 1.36464981
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14720/ 20000/ t/epoch=0.33............. Loss: 0.74646354, mean(E): -21.76418079+0.00001941j, var(E): 1.16930563
-0.0
tensor(13.5906, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14730/ 20000/ t/epoch=0.32............. Loss: -0.11950304, mean(E): -21.63941410-0.00007746j, var(E): 1.04380228
-0.0
tensor(13.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14740/ 20000/ t/epoch=0.32............. Loss: 0.00237229, mean(E): -21.68547973+0.00006704j, var(E): 1.21490296
-0.0
tensor(13.5924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14750/ 20000/ t/epoch=0.32............. Loss: -0.58092436, mean(E): -21.55856953-0.00002492j, var(E): 0.73606222
-0.0
tensor(13.5937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14760/ 20000/ t/epoch=0.32............. Loss: -0.19909370, mean(E): -21.63541709+0.00003998j, var(E): 0.71204272
-0.0
tensor(13.5949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5950, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14770/ 20000/ t/epoch=0.33............. Loss: 0.06761246, mean(E): -21.65706846+0.00003216j, var(E): 0.80540912
-0.0
tensor(13.5959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14780/ 20000/ t/epoch=0.33............. Loss: 0.47027958, mean(E): -21.74919635-0.00010282j, var(E): 1.03987610
-0.0
tensor(13.5966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14790/ 20000/ t/epoch=0.32............. Loss: -1.08961829, mean(E): -21.42987116-0.00003608j, var(E): 0.71276006
-0.0
tensor(13.5974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14800/ 20000/ t/epoch=0.33............. Loss: 0.10149576, mean(E): -21.68528687-0.00001631j, var(E): 0.76779357
-0.0
tensor(13.5987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14810/ 20000/ t/epoch=0.32............. Loss: 0.32692870, mean(E): -21.72415882+0.00004056j, var(E): 0.83309490
-0.0
tensor(13.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14820/ 20000/ t/epoch=0.33............. Loss: -0.16842328, mean(E): -21.63270631-0.00000284j, var(E): 0.89435900
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14830/ 20000/ t/epoch=0.32............. Loss: 0.52490911, mean(E): -21.69280939+0.00003028j, var(E): 1.58748214
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14840/ 20000/ t/epoch=0.33............. Loss: 0.43176022, mean(E): -21.70798717-0.00002389j, var(E): 1.31008449
-0.0
tensor(13.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.5999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14850/ 20000/ t/epoch=0.33............. Loss: -0.17436949, mean(E): -21.63300209+0.00003249j, var(E): 0.51165042
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14860/ 20000/ t/epoch=0.33............. Loss: 1.07556301, mean(E): -21.75468073-0.00000915j, var(E): 3.21109481
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14870/ 20000/ t/epoch=0.32............. Loss: -0.10354545, mean(E): -21.69113860-0.00002229j, var(E): 0.42986572
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14880/ 20000/ t/epoch=0.33............. Loss: -0.33352390, mean(E): -21.61458715-0.00000541j, var(E): 0.72442236
-0.0
tensor(13.6004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14890/ 20000/ t/epoch=0.32............. Loss: 0.51836108, mean(E): -21.73379119+0.00001374j, var(E): 0.56822998
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14900/ 20000/ t/epoch=0.33............. Loss: -0.04137249, mean(E): -21.65787734+0.00002788j, var(E): 0.70806134
-0.0
tensor(13.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6011, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14910/ 20000/ t/epoch=0.33............. Loss: -0.53617358, mean(E): -21.54612502+0.00002654j, var(E): 0.64584410
-0.0
tensor(13.6017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14920/ 20000/ t/epoch=0.33............. Loss: -0.04323448, mean(E): -21.64991190-0.00001654j, var(E): 0.39284218
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14930/ 20000/ t/epoch=0.32............. Loss: -0.28847581, mean(E): -21.62712994-0.00002075j, var(E): 1.14169360
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14940/ 20000/ t/epoch=0.33............. Loss: 0.27692518, mean(E): -21.70261525+0.00001783j, var(E): 0.82139036
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14950/ 20000/ t/epoch=0.32............. Loss: 0.03436306, mean(E): -21.65139384-0.00002304j, var(E): 0.73923311
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14960/ 20000/ t/epoch=0.32............. Loss: -0.23479287, mean(E): -21.64135392-0.00004392j, var(E): 0.51012658
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14970/ 20000/ t/epoch=0.32............. Loss: -0.41627455, mean(E): -21.59882167-0.00006677j, var(E): 0.43478684
-0.0
tensor(13.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14980/ 20000/ t/epoch=0.32............. Loss: 0.34368742, mean(E): -21.66108979-0.00004783j, var(E): 1.02517585
-0.0
tensor(13.6021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 14990/ 20000/ t/epoch=0.33............. Loss: -1.00957920, mean(E): -21.53503791+0.00010478j, var(E): 1.06381045
-0.0
tensor(13.6027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15000/ 20000/ t/epoch=0.32............. Loss: 0.05684170, mean(E): -21.67343298+0.00001752j, var(E): 0.22538786
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15010/ 20000/ t/epoch=0.32............. Loss: -0.59221320, mean(E): -21.55100978-0.00001146j, var(E): 0.93166675
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15020/ 20000/ t/epoch=0.32............. Loss: -0.01914923, mean(E): -21.70455727+0.00000047j, var(E): 0.60051893
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15030/ 20000/ t/epoch=0.33............. Loss: -0.49475822, mean(E): -21.53471310-0.00011326j, var(E): 0.81347227
-0.0
tensor(13.6034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15040/ 20000/ t/epoch=0.33............. Loss: -0.05087146, mean(E): -21.67950032+0.00001374j, var(E): 1.08522320
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15050/ 20000/ t/epoch=0.32............. Loss: -0.04354274, mean(E): -21.65595340+0.00000339j, var(E): 0.66739942
-0.0
tensor(13.6038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15060/ 20000/ t/epoch=0.32............. Loss: 0.06901380, mean(E): -21.70359425+0.00001746j, var(E): 0.35435362
-0.0
tensor(13.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15070/ 20000/ t/epoch=0.33............. Loss: 0.30798742, mean(E): -21.70514663-0.00002651j, var(E): 0.77145826
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15080/ 20000/ t/epoch=0.32............. Loss: -0.46710760, mean(E): -21.55760116-0.00005777j, var(E): 0.80980895
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15090/ 20000/ t/epoch=0.33............. Loss: -0.02144133, mean(E): -21.71131874-0.00002406j, var(E): 0.93652468
-0.0
tensor(13.6046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15100/ 20000/ t/epoch=0.33............. Loss: -0.01019918, mean(E): -21.63817000-0.00001092j, var(E): 1.04634891
-0.0
tensor(13.6052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15110/ 20000/ t/epoch=0.32............. Loss: -0.21525138, mean(E): -21.63411667-0.00001546j, var(E): 0.20148320
-0.0
tensor(13.6061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15120/ 20000/ t/epoch=0.32............. Loss: -0.29657671, mean(E): -21.58643616+0.00002832j, var(E): 0.82893459
-0.0
tensor(13.6069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15130/ 20000/ t/epoch=0.33............. Loss: 0.13661262, mean(E): -21.71115783+0.00001179j, var(E): 0.39590325
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15140/ 20000/ t/epoch=0.32............. Loss: -0.58753269, mean(E): -21.57635482+0.00000162j, var(E): 0.51259858
-0.0
tensor(13.6075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6077, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15150/ 20000/ t/epoch=0.32............. Loss: -0.21204988, mean(E): -21.62673839+0.00000639j, var(E): 0.59263639
-0.0
tensor(13.6080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15160/ 20000/ t/epoch=0.32............. Loss: 0.14789750, mean(E): -21.68380831+0.00002509j, var(E): 0.80832782
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15170/ 20000/ t/epoch=0.32............. Loss: 0.21463352, mean(E): -21.69890990-0.00003452j, var(E): 0.96612134
-0.0
tensor(13.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15180/ 20000/ t/epoch=0.32............. Loss: -0.41589086, mean(E): -21.60280112-0.00000276j, var(E): 0.75683809
-0.0
tensor(13.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15190/ 20000/ t/epoch=0.32............. Loss: -0.48143731, mean(E): -21.53647617-0.00001272j, var(E): 1.19439344
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15200/ 20000/ t/epoch=0.32............. Loss: 0.23417283, mean(E): -21.70819667+0.00000493j, var(E): 1.08494709
-0.0
tensor(13.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15210/ 20000/ t/epoch=0.32............. Loss: -0.20496795, mean(E): -21.64609077-0.00000472j, var(E): 1.09933959
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15220/ 20000/ t/epoch=0.32............. Loss: -0.01564596, mean(E): -21.62644980+0.00005743j, var(E): 0.37382882
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15230/ 20000/ t/epoch=0.32............. Loss: 0.22931476, mean(E): -21.73436475-0.00000603j, var(E): 1.50098074
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15240/ 20000/ t/epoch=0.32............. Loss: -0.07511233, mean(E): -21.59939841-0.00002111j, var(E): 0.93813165
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15250/ 20000/ t/epoch=0.32............. Loss: 0.20398110, mean(E): -21.71565141-0.00000676j, var(E): 0.61093215
-0.0
tensor(13.6117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15260/ 20000/ t/epoch=0.32............. Loss: -0.05300164, mean(E): -21.62856248+0.00001779j, var(E): 0.93840640
-0.0
tensor(13.6127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15270/ 20000/ t/epoch=0.32............. Loss: -0.34803392, mean(E): -21.62845728-0.00002660j, var(E): 0.99460580
-0.0
tensor(13.6131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15280/ 20000/ t/epoch=0.32............. Loss: -0.19591828, mean(E): -21.63351272-0.00004119j, var(E): 1.24747843
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15290/ 20000/ t/epoch=0.32............. Loss: -0.12089310, mean(E): -21.68626235-0.00015346j, var(E): 0.55788599
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15300/ 20000/ t/epoch=0.32............. Loss: 0.39690155, mean(E): -21.78836097+0.00007276j, var(E): 0.65048815
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15310/ 20000/ t/epoch=0.32............. Loss: -0.14369214, mean(E): -21.67483722-0.00004089j, var(E): 0.70026004
-0.0
tensor(13.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15320/ 20000/ t/epoch=0.32............. Loss: 0.33852180, mean(E): -21.73880503+0.00003413j, var(E): 1.11623712
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15330/ 20000/ t/epoch=0.32............. Loss: -0.44735099, mean(E): -21.54218283-0.00002141j, var(E): 1.68168826
-0.0
tensor(13.6136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15340/ 20000/ t/epoch=0.32............. Loss: -0.17117746, mean(E): -21.66410083+0.00001248j, var(E): 0.66174124
-0.0
tensor(13.6146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15350/ 20000/ t/epoch=0.32............. Loss: 0.40951883, mean(E): -21.74938973+0.00005804j, var(E): 1.21972875
-0.0
tensor(13.6155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15360/ 20000/ t/epoch=0.33............. Loss: -0.55242568, mean(E): -21.52794760-0.00001813j, var(E): 0.71671862
-0.0
tensor(13.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15370/ 20000/ t/epoch=0.32............. Loss: 0.31550616, mean(E): -21.75124211-0.00004408j, var(E): 0.59219004
-0.0
tensor(13.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15380/ 20000/ t/epoch=0.32............. Loss: -0.16244240, mean(E): -21.66394287-0.00001622j, var(E): 0.90678538
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15390/ 20000/ t/epoch=0.32............. Loss: 0.22652542, mean(E): -21.69346967+0.00007703j, var(E): 0.88097267
-0.0
tensor(13.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15400/ 20000/ t/epoch=0.33............. Loss: -0.06864428, mean(E): -21.64122568-0.00004655j, var(E): 1.19286629
-0.0
tensor(13.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15410/ 20000/ t/epoch=0.33............. Loss: -0.10193609, mean(E): -21.70864010+0.00001104j, var(E): 1.05802589
-0.0
tensor(13.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15420/ 20000/ t/epoch=0.32............. Loss: 0.33649651, mean(E): -21.73703289-0.00005998j, var(E): 0.71688116
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15430/ 20000/ t/epoch=0.33............. Loss: -0.47936722, mean(E): -21.66885672+0.00008870j, var(E): 1.64415916
-0.0
tensor(13.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15440/ 20000/ t/epoch=0.33............. Loss: 0.35064904, mean(E): -21.81016669+0.00001628j, var(E): 1.49354491
-0.0
tensor(13.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15450/ 20000/ t/epoch=0.32............. Loss: -0.48141246, mean(E): -21.51514858-0.00000990j, var(E): 1.00349967
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15460/ 20000/ t/epoch=0.32............. Loss: -0.53694038, mean(E): -21.54857578-0.00000309j, var(E): 0.70994043
-0.0
tensor(13.6201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15470/ 20000/ t/epoch=0.33............. Loss: -0.09814214, mean(E): -21.67859083-0.00000261j, var(E): 0.61081044
-0.0
tensor(13.6210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15480/ 20000/ t/epoch=0.32............. Loss: -0.45339056, mean(E): -21.61817755+0.00001066j, var(E): 0.74698886
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15490/ 20000/ t/epoch=0.33............. Loss: 0.44596380, mean(E): -21.68868886-0.00001616j, var(E): 1.76352616
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15500/ 20000/ t/epoch=0.33............. Loss: 0.05763567, mean(E): -21.69664908-0.00000545j, var(E): 0.78592101
-0.0
tensor(13.6221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15510/ 20000/ t/epoch=0.32............. Loss: -0.03026415, mean(E): -21.64371687+0.00001472j, var(E): 1.55505873
-0.0
tensor(13.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15520/ 20000/ t/epoch=0.33............. Loss: -0.58966444, mean(E): -21.53906945-0.00001080j, var(E): 0.77419254
-0.0
tensor(13.6235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15530/ 20000/ t/epoch=0.33............. Loss: 0.31971153, mean(E): -21.80358726+0.00000138j, var(E): 0.80851533
-0.0
tensor(13.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15540/ 20000/ t/epoch=0.33............. Loss: -0.35689784, mean(E): -21.60987794+0.00000271j, var(E): 0.68992063
-0.0
tensor(13.6253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15550/ 20000/ t/epoch=0.32............. Loss: 0.29693741, mean(E): -21.69718382-0.00000275j, var(E): 0.89827681
-0.0
tensor(13.6264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15560/ 20000/ t/epoch=0.32............. Loss: 0.35993634, mean(E): -21.71435448-0.00000302j, var(E): 1.62429025
-0.0
tensor(13.6276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15570/ 20000/ t/epoch=0.33............. Loss: 1.14280101, mean(E): -21.76478610-0.00000231j, var(E): 2.44722938
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15580/ 20000/ t/epoch=0.33............. Loss: -0.67640871, mean(E): -21.53967075+0.00000401j, var(E): 1.30557526
-0.0
tensor(13.6281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15590/ 20000/ t/epoch=0.33............. Loss: -0.39811810, mean(E): -21.60205634-0.00000404j, var(E): 0.48689801
-0.0
tensor(13.6286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15600/ 20000/ t/epoch=0.32............. Loss: -0.05415907, mean(E): -21.66272733-0.00000414j, var(E): 0.99229750
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15610/ 20000/ t/epoch=0.32............. Loss: -0.21686475, mean(E): -21.64914592-0.00000328j, var(E): 0.74248875
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15620/ 20000/ t/epoch=0.32............. Loss: 0.47680180, mean(E): -21.69672996-0.00000076j, var(E): 1.15918175
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15630/ 20000/ t/epoch=0.33............. Loss: 0.11366665, mean(E): -21.67370355-0.00000495j, var(E): 0.54078175
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15640/ 20000/ t/epoch=0.33............. Loss: -0.42315278, mean(E): -21.59046985-0.00000080j, var(E): 1.35580983
-0.0
tensor(13.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15650/ 20000/ t/epoch=0.32............. Loss: 0.50999494, mean(E): -21.77732355+0.00000206j, var(E): 1.10669816
-0.0
tensor(13.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15660/ 20000/ t/epoch=0.33............. Loss: -0.46265241, mean(E): -21.64376189+0.00000026j, var(E): 0.98107490
-0.0
tensor(13.6311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15670/ 20000/ t/epoch=0.32............. Loss: 0.62932729, mean(E): -21.68853661-0.00000309j, var(E): 1.21301822
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15680/ 20000/ t/epoch=0.32............. Loss: -0.33718725, mean(E): -21.58619681-0.00000457j, var(E): 1.32503601
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15690/ 20000/ t/epoch=0.33............. Loss: 0.96435542, mean(E): -21.89483704+0.00000015j, var(E): 0.74971514
-0.0
tensor(13.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15700/ 20000/ t/epoch=0.33............. Loss: 0.01330068, mean(E): -21.68403102-0.00000146j, var(E): 0.51150216
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15710/ 20000/ t/epoch=0.33............. Loss: 0.05769550, mean(E): -21.69834663+0.00000032j, var(E): 0.69134377
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15720/ 20000/ t/epoch=0.33............. Loss: 0.66589134, mean(E): -21.75789267+0.00000089j, var(E): 0.98045218
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15730/ 20000/ t/epoch=0.32............. Loss: -0.95030650, mean(E): -21.50307780-0.00000001j, var(E): 1.20497384
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15740/ 20000/ t/epoch=0.32............. Loss: 0.95577085, mean(E): -21.82356327+0.00000052j, var(E): 1.58263722
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15750/ 20000/ t/epoch=0.33............. Loss: -0.02043960, mean(E): -21.67876236-0.00000023j, var(E): 0.64117840
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15760/ 20000/ t/epoch=0.33............. Loss: 0.51756696, mean(E): -21.74793032+0.00000090j, var(E): 1.55094009
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15770/ 20000/ t/epoch=0.33............. Loss: -0.32964898, mean(E): -21.59507499+0.00000039j, var(E): 0.79455216
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15780/ 20000/ t/epoch=0.32............. Loss: 0.68999966, mean(E): -21.78540171-0.00000163j, var(E): 0.95534824
-0.0
tensor(13.6328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15790/ 20000/ t/epoch=0.33............. Loss: 0.66183926, mean(E): -21.77472139+0.00000026j, var(E): 1.14696240
-0.0
tensor(13.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15800/ 20000/ t/epoch=0.32............. Loss: -0.09066806, mean(E): -21.60695015+0.00000054j, var(E): 0.48269465
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15810/ 20000/ t/epoch=0.32............. Loss: 0.48750777, mean(E): -21.78714028-0.00000104j, var(E): 0.84931427
-0.0
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15820/ 20000/ t/epoch=0.33............. Loss: 0.15384263, mean(E): -21.73123601+0.00000061j, var(E): 1.20353510
-0.0
tensor(13.6346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15830/ 20000/ t/epoch=0.32............. Loss: -0.65076928, mean(E): -21.56174151+0.00000030j, var(E): 0.87289837
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15840/ 20000/ t/epoch=0.33............. Loss: 0.80997642, mean(E): -21.74608523-0.00000234j, var(E): 1.97109698
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15850/ 20000/ t/epoch=0.32............. Loss: 0.17956501, mean(E): -21.66703182-0.00000070j, var(E): 1.27497745
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15860/ 20000/ t/epoch=0.33............. Loss: -0.25382083, mean(E): -21.61550205+0.00000098j, var(E): 0.36488113
-0.0
tensor(13.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15870/ 20000/ t/epoch=0.32............. Loss: 0.19442061, mean(E): -21.68108142-0.00001010j, var(E): 0.84480408
-0.0
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15880/ 20000/ t/epoch=0.33............. Loss: -0.20642657, mean(E): -21.63461037-0.00000033j, var(E): 0.46217094
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15890/ 20000/ t/epoch=0.33............. Loss: -0.43804730, mean(E): -21.57324861+0.00000278j, var(E): 1.63101991
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15900/ 20000/ t/epoch=0.33............. Loss: -0.27966380, mean(E): -21.63259987-0.00000106j, var(E): 0.91072595
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15910/ 20000/ t/epoch=0.33............. Loss: -0.16321917, mean(E): -21.63555827+0.00000269j, var(E): 0.64653074
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15920/ 20000/ t/epoch=0.33............. Loss: -0.45858420, mean(E): -21.56141084-0.00000475j, var(E): 0.87688229
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15930/ 20000/ t/epoch=0.33............. Loss: 0.48828223, mean(E): -21.70938694-0.00000440j, var(E): 1.31510351
-0.0
tensor(13.6366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15940/ 20000/ t/epoch=0.33............. Loss: -0.26357917, mean(E): -21.62656471-0.00000883j, var(E): 0.41537747
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15950/ 20000/ t/epoch=0.33............. Loss: 0.17644040, mean(E): -21.64519864-0.00000603j, var(E): 0.69594206
-0.0
tensor(13.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15960/ 20000/ t/epoch=0.33............. Loss: 0.29554653, mean(E): -21.66824133+0.00000912j, var(E): 0.95845992
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6373, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15970/ 20000/ t/epoch=0.33............. Loss: -0.19924657, mean(E): -21.61456753-0.00001061j, var(E): 0.45758781
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15980/ 20000/ t/epoch=0.32............. Loss: 0.64814498, mean(E): -21.81726893-0.00000138j, var(E): 1.32139657
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 15990/ 20000/ t/epoch=0.33............. Loss: -0.44478563, mean(E): -21.62193785+0.00000277j, var(E): 1.64960549
-0.0
tensor(13.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16000/ 20000/ t/epoch=0.32............. Loss: -0.20700643, mean(E): -21.66271404+0.00000464j, var(E): 0.63724140
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16010/ 20000/ t/epoch=0.32............. Loss: -0.28803790, mean(E): -21.65395780-0.00000912j, var(E): 0.65670924
-0.0
tensor(13.6391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6397, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16020/ 20000/ t/epoch=0.33............. Loss: -0.78514102, mean(E): -21.54558708+0.00004072j, var(E): 0.99177459
-0.0
tensor(13.6398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16030/ 20000/ t/epoch=0.33............. Loss: 0.00358664, mean(E): -21.63411521+0.00000323j, var(E): 0.71718950
-0.0
tensor(13.6408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6411, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16040/ 20000/ t/epoch=0.32............. Loss: 0.21597614, mean(E): -21.64402676+0.00006480j, var(E): 2.05800999
-0.0
tensor(13.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6415, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6419, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16050/ 20000/ t/epoch=0.33............. Loss: -0.31005882, mean(E): -21.62101312-0.00007598j, var(E): 1.01509660
-0.0
tensor(13.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16060/ 20000/ t/epoch=0.33............. Loss: 0.48452663, mean(E): -21.80933150-0.00013865j, var(E): 1.34129697
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6423, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16070/ 20000/ t/epoch=0.32............. Loss: -0.33822182, mean(E): -21.60650111+0.00001805j, var(E): 0.69208551
-0.0
tensor(13.6424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6427, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16080/ 20000/ t/epoch=0.33............. Loss: 0.55472177, mean(E): -21.72863235+0.00010925j, var(E): 1.59909062
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16090/ 20000/ t/epoch=0.33............. Loss: -0.08723609, mean(E): -21.65429222+0.00003177j, var(E): 0.76558630
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16100/ 20000/ t/epoch=0.32............. Loss: 0.38754591, mean(E): -21.78745278-0.00002418j, var(E): 0.61860892
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16110/ 20000/ t/epoch=0.33............. Loss: 0.04344744, mean(E): -21.67248590+0.00001254j, var(E): 0.30337484
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16120/ 20000/ t/epoch=0.33............. Loss: -0.47712719, mean(E): -21.57093421+0.00002500j, var(E): 0.73876845
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16130/ 20000/ t/epoch=0.33............. Loss: -0.82592037, mean(E): -21.49614248+0.00000452j, var(E): 1.10259952
-0.0
tensor(13.6430, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16140/ 20000/ t/epoch=0.32............. Loss: -0.40276686, mean(E): -21.58738157-0.00002442j, var(E): 0.36713419
-0.0
tensor(13.6431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6433, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16150/ 20000/ t/epoch=0.33............. Loss: -0.75419773, mean(E): -21.52987013-0.00000335j, var(E): 1.20182755
-0.0
tensor(13.6440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16160/ 20000/ t/epoch=0.32............. Loss: -0.46512839, mean(E): -21.57666124-0.00003320j, var(E): 0.68846438
-0.0
tensor(13.6450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16170/ 20000/ t/epoch=0.32............. Loss: -0.18474983, mean(E): -21.64942630-0.00002074j, var(E): 0.78471733
-0.0
tensor(13.6460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16180/ 20000/ t/epoch=0.33............. Loss: 0.20774535, mean(E): -21.78625629+0.00008052j, var(E): 0.88783380
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16190/ 20000/ t/epoch=0.32............. Loss: 1.27616461, mean(E): -21.77790190-0.00008992j, var(E): 2.86688120
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16200/ 20000/ t/epoch=0.32............. Loss: 0.68271521, mean(E): -21.75433536+0.00004000j, var(E): 1.81810127
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16210/ 20000/ t/epoch=0.32............. Loss: -0.17550300, mean(E): -21.61953567-0.00012217j, var(E): 1.20604456
-0.0
tensor(13.6470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6476, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16220/ 20000/ t/epoch=0.32............. Loss: 0.21490047, mean(E): -21.65072341-0.00002106j, var(E): 0.80951580
-0.0
tensor(13.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6485, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16230/ 20000/ t/epoch=0.33............. Loss: -0.63466371, mean(E): -21.58497122-0.00005578j, var(E): 1.15506092
-0.0
tensor(13.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16240/ 20000/ t/epoch=0.32............. Loss: -0.20710799, mean(E): -21.64096265-0.00004778j, var(E): 0.40209577
-0.0
tensor(13.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16250/ 20000/ t/epoch=0.33............. Loss: -0.20870273, mean(E): -21.61966022+0.00019117j, var(E): 1.01384597
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16260/ 20000/ t/epoch=0.32............. Loss: 0.18846225, mean(E): -21.67040358-0.00003655j, var(E): 0.84618020
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16270/ 20000/ t/epoch=0.32............. Loss: 0.45971096, mean(E): -21.76044679+0.00010961j, var(E): 0.68070475
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16280/ 20000/ t/epoch=0.32............. Loss: -0.80281363, mean(E): -21.54791536+0.00004675j, var(E): 1.03926934
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16290/ 20000/ t/epoch=0.32............. Loss: 0.05360935, mean(E): -21.63629368-0.00001362j, var(E): 2.12299392
-0.0
tensor(13.6494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16300/ 20000/ t/epoch=0.32............. Loss: -0.33409637, mean(E): -21.63071530-0.00011043j, var(E): 0.57491931
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16310/ 20000/ t/epoch=0.32............. Loss: 0.06961582, mean(E): -21.64940276+0.00013063j, var(E): 1.09107041
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6502, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16320/ 20000/ t/epoch=0.32............. Loss: 0.79368105, mean(E): -21.72594681+0.00001117j, var(E): 3.93643144
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6506, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16330/ 20000/ t/epoch=0.33............. Loss: -0.11782376, mean(E): -21.68249244-0.00000291j, var(E): 0.87434758
-0.0
tensor(13.6508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6509, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16340/ 20000/ t/epoch=0.33............. Loss: 0.03134920, mean(E): -21.67508070-0.00003188j, var(E): 0.62944152
-0.0
tensor(13.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16350/ 20000/ t/epoch=0.32............. Loss: 0.38021902, mean(E): -21.72828297-0.00001473j, var(E): 0.62252195
-0.0
tensor(13.6519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16360/ 20000/ t/epoch=0.33............. Loss: -0.29356895, mean(E): -21.61358259-0.00001188j, var(E): 1.00180178
-0.0
tensor(13.6524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16370/ 20000/ t/epoch=0.33............. Loss: -0.17606665, mean(E): -21.62814862+0.00003985j, var(E): 0.61893062
-0.0
tensor(13.6530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16380/ 20000/ t/epoch=0.32............. Loss: 0.25895845, mean(E): -21.74090889-0.00001173j, var(E): 0.84347103
-0.0
tensor(13.6537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16390/ 20000/ t/epoch=0.32............. Loss: -0.33964053, mean(E): -21.58096315-0.00002639j, var(E): 0.53576072
-0.0
tensor(13.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16400/ 20000/ t/epoch=0.32............. Loss: 0.16247591, mean(E): -21.74180721+0.00005370j, var(E): 0.69139810
-0.0
tensor(13.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16410/ 20000/ t/epoch=0.32............. Loss: 0.02748771, mean(E): -21.66856659-0.00003323j, var(E): 0.62981907
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16420/ 20000/ t/epoch=0.32............. Loss: -0.11698627, mean(E): -21.65093774-0.00003617j, var(E): 0.66473102
-0.0
tensor(13.6552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16430/ 20000/ t/epoch=0.32............. Loss: -0.04316136, mean(E): -21.68438988-0.00001857j, var(E): 0.49674836
-0.0
tensor(13.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16440/ 20000/ t/epoch=0.32............. Loss: 0.00374257, mean(E): -21.66779611+0.00005719j, var(E): 0.38701104
-0.0
tensor(13.6562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16450/ 20000/ t/epoch=0.32............. Loss: -0.22247622, mean(E): -21.61608475+0.00006657j, var(E): 0.57696756
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16460/ 20000/ t/epoch=0.33............. Loss: -0.32927454, mean(E): -21.61576794+0.00001678j, var(E): 0.93175350
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16470/ 20000/ t/epoch=0.33............. Loss: 0.60172243, mean(E): -21.81126802+0.00002325j, var(E): 0.88556240
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16480/ 20000/ t/epoch=0.32............. Loss: -0.02836622, mean(E): -21.65705254+0.00000309j, var(E): 1.04826917
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16490/ 20000/ t/epoch=0.32............. Loss: -0.35633702, mean(E): -21.58431746-0.00002324j, var(E): 0.97529934
-0.0
tensor(13.6570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16500/ 20000/ t/epoch=0.32............. Loss: -0.79184634, mean(E): -21.49325956+0.00000804j, var(E): 0.75135944
-0.0
tensor(13.6577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16510/ 20000/ t/epoch=0.32............. Loss: -0.29464036, mean(E): -21.64214675-0.00002472j, var(E): 0.59368090
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16520/ 20000/ t/epoch=0.33............. Loss: 0.05780920, mean(E): -21.64958956-0.00001808j, var(E): 0.54860134
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16530/ 20000/ t/epoch=0.32............. Loss: -0.48880462, mean(E): -21.58645510-0.00001270j, var(E): 0.99717979
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16540/ 20000/ t/epoch=0.33............. Loss: -0.16453814, mean(E): -21.64170491-0.00001241j, var(E): 0.88439851
-0.0
tensor(13.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16550/ 20000/ t/epoch=0.33............. Loss: 0.15403145, mean(E): -21.66528857-0.00000136j, var(E): 1.07378649
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16560/ 20000/ t/epoch=0.33............. Loss: 0.43089335, mean(E): -21.75967270-0.00000514j, var(E): 0.94579179
-0.0
tensor(13.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16570/ 20000/ t/epoch=0.32............. Loss: -0.20796155, mean(E): -21.65347516+0.00000282j, var(E): 0.55252524
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16580/ 20000/ t/epoch=0.32............. Loss: -0.58136546, mean(E): -21.62296628-0.00000152j, var(E): 0.73475917
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16590/ 20000/ t/epoch=0.33............. Loss: 0.06487219, mean(E): -21.64091484+0.00000420j, var(E): 3.49242415
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16600/ 20000/ t/epoch=0.33............. Loss: -0.26334150, mean(E): -21.58641619+0.00000456j, var(E): 0.57992617
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16610/ 20000/ t/epoch=0.33............. Loss: 0.19856498, mean(E): -21.73591740+0.00000021j, var(E): 0.50763375
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16620/ 20000/ t/epoch=0.33............. Loss: 0.35596478, mean(E): -21.73956745+0.00000405j, var(E): 1.06270706
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16630/ 20000/ t/epoch=0.33............. Loss: -0.15906984, mean(E): -21.69289770-0.00000223j, var(E): 0.58497084
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16640/ 20000/ t/epoch=0.32............. Loss: 0.32588530, mean(E): -21.74259348-0.00000394j, var(E): 1.22671947
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16650/ 20000/ t/epoch=0.33............. Loss: 0.39705925, mean(E): -21.73734350+0.00000299j, var(E): 0.59664799
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16660/ 20000/ t/epoch=0.33............. Loss: -0.05757528, mean(E): -21.70519613-0.00000098j, var(E): 0.86941659
-0.0
tensor(13.6595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16670/ 20000/ t/epoch=0.33............. Loss: -0.24626426, mean(E): -21.68604105-0.00000107j, var(E): 0.62028863
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16680/ 20000/ t/epoch=0.33............. Loss: -0.57379133, mean(E): -21.58043358+0.00000082j, var(E): 0.88058881
-0.0
tensor(13.6599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16690/ 20000/ t/epoch=0.33............. Loss: -0.17903630, mean(E): -21.65676294-0.00000101j, var(E): 0.68069015
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16700/ 20000/ t/epoch=0.32............. Loss: 0.13104564, mean(E): -21.68356407+0.00000012j, var(E): 0.36161090
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16710/ 20000/ t/epoch=0.33............. Loss: 0.33642990, mean(E): -21.71794693-0.00000110j, var(E): 0.60272014
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16720/ 20000/ t/epoch=0.33............. Loss: 0.58877377, mean(E): -21.78914070+0.00000037j, var(E): 0.62798285
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16730/ 20000/ t/epoch=0.33............. Loss: 0.38369298, mean(E): -21.70982736+0.00000119j, var(E): 0.90170406
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16740/ 20000/ t/epoch=0.33............. Loss: 0.19379039, mean(E): -21.76393564-0.00000019j, var(E): 1.13618283
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16750/ 20000/ t/epoch=0.32............. Loss: 1.56030939, mean(E): -21.79661596-0.00000110j, var(E): 3.00021698
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16760/ 20000/ t/epoch=0.33............. Loss: -0.01266953, mean(E): -21.69787132+0.00000106j, var(E): 1.10328825
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16770/ 20000/ t/epoch=0.32............. Loss: -0.01477272, mean(E): -21.69112440+0.00000026j, var(E): 0.80284355
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16780/ 20000/ t/epoch=0.32............. Loss: -0.32770812, mean(E): -21.62125432-0.00000038j, var(E): 0.88768280
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16790/ 20000/ t/epoch=0.32............. Loss: 0.14443167, mean(E): -21.68713540-0.00000027j, var(E): 0.75272804
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16800/ 20000/ t/epoch=0.33............. Loss: -0.33119790, mean(E): -21.62443442+0.00000020j, var(E): 0.43276800
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16810/ 20000/ t/epoch=0.32............. Loss: 0.11246855, mean(E): -21.71130794+0.00000117j, var(E): 0.37374807
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16820/ 20000/ t/epoch=0.33............. Loss: 0.21211695, mean(E): -21.70698911+0.00000038j, var(E): 1.33364533
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16830/ 20000/ t/epoch=0.32............. Loss: 0.32397466, mean(E): -21.69319551-0.00000012j, var(E): 1.68029283
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16840/ 20000/ t/epoch=0.33............. Loss: -0.32559317, mean(E): -21.61421408+0.00000016j, var(E): 0.59649375
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16850/ 20000/ t/epoch=0.33............. Loss: -0.44017337, mean(E): -21.65769292-0.00000065j, var(E): 0.68929585
-0.0
tensor(13.6607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16860/ 20000/ t/epoch=0.33............. Loss: -0.13894658, mean(E): -21.65831427-0.00000028j, var(E): 0.65837686
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16870/ 20000/ t/epoch=0.33............. Loss: -0.24165111, mean(E): -21.65651642-0.00000041j, var(E): 0.73993873
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16880/ 20000/ t/epoch=0.33............. Loss: -0.04694518, mean(E): -21.71716877-0.00000055j, var(E): 1.10372928
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16890/ 20000/ t/epoch=0.33............. Loss: -0.78038116, mean(E): -21.56003689+0.00000074j, var(E): 0.98670672
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16900/ 20000/ t/epoch=0.33............. Loss: -0.60640111, mean(E): -21.58966275-0.00000013j, var(E): 0.81332620
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16910/ 20000/ t/epoch=0.32............. Loss: -0.34196265, mean(E): -21.63510188-0.00000011j, var(E): 0.85432494
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16920/ 20000/ t/epoch=0.33............. Loss: 0.35273862, mean(E): -21.76144863-0.00000033j, var(E): 0.47240604
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16930/ 20000/ t/epoch=0.33............. Loss: 0.22165382, mean(E): -21.71521394+0.00000010j, var(E): 1.97108529
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16940/ 20000/ t/epoch=0.33............. Loss: -0.14326593, mean(E): -21.61908727-0.00000006j, var(E): 0.75615231
-0.0
tensor(13.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16950/ 20000/ t/epoch=0.33............. Loss: -0.51349371, mean(E): -21.67258208+0.00000004j, var(E): 1.00889900
-0.0
tensor(13.6623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16960/ 20000/ t/epoch=0.33............. Loss: 0.28441190, mean(E): -21.77938490-0.00000015j, var(E): 0.67665663
-0.0
tensor(13.6634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16970/ 20000/ t/epoch=0.32............. Loss: 0.05129932, mean(E): -21.67962002-0.00000016j, var(E): 0.51639580
-0.0
tensor(13.6642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6646, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16980/ 20000/ t/epoch=0.33............. Loss: -0.18864722, mean(E): -21.67730900+0.00000008j, var(E): 0.46038047
-0.0
tensor(13.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 16990/ 20000/ t/epoch=0.33............. Loss: 0.02966201, mean(E): -21.69845648-0.00000036j, var(E): 0.96775065
-0.0
tensor(13.6652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17000/ 20000/ t/epoch=0.33............. Loss: -0.26985789, mean(E): -21.68038480+0.00000009j, var(E): 0.56559623
-0.0
tensor(13.6660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17010/ 20000/ t/epoch=0.33............. Loss: -1.02896409, mean(E): -21.52351495-0.00000051j, var(E): 0.96669649
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17020/ 20000/ t/epoch=0.33............. Loss: 0.02978157, mean(E): -21.69557965-0.00000041j, var(E): 0.68063849
-0.0
tensor(13.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17030/ 20000/ t/epoch=0.32............. Loss: 0.04070592, mean(E): -21.64010774+0.00000171j, var(E): 1.05029436
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17040/ 20000/ t/epoch=0.33............. Loss: 0.01924608, mean(E): -21.67077146-0.00000179j, var(E): 1.59455554
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17050/ 20000/ t/epoch=0.33............. Loss: -0.48341789, mean(E): -21.59138136-0.00000256j, var(E): 0.68234239
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17060/ 20000/ t/epoch=0.33............. Loss: -0.52282692, mean(E): -21.58639983+0.00000325j, var(E): 0.74948458
-0.0
tensor(13.6669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17070/ 20000/ t/epoch=0.33............. Loss: -0.77340261, mean(E): -21.55221764-0.00000108j, var(E): 0.61545109
-0.0
tensor(13.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17080/ 20000/ t/epoch=0.32............. Loss: 0.00354794, mean(E): -21.69329580+0.00000427j, var(E): 1.13202602
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17090/ 20000/ t/epoch=0.32............. Loss: -0.19894606, mean(E): -21.64575746-0.00001464j, var(E): 0.89663994
-0.0
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17100/ 20000/ t/epoch=0.32............. Loss: -0.86634510, mean(E): -21.56430759-0.00001342j, var(E): 1.10940710
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17110/ 20000/ t/epoch=0.32............. Loss: -0.03222802, mean(E): -21.63464676-0.00000793j, var(E): 0.80611931
-0.0
tensor(13.6682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6684, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6685, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6686, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6688, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17120/ 20000/ t/epoch=0.32............. Loss: 0.19751764, mean(E): -21.73705609-0.00000156j, var(E): 0.58724437
-0.0
tensor(13.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6690, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6691, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6692, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6693, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17130/ 20000/ t/epoch=0.32............. Loss: -0.24219554, mean(E): -21.63957357-0.00002077j, var(E): 0.63283944
-0.0
tensor(13.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6695, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6697, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6700, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6701, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17140/ 20000/ t/epoch=0.33............. Loss: 0.02073500, mean(E): -21.71509752+0.00002765j, var(E): 0.47666797
-0.0
tensor(13.6702, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6703, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6705, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6706, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6707, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17150/ 20000/ t/epoch=0.32............. Loss: -0.02347001, mean(E): -21.65908726-0.00000465j, var(E): 0.38586092
-0.0
tensor(13.6708, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6709, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17160/ 20000/ t/epoch=0.32............. Loss: -0.70347888, mean(E): -21.50922424-0.00005199j, var(E): 0.90285329
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6710, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17170/ 20000/ t/epoch=0.33............. Loss: 0.93356947, mean(E): -21.81511596-0.00006588j, var(E): 1.22859110
-0.0
tensor(13.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17180/ 20000/ t/epoch=0.32............. Loss: -0.21695088, mean(E): -21.64674758-0.00012660j, var(E): 0.90640118
-0.0
tensor(13.6712, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6713, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6716, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17190/ 20000/ t/epoch=0.32............. Loss: -0.38889284, mean(E): -21.60456939-0.00000951j, var(E): 0.64931592
-0.0
tensor(13.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6717, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6718, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6719, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6720, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6721, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6722, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17200/ 20000/ t/epoch=0.32............. Loss: -0.68029535, mean(E): -21.60649378-0.00008344j, var(E): 0.94047855
-0.0
tensor(13.6724, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6725, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6727, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6728, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6730, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6734, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6735, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6736, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17210/ 20000/ t/epoch=0.32............. Loss: -0.30232581, mean(E): -21.61854230+0.00002111j, var(E): 0.49732505
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17220/ 20000/ t/epoch=0.32............. Loss: -0.39594054, mean(E): -21.57995167+0.00006185j, var(E): 0.73540225
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17230/ 20000/ t/epoch=0.32............. Loss: -0.37261620, mean(E): -21.60175107-0.00008086j, var(E): 0.68582547
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6737, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6738, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6739, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17240/ 20000/ t/epoch=0.32............. Loss: 0.01303039, mean(E): -21.66947245-0.00004302j, var(E): 0.32626968
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6740, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17250/ 20000/ t/epoch=0.33............. Loss: -0.38457872, mean(E): -21.60145564-0.00001177j, var(E): 0.57937619
-0.0
tensor(13.6741, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17260/ 20000/ t/epoch=0.32............. Loss: -0.63841072, mean(E): -21.59315830+0.00002907j, var(E): 0.77051494
-0.0
tensor(13.6743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6745, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17270/ 20000/ t/epoch=0.32............. Loss: 0.41792948, mean(E): -21.73122986+0.00005512j, var(E): 0.72274003
-0.0
tensor(13.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6747, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6748, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6749, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17280/ 20000/ t/epoch=0.32............. Loss: -0.24066964, mean(E): -21.65703247+0.00001507j, var(E): 0.35863114
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17290/ 20000/ t/epoch=0.32............. Loss: -0.14486422, mean(E): -21.63813620-0.00001942j, var(E): 1.14957372
-0.0
tensor(13.6754, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17300/ 20000/ t/epoch=0.32............. Loss: -0.14121737, mean(E): -21.68774747+0.00010212j, var(E): 0.56380690
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6751, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6753, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6755, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6756, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6758, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17310/ 20000/ t/epoch=0.32............. Loss: 0.09273063, mean(E): -21.68624218-0.00004095j, var(E): 0.94634662
-0.0
tensor(13.6759, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6761, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6762, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6763, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6764, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6766, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17320/ 20000/ t/epoch=0.32............. Loss: -0.52374233, mean(E): -21.60879813+0.00004492j, var(E): 0.91678180
-0.0
tensor(13.6767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6768, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6769, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6770, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6771, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6773, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6774, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6775, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17330/ 20000/ t/epoch=0.32............. Loss: -0.52633338, mean(E): -21.55830449+0.00000788j, var(E): 0.50625197
-0.0
tensor(13.6776, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6777, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6779, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6780, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6781, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6782, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6783, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17340/ 20000/ t/epoch=0.32............. Loss: -0.36916356, mean(E): -21.60470914-0.00000879j, var(E): 0.37979671
-0.0
tensor(13.6784, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6785, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6786, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17350/ 20000/ t/epoch=0.32............. Loss: 0.26618945, mean(E): -21.70214875+0.00002067j, var(E): 0.68687354
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17360/ 20000/ t/epoch=0.32............. Loss: 0.68767030, mean(E): -21.79892271+0.00002523j, var(E): 0.97087696
-0.0
tensor(13.6787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6788, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6789, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6790, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6791, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17370/ 20000/ t/epoch=0.32............. Loss: -0.08796357, mean(E): -21.66328686-0.00004120j, var(E): 0.41672503
-0.0
tensor(13.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6792, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6793, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6794, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6796, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6797, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6798, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6799, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17380/ 20000/ t/epoch=0.33............. Loss: 0.15588501, mean(E): -21.73036162-0.00001105j, var(E): 0.78377629
-0.0
tensor(13.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6800, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6801, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17390/ 20000/ t/epoch=0.33............. Loss: -0.25694486, mean(E): -21.64485622-0.00000821j, var(E): 0.72995324
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17400/ 20000/ t/epoch=0.33............. Loss: -0.24914014, mean(E): -21.65944970-0.00009419j, var(E): 0.91373558
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6804, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6806, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6807, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6808, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6809, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6810, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6811, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17410/ 20000/ t/epoch=0.33............. Loss: -0.12903422, mean(E): -21.67612386+0.00004460j, var(E): 0.64355827
-0.0
tensor(13.6812, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6813, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6814, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6815, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6817, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6818, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17420/ 20000/ t/epoch=0.32............. Loss: -0.98915818, mean(E): -21.55278375+0.00000559j, var(E): 1.32723775
-0.0
tensor(13.6819, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6820, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6821, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6822, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6823, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6824, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17430/ 20000/ t/epoch=0.33............. Loss: -0.06799317, mean(E): -21.68714256-0.00001208j, var(E): 0.84074724
-0.0
tensor(13.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6826, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6827, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6828, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17440/ 20000/ t/epoch=0.32............. Loss: -0.22162598, mean(E): -21.59609103+0.00000446j, var(E): 0.78427359
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6830, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6831, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6832, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6834, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17450/ 20000/ t/epoch=0.33............. Loss: -0.36710780, mean(E): -21.62045747+0.00000648j, var(E): 0.55114022
-0.0
tensor(13.6836, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6838, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17460/ 20000/ t/epoch=0.33............. Loss: -0.25226101, mean(E): -21.63389437-0.00000704j, var(E): 0.35619813
-0.0
tensor(13.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6840, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17470/ 20000/ t/epoch=0.32............. Loss: 0.58744777, mean(E): -21.69187297-0.00002452j, var(E): 1.17768032
-0.0
tensor(13.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6842, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6845, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6848, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17480/ 20000/ t/epoch=0.33............. Loss: -0.98027678, mean(E): -21.53345803-0.00000760j, var(E): 0.90574792
-0.0
tensor(13.6849, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6851, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6853, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6856, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6859, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6860, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6861, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17490/ 20000/ t/epoch=0.32............. Loss: -0.33566615, mean(E): -21.61250223+0.00001103j, var(E): 0.89560613
-0.0
tensor(13.6862, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6864, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6865, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17500/ 20000/ t/epoch=0.33............. Loss: 0.22360024, mean(E): -21.71840326-0.00000577j, var(E): 0.74679351
-0.0
tensor(13.6867, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6868, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6869, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17510/ 20000/ t/epoch=0.32............. Loss: 0.18223956, mean(E): -21.72395596-0.00004689j, var(E): 0.64547891
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17520/ 20000/ t/epoch=0.33............. Loss: -0.24681087, mean(E): -21.64018228-0.00002326j, var(E): 0.53083406
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6871, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6872, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17530/ 20000/ t/epoch=0.32............. Loss: -0.82187476, mean(E): -21.50769309-0.00004274j, var(E): 1.43097809
-0.0
tensor(13.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17540/ 20000/ t/epoch=0.32............. Loss: 0.25072276, mean(E): -21.70915964+0.00000648j, var(E): 0.31994872
-0.0
tensor(13.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6876, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17550/ 20000/ t/epoch=0.32............. Loss: 0.71270737, mean(E): -21.82728086+0.00000240j, var(E): 1.26143935
-0.0
tensor(13.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6879, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6880, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6881, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6882, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6884, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6885, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6887, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17560/ 20000/ t/epoch=0.32............. Loss: -0.14767040, mean(E): -21.67375813+0.00004523j, var(E): 1.10508989
-0.0
tensor(13.6888, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6889, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6890, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6892, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6893, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6894, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6895, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17570/ 20000/ t/epoch=0.32............. Loss: -0.04716407, mean(E): -21.64412138-0.00002093j, var(E): 1.49081405
-0.0
tensor(13.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6896, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6897, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6898, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6899, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6900, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6901, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6902, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6903, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6904, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17580/ 20000/ t/epoch=0.32............. Loss: 0.21659001, mean(E): -21.73779000-0.00014345j, var(E): 0.77604958
-0.0
tensor(13.6905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6908, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6909, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6910, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6911, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6914, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17590/ 20000/ t/epoch=0.32............. Loss: 0.75644447, mean(E): -21.71333558-0.00021999j, var(E): 1.47536596
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17600/ 20000/ t/epoch=0.32............. Loss: -0.58329439, mean(E): -21.58153391-0.00002347j, var(E): 0.56556591
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6915, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6916, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6917, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6918, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17610/ 20000/ t/epoch=0.33............. Loss: -0.19331662, mean(E): -21.61434247-0.00003022j, var(E): 0.63726463
-0.0
tensor(13.6919, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6920, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6921, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6922, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6923, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6924, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6925, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17620/ 20000/ t/epoch=0.33............. Loss: -0.35468267, mean(E): -21.61711361-0.00006568j, var(E): 0.82659534
-0.0
tensor(13.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6926, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6927, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6928, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6929, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6930, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17630/ 20000/ t/epoch=0.32............. Loss: -0.37612258, mean(E): -21.57488996+0.00003286j, var(E): 0.57374786
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17640/ 20000/ t/epoch=0.32............. Loss: 0.05978501, mean(E): -21.70207366+0.00005150j, var(E): 0.60658849
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17650/ 20000/ t/epoch=0.33............. Loss: -0.04798338, mean(E): -21.67047819+0.00000129j, var(E): 0.79998539
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17660/ 20000/ t/epoch=0.32............. Loss: -0.50872744, mean(E): -21.64374359-0.00001456j, var(E): 1.41715868
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17670/ 20000/ t/epoch=0.33............. Loss: 0.03185868, mean(E): -21.68567319+0.00000243j, var(E): 0.51523622
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17680/ 20000/ t/epoch=0.32............. Loss: -0.09614318, mean(E): -21.67185303-0.00001618j, var(E): 1.12106082
-0.0
tensor(13.6931, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6933, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17690/ 20000/ t/epoch=0.33............. Loss: -0.32378094, mean(E): -21.58417504+0.00000096j, var(E): 0.73986269
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17700/ 20000/ t/epoch=0.33............. Loss: 0.00597814, mean(E): -21.70430857-0.00000725j, var(E): 0.38923028
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17710/ 20000/ t/epoch=0.33............. Loss: 1.37084046, mean(E): -21.82591618+0.00000168j, var(E): 4.36758856
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17720/ 20000/ t/epoch=0.33............. Loss: -0.05383572, mean(E): -21.68814495+0.00000364j, var(E): 0.40551618
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17730/ 20000/ t/epoch=0.32............. Loss: -0.01597471, mean(E): -21.69278284+0.00000082j, var(E): 1.03581079
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6935, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17740/ 20000/ t/epoch=0.33............. Loss: 0.22100758, mean(E): -21.71693714+0.00000501j, var(E): 0.46307448
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6936, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17750/ 20000/ t/epoch=0.33............. Loss: 0.52266929, mean(E): -21.74062494-0.00000276j, var(E): 0.93054091
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17760/ 20000/ t/epoch=0.33............. Loss: 0.20869121, mean(E): -21.70663273+0.00000015j, var(E): 0.87948449
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6938, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6939, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6940, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17770/ 20000/ t/epoch=0.32............. Loss: -0.53060331, mean(E): -21.57016104+0.00000402j, var(E): 1.33528095
-0.0
tensor(13.6941, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6942, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6943, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6944, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6945, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17780/ 20000/ t/epoch=0.32............. Loss: 0.17430405, mean(E): -21.66853631-0.00000343j, var(E): 1.14860795
-0.0
tensor(13.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6946, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6947, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6948, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17790/ 20000/ t/epoch=0.33............. Loss: -0.42350943, mean(E): -21.59713381+0.00000018j, var(E): 0.89612772
-0.0
tensor(13.6949, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6952, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6953, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6955, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6956, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6957, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6958, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6959, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17800/ 20000/ t/epoch=0.33............. Loss: -0.06529885, mean(E): -21.69562950-0.00000041j, var(E): 0.43894804
-0.0
tensor(13.6960, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6962, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6963, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6964, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6965, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6966, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17810/ 20000/ t/epoch=0.32............. Loss: -0.25316649, mean(E): -21.62196625-0.00000206j, var(E): 0.61168288
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17820/ 20000/ t/epoch=0.32............. Loss: 0.52824851, mean(E): -21.77591855+0.00000088j, var(E): 0.83098186
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17830/ 20000/ t/epoch=0.32............. Loss: -0.15051034, mean(E): -21.60822736-0.00000140j, var(E): 0.47368944
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17840/ 20000/ t/epoch=0.32............. Loss: 0.05602922, mean(E): -21.68697838+0.00000090j, var(E): 0.40158903
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17850/ 20000/ t/epoch=0.32............. Loss: -0.51636110, mean(E): -21.61117084-0.00000074j, var(E): 1.99286001
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17860/ 20000/ t/epoch=0.32............. Loss: 0.28411222, mean(E): -21.74299453-0.00000026j, var(E): 0.61897888
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17870/ 20000/ t/epoch=0.32............. Loss: 0.31501288, mean(E): -21.72729021-0.00000007j, var(E): 1.14059927
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17880/ 20000/ t/epoch=0.32............. Loss: 0.68575932, mean(E): -21.78798380+0.00000043j, var(E): 1.52467044
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17890/ 20000/ t/epoch=0.33............. Loss: 0.44895427, mean(E): -21.82545913+0.00000118j, var(E): 0.92438149
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17900/ 20000/ t/epoch=0.33............. Loss: -0.71389488, mean(E): -21.54779019-0.00000026j, var(E): 1.04480790
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17910/ 20000/ t/epoch=0.32............. Loss: 0.18689716, mean(E): -21.72326412+0.00000256j, var(E): 0.94579071
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17920/ 20000/ t/epoch=0.33............. Loss: -1.28885900, mean(E): -21.45219571-0.00000061j, var(E): 1.44855329
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6972, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6973, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6974, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6975, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6977, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17930/ 20000/ t/epoch=0.32............. Loss: -0.54985721, mean(E): -21.55994387+0.00000176j, var(E): 1.26715301
-0.0
tensor(13.6978, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6981, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6982, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6983, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6984, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6985, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6986, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17940/ 20000/ t/epoch=0.32............. Loss: 0.09687743, mean(E): -21.72860885-0.00000038j, var(E): 0.65777953
-0.0
tensor(13.6987, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6988, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6989, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6990, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6991, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17950/ 20000/ t/epoch=0.33............. Loss: -0.50627978, mean(E): -21.57660383-0.00000112j, var(E): 0.56282940
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17960/ 20000/ t/epoch=0.32............. Loss: 0.00494909, mean(E): -21.67774552-0.00000046j, var(E): 0.62700595
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17970/ 20000/ t/epoch=0.32............. Loss: 0.46312373, mean(E): -21.76196785-0.00000056j, var(E): 0.93932219
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17980/ 20000/ t/epoch=0.32............. Loss: 0.15613277, mean(E): -21.68640475-0.00000072j, var(E): 0.82169389
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 17990/ 20000/ t/epoch=0.33............. Loss: -0.04641927, mean(E): -21.65615093-0.00000021j, var(E): 0.40642662
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6992, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18000/ 20000/ t/epoch=0.32............. Loss: -0.11901990, mean(E): -21.64277307-0.00000011j, var(E): 0.55253743
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6993, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18010/ 20000/ t/epoch=0.33............. Loss: 0.03949894, mean(E): -21.65946316-0.00000052j, var(E): 1.42027766
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6995, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6997, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18020/ 20000/ t/epoch=0.33............. Loss: -0.29427164, mean(E): -21.65744430+0.00000015j, var(E): 0.66237712
-0.0
tensor(13.6998, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7001, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7002, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18030/ 20000/ t/epoch=0.32............. Loss: -0.00671340, mean(E): -21.68630275+0.00000080j, var(E): 1.30078807
-0.0
tensor(13.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7003, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7004, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7006, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7007, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18040/ 20000/ t/epoch=0.32............. Loss: 0.47533537, mean(E): -21.70525728-0.00000013j, var(E): 2.10003832
-0.0
tensor(13.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7008, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7012, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7013, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7014, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7016, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18050/ 20000/ t/epoch=0.33............. Loss: -0.14297135, mean(E): -21.71660320+0.00000119j, var(E): 0.69830101
-0.0
tensor(13.7017, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7018, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7019, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7020, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7021, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7022, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18060/ 20000/ t/epoch=0.33............. Loss: -0.20732034, mean(E): -21.64357010+0.00000014j, var(E): 0.92577012
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7024, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7025, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18070/ 20000/ t/epoch=0.32............. Loss: -0.52594835, mean(E): -21.59762724-0.00000006j, var(E): 0.86765095
-0.0
tensor(13.7026, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7028, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18080/ 20000/ t/epoch=0.33............. Loss: -0.20024709, mean(E): -21.66379256-0.00000076j, var(E): 0.64563268
-0.0
tensor(13.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7030, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7031, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7032, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18090/ 20000/ t/epoch=0.33............. Loss: -0.18703855, mean(E): -21.66017513-0.00000118j, var(E): 0.81298742
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18100/ 20000/ t/epoch=0.33............. Loss: -0.18514070, mean(E): -21.66754006-0.00000080j, var(E): 1.37977647
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18110/ 20000/ t/epoch=0.33............. Loss: 0.43567311, mean(E): -21.70578326-0.00000046j, var(E): 1.00097029
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18120/ 20000/ t/epoch=0.32............. Loss: 0.09773138, mean(E): -21.70473135-0.00000110j, var(E): 0.94933682
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18130/ 20000/ t/epoch=0.32............. Loss: 0.52844935, mean(E): -21.78819888+0.00000054j, var(E): 1.73427719
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18140/ 20000/ t/epoch=0.32............. Loss: -0.41024119, mean(E): -21.64619826-0.00000021j, var(E): 0.66480899
-0.0
tensor(13.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7040, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18150/ 20000/ t/epoch=0.32............. Loss: -0.29173265, mean(E): -21.64694958+0.00000085j, var(E): 1.30383889
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18160/ 20000/ t/epoch=0.32............. Loss: 0.05173595, mean(E): -21.71173220+0.00000053j, var(E): 0.80525871
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18170/ 20000/ t/epoch=0.32............. Loss: -0.04175977, mean(E): -21.65828149+0.00000055j, var(E): 0.55273647
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7033, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7034, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18180/ 20000/ t/epoch=0.32............. Loss: 0.06174974, mean(E): -21.69995108-0.00000082j, var(E): 0.69599517
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7035, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7036, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7038, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7039, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7041, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7042, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18190/ 20000/ t/epoch=0.32............. Loss: -0.16902243, mean(E): -21.66052627+0.00000110j, var(E): 0.55655581
-0.0
tensor(13.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18200/ 20000/ t/epoch=0.33............. Loss: 0.01480936, mean(E): -21.69123849-0.00000093j, var(E): 0.44640612
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18210/ 20000/ t/epoch=0.32............. Loss: -0.48612191, mean(E): -21.55919590+0.00000082j, var(E): 0.49341428
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18220/ 20000/ t/epoch=0.33............. Loss: 0.02071296, mean(E): -21.67214892-0.00000110j, var(E): 0.52612988
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18230/ 20000/ t/epoch=0.32............. Loss: 0.14206426, mean(E): -21.63616285+0.00000108j, var(E): 0.88845819
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18240/ 20000/ t/epoch=0.32............. Loss: -0.32882491, mean(E): -21.60821688+0.00000154j, var(E): 0.71487011
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7044, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7045, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7046, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7048, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7049, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18250/ 20000/ t/epoch=0.33............. Loss: 0.10146777, mean(E): -21.67796692-0.00000143j, var(E): 0.62704889
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7050, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7051, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18260/ 20000/ t/epoch=0.33............. Loss: 0.22545363, mean(E): -21.68817726+0.00000083j, var(E): 0.95478976
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18270/ 20000/ t/epoch=0.33............. Loss: 0.21052366, mean(E): -21.74477626-0.00000011j, var(E): 1.02872386
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7052, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7053, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7054, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18280/ 20000/ t/epoch=0.32............. Loss: -0.54480458, mean(E): -21.58986033+0.00000074j, var(E): 0.96918793
-0.0
tensor(13.7055, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7056, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7057, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7059, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7060, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18290/ 20000/ t/epoch=0.33............. Loss: -0.17419349, mean(E): -21.62681066-0.00000170j, var(E): 0.32067318
-0.0
tensor(13.7061, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7064, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7065, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18300/ 20000/ t/epoch=0.33............. Loss: -1.24892419, mean(E): -21.50625903-0.00000042j, var(E): 1.21174979
-0.0
tensor(13.7066, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7067, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7068, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7070, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7071, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18310/ 20000/ t/epoch=0.32............. Loss: -0.36171860, mean(E): -21.62962853-0.00000132j, var(E): 0.66516186
-0.0
tensor(13.7073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7074, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7075, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7076, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7078, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7079, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7080, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7081, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7082, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7083, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18320/ 20000/ t/epoch=0.33............. Loss: 0.48249684, mean(E): -21.68466275+0.00000615j, var(E): 2.05471197
-0.0
tensor(13.7084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7085, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7086, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7087, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7088, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7089, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18330/ 20000/ t/epoch=0.32............. Loss: 0.24270852, mean(E): -21.74068788+0.00000581j, var(E): 0.50204943
-0.0
tensor(13.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7091, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7092, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7093, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18340/ 20000/ t/epoch=0.32............. Loss: -0.62769058, mean(E): -21.61495430+0.00000226j, var(E): 0.99143600
-0.0
tensor(13.7094, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7095, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7096, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7099, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7100, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7101, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18350/ 20000/ t/epoch=0.33............. Loss: -0.42802599, mean(E): -21.63394673-0.00000943j, var(E): 0.80767852
-0.0
tensor(13.7102, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7103, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7104, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7105, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7106, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7107, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7108, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18360/ 20000/ t/epoch=0.32............. Loss: -0.05828969, mean(E): -21.67547242-0.00000613j, var(E): 0.63619498
-0.0
tensor(13.7109, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7110, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7111, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7112, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7113, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7114, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18370/ 20000/ t/epoch=0.32............. Loss: -0.01387414, mean(E): -21.70941309-0.00003067j, var(E): 0.68161881
-0.0
tensor(13.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7115, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7116, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7117, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18380/ 20000/ t/epoch=0.32............. Loss: -0.17138534, mean(E): -21.65281285-0.00002762j, var(E): 0.25594412
-0.0
tensor(13.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7118, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7119, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7120, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7121, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18390/ 20000/ t/epoch=0.32............. Loss: -0.61452338, mean(E): -21.52736436+0.00002922j, var(E): 0.69062926
-0.0
tensor(13.7122, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7123, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7124, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7125, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7126, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7127, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18400/ 20000/ t/epoch=0.32............. Loss: 0.53559771, mean(E): -21.75066321+0.00007784j, var(E): 0.97854306
-0.0
tensor(13.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7128, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7130, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18410/ 20000/ t/epoch=0.32............. Loss: -0.11498471, mean(E): -21.65276477+0.00000236j, var(E): 0.69863866
-0.0
tensor(13.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7132, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18420/ 20000/ t/epoch=0.32............. Loss: -0.48205968, mean(E): -21.55237965+0.00003822j, var(E): 1.36921622
-0.0
tensor(13.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7133, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7134, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7136, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18430/ 20000/ t/epoch=0.32............. Loss: 0.36508432, mean(E): -21.71669564+0.00002857j, var(E): 1.79565278
-0.0
tensor(13.7137, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18440/ 20000/ t/epoch=0.33............. Loss: 0.74450233, mean(E): -21.77489012+0.00012518j, var(E): 1.27230959
-0.0
tensor(13.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7139, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7140, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18450/ 20000/ t/epoch=0.32............. Loss: 0.06346859, mean(E): -21.68663140-0.00008906j, var(E): 0.22010802
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7141, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18460/ 20000/ t/epoch=0.33............. Loss: -0.33599454, mean(E): -21.63494387-0.00007230j, var(E): 0.72138248
-0.0
tensor(13.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7144, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7145, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18470/ 20000/ t/epoch=0.33............. Loss: 0.18257099, mean(E): -21.70897096+0.00003808j, var(E): 0.51538736
-0.0
tensor(13.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7146, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7147, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7148, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7150, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18480/ 20000/ t/epoch=0.32............. Loss: 0.24550953, mean(E): -21.72155016+0.00009867j, var(E): 0.79970873
-0.0
tensor(13.7151, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7153, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7155, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7156, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7157, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7158, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18490/ 20000/ t/epoch=0.32............. Loss: -0.26768521, mean(E): -21.65423003-0.00001048j, var(E): 0.85085488
-0.0
tensor(13.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7161, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7162, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7163, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7164, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18500/ 20000/ t/epoch=0.33............. Loss: 0.58961250, mean(E): -21.75054484-0.00000968j, var(E): 1.24260690
-0.0
tensor(13.7165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7166, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7167, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7168, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7169, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7170, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18510/ 20000/ t/epoch=0.32............. Loss: 0.10324021, mean(E): -21.69088877+0.00003397j, var(E): 1.13075624
-0.0
tensor(13.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7172, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7173, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7174, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7175, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18520/ 20000/ t/epoch=0.33............. Loss: -0.18632279, mean(E): -21.63293572+0.00009869j, var(E): 0.68281270
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18530/ 20000/ t/epoch=0.33............. Loss: 0.40191462, mean(E): -21.69545902+0.00004537j, var(E): 1.04297765
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18540/ 20000/ t/epoch=0.33............. Loss: -0.12755745, mean(E): -21.63351476-0.00000618j, var(E): 0.63508422
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7176, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7177, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7178, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7179, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7180, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7181, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18550/ 20000/ t/epoch=0.33............. Loss: -0.02711868, mean(E): -21.63608107-0.00002886j, var(E): 1.34534245
-0.0
tensor(13.7182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7183, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7184, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7186, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18560/ 20000/ t/epoch=0.32............. Loss: -0.04906951, mean(E): -21.72813474+0.00001112j, var(E): 1.12175721
-0.0
tensor(13.7187, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7189, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7191, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7193, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18570/ 20000/ t/epoch=0.33............. Loss: 0.52698603, mean(E): -21.77691770-0.00001995j, var(E): 0.78350507
-0.0
tensor(13.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7194, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7196, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7197, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7198, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7199, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7200, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18580/ 20000/ t/epoch=0.32............. Loss: 0.02478780, mean(E): -21.66177335-0.00000856j, var(E): 0.93109129
-0.0
tensor(13.7201, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7203, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7204, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7205, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7207, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7208, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18590/ 20000/ t/epoch=0.33............. Loss: -0.15737099, mean(E): -21.62340856-0.00001601j, var(E): 0.48779162
-0.0
tensor(13.7209, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7210, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7211, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7212, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18600/ 20000/ t/epoch=0.32............. Loss: -0.50580646, mean(E): -21.61270670+0.00001477j, var(E): 0.75185397
-0.0
tensor(13.7214, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7215, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7218, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7219, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7220, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7221, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7222, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7223, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18610/ 20000/ t/epoch=0.32............. Loss: -0.33299297, mean(E): -21.65682518-0.00008005j, var(E): 0.82389093
-0.0
tensor(13.7224, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7226, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7227, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7228, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7229, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18620/ 20000/ t/epoch=0.32............. Loss: -0.05075720, mean(E): -21.67713930+0.00001746j, var(E): 0.46489965
-0.0
tensor(13.7230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7231, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7233, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18630/ 20000/ t/epoch=0.32............. Loss: -0.19897219, mean(E): -21.66696634+0.00000246j, var(E): 1.32948571
-0.0
tensor(13.7234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7237, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7238, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18640/ 20000/ t/epoch=0.32............. Loss: 0.08989633, mean(E): -21.69693781-0.00002225j, var(E): 0.32187309
-0.0
tensor(13.7240, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7241, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7242, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7243, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7244, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7245, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7247, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18650/ 20000/ t/epoch=0.32............. Loss: -0.39598266, mean(E): -21.65495392+0.00013792j, var(E): 0.63853688
-0.0
tensor(13.7248, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7250, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18660/ 20000/ t/epoch=0.33............. Loss: 0.91867629, mean(E): -21.78617837-0.00002406j, var(E): 1.70644854
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7251, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7252, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7253, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18670/ 20000/ t/epoch=0.33............. Loss: -0.36868532, mean(E): -21.61510638-0.00011612j, var(E): 1.00991812
-0.0
tensor(13.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7255, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7256, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7257, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7258, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7259, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7261, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18680/ 20000/ t/epoch=0.33............. Loss: 0.28349558, mean(E): -21.67595043-0.00001047j, var(E): 1.01853976
-0.0
tensor(13.7262, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7264, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7265, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7266, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7268, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18690/ 20000/ t/epoch=0.32............. Loss: -0.55879626, mean(E): -21.56541406-0.00008897j, var(E): 1.05710346
-0.0
tensor(13.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7270, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7272, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7273, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7274, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18700/ 20000/ t/epoch=0.32............. Loss: 0.39241813, mean(E): -21.72991953+0.00000545j, var(E): 1.11205882
-0.0
tensor(13.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18710/ 20000/ t/epoch=0.32............. Loss: 0.26404989, mean(E): -21.71672038-0.00000326j, var(E): 0.80984452
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18720/ 20000/ t/epoch=0.32............. Loss: -0.74627360, mean(E): -21.51206563+0.00002388j, var(E): 1.42127957
-0.0
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18730/ 20000/ t/epoch=0.32............. Loss: 0.35888105, mean(E): -21.71750198-0.00001754j, var(E): 1.11019035
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18740/ 20000/ t/epoch=0.32............. Loss: 0.52014675, mean(E): -21.73768085+0.00000817j, var(E): 0.89268742
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18750/ 20000/ t/epoch=0.32............. Loss: -0.44873116, mean(E): -21.63622049+0.00000735j, var(E): 1.57444844
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18760/ 20000/ t/epoch=0.32............. Loss: 0.08862006, mean(E): -21.70990729+0.00000376j, var(E): 0.29299567
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18770/ 20000/ t/epoch=0.33............. Loss: 0.25288172, mean(E): -21.75762400+0.00002833j, var(E): 0.51516365
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18780/ 20000/ t/epoch=0.32............. Loss: 0.23533700, mean(E): -21.73528498+0.00004981j, var(E): 0.97241033
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18790/ 20000/ t/epoch=0.33............. Loss: 0.06257914, mean(E): -21.69734592-0.00017166j, var(E): 1.04705114
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18800/ 20000/ t/epoch=0.32............. Loss: -0.05967450, mean(E): -21.64486646+0.00003709j, var(E): 0.78435180
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18810/ 20000/ t/epoch=0.32............. Loss: 0.02875151, mean(E): -21.70582154-0.00008010j, var(E): 0.70453195
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18820/ 20000/ t/epoch=0.32............. Loss: 0.16724104, mean(E): -21.70939166+0.00001049j, var(E): 0.93385311
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7275, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18830/ 20000/ t/epoch=0.32............. Loss: -0.06475741, mean(E): -21.70775736+0.00010830j, var(E): 0.87508421
-0.0
tensor(13.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7276, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7278, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7279, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7281, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7282, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7283, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18840/ 20000/ t/epoch=0.32............. Loss: -0.24596578, mean(E): -21.68507291-0.00007176j, var(E): 0.84846758
-0.0
tensor(13.7284, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7285, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18850/ 20000/ t/epoch=0.33............. Loss: 0.10164732, mean(E): -21.68079873+0.00007259j, var(E): 0.99317494
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7286, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7287, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18860/ 20000/ t/epoch=0.33............. Loss: -0.62516786, mean(E): -21.55695821-0.00003539j, var(E): 0.79028274
-0.0
tensor(13.7288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7289, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7291, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7292, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7293, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18870/ 20000/ t/epoch=0.32............. Loss: 0.02168639, mean(E): -21.67927799+0.00010358j, var(E): 0.91402970
-0.0
tensor(13.7295, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18880/ 20000/ t/epoch=0.33............. Loss: -0.20977940, mean(E): -21.65424156+0.00000698j, var(E): 0.42511859
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7296, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18890/ 20000/ t/epoch=0.32............. Loss: -0.57993997, mean(E): -21.58374246-0.00002871j, var(E): 1.01771104
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7297, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7298, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7299, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7301, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18900/ 20000/ t/epoch=0.33............. Loss: -0.15802676, mean(E): -21.69039241-0.00002806j, var(E): 0.89846534
-0.0
tensor(13.7302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7303, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7304, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18910/ 20000/ t/epoch=0.32............. Loss: -0.48793320, mean(E): -21.61560112-0.00003187j, var(E): 0.93031784
-0.0
tensor(13.7305, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7306, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7307, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18920/ 20000/ t/epoch=0.32............. Loss: 0.07935677, mean(E): -21.72041574-0.00001449j, var(E): 0.69246161
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18930/ 20000/ t/epoch=0.32............. Loss: -0.24020713, mean(E): -21.59873911+0.00002649j, var(E): 0.65568721
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7310, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7311, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18940/ 20000/ t/epoch=0.33............. Loss: -0.26655633, mean(E): -21.65749879-0.00000894j, var(E): 0.75770385
-0.0
tensor(13.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7312, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7313, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18950/ 20000/ t/epoch=0.32............. Loss: 0.24269044, mean(E): -21.72720873+0.00000471j, var(E): 1.23853507
-0.0
tensor(13.7314, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7315, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7317, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7318, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7319, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18960/ 20000/ t/epoch=0.32............. Loss: -0.37653541, mean(E): -21.58727361+0.00000830j, var(E): 0.68736163
-0.0
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7320, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18970/ 20000/ t/epoch=0.33............. Loss: 0.16105479, mean(E): -21.71445193-0.00000022j, var(E): 0.64957159
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7321, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7322, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7323, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7324, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7326, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18980/ 20000/ t/epoch=0.33............. Loss: -0.00869877, mean(E): -21.67628085+0.00005291j, var(E): 0.76922788
-0.0
tensor(13.7327, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7328, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7329, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7330, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7331, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 18990/ 20000/ t/epoch=0.33............. Loss: 0.24901002, mean(E): -21.69600461+0.00001193j, var(E): 1.43805685
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19000/ 20000/ t/epoch=0.33............. Loss: -0.00113644, mean(E): -21.68903134+0.00001675j, var(E): 0.79156851
-0.0
tensor(13.7332, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7333, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7335, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19010/ 20000/ t/epoch=0.33............. Loss: -0.58623994, mean(E): -21.59530859+0.00000343j, var(E): 0.81917595
-0.0
tensor(13.7336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7337, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7339, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7340, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7341, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19020/ 20000/ t/epoch=0.33............. Loss: -0.05005634, mean(E): -21.64242835+0.00002015j, var(E): 0.59252457
-0.0
tensor(13.7342, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7343, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7344, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19030/ 20000/ t/epoch=0.33............. Loss: 0.01619760, mean(E): -21.69746598+0.00003929j, var(E): 0.67467255
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7345, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7346, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19040/ 20000/ t/epoch=0.33............. Loss: 0.39183042, mean(E): -21.74468508+0.00000162j, var(E): 0.92288480
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7347, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7348, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19050/ 20000/ t/epoch=0.32............. Loss: -0.00541051, mean(E): -21.70215574-0.00002151j, var(E): 0.98110500
-0.0
tensor(13.7349, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19060/ 20000/ t/epoch=0.32............. Loss: 0.25952486, mean(E): -21.74393484+0.00003287j, var(E): 1.02729000
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7350, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7352, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7353, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19070/ 20000/ t/epoch=0.33............. Loss: -0.75302699, mean(E): -21.56951869+0.00005395j, var(E): 0.89963999
-0.0
tensor(13.7354, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7355, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7356, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7357, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7358, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19080/ 20000/ t/epoch=0.32............. Loss: -0.21332740, mean(E): -21.66907766+0.00000104j, var(E): 0.51750784
-0.0
tensor(13.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7359, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7361, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19090/ 20000/ t/epoch=0.33............. Loss: -0.21667260, mean(E): -21.66321294+0.00002884j, var(E): 1.05994563
-0.0
tensor(13.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7363, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7364, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7365, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7366, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7367, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7369, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19100/ 20000/ t/epoch=0.33............. Loss: -0.33522870, mean(E): -21.56416548+0.00004329j, var(E): 2.21260443
-0.0
tensor(13.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7370, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7374, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7375, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7376, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19110/ 20000/ t/epoch=0.32............. Loss: 0.09024557, mean(E): -21.63918697-0.00003112j, var(E): 1.46156806
-0.0
tensor(13.7377, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7379, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7380, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7381, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7382, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7383, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7384, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19120/ 20000/ t/epoch=0.33............. Loss: -0.15232553, mean(E): -21.66364803-0.00008634j, var(E): 0.98567759
-0.0
tensor(13.7385, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7386, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7387, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19130/ 20000/ t/epoch=0.33............. Loss: 0.41582013, mean(E): -21.71437213-0.00004455j, var(E): 1.60924013
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19140/ 20000/ t/epoch=0.32............. Loss: 1.26220563, mean(E): -21.85110918-0.00011801j, var(E): 1.86982499
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19150/ 20000/ t/epoch=0.33............. Loss: -0.19662523, mean(E): -21.65802144+0.00000179j, var(E): 0.35760661
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19160/ 20000/ t/epoch=0.32............. Loss: -0.11189940, mean(E): -21.65583183-0.00001658j, var(E): 1.18332312
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7388, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7390, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19170/ 20000/ t/epoch=0.33............. Loss: 0.59535821, mean(E): -21.78999714+0.00000171j, var(E): 0.66032942
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7391, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7392, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7393, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7394, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7395, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7396, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7398, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7399, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19180/ 20000/ t/epoch=0.32............. Loss: -0.45118461, mean(E): -21.60215479+0.00002264j, var(E): 0.49817807
-0.0
tensor(13.7400, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7401, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7402, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7403, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7404, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7406, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7407, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7408, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19190/ 20000/ t/epoch=0.33............. Loss: -0.61200547, mean(E): -21.59394703+0.00002735j, var(E): 1.19499655
-0.0
tensor(13.7409, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7410, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7412, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7413, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7414, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7416, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7417, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7418, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7421, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19200/ 20000/ t/epoch=0.33............. Loss: -0.25932448, mean(E): -21.63467849-0.00002871j, var(E): 0.63571154
-0.0
tensor(13.7422, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7425, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7426, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7428, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7429, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7431, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7432, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7434, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19210/ 20000/ t/epoch=0.32............. Loss: 0.09936889, mean(E): -21.69249962+0.00001104j, var(E): 1.28464017
-0.0
tensor(13.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7437, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7438, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7439, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7440, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7442, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19220/ 20000/ t/epoch=0.32............. Loss: -0.05491927, mean(E): -21.71203240+0.00000863j, var(E): 1.19980015
-0.0
tensor(13.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7443, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7444, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19230/ 20000/ t/epoch=0.33............. Loss: -0.24171213, mean(E): -21.66735704-0.00000455j, var(E): 0.69805926
-0.0
tensor(13.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7446, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7447, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7448, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19240/ 20000/ t/epoch=0.32............. Loss: -0.80467949, mean(E): -21.56385200-0.00000296j, var(E): 1.29394802
-0.0
tensor(13.7449, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7450, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7451, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7453, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7454, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7455, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19250/ 20000/ t/epoch=0.32............. Loss: 0.18676073, mean(E): -21.70992596+0.00000305j, var(E): 0.45981361
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19260/ 20000/ t/epoch=0.33............. Loss: -0.43147132, mean(E): -21.61566191-0.00000302j, var(E): 0.99285261
-0.0
tensor(13.7456, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7459, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7461, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19270/ 20000/ t/epoch=0.32............. Loss: -0.07931634, mean(E): -21.70798587-0.00002552j, var(E): 0.54204867
-0.0
tensor(13.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7463, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7464, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7465, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7466, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19280/ 20000/ t/epoch=0.32............. Loss: -0.20626844, mean(E): -21.62707615+0.00000362j, var(E): 0.61303693
-0.0
tensor(13.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7468, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7469, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7470, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19290/ 20000/ t/epoch=0.33............. Loss: -0.43628298, mean(E): -21.58213109-0.00000288j, var(E): 0.61127990
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7471, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7472, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7473, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7474, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7475, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19300/ 20000/ t/epoch=0.32............. Loss: -0.15923137, mean(E): -21.63937128-0.00000162j, var(E): 0.61159600
-0.0
tensor(13.7477, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7478, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19310/ 20000/ t/epoch=0.32............. Loss: -0.34642911, mean(E): -21.63933032-0.00000683j, var(E): 0.84501449
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19320/ 20000/ t/epoch=0.32............. Loss: -0.00650942, mean(E): -21.72189932+0.00000371j, var(E): 0.65280704
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19330/ 20000/ t/epoch=0.32............. Loss: -0.01419334, mean(E): -21.67574507-0.00000585j, var(E): 0.44037211
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19340/ 20000/ t/epoch=0.33............. Loss: -0.21842302, mean(E): -21.65506586-0.00000097j, var(E): 1.44733272
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7480, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7481, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19350/ 20000/ t/epoch=0.32............. Loss: -0.53482328, mean(E): -21.58318588-0.00000009j, var(E): 0.99915618
-0.0
tensor(13.7483, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7484, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7487, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7488, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7489, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7490, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19360/ 20000/ t/epoch=0.32............. Loss: -0.38683654, mean(E): -21.61456631+0.00000414j, var(E): 0.68306311
-0.0
tensor(13.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7492, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7493, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7496, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19370/ 20000/ t/epoch=0.33............. Loss: 0.19957195, mean(E): -21.72164036+0.00000062j, var(E): 0.44712735
-0.0
tensor(13.7497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7498, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7499, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7500, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7503, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7504, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7505, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7507, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7508, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19380/ 20000/ t/epoch=0.32............. Loss: -0.34085731, mean(E): -21.62740688-0.00000190j, var(E): 0.94541141
-0.0
tensor(13.7510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7511, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7512, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7513, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7514, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19390/ 20000/ t/epoch=0.32............. Loss: -0.54428315, mean(E): -21.55924313+0.00000364j, var(E): 0.62943198
-0.0
tensor(13.7515, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7517, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7518, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7519, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19400/ 20000/ t/epoch=0.33............. Loss: -0.58163157, mean(E): -21.59921799+0.00000151j, var(E): 0.81205366
-0.0
tensor(13.7521, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7522, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7523, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7524, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19410/ 20000/ t/epoch=0.32............. Loss: -0.06327002, mean(E): -21.68814568+0.00001641j, var(E): 0.86988534
-0.0
tensor(13.7525, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19420/ 20000/ t/epoch=0.32............. Loss: -0.16700448, mean(E): -21.67613170+0.00000215j, var(E): 0.65451016
-0.0
tensor(13.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7528, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7530, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19430/ 20000/ t/epoch=0.32............. Loss: 0.22131707, mean(E): -21.71752013-0.00000400j, var(E): 0.59545628
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19440/ 20000/ t/epoch=0.32............. Loss: -0.24820703, mean(E): -21.64319917-0.00000610j, var(E): 1.85202166
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7531, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7532, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19450/ 20000/ t/epoch=0.33............. Loss: -0.59381575, mean(E): -21.62568684+0.00000234j, var(E): 0.54305333
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19460/ 20000/ t/epoch=0.32............. Loss: -0.16045268, mean(E): -21.65611092+0.00000548j, var(E): 0.76501690
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7534, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7535, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19470/ 20000/ t/epoch=0.32............. Loss: 0.17547844, mean(E): -21.67008739-0.00001125j, var(E): 1.12880228
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19480/ 20000/ t/epoch=0.32............. Loss: 0.16671538, mean(E): -21.73754965-0.00000283j, var(E): 1.46864421
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19490/ 20000/ t/epoch=0.32............. Loss: 0.21394795, mean(E): -21.71121019+0.00001187j, var(E): 1.55765275
-0.0
tensor(13.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19500/ 20000/ t/epoch=0.32............. Loss: -0.12397615, mean(E): -21.64279318+0.00001786j, var(E): 0.29607451
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19510/ 20000/ t/epoch=0.32............. Loss: 0.13107198, mean(E): -21.70397708-0.00001321j, var(E): 0.71940528
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19520/ 20000/ t/epoch=0.33............. Loss: 0.42743184, mean(E): -21.72261003+0.00002794j, var(E): 0.76008311
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19530/ 20000/ t/epoch=0.32............. Loss: -0.56596349, mean(E): -21.59831072-0.00004790j, var(E): 1.40393232
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19540/ 20000/ t/epoch=0.32............. Loss: -0.12430345, mean(E): -21.67108933+0.00004598j, var(E): 1.19836852
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7536, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7537, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7538, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19550/ 20000/ t/epoch=0.32............. Loss: 0.31050300, mean(E): -21.72084901+0.00000907j, var(E): 0.55811951
-0.0
tensor(13.7539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7541, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7543, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19560/ 20000/ t/epoch=0.32............. Loss: 0.07410213, mean(E): -21.70242731+0.00003114j, var(E): 0.92986419
-0.0
tensor(13.7545, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7546, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7548, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7549, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7550, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19570/ 20000/ t/epoch=0.32............. Loss: -0.25103513, mean(E): -21.65795988-0.00000336j, var(E): 1.00630316
-0.0
tensor(13.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7551, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7553, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19580/ 20000/ t/epoch=0.33............. Loss: -0.29253279, mean(E): -21.61580597+0.00005501j, var(E): 0.66761999
-0.0
tensor(13.7554, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7555, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7556, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7557, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7558, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19590/ 20000/ t/epoch=0.33............. Loss: -0.21096561, mean(E): -21.65659842-0.00001016j, var(E): 0.92496787
-0.0
tensor(13.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7560, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7561, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7562, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7564, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7565, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7566, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19600/ 20000/ t/epoch=0.33............. Loss: 0.61535636, mean(E): -21.73489118+0.00010367j, var(E): 1.98570439
-0.0
tensor(13.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7568, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19610/ 20000/ t/epoch=0.33............. Loss: -0.24259507, mean(E): -21.66291139-0.00001909j, var(E): 0.61098315
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7569, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19620/ 20000/ t/epoch=0.32............. Loss: -0.20569847, mean(E): -21.66829095-0.00000477j, var(E): 0.91316571
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7570, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7571, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19630/ 20000/ t/epoch=0.32............. Loss: -0.24912356, mean(E): -21.65853712-0.00001006j, var(E): 0.68690136
-0.0
tensor(13.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7574, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7575, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19640/ 20000/ t/epoch=0.32............. Loss: -0.09055917, mean(E): -21.62941182-0.00003603j, var(E): 0.71012595
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7576, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19650/ 20000/ t/epoch=0.33............. Loss: 0.14529966, mean(E): -21.73493906+0.00000193j, var(E): 0.75424265
-0.0
tensor(13.7577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7578, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7579, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7580, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7581, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19660/ 20000/ t/epoch=0.32............. Loss: -0.54290040, mean(E): -21.56304599+0.00002709j, var(E): 1.01580992
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19670/ 20000/ t/epoch=0.33............. Loss: -0.13920797, mean(E): -21.64364720+0.00001053j, var(E): 1.01423128
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19680/ 20000/ t/epoch=0.32............. Loss: 0.52199824, mean(E): -21.79703801+0.00001390j, var(E): 1.10649086
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19690/ 20000/ t/epoch=0.33............. Loss: 0.43296195, mean(E): -21.74923951-0.00001407j, var(E): 1.26484878
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7582, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7583, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7584, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7586, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19700/ 20000/ t/epoch=0.32............. Loss: -0.20869898, mean(E): -21.61840946-0.00000330j, var(E): 0.44660119
-0.0
tensor(13.7587, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7588, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7589, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7590, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7591, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7592, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7593, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19710/ 20000/ t/epoch=0.32............. Loss: -0.33725339, mean(E): -21.64663730+0.00002241j, var(E): 0.61957914
-0.0
tensor(13.7594, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7595, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7596, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7597, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7598, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7599, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19720/ 20000/ t/epoch=0.33............. Loss: -0.44268444, mean(E): -21.62415333+0.00001979j, var(E): 0.84330128
-0.0
tensor(13.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7600, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7602, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7603, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7604, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19730/ 20000/ t/epoch=0.32............. Loss: 0.15805566, mean(E): -21.68849983-0.00003538j, var(E): 1.22352241
-0.0
tensor(13.7605, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7606, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7608, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7610, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7611, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19740/ 20000/ t/epoch=0.32............. Loss: -0.20441190, mean(E): -21.64712589+0.00003751j, var(E): 0.33739733
-0.0
tensor(13.7612, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7614, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7615, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7616, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7617, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19750/ 20000/ t/epoch=0.33............. Loss: -0.71893974, mean(E): -21.55887259+0.00002890j, var(E): 0.94369703
-0.0
tensor(13.7618, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19760/ 20000/ t/epoch=0.32............. Loss: -0.24096297, mean(E): -21.63511816+0.00000019j, var(E): 0.64194874
-0.0
tensor(13.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19770/ 20000/ t/epoch=0.32............. Loss: -0.08903107, mean(E): -21.63224017-0.00001702j, var(E): 0.88346155
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19780/ 20000/ t/epoch=0.33............. Loss: 0.14666738, mean(E): -21.67771162-0.00003582j, var(E): 1.07922363
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7619, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19790/ 20000/ t/epoch=0.32............. Loss: -0.36646540, mean(E): -21.60170374+0.00000268j, var(E): 0.77029903
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7622, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7623, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19800/ 20000/ t/epoch=0.32............. Loss: 0.09916696, mean(E): -21.69391433-0.00001243j, var(E): 0.39112077
-0.0
tensor(13.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7625, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7626, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19810/ 20000/ t/epoch=0.32............. Loss: -0.41925767, mean(E): -21.63773098-0.00003641j, var(E): 1.43285920
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7628, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7629, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19820/ 20000/ t/epoch=0.32............. Loss: 0.38419654, mean(E): -21.67121503-0.00000316j, var(E): 0.67151703
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19830/ 20000/ t/epoch=0.33............. Loss: -0.33068595, mean(E): -21.63402293-0.00002490j, var(E): 0.46240124
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7630, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19840/ 20000/ t/epoch=0.32............. Loss: -0.06872269, mean(E): -21.65375502-0.00002292j, var(E): 0.97121615
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7632, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7633, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7634, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7635, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7636, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7637, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19850/ 20000/ t/epoch=0.32............. Loss: -0.08137471, mean(E): -21.65448270+0.00002492j, var(E): 0.61171941
-0.0
tensor(13.7638, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7639, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7640, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7643, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7645, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7648, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7649, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19860/ 20000/ t/epoch=0.32............. Loss: 0.36037734, mean(E): -21.73782609-0.00005204j, var(E): 0.86976836
-0.0
tensor(13.7650, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7651, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7652, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19870/ 20000/ t/epoch=0.32............. Loss: 0.33051104, mean(E): -21.69986712+0.00002842j, var(E): 0.95767732
-0.0
tensor(13.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19880/ 20000/ t/epoch=0.33............. Loss: 0.86691173, mean(E): -21.82327811-0.00002749j, var(E): 1.09813225
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19890/ 20000/ t/epoch=0.33............. Loss: -0.26420213, mean(E): -21.63896476+0.00011511j, var(E): 0.94501581
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19900/ 20000/ t/epoch=0.33............. Loss: -0.22510618, mean(E): -21.64502208-0.00004392j, var(E): 0.55706767
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19910/ 20000/ t/epoch=0.32............. Loss: 0.16950939, mean(E): -21.73317099+0.00000854j, var(E): 0.82451310
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7655, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7656, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7658, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19920/ 20000/ t/epoch=0.32............. Loss: -0.41319040, mean(E): -21.60232195-0.00001314j, var(E): 0.81831706
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7660, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7661, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7662, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7663, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19930/ 20000/ t/epoch=0.32............. Loss: -0.14986403, mean(E): -21.63725811-0.00006253j, var(E): 0.61527355
-0.0
tensor(13.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7666, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7667, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19940/ 20000/ t/epoch=0.32............. Loss: 0.24641867, mean(E): -21.69707121+0.00000616j, var(E): 1.51708595
-0.0
tensor(13.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7669, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7670, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19950/ 20000/ t/epoch=0.33............. Loss: -0.25959478, mean(E): -21.64901350-0.00004345j, var(E): 0.37395039
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19960/ 20000/ t/epoch=0.32............. Loss: 0.21212655, mean(E): -21.72838443-0.00000637j, var(E): 0.42589896
-0.0
tensor(13.7672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7673, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7675, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19970/ 20000/ t/epoch=0.33............. Loss: 0.22627738, mean(E): -21.74015217+0.00003225j, var(E): 0.46524883
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19980/ 20000/ t/epoch=0.32............. Loss: -0.41327821, mean(E): -21.57963477+0.00001387j, var(E): 0.69182658
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7676, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7677, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7678, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 19990/ 20000/ t/epoch=0.33............. Loss: 0.20482368, mean(E): -21.70588387-0.00008710j, var(E): 0.57618826
-0.0
tensor(13.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7679, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7680, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
-0.0
tensor(13.7681, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Epoch: 20000/ 20000/ t/epoch=0.33............. Loss: -0.02836573, mean(E): -21.64446090+0.00001348j, var(E): 0.71673163
